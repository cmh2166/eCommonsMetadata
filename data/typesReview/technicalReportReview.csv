oai:ecommons.cornell.edu:1813/352,"Water resources, agriculture and the environment.","In this article, water utilization by individuals and especially agricultural systems is analyzed. Interrelationships exist among population growth, water use and distribution, the status of biodiversity, the natural environment, plus the impacts of water borne human diseases are reported.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/648,"Collection development and management at Cornell : an interim report on activities of the Cornell University Libraries' project for collection development and management, July 1977-June 1979 ; prepared under a grant from the Andrew W. Mellon Foundation","This document covers the first year-and-a-half of the Cornell University Libraries' Project for Collection Development and Management and as such is primarily a statement of the issues that the the Library faced and the investigative design that Edelman proposed to address them.  The issues-- decline in acquisitions rates, concern over methodology for funds allocation, library space-- will seem remarkably contemporary.  Twenty-five years on, readers will be struck by the writers' confidence that all research library activity derived from the collections and that their description, evaluation and planning would, necessarily, improve services.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/649,"Collection development and management at Cornell : a concluding report on activities of the Cornell University Libraries' project for collection development and management, July 1979-June 1980, with proposals for future planning","Miller's work addresses two primary audiences, the Andrew W. Mellon Foundation, which funded the two-year study at Cornell, and the University's administrators, who would assess the extent to which they would underwrite the report's recommendations.  It lays out a series of activities that the library conducted to measure the Project's research design and makes specific recommendations for the organization, selection policy, budget control and planning of collection development at Cornell.  The report's scope and tone-- whose principal leitmotifs are limits, controls and bounds-- contrasts sharply with the optimism of the interim report, written two years earlier.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/692,"Peaking of Oil Production: Impacts, Mitigation, & Risk Management","The peaking of world oil production presents the U.S. and the world with an unprecedented risk management problem. As peaking is approached, liquid fuel prices and price volatility will increase dramatically, and, without timely mitigation, the economic, social, and political costs will be unprecedented.  Viable mitigation options exist on both the supply and demand sides, but to have substantial impact, they must be initiated more than a decade in advance of peaking.  This U.S. Department of Energy funded paper reports the problem of the peaking of world conventional oil production is unlike any yet faced by modern industrial society.  The challenges and uncertainties need to be much better understood. Technologies exist to mitigate the problem. Timely, aggressive risk management will be essential.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/1508,"The Northern Root-Knot Nematode on Carrot, Lettuce, and Onion in New York","Root-knot nematodes (Meloidogyne spp.) are major
pathogens of vegetables throughout the United States
and world, impacting both the quantity and quality
of marketable yields. In addition, root-knot nematodes
interact with other plant pathogens, resulting
in increased damage caused by other diseases. To
date, only the northern root-knot nematode (NRKN;
Meloidogyne hapla) has been found on vegetables
grown on organic or mineral soil in New York, as it
is able to survive the extreme low temperatures
during winter. The NRKN has a wide host range
consisting of more than 550 crop and weed species,
including weeds common to muck soils such as
dandelion (Taraxacum officinalis), purslane (Portulaca
oleracea), mallow (Malva rotundifolia) and
plantain (Plantago major). The increasing occurrence
and damage of this nematode to onions, lettuce,
and carrots grown on organic soils in New
York was recently documented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/2101,Organic and Conventional Farming Systems: Environmental and Economic Issues.,,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/2464,Development of a Drug Delivery System with a Constant Rate of Release,"You do not have to search long to find someone who is taking orally administered medication on a daily basis.  Pharmaceuticals such as antibiotics and pain relievers help us live healthier lives; however the administration of these drugs is more involved than simply the swallowing of a pill.  Maintaining a constant level of drug in the body is an important requirement for a variety of medications.  The more constant the rate of drug release from a pill, the more effective the drug will be.  Our model will compare different crater geometries to demonstrate the effect of crater shape on the release rate of a drug under human body conditions.   Our objective is to achieve a constant rate of drug release from a pill.    Analysis will demonstrate and allow us to conclude that a hemispherical crater geometry is best to accomplish this objective.  We were able to achieve a fairly constant rate of release after approximately 17 minutes and this situation would be beneficial for many pharmaceuticals compared to other, less constant drug delivery systems.",,application/msword,Technical Report
oai:ecommons.cornell.edu:1813/2710,Watershed modeling of the Cannonsville Basin using SWAT2000: Model,"This report describes the calibration and validation of a spatially 
distributed watershed model of the Cannonsville Reservoir Basin.  The Soil and 
Water Assessment Tool 2000 (SWAT2000) was selected as the watershed model.  A 
set of SWAT2000 inputs representative of the watershed conditions was derived 
from a wide array of data sources.  Important methods were developed for 
converting available information to SWAT2000 inputs for groundwater soluble 
phosphorus concentrations, initial soil phosphorus levels and daily manure 
application.   The Cannonsville Reservoir is a New York City water supply 
reservoir located in upstate New York that has historically experienced water 
quality problems associated with phosphorus loading.  As a result, the 
watershed has been subjected to multiple water quality regulations including a 
recent Total Maximum Daily Load (TMDL) assessment for phosphorus.  The 
reservoir watershed covers an 1178 km2 area and is dominated by agriculture, 
particularly dairy farming.  The SWAT2000 model of the Cannonsville Reservoir 
Watershed is a valuable tool that can be used to help identify and evaluate 
quantitatively the long-term effects of various phosphorus management options 
for mitigating loading to the reservoir. SWAT2000 was developed by the 
Agricultural Research Service of the United States Department of Agriculture.  
SWAT2000 simulates through time the daily soil water balance, growth of plants, 
build-up and subsequent transport of soil nutrients to surface waters in 
response to agricultural management practices.  The simulated mass balance of 
soil phosphorus in SWAT2000 is an important aspect of any watershed model that 
is to be used for regulatory purposes.  The authors modified a few of the SWAT 
model equations to better simulate measured flows, sediment loading and 
phosphorus loading during the winter. The model was calibrated and validated 
for the prediction of dissolved and particulate phosphorus transport, and 
therefore also flow and sediment transport, against a large set of monitoring 
data.  Extensive continuous flow and water quality data over a 10-year period 
from multiple locations within the basin were used for model calibration and 
validation.  Sensitive model parameters were adjusted within their feasible 
ranges during calibration to minimize model prediction errors for daily flows 
and monthly sediment and phosphorus loading.  At the main flow gauging station 
in the basin (Walton), draining almost 80% of the watershed, daily calibration 
resulted in model predictions of average flow within 1.0% of the measured 
average flow while the daily Nash-Sutcliffe (NS) measure was 0.79.  Daily 
validation results at Walton showed the model predicted average flow within 
4.5% of the measured average flow with a NS of 0.78.  At the main water quality 
gauging station in the basin (Beerston), just downstream of Walton, the 
calibration results showed the model predicted the average monthly sediment and 
total phosphorus loading within 3% and 6% of their respective measured average 
monthly loadings.  The monthly calibration NS values at Beerston for sediment 
and total phosphorus loading were 0.66 and 0.68, respectively.  Validation 
results at Beerston showed the model predicted the average monthly sediment and 
total phosphorus loading within 27% and 9% of their respective measured average 
monthly loadings.  The monthly validation NS values at Beerston for sediment 
and total phosphorus loading were 0.51 and 0.61, respectively.  The largest 
errors in model predictions for phosphorus and sediment loading were always 
associated with peak flow prediction errors. Model predictions were also shown 
to qualitatively replicate bi-weekly sampling of total phosphorus 
concentrations taken from 10 different locations across the watershed.  Model 
simulation results over the calibration and validation period (1990-2000) 
highlighted a number of useful findings.  The model predicted that 68% of the 
total phosphorus loading to surface waters in the watershed originates from 
active agricultural lands.  Corn land use was simulated as the major source of 
agricultural phosphorus loading even though it covered only 1.2% of the 
watershed area.  Areas North and East of the Town of Delhi tended to have the 
largest rates of phosphorus loading per unit area.  Areas immediately 
surrounding the Cannonsville Reservoir that are not monitored were simulated to 
have substantially lower non-point source phosphorus (NPS) unit area loading 
rates than the monitored portion of the watershed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/2712,Franz Reuleaux: Contributions to 19th C. Kinematics and Theory of,"This review surveys late 19th century kinematics and the theory of 
machines as seen through the contributions of the German engineering scientist, 
Franz Reuleaux (1829-1905), often called the ""father of kinematics"". Extremely 
famous in his time and one of the first honorary members of ASME, Reuleaux was 
largely forgotten in much of modern mechanics literature in English until the 
recent rediscovery of some of his work. In addition to his contributions to 
kinematics, we review Reuleaux's ideas about design synthesis, optimization and 
aesthetics in design, engineering education as well as his early contributions 
to biomechanics. A unique aspect of this review has been the use of Reuleaux's 
kinematic models at Cornell University and in the Deutsches Museum as a tool to 
rediscover lost engineering and kinematic knowledge of 19th century history of 
machine.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/2713,How it was to study and to teach mathematics in Cornell at the end of,"Cornell University's Kroch Library Rare Book and Manuscript Division 
has a collection called ""Department of Mathematics records 1877-1976"". It was 
used already as case studies of the emergence of mathematical research at 
Cornell University in several publications; but I will talk about my experience 
going through these records and trying to imagine what mathematics students had 
learned before entering Cornell University (looking at entrance exams they were 
given). The earlier publications reported that mathematics entrance 
requirements to Cornell ""were minimal by today's standards"" but I found that 
this was not the case.  Many of the students taking the entrance exams were 
engineering students. At that time the Reuleaux kinematic models collection was 
used to bring mathematical ideas into engineering curriculum. Preliminary 
report partially supported by National Science Foundation's National Science, 
Technology, Engineering, and Mathematics Education Digital Library (NSDL) 
Program under grant DUE-0226238.   (Based on a talk given at AMS- MAA Joint 
Conference Special Session in History of Mathematics, January 18, 2003, 
Baltimore.)",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/2714,Experiencing Meanings in Geometry,"It is deep experience of meanings in geometry (and indeed in all of 
mathematics and well as art and engineering) that we believe deserve to be 
called aesthetic experiences. We believe that mathematics is a natural and deep 
part of human experience and that experiences of meaning in mathematics should 
be accessible to everyone. Much of mathematics is not accessible through formal 
approaches except to those with specialized learning. However, through the use 
of non-formal experience and geometric imagery, many levels of meaning in 
mathematics can be opened up in a way that most people can experience and find 
intellectually challenging and stimulating. Many formal aspects of mathematics 
have now been mechanized and this mechanization is widely available on personal 
computers or even handheld calculators, but the experience of meaning in 
mathematics is still a human enterprise. Experiencing meanings is vital for 
anyone who wishes to understand mathematics, or anyone wishing to understand 
something in their experience through the vehicle of mathematics. We observe in 
ourselves and in our students that these are, at their core, aesthetic 
experiences. In this paper we will tell some stories of our experience of 
meanings in geometry and art. David's story starts with art and ends with 
geometry, while Daina's story starts with geometry and ends with art. However 
we both share the bulk in the middle, including experiences of non-Euclidean 
geometries and kinematics models.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/2715,3D-Printing the History of Mechanisms,"Physical models of machines have played an important role in the 
history of engineering for teaching, analyzing, and exploring mechanical 
concepts. Many of these models have been replaced today by computational 
representations, but new rapid-prototyping technology allows reintroduction of 
physical models as an intuitive way to demonstrate mechanical concepts. This 
paper reports on the use of computer-aided modeling tools and rapid prototyping 
technology to document, preserve, and reproduce in three dimensions, historic 
machines and mechanisms. We have reproduced several pre-assembled, 
fully-functional historic mechanisms such as early straight line mechanisms, 
ratchets, pumps, and clock escapements, including various kinematic components 
such as links, joints, gears, worms, nuts, bolts, and springs. The historic 
mechanisms come from the Cornell Collection of Reuleaux Kinematic Models as 
well as models based on the work of Leonardo da Vinci. The models are available 
as part of a new online museum of mechanism, which allows visitors not only to 
read descriptions and view pictures and videos, but now also download, 3D-print 
and interact with their own physical replicas. Our aim in this paper is to 
demonstrate the ability of this technology to reproduce accurate historical 
kinematic models and machines as a tool for both artifact conservancy as well 
as for teaching, and to demonstrate this for a wide range of mechanism types. 
We expect that this new form of ?physical? preservation will become prevalent 
in future archives. We describe the background and history of the collection as 
well as aspects of modeling and printing such functional replicas.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/2716,How to Use History to Clarify Common Confusions in Geometry,"We have found that students and even mathematicians are often 
confused about the history of geometry. Many expository descriptions of 
geometry (especially non-Euclidean geometry) contain confusing and 
sometimes-incorrect statements. Therefore, we found it very important to give 
some historical perspective of the development of geometry, clearing up many 
common misconceptions.  In this paper we use history to clarify the following 
questions, which often have confusing or misleading (or incorrect) answers: 1. 
What is the first non-Euclidean geometry? 2. Does Euclid's parallel postulate 
distinguish the non-Euclidean geometries from Euclidean geometry? 3. Is there a 
potentially infinite surface in 3-space whose intrinsic geometry is hyperbolic? 
4. In what sense are the Models of Hyperbolic Geometry 'models'? 5. What does 
'straight' mean in geometry?  How can we draw a straight line? We noticed that 
most confusions related to the above questions come from not recognizing 
certain strands in the history of geometry. The main aspects of geometry today 
emerged from four strands of early human activity that seem to have occurred in 
most cultures: art/patterns, building structures, motion in machines, and 
navigation/stargazing. These strands developed more or less independently into 
varying studies and practices that eventually from the 19th century on were 
woven into what we now call geometry. In this paper we describe how these 
strands can be used to clarify issues surrounding these questions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/2717,"Usability, Learning, and Subjective Experience: User Evaluation of","This paper describes an evaluation effort of the use of the 
Kinematic Model for Design Digital Library (K-MODDL) in an undergraduate 
mathematics class. Based on CIAO! framework, the research revealed usability 
problems and users? subjective experience when using K-MODDL, confirmed the 
usefulness of various physical and digital models in facilitating learning, and 
revealed interesting relationships among usability, learning, and subjective 
experience.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/2718,Historical Mechanisms for Drawing Curves,"Mechanical devices such as linkages for drawing curves are known 
already from Ancient Greece. Later linkages found use in different mechanical 
devices and machines like we can see it in 13th century drawings by Honnecourt 
or in 16th century machine drawings by Agricola. In 17th century Descartes 
accepted only those curves that had a mechanical device to draw them. 
Mechanical curve drawing devices later became incorporated into different 
machine design. In this paper examples from Reuleaux kinematic model collection 
in Cornell University are given and some history of linkages discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/3215,Documenting a Metadata Standard for the Performing Arts: An Application Profile for the Global Performing Arts Database (GloPAD),"This paper explains the implementation of the metadata standards for the Global Performing Arts Database, a database of digital objects related to the performing arts worldwide. The paper discusses how the controlled vocabularies were developed, the existing metadata standards used, and how to read the GloPAD Application Profile, a version of which is attached to this record.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/3299,Predicting Harvest Date Windows for Apples,"This information bulletin discusses how harvest dates affect apple quality, how to forecast and verify harvest windows, picking, and segregating lots for long-term CA storage. Full-color plates show how to use and interpret the starch-iodine test for determining maturity and the best harvest dates for quality. McIntosh, Cortland, Empire, Delicious, Mutsu/Crispin, and Idared varieties are covered. Dates for other varieties can be interpreted from the information presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/3437,Dynamic Modeling Of Tree Growth And Energy Use In A Nursery Greenhouse Using Matlab And Simulink,"The purpose of this project was to create a process-based model of a tree seedling nursery as an aid to greenhouse operators concerned about energy management.  This model termed GUESS, Greenhouse Use of Energy & Seedling Simulator, integrates a lumped parameter heat&mass transfer model of the greenhouse envelope with a process based model of the crop canopy, allowing the user to simultaneously assess the cost of production decisions alongside the impacts upon the health and growth of the crop.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5240,"Planning Information Infrastructure through a New Library Research Partnership: Interim Report, July 2005","The Cornell Language Acquisition Laboratory and Albert R. Mann Library are in the midst of developing an innovative collaboration between a research laboratory and an academic library to plan for the data preservation and discovery needs of the twenty-first century.  Digital technology and internet communication now provide the opportunity to revolutionize the research process, through the ability to store, preserve, share, discover, and reanalyze vast amounts of data.  While some disciplines, such as genomics or astronomy, have already developed sophisticated information technology infrastructure for these tasks, others are only beginning such work.  In many, if not most research fields, it is especially difficult for those uninitiated to discover where data are located, what they describe, and how they may be used.  This project has begun to tackle these issues by taking advantage of the library's existing expertise in preservation, archiving, and metadata creation, building on the existing ontology-software tools the library has developed, and introducing a new conceptual framework that divides the tasks of data sharing into discrete levels that may be managed and presented in defferent ways not only for different audiences but respecting political divisions and control issues that will always be present throughout the laboratories and institutions of academia.",This document is an interim report on a Small Grant for Exploratory Research (SGER).  This interim report was submitted to the National Science Foundation in July 2005.,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5242,Assessing models of outreach in ELSI projects: Final Report to the DOE's ELSI program,"This report examined the presence of four models of science communication in outreach projects funded by the U.S. Department of Energy's Ethical, Legal, and Societal Implications (ELSI) program.  The four models were: deficit model, contextual model, lay knowledge model, and public engagement model.  Although theoretical literature in science communication has recently been highly critical of the deficit model, we found that most projects -- including those that labeled themselves as public engagement -- contained a substantial amount of deficit model communicatio",Final Report.,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5285,Tug Hill Tomorrow Land Trust Strategic Land Conservation Plan,"Over the Fall semester of 2006, 13 graduate students undertook the task of creating a Strategic Conservation Plan for Tug Hill Tomorrow Land Trust (THTLT), based in Watertown, NY. The plan features a series of natural resource inventories as well as a scenic viewshed analysis of the 1.3 million acre Tug Hill plateau. Regional land use history and demographic trends are explored. Using the resource inventories a vision conservation infrastructure was created for featuring recreational corridors, river corridors and wildlife areas. To help land trust decision makers in selecting solid conservation projects, a GIS suitability model was created based the land trust's own land protection criteria. Focus areas or high priority areas for pro-active conservation were outlined and tested using the suitability model. Finally, the Cornell team identified several tools for implementation based on the condition of four separate regions of Tug Hill.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5289,Southern Madison Heritage Trust Strategic Land Protection Plan,"Over the Fall semester of 2005, 12 graduate students undertook the task of creating a Strategic Land Protection Plan for the Southern Madison Heritage Trust (SMHT), a land trust based in Hamilton, NY. The Strategic Land Protection Plan is a bold vision. The plan is based on demographic research and inventories of both natural and scenic resources. Using these inventories, suitability models in GIS were created to display various land protection scenarios. Taking advantage of the New York State Canal Corporation's proposal for an Empire State Greenway building on the historic Erie Canal network, the students crafted a proposed greenway for recreational uses, natural resource functions and growth management. As the Chenango Canal is an integral part of the proposed greenway, the long term protection of this corridor is major concern for SMHT. Within the proposed greenway, the students modeled a greenbelt surrounding the four major municipalities that is designed to allow growth while protecting the gateways to the villages, surrounding farmland and biodiversity of the region. The conservation of the proposed 16,000 acre greenbelt can be achieved through the use of regulatory tools, transfer of lands from key partners to SMHT, improved land management by private landowners as well as the exercise of real estate tools used by SMHT such as securing easements through outright purchase or donation from willing landowners.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5421,Multi-level Comparisons of Organic and Integrated Fruit Production (IFP) Systems for 'Liberty' Apple in a New York Orchard,,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5441,Stereo Viewing Interface for Workstations,"Three dimensional data sets are becoming widespread in scientific
   simulations and analysis of physical systems.  Applications ranging from
   fluid simulations to medical imaging require understanding of three
   dimensional (3D) data.  Researchers often produce images from the data to
   aid in understanding.  In the resulting images, monocular depth cues such as
   object size, parallax motion, and shading help to interpret 3D data.
   However, viewing 3D data is enhanced by using stereo pairs so that binocular
   depth cues are available.  There are several schemes for producing stereo
   pairs on the screen of a workstation (e.g. liquid crystal shutters,
   vibrating mirrors or cylinderical lens).  We describe here a liquid crystal
   shutter system which is easy and inexpensive to construct.
 
   vibrating mirrors or cylinderical lens).  We describe here a liquid crystal
   shutter system which is easy and inexpensive to construct.
     Using liquid-crystal shutter glasses designed for video games, it is
   possible to construct an inexpensive stereo viewing interface to any
   personal computer or workstation which has hardware double-buffering of the
   display screen and which can produce an RS-232 character.  The resulting
   display exhibits strong stereo depth cues.  Flicker is noticeable and
   depends on the refresh rate of the monitor as well as the speed with which
   the double-buffered display can be changed.  On the IBM RISC System 6000,
   equipped with the GL display card (part number xxx), the flicker is
   moderate, the brightness good, and the stereo effect very stable.
     The description given here will assume an IBM RISC System 6000.  There are
   two parts to the system: the software to display two images in the double
   buffer and the hardware which converts an RS-232 character to the waveform
   necessary to drive the liquid-crystal glasses.  Clearly the software will
   have to be modified for other systems, although it should run virtually
   unmodified on Silicon Graphics machines, such as the Personal IRIS.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5442,Parallel Finite Element Analysis of Biomechanical Structures on the Ncube 6400,"This paper presents parallel 3-D finite element analysis for
   distributed memory multiprocessors.  Traditionally, finite element
   analysis has been performed on sequential computers.  Current research
   in high performance finite element analysis shows considerable promise
   for fast, efficient implementation on MIMD and SIMD computers.
      This paper demonstrates the use of a standard, banded Cholesky
   method for solving the finite element system of equations.  The
   uniformity of the underlying data distribution ensures high performance
   due to load balance.  Moreover, since a distributed banded Cholesky
   algorithm is likely to a part of a standard parallel numerical library,
   it reduces the burden on the applications programmer, making this
   method simpler to implement than the substructuring method.  Since a
   parallel solver requires the rows of the coefficient matrix to be
   distributed in a wrap fashion, it might appear that the assembly of
   the element stiffness matrices would not be efficient.  However, as
   shown in this paper, the calculation of element stiffness matrices,
   assembly and the calculation of Gauss-point stresses can be done
   efficiently in parallel without any inter-processor communication.
   In fact, once nodal coordinates and element connectivity is made
   available to all processors, message passing is required only during
   the factorization and solution stages.
      The next few sections describe how parallelism was exploited during
   the assembly, solution and stress recovery strages of the finite
   element analysis.  The parallel program developed was tested on large
   3-D finite element problems arising from biomechanical structural
   systems, on an Ncube 6400.  High performance Basic Linear Algebra
   Subprograms (BLAS) were used to improve the execution speed.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5443,A Preconditioned Conjugate Gradient Approach to Linear Equality,"We propose a new framework for the application of preconditioned
conjugate gradients in the solution of large-scale linear equality constrained
minimization problems. This framework allows for the exploitation of structure
and sparsity in the context of solving the reduced Newton system (despite the
fact that the reduced system may be dense).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5444,Discrete Hedging Under Piecewise Linear Risk Management,"In an incomplete market it is usually impossible to eliminate the intrinsic risk of an option. In this case quadratic risk-minimization is often used to determine a hedging strategy. However, it may be more natural to use piecewise linear risk-minimization since in this case the risk is measured in actual dollars (not dollars squared). We investigate hedging strategies using piecewise linear risk-minimization. We illustrate that piecewise linear risk-minimization often leads to smaller expected total hedging cost and significantly different, possibly more desirable, hedging strategies from those of quadratic risk minimization. The distributions of the total hedging cost and risk show that hedging strategies obtained by piecewise linear risk-minimization have a larger probability of small cost and risk, though they also have a very small probability of larger cost and risk. Comparative numerical results are provided.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5445,Access Normalization: Loop Restructuring for NUMA Compilers,"A common feature of many scalable parallel machines is non-uniform   memory access - a processor can access data in its local memory ten   to a thousand times faster than it can access local data.  In addition,   when a number of remote accesses must be made, it is usually more   efficient to use block transfers of data rather than to use many   small messages.  To run well on such machines, software must exploit   these features.  We believe it is too onerous for a programmer to do   this by hand, so we have been exploring the use of restructuring    compiler technology for this purpose.  In this paper, we start with a   language like FORTRAN-D with user-specified data distributions and   develop a systematic loop transformation strategy called access   normalization that restructures loop nests to exploit both locality   and block transfers whenever possible.  We demonstrate the power of   our techniques using routines from the BLAS (Basic Linear Algebra   Subprograms) library.  Our loop transformation strategy is expressed   in the framework of invertible matrcies and integer lattice theory,    and it is an important generalization of Banerjee's framework of   unimodular matrices.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5446,The Valuation of Convertible Bonds With Credit Risk,"Convertible bonds are typically issued by firms which have both relatively high growth and quite high risk.  Convertibles can be difficult to value, given their hybrid nature of containing elements of both debt and equity.  Further complications arise due to the frequent presence of additional options such as callability and puttability, and contractual complexities such as trigger prices and ""soft call"" provisions, in which the ability of the issuing firm to exercise its option to call is dependent upon the history of its stock price.  This paper explores the valuation of convertible bonds subject to credit risk using an approach based on the numerical solution of a system of coupled linear complementarity problems.  We argue that many of the existing modes, such as that of Tsiveriotis and Fernandes (1998), are unsatisfactory in that they do not explicitly specify what happens in the event of a default by the issuing firm.  In fact, many of the differences between existing models appear to arise from varying implicit assumptions about this.  In existing models it is assumed that upon a default either nothing happens to the firm's stock price or else it instantly jumps to zero.  Neither of these alternatives seems to be entirely appealing: while it is a significant event, implying that there will be some market reaction to the news of a default, a sudden and complete collapse is rare.  Consequently, we propose a model where the firm's stock price falls by some specified percentage between 0% and 100% (which includes the limiting cases implicit in existing models). We also present a detailed description of our numerical algorithm, which uses a partially implicit method to decouple the system of linear complementarity problems at each timestep.  Numerical examples illustrating the convergence properties of the algorithm are provided.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5447,A Preconditioned Conjugate Gradient Approach to Linear Equality Constrained Minimization,We propose a new framework for the application of preconditioned conjugate gradients in the solution of large-scale linear equality constrained minimization problems. This framework allows for the exploitation of structure and sparsity in the context of solving the reduced Newton system (despite the fact that the reduced system may be dense).,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5448,Dynamic Hedging in a Volatile Market,"In financial markets, errors in option hedging can arise from two sources. First, the option value is a nonlinear function of the underlying; therefore, hedging is instantaneous and hedging with discrete rebalancing gives rise to error. Frequent rebalancing can be impractical due to transaction costs. Second, errors in specifying the model for the underlying price movement (model specification error) can lead to poor hedge performance. In this article, we compare the effectiveness of dynamic hedging using the constant volatility method, the implied volatility method, and the recent volatility function method [3]. We provide evidence that dynamic hedging using the volatility function method [3] produces smaller hedge error. We assume that there are no transaction costs, and both the risk-free interest rate r and the dividend rate q are constant.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5449,Efficient Calculation of Jacobian and Adjoint Vector Products in Wave Propagational Inverse Problems Using Automatic Differentiation,"Wave propagational inverse problems arise in several applications including medical imaging and geophysical exploration. In these problems, one is interested in obtaining the parameters describing the medium from its response to excitations. The problems are characterized by their large size, and by the hyperbolic equation which models the physical phenomena. The inverse problems are often posed as a nonlinear data-fitting where the unknown parameters are found by minimizing the misfit between the predicted data and the actual data. In order to solve the problem numerically using a gradient-type approach, one must calculate the action of the Jacobian and its adjoint on a given vector. In this paper, we explore the use of automatic differentiation (AD) to develop codes that perform these calculations. We show that by exploiting structure at 2 scales, we can arrive at a very efficient code whose main components are produced by AD. In the first scale we exploit the time-stepping nature of the hyperbolic solver by using the ""Extended Jacobian"" framework. In the second (finer) scale, we exploit the finite difference stencil in order to make explicit use of the sparsity in the dependence of the output variables to the input variables. The main ideas in this work are illustrated with a simpler, one-dimensional version of the problem. Numerical results are given for both one- and two- dimensional problems. We present computational templates that can be used in conjunction with optimization packages to solve the inverse problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5450,Dynamic Hedging with a Deterministic Local Volatility Function Model,"We compare the dynamic hedging performance of the deterministic local volatility function approach with the implied/constant volatility method. Using an example in which the underlying price follows an absolute diffusion process, we illustrate that hedge parameters computed from the implied/constant volatility method can have significant error even though the implied volatility method is able to calibrate the current option prices of different strikes and maturities. In particular the delta hedge parameter produced by the implied/constant volatility method is consistently significantly larger than that of the exact delta when the underlying price follows an absolute diffusion.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5451,An Object-Oriented Framework For Valuing Shout Options on High-Performance Computer Architectures,"A shout option is a financial contract which allows the holder to change the payoff during the lifetime of the contract.  For example, the holder could have the right to set the strike price to the current value of the underlying asset.  Complex versions of these options are embedded in financial products which offer various types of maturity guarantees such as segregated funds marketed by Canadian insurance companies.  The value of these options can be determined by solving a collection of coupled partial differential equations (PDEs).  In this work we develop an extensible, object-oriented framework for valuing these contracts which is capable of exploiting modern, high-performance supercomputing architectures.  We use this framework to study and illustrate practical aspects of valuing and hedging these contracts.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5452,Three-Dimensional Acoustic Visualization of Zooplankton Patchiness,"Acoustic data were collected and visualized to characterize the 3-dimensional patchiness of zooplankton at a thermally stratified site on Georges Bank. The work was carried out as part of a field study conducted to examine the effects of springtime water-column stratification on the distributions of zooplankton and larval fish on the Bank. The acoustic data were acquired as the ship steamed a survey grid relative to the track of a surface drifter with a subsurface drogue. Although quite irregular in geographical coordinate space, the ship's track relative to the moving water closely matched the intended grid pattern once the drifter's movement in the tidal flow was taken into account. After changing coordinate systems to compensate for tidal advection, the acoustic data set was transformed from its curtain-like distribution in 3-dimensional space to a volumetric distribution. Two-dimensional point kriging was performed on the irregularly spaced data from each 2-m-thick depth stratum to produce a series of 2-dimensional, regularly spaced data grids. These data grids were then stacked to construct the 3-dimensional data grid required for volumetric visualization. A similar procedure was followed with the error variance values produced at each grid point through kriging to construct a three-dimensional, volumetric distribution of the error variance. To examine zooplankton patchiness within the surveyed volume of water, isosurfaces corresponding to specific levels of acoustic backscatter were highlighted in the visualization. The 3-dimensional distribution of error variance was used to control the opacity of the isosurfaces to provide an objective, visual approach for displaying the statistical confidence one can have in the patches detected. In this survey, the ship steamed directly over a large, southwest- to northeast-oriented patch of zooplankton on at least three different passes. It also steamed over several smaller patches. The vertically compressed nature of the patches and their high degree of spatial heterogeneity in the horizontal plane are characteristic of the zooplankton distributions found in the deeper, seasonally stratified portions of Georges Bank.",,application/msword,Technical Report
oai:ecommons.cornell.edu:1813/5453,Option Pricing and Linear Complementarity,"Many American option pricing models can be formulated as linear complementarity problems (LCPs) involving partial differential operators.  While recent work with this approach has mainly addressed the model classes where the resulting LCPs are highly structured and can be solved fairly easily, this paper discusses a variety of option pricing models that are formulated as partial differential complementarity problems (PDCPs) of the convection-diffusion kind whose numerical solution depends on a better understanding of LCP methods.  Specifically, we present second-order upwind finite difference schemes for the PDCPs and derive fundamental properties of the resulting discretized LCPs that are essential for the convergence and stability of the finite difference schemes and for the numerical solution of the LCPs by effective computational methods.  Numerical results are reported to support the benefits of the proposed schemes.  A main objective of this presentation is to elucidate the important role that the LCP has to play in the fast and effective numerical pricing of American options.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5454,Hedging a Portfolio of Derivatives by Modeling Cost,We consider the problem of hedging the loss of a given portfolio of derivatives using a set of more liquid derivative instruments. We illustrate why the typical mathematical formulation for this hedging problem is ill-posed. We propose to determine a hedging portfolio by minimizing a proportional cost subject to an upper bound on the hedge risk; this bound is typically slightly larger than the optimal hedge risk achievable without cost consideration. We illustrate that the optimal hedging portfolio obtained by the proposed method is attractive since it consists of fewer instruments with a comparable risk. Finally we illustrate the importance of modeling volatility uncertainty in hedge risk minimization.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5455,Reconstructing the Unknown Local Volatility Function,"Using market European option prices, a method for computing a smooth 
local volatility function in a 1-factor continuous diffusion model is proposed. Smoothness is introduced to facilitate accurate approximation of the local volatility function from a finite set of observation data. Assuming that the underlying indeed follows a 1-factor model, it is emphasized that accurately approximating the local volatility function prescribing the 1-factor model is crucial in hedging even simple European options, and pricing exotic options. A spline functional approach is used: the local volatility function is represented by a spline whose values at chosen knots are determined by solving a constrained nonlinear optimization problem. The optimization formulation is amenable to various option evaluation methods; a partial differential equation implementation is discussed. Using a synthetic European call option example, we illustrate the capability of the proposed method in reconstructing the unknown local volatility function. Accuracy of pricing and hedging is also illustrated. Moreover, it is demonstrated that, using different implied volatilities for options with different strikes/maturities can produce erroneous hedge factors if the underlying follows a 1-factor model. In addition, real market European call option data on the S and P 500 stock index is used to compute the local volatility function; stability of the approach is demonstrated.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5456,A Newton Method for American Option Pricing,"The variational inequality formulation provides a mechanism to determine both the option value and the early exercise curve implicitly [17]. Standard finite difference approximation typically leads to linear complementarity problems with tridiagonal coefficient matrices. The second order upwind finite difference formulation gives rise to finite dimensional linear complementarity problems with nontridiagonal matrices, whereas the upstream weighting finite difference approach with the van Leer flux limiter for the convection term [19, 22] yields nonlinear complementarity problems. We propose a Newton type interior-point method for solving discretized complementarity/variational inequality problems that arise in the American option valuation. We illustrate that the proposed method on average solves a discretized problem in 2 ~ 5 iterations to an appropriate accuracy. More importantly, the average number of iterations required does not seem to depend on the number of discretization points in the spatial dimension; the average number of iterations actually decreases as the time discretization becomes finer. The arbitrage condition for the fair value of the American option requires that the delta hedge factor be continuous. We investigate continuity of the delta factor approximation using the complementarity approach, the binomial method, and the explicit payoff method. We illustrate that, while the (implicit finite difference) complementarity approach yields continuous delta hedge factors, both the binomial method and the explicit payoff method (with the implicit finite difference) yield discontinuous delta approximations. Hence the early exercise curve computed from the binomial method and the explicit payoff method can be inaccurate. In addition, it is demonstrated that the delta factor computed using the Crank-Nicolson method with complementarity approach oscillates around the early exercise curve.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5457,Efficient Calculation of Jacobian and Adjoint Vector Products in Wave Propagational Inverse Problems Using Automatic Differentiation,"Wave propagational inverse problems arise in several applications including medical imaging and geophysical exploration. In these problems, one is interested in obtaining the parameters describing the medium from its response to excitations. The problems are characterized by their large size, and by the hyperbolic equation which models the physical phenomena. The inverse problems are often posed as a nonlinear data-fitting where the unknown parameters are found by minimizing the misfit between the predicted data and the actual data. In order to solve the problem numerically using a gradient-type approach, one must calculate the action of the Jacobian and its adjoint on a given vector. In this paper, we explore the use of automatic differentiation (AD) to develop codes that perform these calculations.  We show that by exploiting structure at 2 scales, we can arrive at a very efficient code whose main components are produced by AD. In the first scale we exploit the time-stepping nature of the hyperbolic solver by using the \Extended Jacobian"" framework. In the second (finer) scale, we exploit the finite difference stencil in order to make explicit use of the sparsity in the dependence of the output variables to the input variables. The main ideas in this work are illustrated with a simpler, one-dimensional version of the problem. Numerical results are given for both one- and two- dimensional problems. We present computational templates that can be used in conjunction with optimization packages to solve the inverse problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5458,Segmentation of Pulmonary Nodule Images Using Total Variation Minimization,"Total variation minimization has edge preserving and enhancing properties which make it suitable for image segmentation. We present Image Simplification, a new formulation and algorithm for image segmentation. We illustrate the edge enhancing properties of total variation minimization in a discrete setting by giving exact solutions to the problem for piecewise constant functions in the presence of noise. In this case, edges can be exactly recovered if the noise is sufficiently small. After optimization, segmentation is completed using edge detection. We find that our image segmentation approach yields good results when applied to the segmentation of pulmonary nodules.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5459,Dynamic Hedging With a Deterministic Local Volatility Function Model,"We compare the dynamic hedging performance of the deterministic 
local volatility function approach with the implied/constant volatility method. Using an example in which the underlying price follows an absolute diffusion process, we illustrate that hedge parameters computed from the implied/constant volatility method can have significant error even though the implied volatility method is able to calibrate the current option prices of different strikes and maturities. In particular the delta hedge parameter produced by the implied/constant volatility method is consistently significantly larger than that of the exact delta when the underlying price follows an absolute diffusion.  In order to compute a better hedge parameter, accurate estimation of the local volatility function in a region surrounding the current asset price is crucial. We illustrate that a suitably implemented volatility function method can estimate this local volatility function sufficiently accurately to generate more accurate hedge parameters. Hedging using this volatility function for the absolute diffusion example leads to a smaller average absolute hedging error when compared with using the implied/constant volatility rate.  When comparing the hedging performance in the S and P 500 index option market as well as the S and P 500 futures option market, we similarly observe that the delta hedge parameter from the implied/constant volatility method is typically greater than that using the volatility function approach. Examination of the hedging error reveals that using a larger delta factor greater than that of the true volatility yields more positive average hedging error, assuming the underlying follows a deterministic volatility model. We observe that, in both the S and P 500 index option market and futures option market, the average absolute hedging error using the volatility function approach is smaller than that of the implied/constant volatility method for a sufficiently long hedging horizon, approximately 17 days for the S and P 500 index options and 6 days for the S and P 500 futures options. In addition, the average hedging error using the volatility function approach is always smaller than that of the implied/constant volatility method.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5460,An MPEC Approach to Inverse Pricing of American Options: The Case of an Implied Volatility Surface,"This paper presents a novel approach to deal with the computation of an implied volatility surface of American options written on a risky asset.  The approach is based on the simple observation that this computational problem is the inverse of the forward pricing problem of American options.  As detailed in [17], the latter forward problem can be modeled by a discretized partial differential linear complementarity system.  As such, the inverse problem, i.e., the implied volatility problem, becomes an instance of a Mathematical Program with Equilibrium Constraints, which is a class of constrained optimization problem with a finite-dimensional parametric linear comlementarity system as part of its constraints.  Two methods for solving an MPEC are described and applied to the problem of computing and implied volatility surface of American options.  Some computational results on experimental data are reported.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5461,Efficiency Improvements for Pricing American Options with a Stochastic Mesh,"rlo simulation.  First, we develop a mesh-based, biased-low estimator.  By recursively averaging the low and high estimators at each stage, we obtain a significantly more accurate point estimator at each of the mesh points.  Second, adapt the importance sampling ideas for simulation of European path-dependent options in Glasserman, Heidelberger, and Shahabuddin (1998a) to pricing of American options with a stochastic mesh.  Third, we sketch generalizations of the mesh method and we discuss links with other techniques for valuing American options.  Our empirical results show that the bias-reduced point estimates are much more accurate than the standard mesh-method point estimators.  Importance sampling is found to increase accuracy for a smooth option-payoff functions, while variance increases are possible for non-smooth payoffs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5462,Exact Monte Carlo Calculations for Fermions on a Parallel Machine,"We describe how a recently published algorithm - which addresses the sign problem within the context of the Green's function Monte Carlo method - can be implemented in a parallel distributed environment.  The method of parallelization maintains large granularity and therefore large overhead.  Despite the stochastic nature of the algorithm, good load-balancing can be accomplished and reproducibility is ensured.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5463,An efficient trust region method for unconstrained discrete-time optimal control problems,"Discrete-time optimal control (DTOC) problems are large-scale 
optimization problems with a dynamic structure. In previous work this structure has been exploited to provide very fast and efficient local procedures. Two examples are the differential dynamic programming algorithm (DDP) and the stagewise Newton procedure -- both require only O(N) operations per iteration, where N is the number of timesteps. Both exhibit a quadratic  convergence rate. However, most algorithms in this category do not have a satisfactory global convergence strategy. The most popular global strategy is shifting: this sometimes works poorly due to the lack of automatic adjustment to the shifting element.      In this paper we propose a method that incorporates the trust region idea with the local stagewise Newton's method. This method possesses advantages of both the trust region idea and the stagewise Newton's method, i.e., our proposed method has strong global and local convergence properties yet remains economical. Preliminary numerical results are presented to illustrate the behavior of the proposed algorithm. We also collect in the Appendix some DTOC problems that have appeared in the literature.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5464,Solving LP Problems Via Weighted Centers,"The feasibility problem for a system of linear inequalities can be converted into an unconstrained optimization problem using ideas from the ellipsoid method, which can be viewed as a very simple minimization technique for the resulting nonlinear function. Using more sophisticated algorithms, we develop and investigate more efficient methods, which lead to two kinds of  weighted centers for the feasible set. With these centers, we develop new algorithms for solving linear programming problems.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5465,Robustly Hedging Variable Annuities with Guarantees Under Jump and Volatility Risks,"Accurately quantifying and robustly hedging options embedded in the 
guarantees of variable annuities is a crucial task for insurance companies in preventing excessive liabilities. Due to sensitivities of the benefits to tails of the account value distribution, a simple Black-Scholes model is inadequate. A model which realistically describes the real world price dynamics over a long time horizon is essential for the risk management of the variable annuities. In this paper, both jump risk and volatility risk are considered for risk management of lookback options embedded in guarantees with a ratchet feature. We evaluate relative performances of delta hedging and dynamic discrete risk minimization hedging strategies. Using the underlying as the hedging instrument, we show that, under a Black-Scholes model, local risk minimization hedging is significantly better than delta hedging. In addition, we compare risk minimization hedging using the underlying with that of using standard options. We demonstrate that, under a Merton's jump diffusion model, hedging using standard options is superior to hedging using the underlying in terms of the risk reduction. Finally we consider a market model for volatility risks in which the at-the-money implied volatility is a state variable. We compute risk minimization hedging by modeling at-the-money Black-Scholes implied volatility explicitly; the hedging effectiveness is evaluated, however, under a joint underlying and implied volatility model which also includes instantaneous volatility risk. Our computational results suggest that, when implied volatility risk is suitably modeled, risk minimization hedging using standard options, compared to hedging using the underlying, can potentially be more effective in risk reduction under both jump and volatility risks.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5466,Hedging guarantees in variable annuities (under both market and interest rate risks),"In order to prevent possibly very large losses, insurance companies have to devise risk management strategies for the guarantees provided by variable annuities. When hedging the options embedded in these guarantees, due to their long maturities and sensitivity to the underlying accounts tail distributions, it is important to use an appropriate model for the stochastic evolution of the account values as well as the stochastic interest rates. This paper illustrates the discrete hedging of lookback options embedded in guarantees with ratchet features, under jump risk and interest rate risk. Since discrete hedging and the model considered for the underlying price dynamics lead to an incomplete financial market, we compute hedging strategies using local risk minimization. Our numerical results show that computing the hedging strategies under a joint model for the real-world underlying price dynamics and the short interest rates, leads to effective risk reduction. We investigate the performance of hedging using underlying assets and hedging using liquid options. We illustrate that the additional effectiveness in risk reduction, achieved by hedging using options instead of the underlying, can be lost if the interest risk is not accurately modeled in the hedging computation. However, when both equity and interest rate risks are appropriately modeled, hedging with options is superior to hedging with the underlying assets. We also analyze the sensitivity of the hedging performance to the correlation between the underlying asset and the short interest rate.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5468,Computing Eigenvalues and Eigenvectors of a Dense Real Symmetric Matrix on the Ncube 6400,"This report demonstrates parallel versions of the Eispack functions   TRED2 and TQL2 for finding all eigenvalues and eigenvectors of a    dense, real symmetric matrix on the Ncube 6400.  There are several   techniques for solving this problem.  An efficient and accurate   method is tridiagonalization of the original matrix A (TRED2),   followed by application of the QR method on the resulting tridiagonal   matrix (TQL2).  Since the eigenvalues are the roots of a characteristic   polynomial, bisection and inverse iteration can be used to compute all   eigenvalues and eigenvectors.  This method is significantly faster than   the QR method provided the eigenvalues are well separated.  This   technical report will also describe the algorithms TREDs and TQL2 and    their parallel counterparts in greater detail.  The results of   numerical experiments on large problems on a 1024 processors Ncube   6400 are also presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5469,Stiffness of ODEs,"It is argued that even for a linear system of ODEs with constant    coefficients, stiffness cannot properly be characterized in terms of   the eigenvalues of the Jacobian, because stiffness is a transient   phenomenon whereas the significance of eigenvalues is asymptotic.   Recent theory from the numerical solution of PDEs is adapted to show    that a more appropriate characterization of stiffness can be based   upon pseudospectra instead of spectra.  Numerical experiments with an   adaptive ODE solver illustrate these findings.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5470,Block Factorizations on a Cluster of RS/6000s,"This paper discusses optimizing computational linear algebra algorithms   on a ring cluster of IBM RS/6000s.  We offer the results of a block   Cholesky factorization and the underlying BLAS to demonstrate the   advantage of using blocking algorithms on such architectures.  A   thorough analysis of the complexities of the problem is provided.   Different communication protocols, serial versus parallel execution,   and optimization of data traffic is explored.  We provide insight   into some of the techniques we have observed in exploiting this   particular design.  The implementations demonstrate that this    important architecture can be utilized effectively for sufficiently   large dense matrix computations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5471,BLAS Based on Block Data Structures,"The optimization of the BLAS is discussed, with examples given for   the IBM superscalar RISC S/6000.  The approach suggested is to use    block data structures based on store-by-block schemes.  We give results    and analysis of the optimization of DGEMM.  We also suggest how these   results can be applied to the higher level factorizations and the other   BLAS.  Results are given to show the advantages of using block data   structures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5472,A Parallel Row Distributed Linear Algebra System (PRDLA Users' Guide),"The purpose of this system is to provide an easy-to-use et of basic   parallel matrix manipulation subroutines, in C, for use on the Intel   iPSC/860 hypercube.  Most of the subroutines exhibit good performance,   but not necessarily optimal.  Users are welcome to use these    subroutines as building blocks in their own codes, to modify if the    situation warrants this, or just to study the implementation to help    guide their own programming.         The subroutines all operate under the assumption that matrices are   distributed by row in a natural wrap mapping.  That is, if we assume   p processors, row 1 is mapped to processor 0, row 2 is mapped to    processor 1, row p is mapped to processor p-1, row p+1 is mapped to   processor 0, etc.  If this is deemed to restrictive, the user is   welcome to use these codes as a starting point and develop their   own codes (perhaps under less restrictive assumptions).         The codes are not directly portable to other computer systems.   However, the codes do use PICL (the portable instrumented communica-   tion library, developed at Oak Ridge National Laboratory); therefore,   provided PICL is available the codes are easily ported.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5473,GMRES/CR and Arnoldi/Lanczos as Matrix Approximation Problems,"The GMRES and Arnoldi algorithms, which reduce to the CR and   Lanczos algorithms in the symmetric case, both minimize ||p(A)b||   over polynomials p of degree n. The difference is that p is nor-   malized at z=0 for GMRES and at z=infinity for Arnoldi.  Analogous   ""ideal GMRES"" and ""ideal Arnoldi"" problems are obtained if one   removes b from the discussion and minimizes ||p(A)|| instead.   Investigation of these true and ideal approximation problems gives   insight into how fast GMRES converges and how the Arnoldi iteration   locates eigenvalues.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5474,Advantages of Differential Dynamic Programming Over Newton's Method for Discrete-time Optimal Control Problems,"Differential Dynamic Programming (DDP) and stagewise Newton's    method are both quadratically convergent algorithms for solving   discrete time optimal control problems.  Although these two algorithms   share many theoretical similarities, they demonstrate significantly   different numerical performance.  In this paper, we will compare and   analyze these two algorithms in detail and derive another quadratic-   ally convergent algorithm which is a combination of the DDP algorithm   and Newton's method.  This new second-order algorithm plays a key role   in the explanation of the numerical differences between the DDP   algorithm and Newton's method.  The detailed algorithmic and   structural differences for these three algorithms and their impact on   numerical performance will be discussed and explored.  Two test   problems with various dimensions solved by these three algorithms   will be presented.  One nonlinear test problem demonstrates that the   DDP algorithm can be as much as 28 times faster than the stagewise   Newton's method.  The numerical comparsion indicates that the DDP   algorithm is numerically superior to the stagewise Newton's method.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5475,A Singular Loop Transformation Framework Based on Non-singular Matrices,"In this paper, we discuss a loop transformation framework that   is based on integer non-singular matrices.  The transformations   included in this framework are called A-transformations and include   permutation, skewing and reversal, as well as transformation called   loop scaling.  This framework i s more general than existing ones;   however, it is also more difficult to generate code in our frame-   work.  This paper shows how integer lattice theory can be used to   generate efficient code.  An added advantage of our framework over   existing ones is that there is a simple completion algorithm which,   given a partial transformation matrix, produces a full transformation   matrix that satisfies all dependencies.  This completion procedure   has applications in parallelization and in the generation of code    for NUMA machines.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5476,Access Normalization: Loop Restructuring for NUMA Compilers,"A common feature of many scalable parallel machines is non-uniform   memory access - a processor can access data in its local memory ten   to a thousand times faster than it can access local data.  In addition,   when a number of remote accesses must be made, it is usually more   efficient to use block transfers of data rather than to use many   small messages.  To run well on such machines, software must exploit   these features.  We believe it is too onerous for a programmer to do   this by hand, so we have been exploring the use of restructuring    compiler technology for this purpose.  In this paper, we start with a   language like FORTRAN-D with user-specified data distributions and   develop a systematic loop transformation strategy called access   normalization that restructures loop nests to exploit both locality   and block transfers whenever possible.  We demonstrate the power of   our techniques using routines from the BLAS (Basic Linear Algebra   Subprograms) library.  Our loop transformation strategy is expressed   in the framework of invertible matrcies and integer lattice theory,    and it is an important generalization of Banerjee's framework of   unimodular matrices.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5477,Increasing Data Reuse in the Unsymmetric QR Algorithm,"This paper models data use in the Unsymmetric QR Eigenvalue   Algorithm to improve performance on machines with memory hierarchy.   Most of the algorithms and strategies presented can be implemented   so that they are numerically similar to strategies found in such   libraries as LAPACK and EISPACK ([1,5]).  We provide tests to show   improvement of performance.  Some strategies implemented include   the use of block methods, transposing the matrix, reducing the   average stride, reducing data movement with hybrid steps, and using   block data structures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5478,Efficient Parallel Solutions of Large Sparse SPD Systems on Distributed-memory Multiprocessors,"We consider several issues involved in the solution of sparse   symmetric positive definite system by multifrontal method on    distributed-memory multiprocessors.  First, we present a new   algorithm for computing the partial factorization of a frontal   matrix on a subset of processors which significantly improves the   performance of a distributed multifrontal algorithm previously   designed.  Second, new parallel algorithms for computing sparse   forward elimination and sparse backward substitution are described.   The new algorithms solve the sparse triangular systems in multi-   frontal fashion.  Numerical experiments run on an Intel iPSC/860 and   an Intel iPSC/2 for a set of problems with regular and irregular   sparsity structure are reported.  More than 180 million flops per    second during the numerical factorization are achieved for a three-   dimensional grid problem on an iPSC/860 machine with 32 processors.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5479,Quality Mesh Generation in Three Dimensions,"We show how to triangulate a three dimensional polyhedral region   with holes.  Our triangulation is optimal in the following two   senses.  First, our triangulation achieves the best possible aspect   ratio up to a constant.  Second, for any other triangulation of the   same region into m triangles with bounded aspect ratio, our triangu-   lation has size n=O(m).  Such a triangulation is desired as an    initial mesh for a finite element mesh refinement algorithm.  Previous   three dimensional triangulation schemes either worked only on a    restricted class of input, or did not guarantee well shaped tetra-   hedra, or were not able to bound the output size.  We build on some   of the ideas presented in previous work by Bern, Eppstein, and   Gilbert, who have shown how to triangulate a two dimensional    polyhedral region with holes, with similar quality and optimality   bounds.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5480,Stable Numerical Algorithms for Equilibrium,"An equilibrium system (also known as a KKT system, a saddle-   point system, or a sparse tableau) is a square linear system with   a certain structure.  G. Strang has observed that equilibrium   systems arise in optimization, finite elements, structural analysis,   and electrical networks.  Recently, G.W. Stewart established a norm   bound for a type of equilibrium system in the case that the ""stiff-   ness"" portion of the system is very ill-conditioned.  In this paper,   we investigate the algorithmic implications of Stewart's result.   We show that all standard textbook algorithms for equilibrium    systems are unstable.  Then we show that a certain hybrid method has   the right stability property.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5481,IPSC-MATLAB Reference Manual,"IPSC-MATLAB is a programming environment for running MATLAB    programs on the Intel iPSC/860 hypercube.  The system is designed   such that the user can execute computationally intensive poitions of   MATLAB programs on the hypercube, whereas all other code is executed   on a Sun-4 workstation (SPARCstation).  The workstation acts as a   remote host for the hypercube.  MATLAB variables can migrate from   the front-end (workstation) to the back-end (hypercube) and vice   versa.  IPSC-MATLAB combines the flexibility of MATLAB programming   with the speed of the Intel hypercube.         Writing parallel programs in Fortran or C for the hypercube is a   tedious task.  Testing and debugging programs is difficult and time   consuming.  On the other hand, MATLAB, which runs on workstations,    provides a convenient means of writing programs.  However, because   of the limited speed and memory of workstations, large problems   cannot be solved.  The hypercube is fast and has more memory.  IPSC-   MATLAB attempts to use the workstation as well as the hypercube to   provide the user with a fast, flexible environment for programming.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5482,Case Study in KSR Programming: Finding Outliers by the Minimum Volume Ellipsoid Method,"This case study describes the enablement of a parallel application   on Cornell Theory Center's KSR1, a highly parallel machine from Kendall   Square Research. The application is from statistics, and exposes some   interesting facets of the KSR as well as some parallel programming tools   and techniques. Statistics are a novel application area for supercomputing,   at least at the Cornell Theory Center. First we describe the application   itself, then the approaches to parallelizing it, and finally present some   results.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5483,"Advanced Computing Research Institute Semi-annual Research Activity Report, April 1992 - September 1992","The Advanced Computing Research Institute (ACRI) is a unit of the   Cornell Theory Center and is affiliated with the Cornell Computer Science   Department. The ACRI is concerned with research in scientific computation   and its application to engineering and scientific problems. Of particular   importance is the use of and potential of advanced computer architectures   and environments. Research areas include parallelizing compilers for   scientific computation and the design of algorithms for numerical linear   algebra, optimization, and partial differential equations. Currently, ACRI   researchers are collaborating on several large-scale applications in the   computational sciences, including: protein-folding and related molecular   chemistry problems, structural optimization and biomechanics, particle   methods for turbulent combustion, discrete-control problems, and the   application of boundary element methods. The parallel computers available   to the ACRI for research include the Theory Center machines - a 64-node   KSR computer, an IBM ES/9000, a network of IBM RS/6000s, as well as   Computer Science resources: an 8K CM-200, a 32-node Intel iPSC/860, and a   64-node BBN Butterfly. This report consists of two parts. The first part   contains a short summary of the progress made in the last six months on   each of the four main projects: parallelizing compilers, computational   linear algebra, computational optimization, and numerical methods for   partial differential equations. Included also are a list of ACRI   researchers and their research interests, a list of technical reports   produced in the last six months, and a list of ACRI seminars. In the   second part we highlight one of the projects, the parallelizing compiler   work, where we give a more detailed introduction into this area and sketch   our novel approach.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5484,Approximation with Kronecker Products,"Let A be an m-by-n matrix with m=m1m2 and n=n1n2. We consider the   problem of finding (mathematical formula omitted) so that (mathematical   formula omitted) is minimized. This problem can be solved by computing the   largest singular value and associated singular vectors of a permuted   version of A.  If A is symmetric, definite, non-negative, or banded,   then the minimizing B and C are similarly structured. The idea of using   Kronecker product preconditioners is briefly discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5485,On the Convergence of Reflective Newton Methods for Large-scale Nonlinear Minimization Subject to Bounds,"We consider a new algorithm, a reflective Newton method, for the   problem of minimizing a smooth nonlinear function of many variables,   subject to upper and/or lower bounds on some of the variables. This   approach generates strictly feasible iterates by following piecewise   linear paths (""reflection"" paths) to generate improved iterates. The   reflective Newton approach does not require identification as an ""activity   set."" In this report we establish that the reflective Newton approach is   globally and quadratically convergent. Moreover, we develop a specific   example of this general reflective path approach suitable for large-scale   and sparse problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5486,A Reflective Newton Method for Minimizing a Quadratic Function Subject to Bounds on Some of the Variables,"We propose a new algorithm, a reflective Newton method, for the   minimization of a quadratic function of many variables subject to upper   and lower bounds on some of the variables. This method applies to a   general (indefinite) quadratic function, for which a local minimizer   subject to bounds is required, and is particularly suitable for the   large-scale problem. Our new method exhibits strong convergence   properties, global and quadratic convergence, and appears to have   significant practical potential.  Strictly feasible points are generated.   Experimental results on moderately large and sparse problems support the   claim of practicality for large-scale problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5487,Isotropic Effective Energy Simulated Annealing Searches for Low Energy Molecular Cluster States,The search for low energy states of molecular clusters is associated   with the study of molecular conformation and especially protein folding.   This paper describes a new global minimization algorithm which is   effective and efficient for finding low energy states and hence stable   structures of molecular clusters. The algorithm combines simulated   annealing with a class of effective energy functions which are   transformed from the original energy function based on the theory of   renormalization groups. The algorithm converges to low energy states   asymptotically and is more efficient than a general simulated annealing   method.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5488,A New Direction in Hydrodynamic Stability: Beyond Eigenvalues,"Fluid flows that are smooth at low speeds become unstable and then    turbulent at higher speeds. This phenomenon has traditionally been   investigated by linearizing the equations of flow and looking for    unstable eigenvalues of the linearized problem, but the results agree   poorly in many cases with experiments.  Nevertheless, it has become clear   in recent years that linear effects play a central role in hydrodynamic   instability. A reconciliation of these findings with the traditional   analysis can be obtained by considering the ""pseudospectra"" of the    linearized problem, which reveal that small perturbations to the smooth   flow in the form of streamwise vortices may be amplified by factors on   the order of 10**5 by a linear mechanism, even though all the eigenmodes   are stable.  The same principles apply also to other problems in the   mathematical sciences that involve non-orthogonal eigenfunctions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5489,Complexity Issues in Global Optimization: A Survey,"Complexity theory refers to the asymptotic analysis of problems and   algorithms. How efficient is an algorithm for a particular optimization   problem, as the number of variables gets large? Are there problems for   which no efficient algorithm exists? These are the questions that    complexity theory attempts to address. The theory originated in work by   Hartmanis and Stearns (1965). By now there is much known about complexity   issues in nonlinear optimization. In particular, our recent book Vavasis   (1991) contains all the details on many of the results surveyed in this   chapter.  We begin the discussion with a look at convex problems in the   next section. These problems generally have efficient algorithms. In    Section 3 we study the complexity of two nonconvex problems that also   have efficient algorithms because of special structure. In Section 4,   we look into hardness results (proofs of the nonexistence of efficient   algorithms) for general nonconvex problems. Finally, in Section 5 we    look at recent developments in ""approximation"" algorithms. We follow the   notation in this chapter that lower-case boldface letters are vectors,    lower-case italic letters are scalars, and upper-case italic letters are   sets or matrices. Superscript T indicates matrix transpose, and aTx    indicates inner product. The operators 'less than' and 'greater than' are applied component-   wise to vectors; we say x is greater than y if each entry of x is greater than or equal   to the corresponding entry of y.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5490,Preconditioning Legendre Spectral Collocation Approximations to Elliptic Problems,"This work deals with the H(exp 1) condition numbers and the distribution of the Beta~(sub N,M)-singular values of the preconditioned operators{Beta~(exp -1) (sub N,M) W(sub N,M) A^(sub N,M)}.  A^(sub N,M) is the matrix representation of the Legendre Spectral Collocation discretization of the elliptic operator ""A"" defined by A(sub u) := -delta(u) + alpha(sub 1)u(sub x) + alpha(sub 2)u(sub y) + alpha(sub 0)u in omega (the unit square) with boundary conditions: u = 0 on Gamma(sub 0), delta(sub u) divided by delta(mu sub A) = alpha(u) on Gamma(sub 1). Beta~(sub N,M) is the stiffness matrix associated with the finite element discretization of the positive definite elliptic operator ""B"" defined by B(v) := -Delta(v) + b(sub 0i)v in omega with boundary conditions v = 0 on Gamma(sub 0), delta(v) divided by delta(mu sub B) = B(v) on Gamma(sub 1).  The finite element space is either the space of continuous functions which are bilinear on the rectangles determined by the Legendre-Gauss-Lobatto (LGL) points or the space of continuous functions which are linear on a triangulation of omega determined by the LGL points.  W(sub N,M) is the matrix of quadrature weights.  When A = B we obtain results on the eigenvalues of Beta~(exp -1)(sub N,M) W(sub N,M) B^(sub N,M).  We show that there is an integer N(sub 0) and constants alpha,beta with 0 less than alpha less than beta, such that: if min(N,M) gretaer than or equal to N(sub 0),i then all the Beta~(sub N,M)-singular values of Beta~(exp -1)(sub N,M)  W(sub N,M) A^(sub N,M) lie in the interval [alpha,beta].Moreover, there is a smaller interval, [alpha(sub 0), beta(sub 0)], independent of the operator ""A"", such that: if min(N,M) greatre than or equal to N(sub 0), then all but a fixed finite number of the Beta~(sub N,M)-singular value lie in [alpha(sub 0),beta(sub 0)]. These results are related to results of Manteuffel and Parter [MP]Parter and Wong [PW] and Wong [W1], [W2] for finite element discretizations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5491,Update on Tools for Parallel Programming at the CNSF,"Not many CNSF users undertake the arduous task of parallelizing their programs. Of course, training, education, and available hardware will have a lot to do with changing this situation, but we feel that tools also have an important role to play. In 1989, we wrote: ""At the present time, the general lack of parallel programming tools is an inhibitor to parallel programming at the Cornell National Supercomputer Facility (CNSF). The Technology Integration Group (TIG)is evaluating a number of tools designed to make parallel programming easier, including tools for source analysis, program development and execution analysis. The more effective tools will be 'mainstreamed', i.e. turned over to users, integrated into workshops and consulted on by staff."" This provides an update to that status report. The major section ofthis paper describes Tools for Parallel Programming, divided into 12 categories. Each category is summarized in pretty much the same way as in 1989, and then new status and prospects are discussed. The paper concludes with some comments on hybrid program development systems andthe workstation environment. The appendices contain a table of all the tools and list acronyms, names, and institutions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5492,A Modified BFGS Method,"In this paper, we study the global convergence property of the modified BFGS update method proposed by Liao. We show that under certain circumstances this modified BFGS method corrects the eigenvalues better than BFGS does. Our numerical results support this claim and also indicate that the modified BFGS method may be competitive with the BFGS method in general.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5493,A Suite of Software Tools for Managing a Large Parallel Programming Project,"A suite of software tools is presented for managing a large parallel programming project. The tools were selected recognizing that parallel program development is an iterative process and subject to mistakes and that software tools can be useful for maintaining source code flexibility and portability, tracking revisions, and analyzing variable usage and loop structure within a program. The tools discussed are: make, cpp, RCS, and FORGE 90. The concept of a toy program is introduced as a means for experimenting with a simpler version of an application program. Finally, the use of these tools and techniques is demonstrated as part of an optimization and parallelization effort for a scientific application program called ZELIG.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5494,A Parallel Build-up Algorithm for Global Energy Minimizations of Molecular Clusters Using Effective Energy Simulated Annealing,"This work studies the build-up method for the global minimizationproblem for molecular conformation, especially protein folding. The problem is hard to solve for large molecules using general minimization approaches because of the enormous amount of required computation. We therefore propose a build-up process to systematically ""construct"" the optimal molecular structures. A prototype algorithm is designed using the anisotropic effective energy simulated annealing method at each build-up stage. The algorithm has been implemented on the InteliPSC/860 parallel computer, and tested with the Lennard-Jones microcluster conformation problem. The experiments showed that the algorithm was effective for relatively large test problems, and also very suitable for massively parallel computation. In particular, for the 72-atom Lennard-Jones microcluster, the algorithm found a structure whose energy is lower than any others found in previous studies.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5495,Magnetoconvection Dynamics in a Stratified Layer. I. 2D Simulations and Visualization (Revised 10/93),"To gain insight into the problem of fluid convection below the solar photosphere, time-dependent magnetohydrodynamic convection is studied  by numerical simulation of the magneto-anelastic equations, a model appropriate for low Mach numbers.  Numerical solutions to the equations are generated on a two-dimensional Cartesian mesh by a finite-difference, predictor-corrector algorithm.  The thermodynamic properties of the fluid are held constant at the rigid, stress-free top and bottom boundaries of the computational box, while lateral boundaries are treated as periodic.  In most runs the background polytropic fluid configuration is held fixed at Rayleigh number R=5.44 times the critical value, Prandtl number P=1.8, and aspect ratio a=1, while the magnetic parameters are allowed to vary.  The resulting dynamical behavior is shown to be strongly influenced by a horizontal magnetic field which is imposed at the bottom boundary.  As the field strength increases from zero, an initially unsteady ""single-roll"" state, featuring complex time dependence, is replaced by a steady ""traveling-wave"" tilted state; then, an oscillatory or ""sloshing"" state; then, a steady two-roll state with no tilting; and finally, a stationary state.  Because the magnetic field is matched onto a potential field at the top boundary, it can penetrate into the nonconducting region above.  By varying the magnetic diffusivity, the concentrations of weak magnetic fields at the top of these flows can be shown to be explainable in terms of an advection-diffusion balance.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5496,Initial Experiments in the Integration of ParaScope and Lambda,"This document describes the incorporation of the Lambda loop transformation Toolkit into the ParaScope parallel programming environment. The goal was to extend the functionality of ParaScope, to determine the usefulness of the Lambda Toolkit in environments other than that of its original development, and to evaluate the quality of code generation before and after incorporation of Lambda-based analysis and transformation. We learned that ParaScope could be extended, but only by very brave people; we learned that the Lambda Toolkit could be used by other programming systems to good effect; we also compared two different proposed interfaces for the Lambda Toolkit.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5497,Perturbative Forward Walking in the Context of the Mirror Potential Approach to the Fermion Problem,"We introduce and discuss a perturbative variant of ""forward walking"" in Quantum Monte Carlo and develop the theory as applied to many-fermion problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5498,Modeling the Landscape as a Dynamic Mosaic of Patches: Some Computational Aspects,"The only thing that is certain about Nature is its patchiness. Patchiness is ubiquitous, occurring across systems, organizational levels, and spatio-temporal scales. Traditional modeling approaches in ecology often fail to recognize spatial patchiness because they usually assume spatial homogeneity. A landscape may be viewed as a hierarchical mosaic system of patches that are different in their age, size, shape, content, and other aspects. The spatial change of the patch mosaic results in the landscape pattern, whereas the phase change of individual patches at the local scale and temporal change in patch mosaics at larger scales gives rise to the landscape dynamics. Following such a patch dynamics conceptualization, a spatially explicit patch dynamic modeling approach has been developed based on a serpentine annual grassland. The model has two basic submodels: a spatially-explicit, age/size- structured patch demographic model and a multi-specific plant population dynamic model of a non-equilibrium island biogeographic type. In this paper, the basic structure and some computational aspects of the model are discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5499,The Effective Energy Transformation Scheme as a General Continuation Approach to Global Optimization with Application to Molecular Conformation,"This paper discusses a generalization of the special function transformation scheme for global minimization for molecular conformation used in [3,4,14,15]. Theories for the method as a general continuation approach are established. We show that the method can transform an onlinear objective function into a class of gradually deformed, but ""smoother"", functions. An optimization procedure can then be applied to the new functions successively, to trace the solution back to theoriginal function. Two types of transformation are defined:  the isotropic and the anisotropic. We show that both, although not applicable numerically to arbitrary functions because of the required high dimensional integration, can be applied to a large class of nonlinear partially separable functions, and, in particular, the energy functions for molecular conformation. Methods to compute exactly the required transformations are given. Advantages of this transformation approach over the conventional homotopy methods also are discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5500,An Efficient Trust Region Method for Unconstrained Discrete-Time Optimal Control Problems,"Discrete-time optimal control (DTOC) problems are large-scaleoptimization problems with a dynamic structure. In previous work this structure has been exploited to provide very fast and efficient local procedures. Two examples are the differential dynamic programming algorithm (DDP) and the stagewise Newton procedure - both require only O(N) operations per iteration, where N is the number of time steps.  Both exhibit a quadratic convergence rate. However, most algorithms in this category do not have a satisfactory global convergence strategy. The most popular global strategy is shifting: this sometimes works poorly due to the lack of automatic adjustment to the shifting element. In this paper we propose a method that incorporates the trust region idea with the local stagewise Newton's method.  This method possesses advantages of both the trust region idea and the stagewise Newton's method, i.e., our proposed method has strong global and local convergence properties yet remains economical.  Preliminary numerical results are presented to illustrate the behavior of the proposed algorithm. We also collect in the Appendix some DTOC problems that have appeared in the literature.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5501,Solving LP Problems via Weighted Centers,"The feasibility problem for a system of linear inequalities can be converted into an unconstrained optimization problem using ideas from the ellipsoid method, which can be viewed as a very simple minimization technique for the resulting nonlinear function. Using more sophisticated algorithms, we develop and investigate more efficient methods, which lead to two kinds of weighted centers for the feasible set. With these centers, we develop new algorithms for solving linear programming problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5502,Parallel Structural Optimization Applied to Bone Remodeling on Distributed Memory Machines,"This paper demonstrates parallel structural optimization methods on distributed memory MIMD machines. We have restricted ourselves to the simpler case of minimizing a multivariate non-linear function subject to bounds on the independent variables, when the objective function is expensive to evaluate as compared to the linear algebra portion of the optimization. This is the case in structural applications, when a large three-dimensional finite element mesh is used to model the structure. This paper demonstrates how parallelism can be exploited during the function and gradient computation as well as the optimization iterations. For the finite element analysis, a 'torus-wrapped' skyline solver is used. The reflective Newton method which attempts to reduce the number of iterations at the expense of more linear algebra per iteration is compared with the more conventional active set method. All code is developed for an Intel iPSC/860, but it can be ported to other distributed memory machines. The methods developed are applied to problems in bone remodeling. In the area of biomechanics, optimization models can be used to predict changes in the distribution of material properties in bone due to the presence of an artificial implant. The model we have used minimizes a linear combination of the mass and strain energy in the entire domain subject to bounds on the densities in each finite element. Early results show that the early reflective Newton method can outperform active set methods when a significant number of variables are not active at the minimum.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5503,Exact Monte Carlo Calculations for Fermions on a Parallel Machine,"We describe how a recently published algorithm--which addresses the sign problem with the context of the Green's function Monte Carlo method--can be implemented in a parallel distributed environment. The method of parallelization maintains large granularity and therefore low overhead. Despite the stochastic nature of the algorithm, good load-balancing can be accomplished and reproducibility is ensured.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5504,An Accelerated Interior Point Method Whose Running Time Depends Only on A,"We propose a ""layered-step"" interior point (LIP) algorithm for linear programming. This algorithm follows the central path, either with shortsteps or with a new type of step called a ""layered least squares"" (LLS)step. The algorithm returns the exact global minimum after a finite numberof steps - in particular, after O (mathematical symbol omitted) iterations, where c(A) is a function of the coefficient matrix. The LLS steps can be thought of as accelerating a path-following interior point method whenever near-degeneracies occur. One consequence of the new method is a new characterization of the central path: we show that it composed of at most n-squared alternating straight and curved segments. If the LIP algorithm is applied to integer data, we get as another corollary a new proof of a well-known theorom by Tardos that linear programming can be solved in strongly polynomial time provided that A contains small-integerentries.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5505,Pseudospectra of the Wave Operator with an Absorbing Boundary,"For systems which can be described by u(sub t) = Au with a highly non-normal matrix or operator A, the spectrum of A may describe the behavior of the system poorly. One such operator arises from the one-dimensional wave equation on a finite interval with a homogeneous Dirichlet condition at one end and a linear damping condition at the other.  In this paper the pseudospectra (norm of the resolvent) of this operator are computed in an energy norm, using analytical techniques and computations with discrete approximations. When the damping condition is perfectly absorbing, the pseudospectra are half-planes parallel to the imaginary axis, and in other cases they are periodic in the imaginary direction and approximate strips of finite thickness. The non-normality of the operator is related to the behavior of the system and the limitations of spectral analysis.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5506,Some Efficient Algorithms for Unconstrained Discrete-time Optimal Control Problems,"The differential dynamic programming algorithm (DDP)and the stagewise Newton procedure are two typical examples of efficient local procedures for discrete-timeoptimal control (DTOC) problems. It is desirable to generalize these local procedures to globally convergent methods. One successful globalization was recently proposed by Coleman and Liao [3] which combines the trust region idea with Pantoja's stagewise Newton procedure. In this paper, we propose several algorithms for DTOC problems which combine a modified ""dogleg"" algorithm with DDP or Pantoja's Newton procedure. These algorithms possess advantages of both the dogleg algorithm and the DDP or the stagewise procedure, i.e.,they have strong global and local convergence properties yet remain economical. Numerical results are presentedto compare these algorithms and the Coleman-Liao algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5507,The Application of Automatic Differentiation to Problems in Engineering Analysis,"Automatic differentiation is a technique of computing the derivative of a function or a subroutine written in a higher level language such as FORTRAN or C. Significant progress has been made in this field in the last few years. Here, we give a short exposition to automatic differentiation and demonstrate its applicability to several fields of engineering analysis.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5508,Experiments in the Concurrent Computation of Spatial Association on the KSR1,"Spatial association measures, when computed for large data sets, have significant computational requirements. Parallel processing is one way to address these requirements.  The design of parallel programs, however, requires careful planning since many factors under programmer control affect the efficiency of the resulting computations. In this paper, two strategies of parallel processing are described using as an illustration a measure of spatial association, G(d).  An evaluation is made of the efficiency of the parallel implementations by varying the problem size and the number of processors used in parallel.  The results obtained indicate that parallel processing can currently enable analysts to work in near-real-time with problems that range in the tens of thousands of observations; such problems require less than two minutes of execution time on the KSR1.  Also super linear speed ups of almost 1500 are obtained for the computation phase of the problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5509,How Parallel Programming Tools are Used,"Parallel programming is a hot topic among scientists and engineers. The number of parallel machines available to them is constantly increasing. These powerful machines provide a new research platform for engineers and scientists.  In order to exploit all their power, new programming techniques are needed. Fortunately, several parallel programming tools have appeared to make this complex programming endeavor much easier. We analyze paths to parallel programming from traditional scientific programming through parallelization of a molecular simulation application. We hope this paper encourages scientists and engineers at Cornell's Theory Center to take the step towards parallelization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5510,An Efficient Linear Scaling Algorithm for Tight Bonding Molecular Dynamics,"A novel formulation for tight binding total energy calculations and tight binding molecular dynamics, which scales linearily with the size of the system, is presented. The linear complexity allows us to treat systems of very large size and the algorithm is already faster than the best implementation of classical diagonalization for systems of 64 atoms. In addition, it is naturally parallelizable and it permits us therefore to perform molecular dynamics simulations of systems of unprecedented size. Finite electronic temperatures can also be taken into account. We illustrate this method by investigating structural and dynamical properties of solid and liquid carbon at different densities.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5511,Parallel Simulation of the Ising Model,(The following contains mathematical formula and symbols that may become distorted in ASCII text.) New methods for parallelizing Ising model simulations are presented. A parallel single-spin Metropolis algorithm has been implemented with a speedup of 27 on 50 processors of the KSR-1 parallel computer. Our parallel Swendsen-Wang algorithm obtains a speedup of 3.2 on 9 processors of the same computer. Both of these simulations were carried out on 200x200 lattices. The parallel Local Cluster algorithm has been implemented with an almost linear speedup. We also discuss ongoing research using the parallel Local Cluster algorithm.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5512,Vectorization of Multiple Small Matrix Problems,"Multiple independent matrix problems of very small size appear in a variety of different fields. In this work, we study the implementation of elementary linear algebra subroutines so as to best use vectorizing compilers and vector hardware for multiple small problem instances. We cheek the performance improvement over the single-instance optimized codes on different vector supercomputers. We also describe how to automate the transformation of a single-instance linear algebra solver into a multiple instance solver",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5513,Fast Wavelet Transforms for Matrices Arising from Boundary Element Methods,"(The following contains mathematical formulae and symbols that may become distorted in ASCII text.) For many boundary element methods applied to Laplace's equation in two dimensions, the resulting integral equation has both an integral with a logarithmic kernel and an integral with a discontinuous kernel. If standard collocation methods are used to discretize the integral equation we are left with two dense matrices. We consider expressing these matrices in terms of wavelet bases with compact support via a fast wavelet transform as in Beylkin, Coifman, and Rokhlin. Upper bounds on the size of the wavelet transform elements are obtained. These bounds are then used to show that if the original matrices are of the size N x N, the resulting transformed matrices are sparse, having only O(N log N) significant entries. Some numerical results will also be presented. Unlike Beylkin, Coifman and Rokhlin who use the fast wavelet transform as a numerical approximation to a continuous operator already expressed in a full wavelet basis of L2(IR), we think of the fast wavelet transform as a change of basis matrix for a finite dimension, and apply it to a discretized function or matrix. As a result, we can use this fast wavelet transform as a ""black box"" transformation in existing boundary element codes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5514,Parallel Continuation-Based Global Optimization for Molecular Conformation and Protein Folding,"This paper presents our recent work on developing parallel algorithms and software for solving the global minimization problem for molecular conformation, especially protein folding. Global minimization problems are difficult to solve when the objective functions have many local minimizers, such as the energy functionsfor protein folding. In our approach, to avoid directly minimizing a ""difficult"" function, a special integral transformation is introduced to transform the function into a class of gradually deformed, but ""smoother"" or ""easier"" functions. An optimization procedure is then applied to the new functions successively, to trace their solutions back to the original function. The method can be applied to a large class of nonlinear partially separable functions including energy functions for molecular conformation and protein folding. Mathematical theory for the method, as a special continuation approach to global optimization, is established. Algorithms with different solutions tracing strategies are developed. Different levels of parallelism are exploited for the implementation of the algorithms on massively parallel architectures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5515,Exploitation of Latency Hiding on the KSR1 - Case Study: The Barnes Hut Algorithm,"This study is aimed at examining the performance of dynamic, irregular and loosely synchronous class of applications on the KSR1 distributed shared memory COMA system. The Barnes-Hut tree based algorithm for simulating galactic evolution [1], was chosen as a representative of this class of applications. The performance measures include the overall time-stepping loop execution time, the efficacy of the scaling rules (EES and RCTS) proposed in [2] as well as the computational load balance achieved by the CostZone  data partitioning scheme [1] under these scaling rules. We define notions of geographical locality, transfer locality flux and partition locality flux to explain the sources of remote memory accesses in the application. The contributions of our study include two runtime latency hiding techniques PST and PREFH proposed for the effective and automatic utilization of the poststore  and prefetch instructions to hide the latencies of remote memory accesses.  The architectural support assumed,  compiler analysis required and code instrumentation schemes for the implementation of the PST and PREFH techniques are presented in this paper. We also examine the scalability of our schemes under the afore mentioned scaling rules. These schemes were tuned for a 32k particle simulation size on a 112 processor configuration, producing a reduction of 30% in the overall loop execution time of the simulation.  Further, a combination of the schemes, PREPST, produced an overall reduction of 50% in the loop execution time of simulation. These improvements were traced to a reduction in the problems of locality fluxes  which arose as the application was scaled under the EES and RCTS rules/ Interestingly, the problems of locality fluxes manifested themselves as load imbalance conditions in the application.  We found that our schemes did not scale too well under EES scaling, but produced appreciable reductions in execution timings under RCTS scaling. It needs to be emphasized that our work involved the study of a whole  application and on a 128 processor  KSR1 machine, as opposed to most other work reported to date which examine performances of computational kernels on 32 or 64 processor configurations only.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5516,Rate Equations for the Growth of Cu Islands on Cu(001),"The kinetics of island nucleation and growth during deposition of Cu atoms on Cu(001) is studied using rate equations.  The equations are derived using microscopic calculations of the energy landscape on the surface, previously used in Monte Carl (MC) simulations.  This allows a quantitative comparison between the rate equations and the MC results.  Our rate equations take into account atoms that fall on the bare substrate as well as on top of existing islands, the mobility of single atoms and small islands, the coalescence of adjacent islands and the possible separation of atoms from island edges.  The rate equations are used to explore the island size distribution and island density as a function of the coverage and deposition rates.  These rate equations provide a useful and flexible tool that allows to easily modify particular microscopic properties of the system such as the mobility of small islands or the rate of coalescence and examine their effect while leaving all other features intact.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5517,Calculation of Pseudospectra by the Arnoldi Iteration,"The Arnoldi iteration, usually viewed as a method for calculating eigenvalues, can also be used to estimate pseudospectra.  This possibility may be of practical importance, for in applications involving highly non-normal matrices or operators, such as hydrodynamic stability, pseudospectra may be physically more significant than spectra.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5518,The Integration of ParaScope and Lambda,"We have been experimenting with combining three powerful language tools for large, scientific, parallel Fortran codes.  One tool is ParaScope, a programming envirnment; another tool is the Lambda Toolkit, a collection of routines for performing loop transformations using invertible matrices; the third is FORGE 90, a collection of tools for parallelizing Fortran programs.  Initial sucess with incorporating the Lambda Toolkit into ParaScope led us to undertake the work leading to a new program preparation strategy, in which one first uses a modified ParaScope to perform DataAccess Normalization, then uses FORGE 90 to produce a parallel program for a distributed memory platform. We describe the details of this strategy and present some performance results for the IBM SP1.  We conclude that the combination of ParaScope and the Lambda Toolkit (called ""ped-Lambda"") is a useful transformation tool.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5519,"Optimization and Parallelization of a Commodity Trade Model for the SP1, Using Parallel Programming Tools","We compare two different approaches to parallelization of Fortran programs. The first approach is to optimize the serial code so that it runs as fast as possible on a single processor, and then optimize the parallel version. In this paper a variety of parallel programming tools is used to obtain an optimal, parallel version of an economic policy modelling application for the IBM SP1.  We apply a new technique called Data Access Normalization; we use an extended ParaScope as our parallel programming environment; we use FORGE 90 as our parallelizer; and we use KAP as our optimizer.  We make a number of observations about the effectiveness of these tools. Both strategies obtain a working, parallel program, but use different tools to get there.  On this occasion, both KAP and Data Access Normalization lead to the same critical transformation of inverting four of the twelve loop nests in the original program.  The next most important optimization is parallel I/O, one of the few transformations that had to be done by hand.  Speedups are obtained on the SP1 (using MPLp communication over the High Speed Switch).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5520,Tight Binding Molecular Dynamics on Parallel Computers,"With a new and intrinsically parallel algorithm for Tight Binding Molecular Dynamics we obtain a performance of 3.4 Gigaflops per million dollar on a cluster of 8 Hewlett Packard workstations in a simulation of 216 Silicon atoms.  One time step with this new algorithm takes as much time for the 216 atom system as one time step with a conventional algorithm on a NEC-SX3 supercomputer.  In addition, the linear scaling of new algorithm allows us to calculate systems of unprecendented size which are not any more accessible by the combination of standard algorithms and vector supercomputers.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5521,Parallel Multifrontal Solution of Sparse Linear Least Squares Problems on Distributed-memory Multiprocessors,"We describe the issues involved in the design and implementation of efficient parallel algorithms for solving sparse linear least squares problems on distributed-memory multiprocessors.  We consider both the QR factorization method due to Golub and the method of corrected semi-normal equations due to Bjorck.  The major tasks involved are sparse QR factorization, sparse triangular solution and sparse matrix-vector multiplication.  The sparse QR factorization is accomplished by a parallel multifrontal scheme recently introduced.  New parallel algorithms for solving the related sparse triangular systems and for performing sparse matrix-vector multiplications are proposed.  The arithmetic and communication complexities of our algorithms on regular grid problems are presented.  Experimental results on an Intel iPSC/860 machine are described.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5522,Software Management Tools,"This report comprises the final report for a Cornell Theory Center intership during the Spring 1994 semester.  The goal of the internship was to organize a major software package for a research group in chemistry to be portable, flexible, and easy to maintain.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5523,All-Electron Study of Gradient Corrections to the Local Density Functional in Metallic Systems,"Using the all-electron Linearized Augmented Plane Wave (LAPW) method, we calculate the effect of including gradient corrections to the exchange correlation functional on the structural properties of the simple metal Al, transition metals Ta, W, Pt, and noble metals Cu, Ag, Au.  For all the systems studied, the local density approximation (LDA) yields bond-lengths that are too short and bulk moduli that are too large.  The generalized gradient functional introduced by Perdew and Wang (PW91) yields corrections that are in the right direction (larger bond-lengths and smaller bulk moduli), but it frequently over compensates, particularly for the heavier elements.  The PW 91 functional predicts the lattice constant and bulk modulus of Al and Cu more accurately than the LDA but yields values thatare less accurate than the LDA for W, Pt, Au.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5524,The Lambda Loop Transformation Toolkit (User's Reference Manual),"Loop transformations are becoming critical to exploiting parallelism and data locality in parallelizing and optimizing compilers. This document describes the Lambda loop transformation toolkit, an implementation of the non-singular matrix transformation theory, which can represent any linear one-to-one transformation.  Lambda has a simple interface, and is independent of any compiler intermediate representation. It has been used in parallelizing compilers for multiprocessor machines as well as optimizing compilers for uniprocessor machines.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5525,A New Parallel Algorithm for Global Optimization with Application to the Molecular Cluster Problem,"In this paper we present a simple algorithm for global optimization. This algorithm combines random searches with efficient local minimization algorithms.  The proposed algorithm begins with an initial ""local minimizer.""  In each iteration, a search direction is generated randomly, along which some points are chosen as the initial points for the local optimization algorithm and several ""local minimizers"" are obtained.  The next iteration is determined by comparing these localminimizers.  We will discuss the expected number of iterations for finding a global minimizer with this algorithm.  Several variants of the algorithm that take advantage of the partially separable structure are proposed for the Lennard-Jones cluster problem and tested on the IBM SP1 parallel computer.  Our numerical results show that our algorithms are promising.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5526,Pull the Weighted Center Towards the Solution of LP,"In the paper of Liao and Todd [3] two weighted centers are introduced and used to design algorithms for solving systems of linear inequalities.  The linear programming problems can be solved via the weighted centers of a sequence of linear inequalities formed by letting the objective be an extra constraint and increasing the lower bound corresponding to the objective function as long as it is possible.  In this paper we study the second kind of weighted center of [3] which ismore computationally oriented and show that, under a regularity assumption, the weighted center of the linear inequality with the objective as an extra constraint converges to the solution of the linear programming problem under consideration as the upper bound corresponding to the objective function is pulled towards the infinity.  We propose a relaxed version of one of the algorithms of [3].  This modified version does not try to find an accurate center during each iteration; instead, an approximate center which is the k-th feasible iterate is determined in the k-th iteration.  We show  that this modified algorithm finds an e-solution in finity many iterations. Some limited numerical results are presented to compare our algorithm with the simplex method and indicate that our algorithm is promising.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5527,Getting CUTE with Matlab,"CUTE is a testing environment for nonlinear programming algorithms developed by Bongartz, Conn, Gould, and Toint ([CUTE: Constrained and unconstrained testing environment , Research Report RC 18860, IBM T.J. Watson Research Center, Yorktown Heights, USA, 1993]).  The test problems in this environment are encoded in standard input format (SIF) and accessed by a set of FORTRAN subroutines. An extension to this environment was developed to allow fast access to the CUTE test problems from Matlab. This report describes this new Matlab interface to CUTE and how to use it.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5528,Advanced Computing Research Institute Annual Research Activity Report September 1993 - September 1994,"The Advanced Computing Research Institute (ACRI) is a unit of the Cornell Theory Center and is affiliated with the Cornell Computer Science Department. The ACRI is concerned with research in scientific computation and its application to engineering and scientific problems with the emphasis on the use and potential of advanced computer architecture and environments. Research areas include restructuring compilers for scientific computation, and the design of algorithms for numerical linear algebra, optimization, and differential equations. Currently, ACRI researchers are collaborating on several large-scale applications in the computational sciences, including: protein-folding and related molecular chemistry problems, structural optimization and biomechanics, particle methods for turbulent combustion, discrete-control problems, and the application of boundary elementmethods. The parallel computers available to ACRI for research include the Theory Center machines - a 128-node KSR computer, a 64-node IBM SP, and a network of IBM RS/6000s. This report contains a short summary of the progress made in the last year on each of the four main projects:  parallelizing compilers, computational linear algebra, computational optimization, and numerical methods for partial differential equations. Included also are a list of ACRI researchers and their research interests, a list of technical reports produced this last year, and a list of ACRI seminars.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5529,Slip Complexity in a Crustal-Plane Model of an Earthquake Fault,"We study numerically the behavior of a two-dimensional elastic plate (acrustal plane) that terminates along one of its edges at a homogeneous fault boundary. Slip-weakening friction at the boundary, inertial dynamics in the bulk, and uniform slow loading via elastic coupling to a substrate combine to produce a complex, deterministically chaotic sequence of slipping events. We observe a power-law distribution of small to moderately large events and an excess of very large events. For the smaller events, the moments scale with the rupture length in a manner that is consistent with seismological observations. For the largest events, rupture occurs in the form of narrow propagating pulses.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5530,On Global Convergence of a Trust Region and Affine Scaling Method for Nonlinearly Constrained Minimization,"(The following contains mathematical formulae and symbols that may become distorted in ASCII text.) A nonlinearly constrained optimization problem can be solved by the exact penalty approach involving non differentiable functions (summation(i)of |ci(x)|)  and (summation(i) of max(0,ci(x))). In [11], a trust region affine scaling approach based on a 2-norm subproblem is proposed for solving a nonlinear l 1 problem. The (quadratic) approximation and the trust region subproblem are defined using affine scaling techniques. Explicit sufficient decrease conditions are proposed to obtain a limitpoint satisfying complementarity, dual feasibility, and second order optimality. In this paper, we present the global convergence properties of this new approach.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5531,A Trust Region and Affine Scaling Method for Nonlinearly Constrained Minimization,"(The following contains mathematical formulae and symbols that may become distorted in ASCII text.) A nonlinearly constrained optimization problem can be solved by the exact penalty approach involving non differentiable functions (summation(i)of |ci(x)|)  and (summation(i) of max(0,ci(x))). In the paper, a trust region affine scaling approach based on a 2-norm subproblem is proposed for solving a nonlinear l 1 problem. The (quadratic) approximation and the trust region subproblem are defined using affine scaling techniques.  Explicit sufficient decrease conditions based on the approximations are suggested for obtaining a limit point satisfying complementarity, Kuhn-Tucker conditions, and second order necessary conditions. In global convergence analysis of the method is presented in [4].",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5532,An Affine Scaling Algorithm for Minimizing Total Variation in Image Enhancement,"A computational algorithm is proposed for image enhancement based on total variation minimization with constraints. This constrained minimization problem is introduced by Rudin et al [13,14,15] to enhance blurred and noisy images. Our computational algorithm solves the constrained minimization problem directly by adapting the affine scaling method for the unconstrained l 1 problem [3]. The resulting computational scheme, when viewed as an image enhancement process, has the feature that it can be used in an interactive manner in situations where knowledge of the noise level is either unavailable or unreliable. This computational algorithm can be implemented with a conjugate gradient method. It is further demonstrated that the interactive enhancement  process is efficient.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5533,"ARCH, An Object-Oriented Library for Asynchronous and Loosely Synchronous System Programming","ARCH is a C++-based library for asynchronous and loosely synchronous system programming.  The current version offers a set of programming constructs that are outlined below:
*** Threads: The construct is presented as a class from which the user can derive his own classes.  The class encapsulates a small set of status variables and offers a set of functions for declaration, initialization, scheduling, priority setting, yielding and stopping.
*** Processes:  A process is a more regular and structured programming construct whose scheduling and termination obey additional synchronization rules. Together with the synchronous point-to-point communication system offered in the library (see below), processes favor a parallel programming style similar to OCCAM's (actually, an extension of it that removes most static features and allows processes to share data).  The semantics of this model is well understood and will undoubtedly facilitate the development of correct large asynchronous code.  The library has been designed so that the C++ compiler is able to check the static semantics of programs (complete type checking, send-recv correct matching, ...).
*** Synchronous communication: Threads and processes synchronize and communicate via communication channels.  There are four types of communication channels for local or remote synchronization or synchronous point-to-point communication.  Inter-processor channels are essentially tools for building virtual topologies.  The channel classes offer functions to send to or receive from a channel and get the size of the latest received message.  More specialized synchronization-communication tools can be derived from channels.
*** Global data and pointers:  Beside threads, the library offers basic tools for developing distributed data abstractions.  Global data are data that can be defined at given locations in the distributed memory but are visible from all processors.  Global pointers are a generalization of C++ pointers that allow for addressing global data at any place over the distributed memory. As usual pointers, global pointers are subjected to arithmetic and logic manipulations (incrementation, dereferencing, indexing, comparision...). The library provides basic operators for global data and pointer definition.
*** Global read/write functions:  Global pointer expressions provide global references over the distributed memory that can subsequently be used asarguments to global read/write functions.  These functions allow the processors to get access to all global data regardless of their locations over the distributed memory.  In their most complete form, the read/write functions operate as remote procedure calls.  At the programmer's level, global read/write functions appear as ""one-sided"": a read/write operationis executed on the processor that needs to read/write global data but need not be explicitly handled by the processor associated to the memory holding the data.
*** Spread and remote Arrays.  Two basic distributed data structures have been built in the library.  Spread arrays are arrays that have some of their dimensions spread over the distributed memory according to a given policy.  Remote arrays are arrays that are defined at a given place in the distributed memory but can be accessed from any other.  The spread and remote array classes (SpreadArray and RemoteArray) provide functions for global reference calculation.  Global references can subsequently be used as arguments to global read/write functions.  One can specialize global pointers to operate on spread or remote arrays.  The global pointer class (Star class) offers distinct arithmetic and logic operator sets for unassigned, spread and remote global pointers.  The library encourages parallel code writing in a style that relies on the object-oriented approach: first, build the abstractions that the application at hand relies on; next, make an efficient implementation of the abstraction; and finally, develop the application on top of them.  The abstractions can be distributed data types derived from those built in the library (spread and remote arrays: see code of the segmentation algorithm provided with the library) or new distributed types built in the same way or types reused from other applications.  This approach should favor parallel code production with many desirable properties such as efficiency, portability, reusability, ... . The library uses MPI as a communication interface.  The current implementation runs on the IBM-SP2.  Two versions of the library have currently been released.The first one is based on the IBM C++ compiler and MPI library.  The second one makes use of the GNU g++ compiler and the MPICH public domain version of MPI.  Porting the latter to any parallel machine supporting these two software systems should be straightforward.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5541,Complete Orthogonal Decomposition for Weighted Least Squares,"Consider a full-rank weighted least squares problem in which the weight matrix is highly ill-conditioned. Because of the ill-conditioning, standard methods for solving least-squares problems, QR factorization and the nullspace method for example, break down. G.W. Stewart established a norm bound for such a system of equations, indicating that it may be possible to find an algorithm that gives an accurate solution. S.A. Vavasis proposed a new definition of stability that is based on this result. He also defined the NSH algorithm for solving this least-squares problem and showed that it satisfies his definition of stability. In this paper, we propose a complete orthogonal decomposition algorithm to solve this problem and show that it is also stable. This new algorithm is simpler and more efficient than the NSH method.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5542,Enhancement of Environments for Analysis of Trace Files of Parallel Programs,"One of the important phases of parallel programming is performance analysis. Trace data provides information about where time is spent in programs. Since this data is huge, a tool for analyzing and visualizing the trace data is convenient and necessary for performance analysis of parallel programs. Environments which provide such a faclility are many and varied. In this report, we discuss our work on the enhancement of one such environment for accessibility over more platforms and better visualization capabilities. The environment is Pablo.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5543,A New Trust Region Algorithm for Equality Constrained Optimization,We present a new trust algorithm for solving nonlinear equality constrained optimization problems. At each iterate a change of variables is performed to improve the ability of the algorithm to follow the constraint level sets. The algorithm employs L2 penalty function for obtaining global convergence. Under certain assumptions we prove that this algorithm globally converges to a point satisfying the second order necessary optimally conditions; the local convergence rate is quadratic. Results of preliminary numerical experiments are presented.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5544,A Quasi-Newton L2-Penalty Method for Minimization Subject to Nonlinear Constraints,We present a modified L2 penalty function method for equality constrained optimization problems. The pivotal feature of our algorithm is that at every iterate we invoke a special change of variables to improve the ability of the algorithm to follow the constraint level sets. This change of variables gives rise to a suitable block diagonal approximation to the Hessian which is then used to construct a quasi-Newton method. We show that the complete algorithm is globally convergent with a local Q-superlinearly convergence rate. Preliminary results are given for a few problems.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5545,Mass-Extinction: Evolution and the Effects of External Influences on Unfit Species,"We present a new model for extinction in which species evolve in bursts or 'avalanches,' during which they become on average more susceptible to environmental stresses such as harsh climates and so are more easily rendered extinct. Results of simulations and analytic calculations using our model show a power-law distribution of extinction sizes which is in reasonable agreement with fossil data. We also see a number of features qualitatively similar to those seen in the fossil record. For example, we seefrequent smaller extinctions in the wake of a large mass extinction, which arise because there is reduced competition for resources in the aftermath of a large extinction event, so that species which would not normally be able to compete can get a foothold, but only until the next cold winter or bad attack of the flu comes along to wipe them out.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5546,Eigenmodes of Isospectral Drums,"Recently it was proved that there exist nonisomeric planar regions that have identical Laplace spectra. That is, one cannot ""hear the shape of a drum."" All known examples of such regions are bounded by polygons with reentrant corners. While the isospectrality can be proven mathematically, analytical techniques are unable to produce eigenvalues themselves. Furthermore, standard numerical methods for computing the eigenvalues, such as adaptive finite elements, are highly inefficient. Physical experiments have been performed to measure the spectra, but the accuracy and flexibility of this method are limited. We describe an algorithm due to Descloux and Tolley that blends finite elements with domain decomposition, and show that, with a modification that doubles its accuracy, this algorithm can be used to compute efficiently the eigenvalues for polygonal regions. We present results accurate to twelve digits for the most famous pair of isospectral drums, as well as results for another pair.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5547,A Level-set Approach Inverse Problems Involving Obstacles,"An approach for solving inverse problems involving obstacles is proposed. The approach uses a level-set method which has been shown to be effective in treating problems involving moving boundaries. We develop two computational methods based on this idea. One method results in a nonlinear time-dependent partial differential equation for the level-set function whose evolution minimizes the residual in the data fit. The second method is an optimization that generates a sequence of level-set functions that reduces the residual. The methods are illustrated in two applications: a deconvolution problem, and a diffraction screen reconstruction problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5548,Parallel Solution of Sparse Linear Least Squares Problems on Distributed-memory Multiprocessors,This paper studies the solution of large-scale sparse linear least squares problems on distributed-memory multiprocessors. The method of corrected semi-normal equations is considered. New block-oriented parallel algorithms are developed for solving the related sparse triangular systems.  The arithmetic and communication complexities of the new algorithms applied to regular grid problems are analyzed. The proposed parallel sparse triangular solution algorithms together with a block-oriented parallel sparse QR factorization algorithm result in a highly efficient block-oriented approach to the parallel solution of sparse linear least squares problems on distributed-memory multiprocessors. Performance of the block-oriented approach is demonstrated empirically through an implementation on an IBM Scalable POWER parallel system SP2. The largest problem solved has over two million rows and more than a quarter million columns. The execution speed for the numerical factorization of this problem achieves over 3.7 gigaflops per second on an IBM SP2 machine with 128 processors.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5549,Model Fermion Monte Carlo with Correlated Pairs,"The issues that prevent the development of efficient and stable algorithms for fermion Monte Carlo in continuum systems are reexamined with special reference to the implications of the ""plus/minus"" symmetry. This is a property of many algorithms that use signed walkers, namely that the dynamics are unchanged when the signs of the walkers are interchanged. Algorithms that obey this symmetry cannot exhibit the necessary stability. Specifically, estimates of the overlap with any antisymmetric test function cannot be bounded away from zero in the limit of many iterations. Within the framework of a diffusion Monte Carlo treatment of the Schroedinger equation, it is shown that this symmetry is easily broken for pairs of walkers while at the same time preserving the correct marginal dynamics for each member of the pair. The key is to create different classes of correlations between members of pairs and to use (at least) two distinct correlations for a pair and for the same pair withthe signs exchanged. The ideas are applied successfully for a class of simplemodel problems in two dimensions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5550,Fast Compiled Logic Simulation Using Linear BDDs,"This paper presents a new technique for compiled zero delay logic simulation, and includes extensive experiments that demonstrate its performance on standard benchmarks. Our compiler partitions the circuit into fanout-freeregions (FFRs), transforms each FFR into a linear sized BDD, and converts each BDD into executable code. In our approach, the computation is sublinear in the number of variables within each partition because only one path, from root to leaf, of the BDD is executed; therefore in many cases, substantial computation is avoided. In this way, our approach gets dome to the advantages of oblivious as well as demand-driven evaluation. We investigated the impact of the various heuristics on performance, and based on this data, we recommend good values for design parameters. A performance improvement of up to 67% over oblivious simulation is observed for our benchmarks.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5551,Automatic Optimization,We propose some automatic techniques for unconstrained optimization with the objective function given by some computer program. We show that the Newton step can be calculated in O(m2) operations where m is the number of stages in the function evaluation program. We also show that methods developed in Coleman and Liao [1] and Liao [8] for unconstrained discrete-time optimal control problems can be modified to handle general cases.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5552,Nonlinear Wave Equations for Relativity,"Gravitational radiation is described by canonical Yang-Mills wave equations on the curved space-time manifold, together with evolution equations for the metric in the tangent bundle. The initial data problem is described in Yang-Mills scalar and vector potentials, resulting in Lie-constraints in addition to the familiar Gauss-Codacci relations",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5553,"A Subspace, Interior, and Conjugate Gradient Method for Large-scale Bound-constrained Minimization Problems",A subspace adaption of the Coleman-Li trust region and interior method is proposed for solving large-scale bound-constrained minimization problems. This method can be implemented with either sparse Cholesky factorization or conjugate gradient computation. Under reasonable conditions the convergence properties of this subspace trust region method are as strong as those of its full-space version.   Computational performance on various large-scale test problems are reported; advantages of our approach are demonstrated.  Our experience indicates our proposed method represents an efficient way to solve large-scalebound-constrained minimization problems.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5554,Monte Carlo Study of the Random-field Ising Model,"Using a cluster-flipping Monte Carlo algorithm combined with a generalization of the histogram reweighting scheme of Ferrenberg and Swendsen, we have studied the equilibrium properties of the thermal random-field Ising model on a cubic lattice in three dimensions. We have equilibrated systems of L x L x L spins, with values of L up to 32, and for these systems the cluster-flipping method appears to a large extent to overcome the slow equilibration seen in single-spin-flip methods. From the results of our simulations we have extracted values for the critical exponents and the critical temperature and randomnessof the model by finite size scaling. For the exponents we find v=1.02 +- 0.06, B=0.06 +- 0.07, y=1.9 +- 0.2, and mean(y)=2.9 +- 0.2.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5555,A Method for Imaging Corrosion Damage in Thin Plates from Electrostatic Data,The problem of quantitative nondestructive evaluation of corrosion in plates is considered. The inpection method uses boundary measurements of currents and voltages to determine the material loss caused by corrosion. The development of the method is based on linearization and the assumption that the plate is thin. The behavior of the method is examined in numerical situations.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5556,A Model for Evolution and Extinction,"We present a model for evolution and extinction in large ecosystems. The model incorporates the effects of interactions between species and the influences of abiotic environmental factors. We study the properties of the model by approximate analytic solution and also by numerical simulation, and use it to make predictions about the distribution of extinctions and species lifetimes that we would expect to see in real ecosystems. It should be possible to test these predictions against the fossil record. The model indicates that a possible mechanism for mass extinction is the coincidence of a large coevolutionary avalanche in the ecosystem with a severe environmental disturbance.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5557,Multithreaded model for dynamic load balancing parallel adaptive PDE computations,"We present a multithreaded model for the dynamic load-balancing ofnumerical, adaptive computations required for the solution of Partial Differential Equations (PDEs) on multiprocessors.  Multithreading is used as a means of exploring concurrency in the processor level inorder to tolerate synchronization costs inherent to traditional (non-threaded) parallel adaptive PDE solvers.  Our preliminary analysis for parallel, adaptive PDE solvers indicates that multithreading can be used as a mechanism to mask overheads required for the dynamic balancing of processor workloads with computations required for the actual numerical solution of the PDEs.  Also, multithreading can simplify the implementation of dynamic load-balancing algorithms, a task that is very difficult for traditional data parallel adaptive PDE computations.  Unfortunately, multithreading does not always simplify program complexity, often makes code re-usability not an easy task, and increases software complexity.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5558,An Aspect Ratio Bound for Triangulating a d-grid Cut by a Hyperplane,"We consider the problem of triangulating a d-dimensional uniform grid of d-cubes that is cut by a k-dimensional affine subspace.  The goal is to obtain a triangulation with bounded aspect ratio.  To achieve this goal, we allow some of the box faces near the affine subspace to be displaced.  This problem has applications to finite element mesh generation.  For general d and k, the bound on aspect ratio that we attain is double-exponential in d.  For the important special case of d = 3, the aspect ratio bound is small enough that the technique is useful in practice.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5559,A Newton Acceleration of the Weiszfeld Algorithm for Minimizing the Sum of Euclidean Distances,"The Weiszfeld algorithm for continuous location problems can be considered as an iteratively reweighted least squares method.  It exhibits linear convergence.  In this paper, a Newton type algorithm with similar simplicity is proposed to solve a continuous multifacility location problem with Euclidean distance measure.  Similar to the Weiszfeld algorithm, at each iteration the main computation can be solving a weighted least squares problem.  A Cholesky factorization of a symmetric positive definite band matrix, typically with a relatively small band width (e.g., a band width of two for a Euclidean location problem on a plane) is required.  This new algorithm can be regarded as a Newton acceleration to the Weiszfeld algorithm with fast global and local convergence.  The simplicity and efficiency of the proposed algorithm makes it particularly suitable for large-scale Euclidean location problems and parallel implementation.  Computational experience also suggests that the proposed algorithm performs remarkably well in the presence of degeneracy and near degeneracy.  In addition, it is proven to be globally convergent.  Although the local convergence analysis is still under investigation, computation results suggest that it is typically superlinearly convergent.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5560,The Efficient Computation of Sparse Jacobian Matrices Using Automatic Differentiation,"This paper is concerned with the efficient computation of sparse Jacobian matrices of nonlinear vector maps using automatic differentiation (AD).  Specifically, we propose the use of a graph coloring technique, bi-coloring, to exploit the sparsity of the Jacobian matrix J and thereby allow for the efficient determination of J using AD software.  We analyze both a direct scheme and a substitution process.  We discuss the results of numerical experiments indicating significant practical potential of this approach.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5561,Pseudospectra of Linear Operators,"The following contains mathematical formulae and symbols that may become distorted in ASCII text format. The advent of ever more powerful computers has brought with it a new way of conceiving some of the fundamental eigenvalue problems of applied mathematics.  If a matrix or linear operator ""A"" is far from normal, its eigenvalues or more generally its spectrum may have little to do with its behavor as measured by quantities such as ||A**N|| or ||exp(tA)||.  More may be learned by examining the sets in the complex plane known as the ""pseudospectra"" of A, defined by level curves of the norm of the resolvent, ||(zI - A)**-1||.  Five years ago, the author published a paper that presented computed pseudospectra of thirteen highly non-normal matrices arising in various applications.  Since that time, analogous computations have been carried out for differential and integral operators.  This paper, a companion to the earlier one, presents ten examples, each chosen to illustrate one or more mathematical or physical principles.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5562,Dealing with Dense Rows in the Solution of Sparse Linear Least Squares Problems,Sparse linear least squares problems containing a few relatively dense rows occur frequently in practice.  Straightforward solution of these problems could cause catastrophic fill and delivers extremely poor performance.  This paper studies a scheme for solving such problems efficiently by handling dense rows and sparse rows separately.  How a sparse matrix is partitioned into dense rows and sparse rows determines the efficiency of the overall solution process.  A new algorithm is proposed to find a partition of a sparse matrix which leads to satisfactory or even optimal performance.  Extensive numerical experiments are performed to demonstrate the effectiveness of the proposed scheme.  A MATLAB implementation is included.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5563,A Comparison of Optimization Heuristics for the Data Mapping Problem,"In this paper we compare the performance of six heuristics with
suboptimal solutions for the data mapping problem of two dimensional meshes that are used for the numerical solution of Partial Differential Equations(PDEs) on multicomputers.  The data mapping heuristics are evaluated with respect to seven criteria covering load balancing, interprocessor communication,flexibility and ease of use for a class of single-phase iterative PDE solvers. Our evaluation suggests that the simple and fast block distribution heuristic can be as effective as the other five complex and computationally expensive algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5564,Solving Unconstrained Discrete-time Optimal Control Problems Using Trust Region Method,"Trust region method for a class of large-scale minimization problems,
the unconstrained discrete-time optimal control (DTOC) problems, is considered. Although the trust region algorithms developed in [4] and [13] are very economical they lack the ability to handle the so-called hard case.  In this paper, we show that the trust region subproblem can be solved within an acceptable accuracy without forming the Hessian explicitly.  The new approach is based on the inverse power method for eigenvalue problem and possesses the ability to handle the hard case.  Our proposed approach leads to more efficient algorithms for DTOC problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5565,Locality-Conscious Load Balancing:  Connectionist Architectural Support,"Traditionally, in distributed memory architectures, locality maintenance and load balancing are seen as user level activities involving compiler and runtime system support in software.  Such software solutions require an explicit phase of execution, requiring the application to suspend its activities.  This paper presents the first (to our knowledge) architecture-level scheme for extracting locality concurrent with the application execution.  An artificial neural network coprocessor is used for dynamically monitoring processor reference streams to learn temporally emergent utilities of data elements in ongoing local computations.  This facilitates use of kernel-level load balancing schemes thus, easing the user programming burden.  The kernel-level scheme migrates data to processor memories evincing higher utilities during load-balancing.  The performance of an execution-driven simulation evaluating the proposed coprocessor is presented for three applications.  The applications chosen represent the range of load and locality fluxes encounted in parallel programs, with (a) static locality and load characteristics, (b) slowly varying localities for fixed datasetsizes and (c) rapidly fluctuating localities among slowly varying datasetsizes.  The performance results indicate the viability and success of the coprocessor in concurrently extracting locality for use in load balancing activities.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5566,Multiconfiguration Wavefunctions for Quantum Monte Carlo Calculations of First-row Diatomic Molecules,We use the variance minimization method to determine accurate wavefunctions for first-row homonuclear diatomic molecules.  The form of the wave function is a product of a sum of determinants and a generalized Jastrow factor.  One of the important features of the calculation is that we are including low-lying determinants corresponding to single and double excitations from the Hartree-Fock configuration within the space of orbitals whose atomic principal quantum numbers do not exceed those occurring in the Hartree-Fock configuration.  The idea is that near-degeneracy correlation is most effectively described by a linear combination of low-lying determinants whereas dynamic correlation is well described by the generalized Jastrow factor.  All the parameters occurring in both the determinantal and the Jastrow parts of the wave function are optimized.  The optimized wave functions recover 77-94% of the correlation energy in variational Monte Carlo and 91-99% of the correlation energy in diffusion Monte Carlo.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5567,Numerical Conformal Mapping Using Cross-ratios and Delaunay Triangulation,"We propose a new algorithm for computing the Riemann mapping of the unit disk to a polygon, also known as the Schwarz-Christoffel transformation. The new algorithm, CRDT, is based on cross-ratios of the prevertices, and also on cross-ratios of quadrilaterals in a Delaunay triangulation of the polygon. The CRDT algorithm produces an accurate representation of the Riemann mapping even in the presence of arbitrary long, thin regions in the polygon, unlike any previous conformal mapping algorithm.  We believe that CRDT can never fail to converge to the correct Riemann mapping, but the correctness and convergence proof depend on conjectures that we have so far not been able to prove.  We demonstrate convergence with computational experiments. The Riemann mapping has applications to problems in two-dimensional potential theory and to finite-difference mesh generation.  We use CRDT to produce a mapping and solve a boundary value problem on long, thin regions for which no other algorithm can solve these problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5568,Analysis of the Early Workload on the Cornell Theory Center IBM SP2,"Parallel computers have matured to the point where they are capable of running a significant production workload.  Characterizing this workload, however, is far more complicated than for the single-processor case. Besides the varying number of processors that may be invoked, the nodes themselves may provide differing computational resources (memory size, for example).  In addition, the batch schedulers may introduce further categories of service which must be considered in the analysis. The Cornell Theory Center (CTC) put a 512-node IBM SP2 system into production in early 1995.  Extended traces of batch jobs began to be collected in mid-1995 when the usage base became sufficiently large.  This paper offers an analysis of this early batch workload.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5569,Low-dimensional models of subcritical transition to turbulence,"In the past five years, working largely independently, five groups of researchers have proposed low-dimensional models of the behavior of parallel shear flows at high Reynolds numbers.  These models are compared, and it is found that they are more similar than their authors have recognized.  Among other similarities, most of them exhibit a threshold amplitude c=O(R**alpha) as R to infinity for some alpha less than -1, where R is the Reynolds number, for perturbations of the laminar state that may excite transition to turbulence.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5570,"Avalanches, Scaling, and Coherent Noise","We present a simple model of a dynamical system driven slowly by externally-imposed coherent noise.  Although the system never becomes critical in the sense of possessing spatial correlations of arbitrarily long range, it does organize into a stationary state characterized by avalanches with a universal power-law size distribution.  We explain the behavior of the model within a time-averaged approximation, and discuss its connection to the dynamics of earthquakes, the Gutenberg-Richter law, and to recent experiments on avalanches in rice piles.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5571,Structure and Efficient Jacobian Calculation,"Many computational tasks require the determination of the Jacobian matrix, at a given argument, for a large nonlinear system of equations. Calculation or approximation of a Newton step is a related task.  The development of robust automatic differentiation (AD) software allows for ""painless"" and accurate calculation of these quantities; however, straight forward application of AD software on large-scale problems can require an inordinate amount of computation.  Fortunately, large-scale systems of nonlinear equations typically exhibit either sparsity or structure in their Jacobian matrices.  In this paper we proffer general approaches for exploiting sparsity and structure to yield efficient ways to determine Jacobian matrices (and Newton steps) via automatic differentiation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5572,MultiMATLAB: MATLAB on Multiple Processors,"MATLAB(R), a commercial product of The MathWorks, Inc., has become one of the principal languages of desktop scientific computing.  A system is described that enables one to run MATLAB conveniently on multiple processors.  Using short, MATLAB-style commands like Eval, Send, Recv, Bcast, Min, and Sum, the user operating within one MATLAB session can start various processes in a fashion that maintains MATLAB's traditional user-friendliness. Multi-processor graphics is also supported.  The system currently runs under MPICH on an IBM SP2 or a network of Unix workstations, and extensions are planned to networks of PCs.  MultiMATLAB is potentially useful for education in parallel programming, for prototyping parallel algorithms, and for fast and convenient execution of easily parallelizable numerical computations on multiple processors.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5573,The Chebyshev Polynomials of a Matrix,"A Chebyshev polynomial of a square matrix A is a monic polynomial of specified degree that minimizes ||p(A)||(sub2). The study of such polynomials is motivated by the analysis of Krylov subspace iterations in numerical linear algebra. An algorithm is presented for computing these polynomials based on reduction to a semidefinite program which is then solved by a primal-dual interior point method. Examples of Chebyshev polynomials of matrices are presented, and it is noted that if A is far from normal, the lemniscates of these polynomials tend to approximate pseudospectra of A.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5574,Domain Decomposition Methods for Conformal Mapping and Eigenvalue Problems,"Domain decomposition is widely used in the numerical solution of elliptic boundary value problems. It is appealing in part because of improved efficiency and straightforward parallelization. Conceptually, domain decomposition often exploits a natural feature of elliptic problems: data at one point may have an exceedingly weak influence on the solution at a far-removed point. The application of domain decomposition to other elliptic problems is less fully developed. One such area is numerical conformal mapping. We introduce the SC Toolbox for Matlab, an interactive graphical software package for the Schwarz-Christoffel mapping of polygons. The Toolbox can be used for interior and exterior mapping from several fundamental domains. Elongations in the polygon lead to crowding, in which the preimages of affected vertices are exponentially close together. Such regions are candidates for decomposition. We describe CRDT, an overlapping subdomain method developed with Vavasis for numerical Schwarz-Christoffel mapping. The method uses Delaunay triangulation to decompose the polygon into overlapping quadrilaterals, which in turn define cross-ratios that form the basis of a nonlinear system. Each quadrilateral induces an embedding of the prevertices so that locally, the map can be computed accurately. Apparently CRDT can deal with any degree of crowding, as is demonstrated by examples. Another application in conformal mapping is in Symm's integral equation. An important feature of existing software for Symm's equation is the efficient treatment of corner singularities. Careful generalization to multiple domains allows this treatment to be preserved and extended. An onoverlapping formulation leads to a linear system that is ideal for Schur complementation. The resulting method asymptotically requires a fraction of the single-domain work and is easily parallelized. We also consider a domain decomposition algorithm for the Laplace eigenvalue problem on polygons. This method, an improvement on one described by Descloux and Tolley, searches for the matching of Fourier-Bessel expansions at each corner to locate eigenvalues. We apply the algorithm to the ""isospectral drums"" discovered by Gordon, Webb, and Wolpert to find 25 eigenvalues to 12 digits. The method is far more accurate and efficient than standard methods for this problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5575,Toward a Portable Parallel Library for Space-Time Adaptive Methods,"Space-time adaptive processing (STAP) refers to a class of methods for detecting targets using an array of sensors.  The output of the array is weighted using data collected from the sensors over a given period of time. An optimal method of calculating weights exists; however, this method is usually computationally impractical.  Therefore, various heuristic methods are used that approximate the optimal method.  These heuristics use many of the same operations and are computationally demanding. We are in the process of constructing a portable, parallel library of subroutines useful for constructing STAP heuristics.  As a first step in this process, we implemented one STAP heuristic, higher-order post-Doppler processing, using three different parallel methods on the IBM SP2 and the Intel Paragon: these methods characterize different parallel approaches to the STAP problem.  From implementing these algorithms, we have been able to identify components for our parallel library.  We propose models for some of the components and give preliminary timing results for the parallel methods.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5576,Workload Evolution on the Cornell Theory Center IBM SP2,"The Cornell Theory Center (CTC) put a 512-node IBM SP2 system into production in early 1995, and extended traces of batch jobs began to be collected in June of that year.  An analysis of the workload shows that it has not only grown, but that its characteristics have changed over time.  In particular, job duration increased with time, indicative of an expanding production workload. In addition, there was increasing use of parallelism. As the load has increased and larger jobs have become more frequent, the batch management software (IBM's LoadLeveler) has had difficulty in scheduling the requested resources.  New policies were established to improve the situation. This paper will profile how the workload has changed over time and give anin-depth look at the maturing workload.  It will examine how frequently certain resources are requested and analyze user submittal patterns.  It will also describe the policies that were implemented to improve the scheduling situation and their effect on the workload.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5577,Matrix Iterations: The Six Gaps Between Potential Theory and Convergence,"The theory of the convergence of Krylov subspace iterations for linear systems of equations (conjugate gradients, biconjugate gradients, GMRES, QMR, Bi-CGSTAB, ...) is reviewed.  For a computation of this kind, an estimated asymptotic convergence factor rho less than 1 can be derived by solving a problem of potential theory or conformal mapping.  Six approximations are involved in reducing the actual computation to this scalar estimate.  These six approximations are discussed in a systematic way and illustrated by a sequence of examples computed with tools of numerical conformal mapping and semidefinite programming.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5578,"Self-organized criticality, evolution, and extinction","Statistical analysis indicates that the fossil exctinction record is compatible with a distribution of extinction events whose frequency is related to their size by a power law with exponent tau approx. = 2.  This result is in agreement with preductions based on self-organized critical models of extinction, and might well be taken as evidence for self-organizing behavior in terrestrial evolution.  We argue however that there is a much simpler explanation for the appearance of a power law in terms of extinctions caused by stresses (either biotic or abiotic) to which species are subjected by their environment.  We give an explicit model of this process and discussits properties and implications for the interpretation of the fossil record.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5579,Separation of the Exchange-Correlation Potential into Exchange plus Correlation: an Optimized Effective Potential Approach,"Most approximate exchange-correlation functionals used within density functional theory are constructed as the sum of two distinct contributions for exchange and correlation.  Separating the exchange component from the entire functional is useful since, for exchange, exact relations exist under uniform density scaling and spin scaling.  In the past, accurate exchange-correlation potentials have been generated from essentially exact densities but they have not been correctly decomposed into their separate exchange and correlation components (except for two-electron systems).  Using a recently proposed method, equivalent to the solution of an optimized effective potential problem with the corresponding orbitals replaced by the exact Kohn-Sham orbitals, we obtain the separation according to the density functional theory definition.  We compare the results for the Ne and Be atoms with those obtained by the previously used appromixate separation scheme.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5580,Generalized gradient approximations to density functional theory: comparison with exact results,"In order to assess the accuracy of commonly used approximate exchange-correlation density functionals, we present a comparison of accurate exchange and correlation potentials, exchange energy densities and energy components with the corresponding approximate quantities.  Four systems are used as illustrative examples: the model system of two electrons in a harmonic potential and the De, Be and Ne atoms.  A new ingredient in the paper is the separation of the exchange-correlation potential into exchange and correlation according to the density functional theory definition.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5581,Transformation Techniques for Toeplitz and Toeplitz-plus-Hankel Matrices Part I. Transformations,"Transformations of the form A to C1AC2 are investigated that
transform Toeplitz and Toeplitz-plus-Hankel matrices into generalized Cauchy matrices.  C1 and C2 are matrices related to the discrete Fourier transformation or to various real trigonometric transformations.  Combining these results with pivoting techniques, in part II algorithms for Toeplitz and Toeplitz-plus-Hankel systems will be presented that are more stable than classical algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5582,Transformation Techniques for Toeplitz and Toeplitz-plus-Hankel Matrices Part II. Algorithms,"In the first part of the paper transformations mapping Toeplitz
and Toeplitz-plus-Hankel matrices into generalized Cauchy matrices were studied.  In this second part fast algorithms for LU-factorization and inversion of generalized Cauchy matrices are discussed.  It is shown that the combination of transformation pivoting techniques leads to algorithms for indefinite Toeplitz and Toeplitz-plus-Hankel matrices that are more stable than the classical ones  Special attention is paid to the symmetric and hermitian cases.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5583,Piecewise Differentiable Minimization for Ill-posed Inverse Problems,"Based on minimizing a piece wise differentiable lp function subject
to a single inequality constraint, this paper discusses algorithms for a discretized regularization problem for ill-posed inverse problems.  We examine computational challenges of solving this regularization problem.  Possible minimization algorithms such as the steepest descent method, iteratively weighted least squares (IRLS) method and a recent globally convergent affine scaling Newton approach are considered.  Limitations and efficiency of these algorithms are demonstrated using the geophysical travel time tomographic inversion and image restoration applications.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5584,On the Efficient Methods to Solve ODEs and BVPs Using Automatic Differentiation,"A large number of physical phenomena are modeled by a system of ODEs
or a system of implicit ODEs.  We demonstrate applicability of automatic differentiation (AD) for solving: (1) Boundary value problems in ODEs and implicit ODEs. (2) Initial state and parameter estimation problems. The impact of using AD is two fold.  Firstly, efficient methods for computing the gradient vectors and Jacobian matrices have been developed using AD. Secondly the process of getting derivatives via AD is robust, more user friendly, and provides error free derivatives.  Furthermore, techniques using AD have been developed which exploit structure in the user's computation, and particularly the structure we observe in boundary value problems or state/parameter estimation problems.  We demonstrate by a few experiments the efficiency gained by the usage of AD in solving these problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5585,Scalable Parallel Electronic Structure Calculations on the IBM SP2,"We have developed a highly efficient and scalable electronic 
structure code for parallel computers using message passing.  The algorithm takes advantages of the natural parallelism in quantum chemistry problems to obtain very high performance even on a large number of processors.  Most of the terms which scale cubically with respect to the number of atoms have been eliminated allowing the treatment of very large systems.  It uses one of the most precise versions of Density Functional Theory, namely Self-Interaction Corrected Density Functional Theory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5586,The Procrustes Problem for Orthogonal Stiefel Matrices,"(This abstract contains mathematical symbols that may not reproduce wellin ASCII text.) In this paper we consider the Procrustes problem on the manifold of orthogonal Stiefel matrices.  That is, given matrices A epsilon R(m*k), B epsilon R(m*p), m greater tahn or equal to p greater than or equal to k, we seek the minimum of ||A - BQ||2 for all matrices Q epsilon R(p*k), QTQ = I(k*k). We introduce a class of relaxation methods for generating minimizing sequences and offer a geometric interpretation of these methods.  Results of numerical experiments illustrating the convergence of the methods are given.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5587,Stable and Efficient Solution of Weighted Least-Squares Problems with Applications in Interior Point Methods,"In this thesis, we consider two closely related problems.  The first is a full-rank weighted least-squares problem with a weight matrix that is positive definite, diagonal, and extremely ill conditioned.  The ill-conditioning can cause standard algorithms to compute solutions with, in some cases, no digits of accuracy.  Theory suggests the existence of an algorithm that will compute an accurate solution despite the ill-conditioning in the weight matrix.  We describe a new algorithm, the Complete Orthogonal Decomposition (COD) Algorithm, for solving the weighted least-squares problem and show that it has this desirable property.  In addition, the COD Algorithm is based on standard, well-understood techniques and is straightforward to implement. A natural application for the weighted least-squares problem described in the previous paragraph is interior point methods for linear programming.  We discuss the problem in this context, and describe how the COD algorithm can be extended and used in this setting.  Unlike other algorithms, this one is stable for interior point methods without assuming nondegeneracy in the linear programming instance.  Computational experiments indicate that it is more reliable than other algorithms when the problem is near degenerate. The second problem involves a particular interior point algorithm.  In 1994, Vavasis and Ye proposed a new primal-dual path-following interior point method, the layered-step interior point (LIP) method.  This algorithm interleaves traditional steps with longer, layered least-squares (LLS) steps.  Computation of a LLS step requires solving a weighted least-squares problem similar to the one described above, but the weight matrix also has the property that the weights fall into well-separated groups.  This additional structure allows the problem to be broken down into smaller, constrained problems with well-conditioned weight matrices.  The smaller problems can then be solved stably with standard algorithms, and the LLS step can be computed. Vavasis and Ye did not propose a particular algorithm for solving the LLS problem.  In this thesis, we present an algorithm based on Cholesky factorization.  The algorithm is such that a modified version of the sparse Cholesky code of Ng and Peyton of Oak Ridge National Laboratories can be used. Thus, the theoretical results are straight forward, and this algorithm proves to be accurate and efficient in practice.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5588,Structure and Efficient Hessian Calculation,"Modern methods for numerical optimization calculate (or approximate) the matrix of second derivatives, the Hessian matrix, at each iteration.  The recent arrival of robust software for automatic differentiation allows for the possibility of automatically computing the Hessian matrix, and the gradient, given a code to evaluate the objective function itself.  However, for large-scale problems direct application of automatic differentiation may be unacceptably expensive.  Recent work has shown that this cost can be dramatically reduced in the presence of sparsity.  In this paper we show that for structured problems it is possible to apply automatic differentiation tools in an economical way - even in the absence of sparsity in the Hessian.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5589,Non-normal Dynamics and Hydrodynamic Stability,"This thesis explores the interaction of non-normality and nonlinearity incontinuous dynamical systems.  A solution beginning near a linearly stable fixed point may grow large by a linear mechanism, if the linearization is non-normal, until it is swept away by nonlinearities resulting in a much smaller basin of attraction than could possibly be predicted by the spectrum of the linearization.  Exactly this situation occurs in certain linearly stable shear flows, where the linearization about the laminar flow may be highly non-normal leading to the transient growth of certain small disturbances by factors which scale with the Reynolds number. These issues are brought into focus in Chapter 1 through the study of atwo-dimensional model system of ordinary differential equations proposed by Trefethen, et al. [Science, 261, 1993]. 
 In Chapter 2, two theorems are proved which show that the basin of attraction of a stable fixed point, in systems of differential equations combining a non-normal linear term with quadratic nonlinearities, can decrease rapidly as the degree of non-normality is increased, often faster than inverse linearly.
 Several different low-dimensional models of transition to turbulence are examined in Chapter 3.  These models were proposed by more than a dozen authors for a wide variety of reasons, but they all incorporate non-normal linear terms and quadratic nonlinearities.  Surprisingly, in most cases, the basin of attraction of the ""laminar flow"" shrinks much faster than the inverse Reynolds number.
 Transition to turbulence from optimally growing linear disturbances, streamwise vortices, is investigated in plane Poiseuille and plane Couette flows in Chapter4.  An explanation is given for why smaller streamwise vortices can lead to turbulence in plane Poiseuille flow.  In plane Poiseuille flow, the transient linear growth of streamwise streaks caused by non-normality leads directly to a secondary instability.
 Certain unbounded operators are so non-normal that the evolution of infinitesimal perturbations to the fixed point is entirely unrelated to the spectrum, even as i to infinity.  Two examples of this phenomenonare presented in Chapter 5.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5590,Optimal Portfolio Selection with Fixed Transactions Costs in the presence of Jumps and Random Drift,"In this paper, we study the general problem of optimal portfolio selection with fixed transactions costs in the presence of jumps.  We extend the analysis of Morton and Pliska to this setting by modeling the return processes of the risky assets in the investor's portfolio as jump-diffusion processes and derive the expression for the related optimal stopping time problem of a Markov process with jumps and explicitly solve it in the situation when the portfolio consists only of one risky asset.  We also provide an asymptotic analysis of our model with one risky asset following the ideas of Wilmott and Atkinson.  In the process, we also obtain a solution for the ""Merton problem"" generalized to the situation when there is credit risk.  Finally, we consider the case where the drift of the stockprice process is random and unobservable and obtain expressions for the optimal trading policies.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5591,European Option Pricing with Fixed Transaction Costs,"In this paper, we study the problem of European option pricing in the presence of fixed transaction costs.  The problems of optimal portfolio selection and option pricing in the presence of proportional transaction costs has been extensively studied in the mathematical finance literature.  However, much less is known when we have fixed transaction costs. In this paper, we show that calculating the price of an European optioninvolves calculating the value functions of two stochastic impulse control problems and we obtain the explicit expressions for the resultant quasi-variational ine qualities satisfied by the value functions and then carry out a numerical calculation of the option price.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5592,A critical assessment of the Self-Interaction Corrected Local Density Functional method and its algorithmic implementation,"We calculate the electronic structure of several atoms and small molecules by direct minimization of the Self-Interaction Corrected Local Density Approximation (SIC-LDA) functional.  To do this we first derive an expression for the gradient of this functional under the constraint that the orbitals be orthogonal and show that previously given expressions do not correctly incorporate this constraint.  In our atomic calculations the SIC-LDA yields total energies, ionization energies and charge densities that are superior to results obtained with the Local Density Approximation (LDA).  However, for molecules SIC-LDA gives bond lengths and reaction energies that are inferior to those obtained from LDA.  The nonlocal BLYP functional, which we include as a representative GGA functional, out performs both LDA and SIC-LDA forall ground state properties we considered.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5593,Monte Carlo Optimization of Trial Wave Functions in Quantum Mechanics and Statistical Mechanics,"This review covers applications of quantum Monte Carlo methods to quantum mechanical problems in the study of electronic and atomic structure, as well as applications to statistical mechanical problems both of static and dynamic nature.  The common thread in all these applications is optimization of many-parameter trial states, which is done by minimization of the variance of the local energy or, more generally for arbitrary eigenvalue problems, minimization of the variance of the configurational eigenvalue.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5594,"Symmetry, Nonlinear Bifurcation Analysis, and Parallel Computation","In the natural and engineering sciences the equations which model physical systems with symmetry often exhibit an invariance with respect to a particular group ""G"" of linear transformations. ""G"" is typically a linear representation of a symmetry group ""g"" which characterizes the symmetry of the physical system.  In this work, we will discuss the natural parallelism which arises while seeking families of solutions to a specific class of nonlinear vector equations which display a special type of group invariance, referred to as equivariance.  The inherent parallelism stems for a global de-coupling, due to symmetry, of the full nonlinear equations which effectively splits the original problem into a set of smaller problems.  Numerical results from asymmetry-adapted numerical procedure, (MMcontcm.m), written in MultiMATLAB are discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5595,Model fermion Monte Carlo with correlated pairs II,Correlated dynamics can produce stable algorithms for excited states of quantum many-body problems.  We study a variety of harmonic oscillator problems to demonstrate the kinds of correlations needed.  We show that marginally correct dynamics that produce a stable overlap with an antisymmetrictrial function give the correct fermion ground state.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5596,Quality Mesh Generation in Higher Dimensions,"We consider the problem of triangulating a d-dimensional region.  Our mesh generation algorithm, called QMG, is a qradtree-based algorithm that can triangulate any polyhedral region including nonconvexregions with holes.  Furthermore, our algorithm guarantees a bounded aspect ratio triangulation provided that the input domain itself has no sharp angles. Finally, our algorithm is guaranteed never to over refine the domain in the sense that the number of simplices produced by QMG is bounded above by a factor times the number produced by any competing algorithm, where the factor depends on the aspect ratio bound satisfied by the competing algorithm. The QMG algorithm has been implemented in C++ and is used as a mesh generator for the finite element method.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5597,Local correlation energies of two-electron atoms and model systems,"We present nearly-local definitions of the correlation energy
density, and its potential and kinetic components, and evaluate them for several two-electron systems.  This information should provide valuable guidance in constructing better correlation functionals than those in common use.  In addition, we demonstrate that the quantum chemistry and the density functional definitions of the correlation energy rapidly approach one another with increasing atomic number.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5598,Accurate Solution of Weighted Least Squares by Iterative Methods,"We consider the weighted least-squares (WLS) problem with a very ill-conditioned weight matrix.  Weighted least-squares problems arise in many applications including linear programming, electrical networks, boundary value problems, and structures.  Because of roundoff errors, standard iterative methods for solving a WLS problem with ill-conditioned weights may not give the correct answer.  Indeed, the difference between the true and computed solution (forward error) may be large.  We propose an iterative algorithm, called MINRES-L, for solving WLS problems.  The MINRES-L method is the application of MINRES, a Krylov-space method due to Paige and Saunders, to a certain layered linear system.  Using a simplified model of the effects of round off error, we prove that MINRES-L gives answers with small forward error.  We present computational experiments for some applications.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5604,Hedging a Portfolio of derivatives by Modeling Cost,"We consider the problem of  hedging the loss of a given portfolio of 
derivatives using a set of more liquid derivative instruments. We illustrate why the typical mathematical formulation for this hedging problem is ill-posed.  We propose to determine a hedging portfolio by minimizing a proportional cost subject to an upper bound on the hedge risk; this bound is typically slightly larger than the optimal hedge risk achievable without cost consideration. We illustrate that  the optimal hedging portfolio obtained by the proposed method is attractive since it consists of fewer instruments with a comparable risk.  Finally  we illustrate the importance of modeling volatility uncertainty in hedge risk minimization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5605,A Nuprl-PVS Connection: Integrating Libraries of Formal Mathematics.,"We describe a link between the Nuprl and PVS proof systems that 
enables users to access PVS from the Nuprl theorem proving environment, to import PVS theories into the Nuprl library, and to browse both Nuprl and PVS theories in a unified formal framework. The combined system is a first step towards a digital library of formalized mathematics that can be shared and used in complex applications.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5606,"Herbivore: A Scalable and Efficient Protocol for Anonymous 
Communication","Anonymity is increasingly important for networked applications 
amidst concerns over censorship and privacy. In this paper, we describe Herbivore, a peer-to-peer, scalable, tamper-resilient communication system that provides provable anonymity and privacy. Building on dining cryptographer networks, Herbivore scales by partitioning the network into anonymizing cliques. Adversaries able to monitor all network traffic cannot deduce the identity of a sender or receiver beyond an anonymizing clique. In addition to strong anonymity, Herbivore simultaneously provides high efficiency and scalability, distinguishing it from other anonymous communication protocols. Performance measurements from a prototype implementation show that the system can achieve high bandwidths and low latencies when deployed over the Internet.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5607,Automated Application-level Checkpointing of MPI Programs,"Because of increasing hardware and software complexity, the running 
time of many computational science applications is now more than the mean-time-to-failure of high-performance computing platforms. Therefore, computational science applications need to tolerate hardware failures.     In this paper, we focus on the stopping failure model in which a faulty process hangs and stops responding to the rest of the system.  We argue that tolerating such faults is best done by an approach called application-level coordinated non-blocking checkpointing, and that existing fault-tolerance protocols in teh literature are not suitable for implementing this approach.     In this paper, we present a suitable protocol, and show how it can be used with a precompiler that instruments C/MPI programs to save application and MPI library state. An advantage of our approach is that it is independent of the MPI implementation.  We present experimental results that argue that the overhead of using our system can be small.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5608,Semi-supervised Clustering with User Feedback,"We present a new approach to clustering based on the observation 
that ``it is easier to criticize than to construct.''  Our approach of {\em semi-supervised clustering} allows a user to iteratively provide feedback to a clustering algorithm.  The feedback is incorporated in the form of constraints which the clustering algorithm attempts to satisfy on future iterations.  These constraints allow the user to guide the clusterer towards clusterings of the data that the user finds more useful.  We demonstrate semi-supervised clustering with a system that learns to cluster news stories from a Reuters data set. %This paper presents semi-supervised clustering, a new approach to %clustering that allows users to provide advice to the clustering %algorithm that guides it towards clusterings they prefer. %Semi-supervised clustering begins with traditional, fully unsupervised %clustering to find an initial clustering of the data.  The clustered %data is then presented to the user so that they may critique it.  User %feedback provides a set of constraints that the system tries to %satisfy to find a new clustering that the user prefers.  This process %of presenting clustered data to the user, and refining the clustering %in response to user feedback, is repeated until the user is happy with %the clusters.  We present a clustering algorithm that learns from user %feedback to find a clustering metric that yields clusters the user is %happy with.  We demonstrate the algorithm on the Reuters and 20 %Newsgroups domains.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5609,A Logic of Events,"There is a well-established theory and practice for creating 
correct-by-construction functional programs by extracting them from constructive proofs of assertions of the form ""For all x:A there exists y:B.R(x,y))."" There have been several efforts to extend this methodology to concurrent programs, say by using linear logic, but there is no practice and the results are limited. In this paper we define a logic of events that justifies the extraction of correct distributed processes from constructive proofs that system specifications are achievable, and we describe an implementation of an extraction process in the context of constructive type theory. We show that a class of message automata, similar to IO automata and to active objects, are realizers for this logic. We provide a relative consistency result for the logic. We show an example of protocol derivation in this logic, and show how to embed temporal logics such as TLA+ in the event logic.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5610,"Parametrized Tractability of Edge-Disjoint Paths on Directed Acyclic 
Graphs","Given a graph and pairs $s_i t_i$ of terminals, the edge-disjoint 
paths problem is to determine whether there exist $s_i t_i$ paths that do not share any edges. We consider this problem on ditected acyclic graphs. It is known to be NP-complete and solvable in time $n^{O(k)}$ where $k$ is the number of paths. It has been a long-standing open question whether it is fixed-parameter tractable in $k$. We resolve this question in the negative: we show that the problem is $W[1]$-hard. In fact it remains $W[1]$-hard even if the demand graph consists of two sets of parallel edges. On a positive side, we give an $O(k! n)$ algorithm for the special case when $G$ is acyclic and $G+H$ is Eulerian, where $H$ is the demand graph. We generalize this result (1) to the case when $G+H$ is ``nearly"" Eulerian, (2) to an analogous special case of the unsplittable flow problem.  Finally, we consider a related NP-complete routing problem when only the first edge of each path cannot be shared, and prove that it is fixed-parameter tractable on directed graphs.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5611,"Quantified Constraint Satisfaction Problems: Closure Properties, 
Complexity, and Proof Systems","There has been much prior work on understanding the complexity of 
the constraint satisfaction problem (CSP), a broad framework capturing many combinatorial problems. This paper studies a natural and strict generalization of the CSP,  the quantified constraint satisfaction problem (QCSP). In the CSP, all variables are existentially quantified; in the QCSP, some variables may be universally quantified. Our contributions include proof systems for the QCSP and the identification of three broad tractable subclasses of the QCSP. Central to our study is the algebraic notion of closure properties of constraints, which has been previously used to study the CSP.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5612,On the Complexity of the Horn Theory of REL,"We show that the universal Horn theory of relational Kleene algebras 
is Pi-1-1-complete.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5613,A Linearly Typed Assembly Language,"Today's type-safe low-level languages rely on garbage collection to 
recycle heap-allocated objects safely.  We present LTAL, a safe, low-level, yet simple language that ``stands on its own'': it guarantees safe execution within a fixed memory space, without relying on external run-time support.  We demonstrate the expressiveness of LTAL by giving a type-preserving compiler for the functional core of ML.  But this independence comes  at a steep price: LTAL's type system imposes a draconian discipline of linearity that ensures that memory can be reused safely, but prohibits any useful kind of sharing.  We present the results of experiments with a prototype LTAL system that show just how high the price of linearity can be.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5614,First-Class Phantom Types,"Classical phantom types are datatypes in which type constraints are 
expressed using type variables that do not appear in the datatype cases themselves.  They can be used to embed typed languages into Haskell or ML.  However,  while such encodings guarantee that only well-formed data can be constructed, they do not permit type-safe deconstruction without additional tagging and run-time checks.  We introduce first-class phantom types, which make such constraints explicit via type equations.  Examples of first-class phantom types include typed type representations and typed higher-order abstract syntax trees. These types can be used to support typed generic functions, dynamic typing, and staged compilation in higher-order, statically typed languages such as Haskell or Standard ML.  In our system, type constraints can be equations between type constructors as well as type functions of higher-order kinds.  We prove type soundness and decidability for a Haskell-like language extended by first-class phantom types.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5615,"Quantified Constraint Satisfaction and Small Commutative Conservative 
Operations","The constraint satisfaction problem (CSP) is a broad framework 
capturing many combinatorial search problems. A natural and strict generalization of the CSP is  the quantified constraint satisfaction problem (QCSP). The CSP involves deciding the truth of constraint networks where all variables are existentially quantified; the QCSP is defined similarly, but variables may be both existentially and universally quantified. While the CSP and QCSP are in their general formulation intractable, they can be parameterized by restricting the constraint language, that is, the types of constraints that are permitted in problem instances. Much attention has been directed towards classifying the complexity of all constraint languages in the case of the CSP. In this paper, we continue the recently initiated study of  QCSP complexity by identifying a   new family of tractable constraint languages, namely, constraint languages over domains of small size that are closed under a commutative conservative operation. This gives the first QCSP tractability result based on binary operations which may be non-associative. We also give a complete classification of maximal constraint languages over domains of size three.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5616,"TeXQuery: A Full-Text Search Extension to XQuery (Part III: Use Cases 
Solutions)","This report describes the TeXQuery use cases solutions. TeXQuery is 
a full-text search extension to XQuery.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5617,"TeXQuery: A Full-Text Search Extension to XQuery (Part I: Language 
Specification)","This report describes the TeXQuery language specification. TeXQuery 
is a full-text search extension to XQuery.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5618,"TeXQuery: A Full-Text Search Extension to XQuery (Part II: Formal 
Semantics)","This report describes the formal semantics of TeXQuery. TeXQuery is 
a full-text search extension to XQuery.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5619,KAT-ML: An Interactive Theorem Prover for Kleene Algebra with Tests,"KAT-ML is an interactive theorem prover for Kleene algebra with 
tests (KAT).  The system is designed to reflect the natural style of reasoning with KAT that one finds in the literature.  We describe the main features of the system and illustrate its use with some examples.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5620,Computability Classes for Enforcement Mechanisms,"A precise characterization of those security policies enforceable by 
program rewriting is given.  This characterization exposes and rectifies problems in prior work on execution monitoring, yielding a more precise characterization of those security policies enforceable by execution monitors and a taxonomy of enforceable security policies.  Some but not all classes can be identified with known classes from computational complexity theory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5621,An Optimizing Compiler for Batches of Temporal Logic Formulas,"Model checking based on validating temporal logic formulas has 
proven practical and effective for numerous applications from verifying hardware designs to proving the correctness of software.  As systems based on this approach have become more mainstream, a need has arisen to deal effectively with large batches of formulas over a common model.  Presently, most systems validate formulas one at a time, with little or no interaction between validation of separate formulas.  This is the case despite the fact that for a wide range of applications a certain level of redundancy between domain-related formulas can be anticipated. This paper presents an optimizing compiler for batches of temporal logic formulas.  A component of the Carnauba Model Checking System, this compiler addresses the need to handle batches of temporal logic formulas by leveraging the framework common to optimizing programming language compilers.  Just as a traditional optimizing compiler attempts to exploit redundancy and other solvable properties in programs to reduce the demand on a runtime system, this compiler exploits similar properties in groups of formulas to reduce the demand on a model checking engine.  Optimizations are performed via a set of distinct, interchangeable optimization passes operating on a common intermediate representation.  The intermediate representation is capable of representing formulas over the full modal mu-calculus, and the optimization techniques are applicable to any temporal logic that can be translated into the modal mu-calculus.  The compiler offers a unified framework for expressing well understood single-formula optimizations as well as numerous inter-formula optimizations that capitalize on redundancy and logical implication.  The result is a system that, when applied to a potentially heterogeneous collection of formulas over a common problem domain, is able to measurably reduce the time and space requirements of the subsequent model checking engine.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5622,On the Representation of Kleene Algebras with Tests,"We investigate conditions under which a given Kleene algebra with 
tests is  isomorphic to an algebra of binary relations. Two simple separation properties are  identified that, along with star-continuity, are sufficient for nonstandard relational  representation. An algebraic condition is identified that is necessary and sufficient  for the construction to produce a standard representation.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5623,A comparison of eager and lazy class initialization in Java,"We prove that under some natural condition eager class 
initialization of a Java program P, as proposed in Kozen and Stillerman (2002), does not depend on the choice of a topological sort of the graph of class initialization dependencies of P. We also identify further natural conditions under which the eager and lazy class initializations of P assign the same initial values to the static fields of P. The latter result partially solves a problem raised in Kozen and Stillerman (2002).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5624,TeXQuery: A Full-Text Search Extension to XQuery,"One of the key benefits of XML is its ability to represent a mix of 
structured and unstructured (text)  data. Although current XML query languages such as XPath and XQuery can express rich queries  over structured data, they can only express very rudimentary queries over text data. We thus propose  TeXQuery, which is a powerful full-text search extension to XQuery. TeXQuery provides a rich set of  fully composable full-text search primitives, such as Boolean connectives, phrase matching, proximity  distance, stemming and thesauri. TeXQuery also enables users to seamlessly query over both structured  and text data by embedding TeXQuery primitives in XQuery, and vice versa. Finally, TeXQuery supports  a flexible scoring construct that can be used to score query results based on full-text predicates. TeX- Query is one of the proposals submitted to the W3C Full-Text Task Force, whose charter is to extend  XQuery with full-text search capabilities.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5625,"Resolving Constrained Existential Queries over Context-Sensitive 
Analyses","A context-sensitive analysis is an analysis in which program 
elements are interpreted with respect to the context in which they occur.  For analyses on imperative languages, this often refers to considering the behavior of called procedures with respect to the calling-stack contexts that precede them.  Algorithms for performing or approximating these types of analyses make up the core of interprocedural program analysis and are pervasive; having applications in program optimization, checkpointing, and model checking.  This paper presents an abstraction of a popular form of context-sensitive analysis based on iteratively encapsulating the cumulative effect of a recurring piece of code.  Given an analysis fitting this abstraction, a technique is presented for resolving queries of the form: Is there an occurring context, subject to a given stack-context constraint, in which a particular set of facts holds at a particular location?  This practical technique, based on manipulating regular languages, is capable not only of answering queries of this form, but also of generating a compact mechanism for dynamically applying the output of the analysis to contexts as they occur.  A comprehensive example is presented along with performance data on a case study code.  Finally, a selection of potential applications is discussed.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5626,Region Analysis for Imperative Languages,"This paper presents a region inference framework designed 
specifically for imperative programs with dynamic allocation and destructive updates. Given an input program, the algorithm automatically translates it into an output program with region annotations on procedures and allocation commands, and with explicit region creation and removal commands. Our framework formulates the analysis problem as a three-step algorithm. In the first phase, it infers region annotations for record declarations in the input language. Second, it performs a unification-based flow analysis of the program, inferring region types at each point in the program. In particular, it determines region types for allocation commands and procedure calls. In the third phase, it uses a single-pass algorithm to inspect each point in the program and insert region creation and removal commands in the control flow of the output program. This transformation ensures that regions are live whenever they are being used, while minimizing region lifetimes. The algorithm is simple, efficient, and provably correct. Furthermore, we show that the framework can be extended with more aggressive analyses (at the expense of making it less modular or more complex), such as interprocedural region liveness or shape analysis, to further improve the accuracy and performance of memory management. More generally, our framework allows existing analysis technology for imperative languages, such as points-to or shape analysis, to be easily integrated and applied to the region inference problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5627,Kleene Algebra with Tests and the Static Analysis of Programs,"We propose a general framework for the static analysis of programs 
based on Kleene algebra with tests (KAT).  We show how KAT can be used to statically verify compliance with safety policies specified by security automata.  We prove soundness and completeness over relational interpretations.  We illustrate the method on an example involving the correctness of a device driver.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5628,The Inlined Reference Monitor Approach to Security Policy Enforcement,"Embedding security enforcement code into applications is an 
alternative to traditional security mechanisms.  This dissertation supports the thesis that such Inlined Reference Monitors, or IRMs, offer many advantages and are a practical option in modern systems.  IRMs enable flexible general-purpose enforcement of security policies, and they are especially well suited for extensible systems and other non-traditional platforms.  IRMs can exhibit similar, or even better, performance than previous approaches and can help increase assurance by contributing little to the size of a trusted computing base.  Moreover, IRMs' agility in distributed settings allows for their cost-effective and trustworthy deployment in many scenarios. In this dissertation, IRM implementations are derived from formal automata-based specifications of security policies.  Then, an IRM toolkit for Java is described in detail.  This Java IRM toolkit uses an imperative policy language that allows a security policy, in combination with the details of its enforcement, to be given in a single complete specification.  Various example policies, including the stack-inspection policy of Java, illustrate the approach.  These examples shed light on practical issues in policy specification, the support needed from an IRM toolkit, and the advantages of the IRM approach.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5629,On the Completeness of Full-Text Search Languages for XML,"We study formal properties of full-text search languages for XML. 
Our main contribution is the development of a formal model for full-text search based on the positions of tokens in XML nodes. Building on this model, we define a full-text calculus based on first-order logic, and a full-text algebra based on the relational algebra. We show that the full-text calculus and algebra are equivalent even in the presence of arbitrary position-based predicates, such as distance predicates and phrase matching. This suggests a notion of completeness for full-text languages. None of the full-text search languages that we are aware of are complete under the above characterization. We propose a new full-text language that is complete and naturally generalizes existing full-text languages. Our formalization in terms of the relational model can also serve as the basis for (a) joint optimization of structured and full-text search queries, and (b) ranking full-text search query results by leveraging existing work on the probabilistic relational model.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5630,"Machine Learning for Coreference Resolution: Recent Successes and 
Future Challenges","State-of-the-art coreference resolution systems are mostly 
knowledge-based systems that operate by relying on a set of hand-crafted coreference resolution heuristics. Recently, however, machine learning approaches have been shown to be a promising way to build coreference resolution systems that are more robust than their knowledge-based counterparts. Nevertheless, there are several key issues in existing machine learning approaches to the problem that are either not explored or being overlooked, potentially leading to a deterioration of system performance. This document examines each of these issues in detail and suggests potential solutions.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5631,"Prediction of protein-protein interactions and the interaction site 
from sequence information - an extensive study of the co-evolution model","This paper studies new variants of the co-evolution model for 
prediction of protein-protein interactions from sequence information. Given two query proteins, the method uses information extracted from a database search to generate a multiple alignment and compute the likelihood that the two proteins interact. The model uses four elements, starting from the correlated divergence between proteins from different species, through potentials of correlated mutations, charge and hydrogen bonds. The significance of these measures is estimated from large populations of interacting and non interacting protein pairs. A variant over an EM algorithm is used to identify the subset of the database proteins (the homologs of the query proteins) that are more likely to interact, and a modified correlated mutations model is employed to maximize the strength of the signals.       The algorithm not only tries to suggest if two proteins interact, but also attempts to detect the localized binding box interaction region, information that is hardly ever available. We tune and test our model over a large set of protein interactions we extract from BIND.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5632,Distributed Blinding for ElGamal Re-encryption,"A protocol is given that allows a set of n servers to cooperate and 
produce an ElGamal ciphertext encrypted under one key from an ElGamal ciphertext encrypted under another, but without plaintext ever becoming available.  The protocol is resilient to floor(n-1)/3 of the servers being compromised and requires no assumptions about execution speeds or message delivery delays.  Two new building blocks employed---a distributed blinding protocol and verifiable dual encryption proofs---could have uses beyond re-encryption protocols.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5633,"A comprehensive study of the notion of functional link between   genes 
based on microarray data, promoter signals, protein-protein   interactions and pathway analysis","It is commonly accepted that genes with similar expression profiles  
 are functionally related.  However, so far no clear distinction has   been made as for the type of the functional link between genes as   suggested by microarray data.  Similarly expressed genes can be part   of the same complex as interacting partners; they can participate in   the same pathway without interacting directly; they can perform   similar functions; or they can simply have similar regulatory   sequences.   Here we embark on a rigorous study of the notion of functional link   as implied from expression data.  We analyze different similarity   measures of gene expression profiles and assess their usefulness and   robustness in detecting biological relationships by comparing the   similarity scores with results obtained from databases of   interacting proteins, promoter signals, and cellular pathways, as   well as through sequence comparisons and pathway modeling.  We also   introduce new similarity measures we specifically developed for the   analysis of expression data.  These measures are based on   statistical analysis and better discriminate genes which are   functionally nearby and faraway.   With the optimized similarity measures we proceed to analyze other   aspects of this data. Specifically, we introduce a method of   inferring the type of relationship by correlating the expression   data with all the other data sets.  This method allows us to not   only predict when genes are functionally related but also to suggest   how they are related. We then cluster the data using clustering   algorithms that are specially tailored to deal with noisy data.   Finally we propose methods for assessing the significance of   clusters and study the correspondence between gene clusters and   biochemical pathways.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5634,"The URMS-RMS hybrid algorithm for fast and sensitive local protein 
structure alignment","We present an efficient and sensitive hybrid algorithm for   local 
structure alignment of a pair of 3D protein structures.  The   hybrid algorithm employs both the URMS (Unit-vector Root Mean   Squared) metric and the RMS metric.  Initial transformations   (rotations) are identified using the algorithm. These   rotations are then clustered and an RMS based dynamic programming   algorithm is invoked to find the maximal local similarities for   representative rotations of the clusters.  Our algorithm searches   efficiently the transformation space using a fast screening   protocol.  Given the transformation based parameters, the algorithm   rigorously finds the optimal alignments.  Statistical significance   of the alignments is estimated using a model that accounts for both   the score of the match and the RMS.   We tested our algorithm over the SCOP classification of protein   domains.  Our algorithm performs very well, its main advantages   being (1) it combines the RMS and the URMS metrics (2) it searches   extensively the transformation space (3) it can detect complex   similarities and structural repeats (4) it is symmetric.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5635,"Type  Theoretical Foundations for Data Structures, Classes, and Objects","In this thesis we explore the question of how to represent 
programming data structures in a constructive type theory. The basic data structures in programing languages are records and objects. Most known papers treat such data structure as primitive. That is, they add new primitive type constructors and supporting axioms for records and objects. This approach is not satisfactory. First of all it complicates a type theory a lot. Second, the validity of the new axioms is not easily ablished. As we will see the naive choice of axioms can lead to contradiction even in the simplest cases.   We will show that records and objects can be defined in a powerful enough type theory. We will also show how to use these type constructors to define abstract data structure.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5636,Dynamic Security Labels and Noninterference,"This paper explores information flow control in systems in which the 
security classes of data can vary dynamically. Information flow policies provide the means to express strong security requirements for data confidentiality and integrity. Recent work on security-typed programming languages has shown that information flow can be analyzed statically, ensuring that programs will respect the restrictions placed on data. However, real computing systems have security policies that vary dynamically and that cannot be determined at the time of program analysis. For example, a file has associated access permissions that cannot be known with certainty until it is opened. Although one security-typed programming language has include support for dynamic security labels, there has been no examination of whether such a mechanism can securely control information flow.  In this paper, we present an expressive language-based mechanism for securely manipulating dynamic security labels.  The mechanism is presented both in the context of a Java-like programming language and, more formally, in a core language based on the typed lambda calculus. This core language is expressive enough to encode previous dynamic label mechanisms; as importantly, any well-typed program is provably secure because it satisfies noninterference.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5637,Distributed Trust:  Supporting Fault-tolerance and Attack-tolerance,"Fault-tolerance and attack-tolerance are crucial for implementing a 
trustworthy service.  An emerging thread of research investigates interactions between fault-tolerance and attack-tolerance---specifically, the coupling of replication with threshold cryptography for use in environments satisfying weak assumptions.  This coupling yields a new paradigm known as distributed trust, which is the subject of this paper.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5638,Querying Peer-to-Peer Networks Using P-Trees,"Peer-to-peer (P2P) systems provide a robust, scalable and 
decentralized way to share and publish data. However, most existing P2P systems only provide a very rudimentary query facility; they only support equality or keyword search queries over files. We believe that future P2P applications, such as resource discovery on a grid, will require more complex query functionality. As a first step towards this goal, we propose a new distributed, fault-tolerant P2P index structure for resource discovery applications called the P-tree.  P-trees efficiently evaluate range queries in addition to equality queries. We describe algorithms to maintain a P-tree under insertions and deletions of data items/peers, and evaluate its performance using both a simulation and a real distributed implementation. Our results show the efficacy of our approach.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5639,Knowledge-Based Sythesis of Distributed Systems Using Event Structures,"To produce a program guaranteed to satisfy a given specification one 
can synthesize it from a formal constructive proof that a computation satisfying that specification exists. This process is particularly effective if the specifications are written in a high-level language that makes it easy for designers to specify their goals. We consider a high-level specification language that results from adding knowledge to a fragment of Nuprl specifically tailored for specifying distributed protocols, called event theory. We then show how high-level knowledge-based programs can be synthesized from the knowledge-based specifications using a proof development system such as Nuprl. Methods of Halpern and Zuck [1992] then apply to convert these knowledge-based protocols to ordinary protocols. These methods can be expressed as heuristic transformation tactics in Nuprl.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5640,"Performance Analysis of the Pipe Problem, a Multi-Physics Simulation 
Based on Web Services","The ongoing convergence of grid computing and web services has   
inspired a number of studies on the use of SOAP-based web services for   scientific computing. These studies have exposed several performance   problems in using SOAP-based communication; to eliminate these   bottlenecks, extensions to the SOAP standard and sophisticated   implementation strategies have been proposed. In this paper, we will   describe the ASP system, a simulation testbed based on web services   for simulating multi-physics, coupled   fluid/thermal/mechanical/fracture problems. The system is organized as   a collection of geographically-distributed software components in   which each component provides a web service, and uses standard   SOAP-based web service protocols to interact with other components.   There are a number of advantages to organizing a system in this way,   which we discuss. We have analyzed the performance of our system for   several applications and a number of problem sizes and have found that   the overhead for using SOAP-based web services is small and tends to   decrease as the problem size increases. Our results suggest that the   previously identified potential bottlenecks may not be major issues in   practice, and that a standards-compliant implementation like ours can   delivery excellent scalable performance even on tightly-coupled   problems, provided web services are used judiciously.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5641,Peer-to-Peer Authentication with a Distributed Single Sign-On Service,"CorSSO is a distributed service for authentication in networks.  It 
allows application servers to delegate client identity checking to combinations of authentication servers potentially residing in separate administrative domains.  In CorSSO, authentication policies enable the system to tolerate expected classes of attacks and failures.  A novel partitioning of the work associated with authentication of principals means that the system scales well with increases in the numbers of users and services.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5642,Better than 1 Hop Lookup Performance with Proactive Caching,"High lookup latencies prohibit peer-to-peer overlays from being used 
in many performance intensive applications, even though they provide self-organization, scalability, and failure resilience.  In this paper, we show that lookup performance of structured DHTs can be improved to any desirable constant, even under 1 hop, by controlled proacive replication.  By exploiting the popularity distribution of objects, we can minimize the number of replicas and reduce the storage and bandwidth cost of replication.  This enables structured DHTs to efficiently support a wide variety of latency sensitive applications.  We describe three different applications, namely DNS, web access, and content distribution, and show how they can derive significant performance gains by using DHTs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5643,Semantic Approximation of Data Stream Joins,"We consider the problem of approximating sliding window   joins over 
data streams in a data stream processing system with   limited resources. In our model, we deal with resource constraints   by shedding load in the form of dropping tuples from the data   streams. We make two main contributions. First, we define the   problem space by discussing architectural models for   data stream join processing and surveying suitable measures for   the quality of an approximation of a set-valued query result.   Second, we examine in detail a large part of this problem   space. More precisely, we consider the number of generated result tuples as   the quality measure, and we propose optimal offline and fast online   algorithms for it. In a thorough experimental study with synthetic and   real data we show the efficacy of our solutions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5644,"Expressing and Implementing the Computational Content Implicit in 
Smullyan's Account of Boolean Valuations","In Smullyan's classic book, First-Order Logic, the notion of a 
Boolean valuation is central in motivating his analytical tableau proof system. Smullyan shows that these valuations are unique if they exist, and then he sketches an existence proof. In addition he suggests a possible computational procedure for finding a Boolean valuation, but it is not related to to the existence proof. A computer scientist would like to see the obvious explicit recursive algorithm for evaluating propositional formulas and a demonstration that the algorithm has the properties of a Boolean valuation. Ideally, the algorithm would be derived from the existence proof. It turns out to be unexpectedly difficult to find a natural existence proof from which the algorithm can be extracted, and it turns out that the implicit computational content of Smullyan's argument is not found where one might expect it. We show that using the notion of a very dependent function type, it is possible to specify the Boolean valuation and prove its existence constructively so that the natural recursive algorithm is extracted and is known to have the mathematically required properties by virtue of its construction. We illustrate all of these points using the Nuprl proof development system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5645,Database Preference Queries Revisited,"In recent years, the database community has paid increasing 
attention to the formulation and treatment of preference queries. In this paper, we discuss a number of semantic and computational issues that preference queries raise. First, we examine the currently favored interpretation of such queries in database systems, showing that it is simply inappropriate semantically. Next, we suggest the ceteris paribus semantics as an appealing alternative that has long been accepted by economists and philosophers. Finally, we examine the computational problem of evaluating preference queries using the recently introduced operator BEST.  We show that while BEST can be intractable given the ceteris paribus semantics, an appealing alternative, ORD, can be implemented efficiently for a wide class of preference queries.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5646,Schema Meta-Matching,"Schema matching is a basic operation in the data integration 
process, and several tools for automating it have been proposed and evaluated in the database community. While in many domains these tools succeed to find the right matching between concepts, empirical analysis shows that there is no single algorithm that is guaranteed to succeed in all possible domains.  In this paper we introduce schema meta-matching, a novel framework for composing an arbitrary ensemble of algorithms for schema matching.  Informally, schema meta-matching is about computing a ""consensus"" ranking of alternative mappings between two sets of concepts, given the ""individual"" graded rankings provided by several schema matching algorithms.  We introduce several algorithms for this problem, varying from adaptations of some standard techniques for general quantitative rank aggregation, to novel techniques specific to the problem of schema matching, and to combinations of both.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5647,Monadic Regions: Formal Type Soundness and Correctness,"Drawing together two lines of research (that done in type-safe 
region-based memory management and that done in monadic encapsuation of effects), we give a type-preserving translation from a variation of the region calculus of Tofte and Talpin into an extension of System F augmented with monadic types and operations.  Our source language is a novel region calculus, dubbed the Single Effect Calculus, in which sets of effects are specified by a single region representing an upper bound on the set.  Our target language is F^RGN, which provides an encapsulation operator whose parametric type ensures that regions (and values allocated therein) are neither accessible nor visible outside the appropriate scope.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5648,Feature-Based Textures,"This paper introduces feature-based textures, a new image 
representation that combines features and texture samples for high-quality texture mapping. Features identify boundaries within a texture where samples change discontinuously.  They can be extracted from vector graphics representations, or explicity added to raster images to improve sharpness. Texture lookups are then interpolated from samples while respecting these boundaries. We present results from a software implementation of this technique demonstrating quality, efficiency and low memory overhead.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5649,Minimizing CVaR and VaR for a portfolio of derivatives,"Value at risk (VaR) and conditional value at risk (CVaR) are the 
most frequently used risk measures in current risk management practice. As an alternative to VaR, CVaR is attractive since it is a coherent risk measure. We analyze the problem of computing the optimal VaR and CVaR portfolios. In particular, we illustrate that VaR and CVaR minimization problems for    derivatives  portfolios are typically ill-posed. For example, the VaR and CVaR minimizations based on  delta-gamma approximations of the derivative values typically have an infinite number of solutions. In this paper, we focus on the portfolio selection problem which yields a portfolio of the minimum CVaR with a specified rate of return. We propose to include cost as an additional preference criterion for the CVaR optimization problem. We demonstrate that, with the addition of a proportional  cost, it is possible to compute an optimal CVaR derivative investment portfolio with significantly fewer instruments  and comparable CVaR and VaR. A computational method based on a smoothing  technique is proposed to solve a simulation based CVaR optimization problem efficiently. Comparison is made with the linear programming approach for solving the simulation based CVaR optimization problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5650,Distributed Constraint-based Location Discovery in Ad hoc Networks,"Location discovery is a fundamental building block for many mobile 
applications.  Yet dedicated infrastructure for determining node locations is expensive, energy consuming, and simply unavailable under certain development scenarios. This paper presents an accurate,cheap and scalable protocol for location discovery.  Called Zoom, this protocol operates by setting up and solving a system of geographic constraints based on connectivity information from the underlying communication network.  Zoom achieves high accuracy by aggressively extracting constraints from the link layer, by propagating this information across multiple network hops and by explicitly tracking the set of possible locations for any given node instead of a single position estimate.  Physical experiments with motes show that a large number(98%)of the nodes in a network can determine their positions based on a small number(30%)of landmark nodes with high accuracy(median error less than 30% of transmission range).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5651,Scalable Extensibility via Nested Inheritance,"Inheritance is a useful mechanism for factoring and reusing code. 
However, it has limitations for building extensible systems.  We describe nested inheritance, a mechanism that addresses some of the limitations of ordinary inheritance and other code reuse mechanisms. Using our experience with an extensible compiler framework, we show how nested inheritance can be used to construct highly extensible software frameworks.  The essential aspects of nested inheritance are formalized in a simple object-oriented language with an operational semantics and type system. The type system of this language is sound, so no run-time type checking is required to implement it and no run-time type errors can occur. We describe our implementation of nested inheritance as an unobtrusive extension of the Java language, called Jx. Our prototype implementation translates Jx code to ordinary Java code, without duplicating inherited code.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5652,FDL: A Prototype Formal Digital Library,"This manual describes the first prototype of a new kind of system 
which we call a Formal Digital Library (FDL). We designed the system and assembled the prototype as part of a research project sponsored by the Office of Naval Research entitled Building Interactive Digital Libraries of Formal Algorithmic Knowledge. A key purpose of the prototype library is to demonstrate that it is possible to build a system with many of the properties called for in the project proposal and to illustrate important scenarios for its use. Experience with the prototype library will influence the design and construction of an improved system. The current prototype includes some expediences that made it possible to create a working system in less than a year. The prototype FDL is one part of the overall project. There are other theoretical and experimental efforts that are described in other publications. The library described here contains definitions, theorems, theories, proof methods, and articles about topics in computational mathematics and books assembled from them. Currently it supports these objects created with the theorem proving systems MetaPRL, Nuprl and PVS. We intend to include material from other implemented logics such as Minlog, Coq, HOL, Isabelle, and Larch in due course. In addition to the purely formal material, the Library supports mathematically literate hypertext articles that cite and use the formal concepts. These include explanations of reference algorithms and explanations of formal mathematical models used in applications. Many operations on the Library are automated and extensible. The basic operations are to find and read material, organize it, and submit new material. New operations can be defined algorithmically. This manual is intended to help users understand the operation of the Library and to demonstrate to those interested in the project what else we intended to build and how it will be used.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5653,Natural Transformations as Rewrite Rules and Monad Composition,"Eklund et al. (2002) present a graphical technique aimed at 
simplifying the verification of various category-theoretic constructions, notably the composition of monads. In this note we take a different approach involving string rewriting. We show that a given tuple (T,mu,eta) is a monad if and only if T is a terminal object in a certain category of functors and natural transformations, and that this fact can be established by proving confluence of a certain string rewriting system. We illustrate the technique on the monad composition problem of Eklund et al.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5654,"Efficient Inverted Lists and Query Algorithms for Structured Value 
Ranking in Update-Intensive Relational Databases","We propose a new ranking paradigm for relational databases called 
Structured Value Ranking (SVR). SVR uses {\em structured data values} to score (rank) the results of keyword search queries over text columns. Our main contribution is a new family of inverted list indices and associated query algorithms that can support SVR efficiently in update-intensive databases, where the structured data values (and hence the scores of documents) change frequently. Our experimental results on real and synthetic data sets using BerkeleyDB show that we can support SVR efficiently in relational databases.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5655,"Optimal Parameter Selection for Efficient Memory Integrity Verification 
Using Merkle Hash trees","A secure, tamper proof execution environment is critical for 
trustworthy network computing.  Newly emerging hardware, such as those developed as part of the TCPA and Palladium initiatives, enables operating systems to implement such an environment through Merkle hash trees.  We examine the selection of optimal parameters, namely blocksize and tree depth, for Merkle hash trees based on the size of the memory region to be protected and the number of memory updates between updates of the hash tree.  We analytically derive an expression for the cost of updating the hash tree, show that there is an optimal block size for the leaves of a Merkle tree for a given file size and update interval that minimizes the cost of update operations, and describe a general method by which the parameters of such a tree can be determined optimally.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5656,Triggers over XML Views of Relational Data,"Current systems that publish relational data as XML views are {\em 
passive} in the sense that they can only respond to user-initiated queries over the XML views. In this paper, we propose an {\em active} system whereby users can place triggers on (unmaterialized) XML views of relational data. In this architecture, we present scalable and efficient techniques for processing triggers over XML views by leveraging existing support for SQL triggers in commercial relational databases. We have implemented our proposed techniques in the context of the Quark system built on top of IBM DB2. Our performance results indicate that our proposed techniques are a feasible approach to supporting triggers over XML views of relational data.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5657,P-Ring: An Index Structure for Peer-to-Peer Systems,"Current peer-to-peer (P2P) index structures only support a subset of 
the desired functionality for P2P database systems. For instance, some P2P index structures support equality queries but not range queries, while others support range queries, but do not support multiple data items per peer or provide guaranteed search performance. In this paper, we devise a novel index structure called P-Ring that supports both equality and range queries, is fault-tolerant, provides guaranteed search performance, and efficiently supports large sets of data items per peer. We are not aware of any other existing index structure that supports all of the above functionality in a dynamic P2P environment. In a thorough experimental study we evaluate the performance of P-Ring and quantify the performance trade-offs of the different system components. We also compare P-Ring with two other P2P index structures, Skip Graphs and Chord.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5658,Approximation Techniques for Spatial Data,"Spatial Database Management Systems (SDBMS), e.g., Geographical   
Information Systems, that manage spatial objects such as points,   lines, and hyper-rectangles, often have very high query processing   costs. Accurate selectivity estimation during query optimization   therefore is crucially important for finding good query plans,   especially when spatial joins are involved. Selectivity estimation   has been studied for relational database systems, but to date has   only received little attention in SDBMS.  In this paper, we   introduce novel methods that permit high-quality selectivity   estimation for spatial joins and range queries. Our techniques can   be constructed in a single scan over the input, handle inserts and   deletes to the database incrementally, and hence they can also be   used for processing of streaming spatial data. In contrast to   previous approaches, our techniques return approximate results that   come with provable probabilistic quality guarantees. We present a   detailed analysis and experimentally demonstrate the efficacy of the   proposed techniques.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5659,CODEX:  A Robust and Secure Secret Distribution System,"CODEX (COrnell Data EXchange) stores secrets for subsequent access 
by authorized clients. It also is a vehicle for exploring the generality of a relatively new approach to building distributed services that are both fault-tolerant and attack-tolerant. Elements of that approach include: embracing the asynchronous (rather than synchronous) model of computation, use of Byzantine quorum systems for storing state, and employing proactive secret sharing with threshold cryptography for implementing confidentiality and authentication of service responses. Besides explaining the CODEX protocols, experiments to measure their performance are discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5660,A Lightweight Approach to Network Positioning,"This paper describes a peer-to-peer overlay network for performing 
location-aware node and path selection in large-scale distributed systems. Our system, Meridian, provides a simple, lightweight and scalable framework for keeping track of location-information for participating nodes. The framework is based on local, relative coordinate systems in multi-resolution rings, direct measurement with scalable node-to-node handoff, and gossip protocols for dissemination. Large scale simulations and an implementation deployed on PlanetLab show that the framework can locate the closest node to given target with less than a 5ms median error, and the simplicity of the approach lends itself to a compact implementation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5661,"Index Structures for Matching XML Twigs Using Relational Query 
Processors","Various index structures have been proposed to speed up the 
evaluation of XML path expressions. However, existing XML path indices suffer from at least one of three limitations: they focus only on indexing the structure (relying on a separate index for node content), or they are useful only for simple path expressions such as root-to-leaf paths, or they cannot be tightly integrated with a relational query processor. Moreover, there is no unified framework to compare these index structures.  In this paper, we present a framework defining a family of index structures, including most existing XML path indices. We also propose two novel index structures in this family, with different space-time tradeoffs, that are effective for the evaluation of XML branching path expressions (i.e., twigs) with value conditions. We also show how this family of index structures can be realized using the access methods of the underlying database system.  Finally, we present an experimental evaluation to understand the performance tradeoff between index space and twig matching time. The experimental results show that our novel indices achieve orders of magnitude improvement in performance for evaluating twig queries, albeit at a higher space cost, over the use of previously proposed XML path indices that can be tightly integrated with a relational query processor.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5662,Correcting BLAST e-values for low-complexity segments,"The statistical estimates of BLAST and PSI-BLAST are of extreme 
importance to determine the biological relevance of sequence matches. While being very effective in evaluating most matches, these estimates usually overestimate the significance of matches in the presence of low complexity segments.  In this paper we present a model, based on divergence measures and statistics of the alignment structure, that corrects BLAST e-values for low complexity sequences without filtering or excluding them. We evaluate our method and compare it to other known methods using the Gene Ontology (GO)knowledge resource as a benchmark. Various performance measures, including ROC analysis, indicate that the new model improves over the state of the art.  The program is available at biozon.org/ftp/ and www.cs.technion.ac.il/~itaish/lowcomp/",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5663,Distance Transforms of Sampled Functions,"This paper provides linear-time algorithms for solving a class of 
minimization problems involving a cost function with both local and spatial terms. These problems can be viewed as a generalization of classical distance transforms of binary images, where the binary image is replaced by an arbitrary sampled function. Alternatively they can be viewed in terms of the minimum convolution of two functions, which is an important operation in grayscale morphology. A useful consequence of our techniques is a simple, fast method for computing the Euclidean distance transform of a binary image. The methods are also applicable to Viterbi decoding, belief propagation and optimal control.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5664,Toward the Automation of Category Theory,"We introduce a sequent system for basic category-theoretic reasoning 
suitable for computer implementation.  We illustrate its use by giving a complete formal proof that the functor categories Fun[CxD,E] and Fun[C,Fun[D,E]] are naturally isomorphic.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5665,Hierarchical Flow,"This paper defines a hierarchical version of the maximum flow 
problem.  In this model, the capacities increase over time and the resulting solution is a sequence of flows that build on each other incrementally.  Thus far, hierarchical problems considered in the literature have been built on NP-complete problems.  To the best of our knowledge, our results are the first to find a polynomial time problem whose hierarchical version is NP-complete.  We present approximation algorithms and hardness results for many versions of this problem, and comment on the relation to multicommodity flow.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5666,X-Ray : Automatic Measurement of Hardware Parameters,"There is growing interest in autonomic, self-tuning software that 
can optimize itself on new platforms, without manual intervention. Optimization requires detailed knowledge of the target platform such as the latency and throughput of instructions, the numbers of registers, and the organization of the memory hierarchy. An autonomic optimization system needs to determine such platform-specific information on its own. In this paper, we describe the design and implementation of X-Ray, which is a tool that automatically measures a large number of such platform-specific parameters. For some of these parameters, we also describe novel algorithms, which are more robust than existing ones. X-Ray is written in C for maximum portability, and it is based on accurate timing of a number of carefully designed micro-benchmarks. A novel feature of X-Ray is that it is easily extensible because it provides simple infrastructure and a code generator that can be used to produce the large number of micro-benchmarks needed for such measurements. There are few existing tools that address this problem. Our experiments show that X-Ray produces more accurate and more complete results than any of them.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5667,"Man vs. Machine : Comparing Handwritten and Compiler-generated 
Application-Level Checkpointing","The contributions of this paper are the following. We describe the 
implementation of the $C^3$ system for semi-automatic application-level checkpointing of C programs. The system has (i) a pre-compiler that instruments C programs so that they can save their states at program execution points specified by the user, and (ii) a novel memory allocator that manages the heap as a collection of pools. We describe two static analyses for reducing the overhead of saving and restoring the application state. The first one optimizes stack variables, while the second one optimizes heap data structures. To benchmark our system, we compare the overheads introduced by our semi-automatic approach with the overhead of handwritten application-level checkpointing in an n-body code written by Joshua Barnes. Except for very small problem sizes, these overheads are comparable. We highlight various algorithmic challenges in the optimization of application-level checkpointing that should provide grist for the mills of the PLDI community.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5668,Region-Based Shape Analysis with Tracked Locations,"This paper proposes a novel approach to shape analysis: using local 
reasoning about individual heap locations instead of global reasoning about entire heap abstractions. We present an inter-procedural shape analysis algorithm for languages with destructive updates and formulate it as a dataflow analysis. The key feature is a novel memory abstraction that differs from traditional abstractions in two ways. First, we build the shape abstraction and analysis on top of a pointer analysis. Second, we decompose the shape abstraction into a set of independent configurations, each of which characterizes one single heap location. Our approach: 1) leads to simpler algorithm specifications, because of local reasoning about the single location; 2) leads to efficient algorithms, because of the abstraction decomposition; and 3) makes it easier to develop context-sensitive, demand-driven, and incremental shape analyses. We have developed simple extensions that use the analysis results to find memory errors in programs with explicit deallocation, including memory leaks and accesses through dangling pointers. We have built a prototype system that implements the ideas in this paper and is designed to analyze C programs. Our experimental results support the intuition that local reasoning leads to more scalable analyses.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5669,"Think Globally, Search Locally","A key step in program optimization is the determination of optimal 
values for code optimization parameters such as cache tile sizes and loop unrolling factors. One approach, which is implemented in most compilers, is to use analytical models to determine these values. The other approach, used in library generators like ATLAS, is to perform a global search over the space of parameter values by generating different versions of the code and executing them on the actual machine to find the parameter values that give the best performance. Neither approach is suitable for use in general-purpose compilers that must generate high quality code for large programs running on complex architectures. Model-driven optimization may incur a performance penalty of 10-20\% even for a relatively simple code like matrix multiplication, as was shown recently by Yotov et al. On the other hand, global search is not tractable for optimizing large programs for complex architectures because the optimization space is too large. To address this problem, some researchers are exploring more sophisticated search algorithms such as the simplex method, but it remains to be seen if these methods are successful in reducing search time without compromising on the quality of the solution. In this paper, we advocate a different methodology for generating high-performance code without increasing search time dramatically. Our methodology has three components: (i) modeling, (ii) local search, and (iii) model refinement. We use analytical models to estimate optimal values for transformation parameters. Since it is impossible to build tractable analytical models that capture all the features of complex architectures, we advocate improving these estimates by using a local search in the neighborhood of the model-predicted values. Finally, if the performance gap between handwritten code and generated code is substantial on some architecture, we advocate model refinement. To demonstrate this methodology, we built a modified ATLAS system that used a simple analytical model and local search, and showed that on most architectures, the performance of the code produced by this system was comparable to that of code produced by the original ATLAS system using global search. However, on x86 architectures, the gap in performance was substantial, and could not be bridged by local search alone. We argue that the problem is that the model assumed aggressive operation scheduling to mask instruction latencies, but such scheduling can actually be harmful on x86 architectures, a somewhat surprising fact that does not appear to be known widely. To address this problem, we use model refinement to generate a more sophisticated model that, when combined with local search, enables the production of high-quality code on both RISC and CISC architectures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5670,Automatic Measurement of Memory Hierarchy Parameters,"On modern computers, the running time of many applications is 
dominated by the cost of memory operations. To optimize such applications for a given platform, it is necessary to have a detailed knowledge of the memory hierarchy parameters of that platform. In practice, this information is usually poorly documented if at all. Moreover, there is growing interest in self-tuning, autonomic software systems that can optimize themselves for different platforms, and these systems must determine memory hierarchy parameters automatically without human intervention. One solution is to use micro-benchmarks to determine the parameters of the memory hierarchy. In this paper, we argue that existing micro-benchmarks are inadequate, and present novel micro-benchmarks for determining the parameters of all levels of the memory hierarchy, including registers, all caches levels and the translation look-aside buffer. We have implemented these micro-benchmarks into an integrated tool that can be ported with little effort to new platforms. We present experimental results that show that this tool successfully determines memory hierarchy parameters on many current platforms, and compare its accuracy with that of existing tools.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5671,Second-Order Abstract Interpretation via Kleene Algebra,"Most standard approaches to the static analysis of programs, such as 
the popular worklist method, are first-order methods that inductively annotate program points with abstract values. In this paper we introduce a second-order approach based on Kleene algebra. In this approach, the primary objects of interest are not the abstract data values, but the transfer functions that manipulate them. These elements form a Kleene algebra. The dataflow labeling is not achieved by inductively labeling the program with abstract values, but rather by computing the star (Kleene closure) of a matrix of transfer functions. In this paper we introduce the method and prove soundness and completeness with respect to the standard worklist algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5672,Kleene Algebra and Bytecode Verification,"Most standard approaches to the static analysis of programs, such as 
the popular worklist method, are first-order methods that inductively annotate program points with abstract values. In a recent paper we introduced a second-order approach based on Kleene algebra. In this approach, the primary objects of interest are not the abstract data values, but the transfer functions that manipulate them. These elements form a Kleene algebra. The dataflow labeling is not achieved by inductively labeling the program with abstract values, but rather by computing the star (Kleene closure) of a matrix of transfer functions. In this paper we show how this general framework applies to the problem of Java bytecode verification.We show how to specify transfer functions arising in Java bytecode verification in such a way that the Kleene algebra operations (join, composition, star) can be computed efficiently. We also give a hybrid dataflow analysis algorithm that computes the closure of a matrix on a cutset of the control flow graph, thereby avoiding the recalculation of dataflow information along long paths. This method could potentially improve the performance over the standard worklist algorithm when a small cutset can be found.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5673,"An Empirical Comparison of Supervised Learning Algorithms Using 
Different Performance Metrics","We present the results of a large-scale empirical comparison between 
seven learning methods: SVMs, neural nets, decision trees, memory-based learning, bagged trees, boosted trees, and boosted stumps.  A novel aspect of our study is that we compare these methods on nine different performance criteria: accuracy, squared error, cross entropy, ROC Area, F-score, precision/recall break-even point, average precision, lift, and probability calibration.  The models with the best performance overall are neural nets, SVMs, and bagged trees. However, if we apply Platt calibration to boosted trees, they become the best model overall.  Detailed examination of the results shows that even the best models perform poorly on some problems or metrics, and that even the worst models sometimes yield the best performance.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5674,Automatic Measurement of Hardware Parameters for Embedded Processors,"Embedded processor designs are increasingly based on general-purpose 
processor families, modified and extended in various ways. However, the production of software for embedded processors remains a challenging problem. One promising approach for addressing this problem is self-optimizing software: instead of writing a program, one implements a program generator that produces a large number of program variants, and then determines empirically which variant performs best. The particular aspect of performance that is optimized can be execution time, power consumption, throughout, etc. To prevent a combinatorial explosion in the number of program variants that have to be considered, self-optimizing systems bound the search space by exploiting knowledge of hardware parameters such as the number of registers, the capacity of the L1 cache, etc. For software to be truly self-optimizing, hardware parameter values relevant for software optimization must be determined automatically. This paper makes the following contributions.     - We describe X-Ray - a robust and extensible micro-benchmark framework for measuring hardware parameters, in which it is very easy to implement new micro-benchmarks. This is particularly important in the embedded processor context because designers constantly add new features to architectures.     - We describe novel algorithms for measuring commonly used hardware parameters and show how they can be implemented in this framework. We evaluate our implementation experimentally on both embedded and desktop architectures, and show that it produces more accurate and complete results than existing tools.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5675,"Transforming the Academy:  Knowledge Formation in the Age of Digital 
Information","Computer-mediated knowledge formation will profoundly change every 
academic discipline and pose fundamental challenges to the mission of the modern research university in teaching the new knowledge, securing sound methods for creating it, directing it to our deepest intellectual concerns, and insuring that we become wiser for it. Digital information, now measured in petabytes, is expanding rapidly; already most of it will never be examined by any human.  Computers show us where to look and help us see patterns and extract meaning.  How will this way of knowing impact the research university as the Age of Digital Information unfolds? To grasp the magnitude of the changes we face, it is important to realize that knowledge created with computer assistance goes well beyond classical knowledge formation rising from computer processing of digital information resources on a scale that could not be achieved by all peoples of the earth acting in concert using all their cognitive powers.  Computers change the scale at which resources can be examined, and they already provide sufficient discriminatory powers that scale and speed compensate for their currently limited intelligence as they draw conclusions, make predictions, and participate in discoveries.  The academy is not generally aware of the potential of this transformation, although some computer scientists and computational scientist are.  The challenge for society is to assimilate digital knowledge and to improve the human condition by its application.  We also seek to understand how it will shape our sense of self, individually and collectively as a society and a culture.  In all of these tasks, the universities play an indispensable role for which they must prepare.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5676,Belief in Information Flow,"Measurement of information flow requires a definition of leakage, 
which traditionally has been defined to occur when an attacker's uncertainty about secret data is reduced.  We show that this uncertainty-based approach is inadequate for measuring information flow when an attacker is making assumptions about secret inputs and these assumptions might be incorrect.  Moreover, we show that such attacker beliefs are an unavoidable aspect of any satisfactory definition of leakage.  To reason about information flow based on beliefs, we develop a model that describes how an attacker's belief changes due to the attacker's observation of the execution of a probabilistic (or deterministic) program.  The model leads to a new metric for quantitative information flow that measures accuracy rather than uncertainty of beliefs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5677,"""Distance Estimation and Object Location via Rings of Neighbors""","We approach several problems on distance estimation and object 
location using a common technique called \emph{rings of neighbors}. Using this technique on metrics of low doubling dimension, we obtain significant improvements for low-stretch routing schemes, distance labeling, searchable small worlds, and triangulation-based distance estimation. Apart from improving the previously known bounds for these problems, our contributions include extending Kleinberg's small world model to metrics of low doubling dimension, and a short proof of the main result in [Chan et al., SODA'05]. Doubling dimension is a combinatorial (non-geometric) notion of dimensionality that has recently become popular in theoretical CS literature. A collection of rings of neighbors is a sparse distributed data structure that captures the distances and routing information. The idea is that every node $u$ stores pointers to some nodes called 'neighbors'; these pointers are partitioned into several 'rings', so that for some increasing sequence of balls $\{B_i\}$ around $u$, the neighbors in the $i$-th ring lie inside $B_i$; the radii of these balls and the distribution of neighbors in a given ring depend on the specific application. For metrics of low doubling dimension it has been particularly helpful to combine the following two collections of rings: in the first collection, the cardinalities of the balls $B_i$ grow exponentially, and the neighbors are distributed randomly; in the second collection the \emph{radii} of the $B_i$'s grow exponentially, and the neighbors are distributed geographically.  Although used implicitly in several contexts, rings of neighbors have not been articulated as a general proof technique.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5678,Demonstration of RTT and BDB,This document demonstrates how BDB and RTT works.,,application/vnd.ms-powerpoint,Technical Report
oai:ecommons.cornell.edu:1813/5679,BioDataBase,"This paper contains the concept of ""Relational Taxonomy Tree (RTT)"" 
and BioDataBase (BDB). RTT solves the following problems 1. how do we represent hierarchical entities like biological taxonomy? (section II and III in the document) 2. How do we perform Join operations across the hierarchy? (section IV) BDB solves the following problem: 3. correlate two disparate kinds of data.  E.g. environmental factors (humidity, average temperature) with Gene Expression Data (section VII).",,application/msword,Technical Report
oai:ecommons.cornell.edu:1813/5680,Thwarting P2P Pollution Using Object Reputation,"This paper describes a distributed object reputation management 
scheme that counteracts content pollution in peer-to-peer filesharing systems.  The proposed scheme allows honest peers to assess the authenticity of online content by securely tabulating and managing endorsements from other peers.  We employ a novel voter correlation scheme to weight the opinions of peers, which gives rise to favorable incentives and system dynamics.  We present simulation results indicating that our system is scalable, efficient, and robust to attack.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5681,Huhn-Kie's concept on Library of Life,"This paper suggests the overall design of Library of Life.  It also 
discusses what kind of services the Library of Life should provide and how the Library of Life can interact with private businesses through advertisement.",,application/msword,Technical Report
oai:ecommons.cornell.edu:1813/5682,"Meridian: A Lightweight Framework for Network Positioning without 
Virtual Coordinates","Selecting nodes based on their position in the network is a basic 
building block for many distributed systems. This paper describes a peer-to-peer overlay network for performing position-based node selection. Our system, Meridian, provides a lightweight, accurate and scalable framework for keeping track of location information for participating nodes. The framework consists of an overlay network structured around multi-resolution rings, query routing with direct measurements, and gossip protocols for dissemination. We show how this framework can be used to address three commonly encountered problems in large-scale distributed systems without having to compute absolute coordinates; namely, closest node discovery, central leader election, and locating nodes that satisfy target latency constraints.  We show analytically that the framework is scalable with logarithmic convergence when Internet latencies are modeled as a growth-constrained metric, a low-dimensional Euclidian metric, or a metric of low doubling dimension. Large scale simulations, based on latency measurements from 6.25 million node-pairs, and an implementation deployed on PlanetLab both show that the framework is accurate and effective",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5683,recognizer for species pictures,"I designed an algorithm that can recognize a picture of a species.  
It is robust to the varying brightness or tilted angle of the pictures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5684,Expressiveness and Performance of Full-Text Search Languages,"We study the expressiveness and performance of full-text search languages. Our
main motivation is to provide a formal basis for comparing such languages and todevelop a model for full-text search that can be tightly integrated withstructured search. We develop a formal model for full-text search based on thepositions of tokens (words) in the input text, and develop a full-text calculus(FTC) and a full-text algebra (FTA) with equivalent expressive power. Thissuggests a notion of completeness for full-text search languages and can be usedas a basis for a study of their expressiveness. We show that existing full-textlanguages are incomplete and develop {\tt COMP}, a complete full-text searchlanguage. We also identify practical subsets of {\tt COMP} that are morepowerful than existing languages, develop efficient query evaluation algorithmsfor these subsets, and study experimentally their performance.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5685,"Publication/Citation: A Proof-Theoretic Approach to Mathematical 
Knowledge Management","There are many real-life examples of formal systems that support 
constructions or proofs, but that do not provide direct support for remembering them so that they can be recalled and reused in the future. In this paper we examine the operations of publication (remembering a proof) and citation (recalling a proof for reuse), regarding them as forms of common subexpression elimination on proof terms. We then develop this idea from a proof theoretic perspective, describing a simple complete proof system for universal Horn equational logic using three new proof rules, publish, cite, and forget. These rules can provide a proof-theoretic infrastructure for proof reuse in any system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5686,Coinductive Proof Principles for Stochastic Processes,"We give an explicit coinduction principle for recursively-defined 
stochastic processes. The principle applies to any closed property, not just equality, and works even when solutions are not unique. We illustrate the use of the rule in deriving properties of a simple coin-flip process.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5687,End-to-End Availability Policies and Noninterference,"This paper introduces the use of static information flow analysis 
for the specification and enforcement of end-to-end availability policies in programs. We generalize the decentralized label model, which is about confidentiality and integrity, to also include security policies for availability. These policies characterize acceptable risks by representing them as principals.  We show that in this setting, a suitable extension of noninterference corresponds to a strong, end-to-end availability guarantee. This approach provides a natural way to specify availability policies and enables existing static dependency analysis techniques to be adapted for availability. The paper presents a simple language in which fine-grained information security policies can be specified as type annotations. These annotations can include requirements for all three major security properties: confidentiality, integrity, and availability. The type system for the language provably guarantees that any well-typed program has the desired noninterference properties, ensuring confidentiality, integrity, and availability.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5688,Guaranteeing Correctness and Availability in P2P Range Indices,"New and emerging P2P applications require sophisticated range query 
capability and also have strict requirements on query correctness, system availability and item availability. While there has been recent work on developing new P2P range indices, none of these indices guarantee correctness and availability. In this paper, we develop new techniques that can provably guarantee the correctness and availability of P2P range indices. We develop our techniques in the context of a general P2P indexing framework that can be instantiated with most P2P index structures from the literature.  As a specific instantiation, we implement P-Ring, an existing P2P range index, and show how it can be extended to guarantee correctness and availability. We quantitatively evaluate our techniques using a real distributed implementation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5689,Multi-query optimization for sensor networks,"The widespread dissemination of small-scale sensor nodes has sparked 
interest in a powerful new database abstraction for sensor networks:  Clients ""program"" the sensors through queries in a high-level declarative language (such as a variant of SQL) permitting the system to perform the low-level optimizations necessary for energy-efficient query processing.  In this paper we consider multi-query optimization for aggregate queries on sensor networks.  We develop a set of distributed algorithms for processing multiple queries that incur minimum communication while observing the computational limitations of the sensor nodes.  Our algorithms support incremental changes to the set of active queries and allow for local repairs to routes in response to node failures.  A thorough experimental analysis shows that our approach results in significant energy savings, compared to previous work.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5690,Life Science Server,"Life Science Server (LSS) is a web server system that answers any 
questions in life science based on BioDataBase.",,application/msword,Technical Report
oai:ecommons.cornell.edu:1813/5691,Hilda: A High-Level Language for Data-Driven Web Applications,"We propose Hilda, a high-level language for developing data-driven 
web applications. The primary benefits of Hilda over existing de- velopment platforms are: (a) it uses a uni- fied data model for all layers of the applica- tion, (b) it is declarative, (c) it models both application queries and updates, (d) it sup- ports structured programming for web sites, (e) it enables conflict detection for concur- rent updates, and (f) it separates application logic from presentation. We also describe the implementation of a simple proof-of-concept Hilda compiler, which translates a Hilda ap- plication program into Java Servlet code.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5692,On the Use of Linear Programming for Unsupervised Text Classification,"We present a new  algorithm for large scale unsupervised text 
classification.  Our method views each document as a  sample of fixed size from a mixture model,  and uses a novel L1-norm based theoretical approach due to Kleinberg and Sandler. We show that our algorithm performs extremely well on data sets of $10^5$ documents and more, and in particular out-performs Latent Semantic Indexing by a large margin. Furthermore, on some tests its prediction accuracy approaches that of {\it supervised}  learning with training set of 5,000 or more documents.  Unlike LSI,  our algorithm produces a ``well-behaved'' projection in general, that in many cases does not require additional clustering algorithm to separate topics. We experiment with the \arxiv - a collection  of scientific abstracts and the \news~dataset - a small snapshot of  20 specific newsgroups.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5693,A Measurement Study of a Publish Subscribe System,"While publish-subscribe systems have attracted much research 
interest in the last decade, few established benchmarks have emerged and there has been little characterization of how they are used in practice. This paper examines RSS, a newly emerging, widely used publishsubscribe system for web micronews. Based on a trace study spanning 45 days at a medium-size academic department, and periodic polling of approximately 100,000 RSS feeds, we extract feed and client characteristics for RSS. We find that the popularity of RSS feeds follows a power law distribution. 16% of RSS feeds are updated hourly and 25% do not change at all during our polling period. 64%of all updates involve less than three lines in the XML document. We also find that RSS feed update sizes are proportional to feed size. Overall, an analysis of RSS, the first widely deployed publish-subscribe system, can help inform the design of next generation pub-sub systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5694,Perils of Transitive Trust in the Domain Name System,"The Domain Name System, DNS, is based on nameserver delegations, 
which introduce complex and subtle dependencies between names and nameservers. In this paper, we present results from a large scale survey of DNS that shows that these dependencies lead to a highly insecure naming system. We report specifically on three aspects of DNS security: the properties of the DNS trusted computing base, the extent and impact of existing vulnerabilities in the DNS infrastructure, and the ease with which attacks against DNS can be launched. The survey shows that a typical name depends on 46 servers on average, whose compromise can lead to domain hijacks, and names belonging to some countries depend on a few hundred nameservers. An attacker exploiting well-documented vulnerabilities in DNS can hijack more than 30% of the names appearing in the Yahoo and DMOZ.org directories. And certain nameservers, especially in educational institutions, control as much as 10% of the namespace.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5695,Constrained Graphcut Texture Synthesis,"This paper describes constrained graphcut texture synthesis (CGS), a 
graphcut-based synthesis algorithm that creates output textures satisfying constraints. We show that constrained texture synthesis can be posed in a principled way as an optimization problem that requires balancing two measures of quality: constraint satisfaction and texture seamlessness. We then present an efficient algorithm for finding good solutions to this problem, using generalized graphcut minimization. CGS enables explicit control while preserving the speed and quality benefits of graphcut texture synthesis. This approach supports the full image analogies framework, while providing superior image quality and performance. A range of applications of CGS are demonstrated, including detail synthesis, artistic filtering by analogy, and texture-by-numbers. CGS is easily extended to handle multiple constraints on a single output, thus enabling novel applications that combine both user-specified and image-based control.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5696,Expressiveness and Performance of Full-Text Search Languages,"We study the expressiveness and performance of full-text search 
languages. Our main motivation is to provide a formal basis for comparing such languages and to develop a model for full-text search that can be tightly integrated with structured search. We develop a formal model for full-text search based on the positions of tokens (words) in the input text, and develop a full-text calculus (FTC) and a full-text algebra (FTA) with equivalent expressive power. This suggests a notion of completeness for full-text search languages and can be used as a basis for a study of their expressiveness. We show that existing full-text languages are incomplete and develop {\tt COMP}, a complete full-text search language. We also identify practical subsets of {\tt COMP} that are more powerful than existing languages, develop efficient query evaluation algorithms for these subsets, and study experimentally their performance.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5697,A General Algebra and Implementation for Monitoring Event Streams,"Recently there has been considerable research on Data Stream 
Management Systems (DSMS) to support analysis of data that arrives rapidly in high-speed streams. Most of these systems have very expressive query languages in order to address a wide range of applications. In this paper, we take a different approach. Instead of starting with a very powerful data stream query language, we begin with a well-known class of languages -- event languages. Through the addition of several simple, but powerful language constructs (namely parameterization and aggregates), we add pieces that extend their expressiveness towards full-fledged languages for processing data streams. Our resulting contributions are a novel algebra for expressing data stream queries, and a corresponding transformation of algebra expressions into finite state automata that can be implemented very efficiently. Our language is simple and natural, and it can express surprisingly powerful data stream queries. We formally introduce the language including a formal mapping of algebra expressions to finite state automata.  Furthermore, we show the efficacy of our approach via an initial performance evaluation, including a comparison with the Stanford STREAM System.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5698,Pre-Processing Environment Maps for Dynamic Hardware Shadows,"Environment maps are a popular method of reproducing complex natural 
lighting. However, current methods for hardware environment map shadows depend on significant pre-computation and cannot support dynamic objects.  This work presents a pre-process that decomposes an environment map into two components: a set of area lights and an ambient map. Once the map is split into these components, each is rendered with an appropriate mechanism. The area lights are rendered using an existing hardware-accelerated soft-shadow algorithm; for our implementation we use penumbra wedges. The ambient region is rendered using pre-integrated irradiance mapping. Using an NVidia 6800 on a standard desktop, we demonstrate high-quality environment map shadows for dynamic scenes at interactive rates.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5699,"Real-time Hardware-accelerated Relighting with Approximate Indirect 
Illumination","Deep framebuffer relighting engines are often used to speed up 
lighting design in geometricallycomplex procedurally-shaded environments where they provide interactive feedback on changes to the direct illumination. This paper presents an extension to these algorithms by providing real-time feedback for one-bounce indirect illumination. This is achieved by relighting a set of cached gather samples generated from the original geometry using a Monte Carlo gathering approach. To improve performance and decrease storage, the gather samples are clustered such that the resulting data structures are efficient for evaluation on modern GPUs. The hardware-accelerated implementation of our algorithm achieves real-time performance and is scalable to environments with high geometric and material complexity while supporting arbitrary direct lighting models, including local ones, and diffuse and glossy materials.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5700,Relational Semantics of Local Variable Scoping,"Most previous work on the equivalence of programs in the presence of 
local state has involved intricate memory modeling and the notion of contextual (observable) equivalence.  We show how relational semantics can be used to avoid these complications.  We define a notion of local variable scoping, along with a purely compositional semantics based on binary relations, such that all contextual considerations are completely encapsulated in the semantics.  We then give an axiom system for program equivalence in the presence of local state that avoids all mention of memory or context and that does not use semantic arguments.  The system is complete relative to the underlying flat equational theory.  We also indicate briefly how the semantics can be extended to include higher-order functions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5701,"Continuity and Monotonicity Properties of an Optimally Controlled 
Double Integrator with State and Input Constraints","This paper presents minimum-time solutions for driving a double 
integrator to a desired state with zero final velocity. The presence of constraints on the magnitude of the control input and the velocity state is assumed. The derived solutions are piecewise constant control efforts, which have to be executed in sequence. Finally, it is shown that the required times are strictly monotone and continuous functions of the constraints.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5702,An Incremental Model for Combinatorial Maximization Problems,"Many combinatorial optimization problems aim to select a subset of 
elements of maximum value subject to certain constraints. We consider an incremental version of such problems, in which some of the constraints rise over time. A solution is a sequence of feasible solutions, one for each time step, such that later solutions build on earlier solutions incrementally. We introduce a general model for such problems, and define incremental versions of maximum flow, bipartite matching, and knapsack. We find that imposing an incremental structure on a problem can drastically change its complexity. With this in mind, we give general yet simple techniques to adapt algorithms for optimization problems to their respective incremental versions, and discuss tightness of these adaptations with respect to the three aforementioned problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5703,Certified In-lined Reference Monitoring on .Net,"MOBILE is an extension of the .NET Common Intermediate Language that 
permits certified In-Lined Reference Monitoring on Microsoft .NET architectures. MOBILE programs have the useful property that if they are well-typed with respect to a declared security policy, then they are guaranteed not to violate that security policy when executed. Thus, when an In-Lined Reference Monitor (IRM) is expressed in MOBILE, it can be certified by a simple type-checker to eliminate the need to trust the producer of the IRM. MOBILE thereby permits development of arbitrarily complex IRM producers without contributing that added complexity to the trusted computing base of the system. Security policies in MOBILE are declarative, can involve potentially unbounded collections of objects allocated at runtime, and can regard finite- or infinite-length histories of security events exhibited by those objects. Our prototype implementation of MOBILE enforces properties expressed by finite-state security automata -- one automaton for each security-relevant object, and can type-check MOBILE programs in the presence of exceptions, finalizers, concurrency, and non-termination. Executing MOBILE programs requires no change to existing .NET virtual machine implementations, since MOBILE programs consist of normal managed CIL code with extra typing annotations stored in .NET attributes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5704,Optimal Resource Utilization in Content Distribution Networks,"This paper examines replication in content distribution networks and 
proposes a novel mechanism for optimally resolving performance versus cost tradeoffs. The key insight behind our work is to formally and analytically capture the relationship between performance, bandwidth overhead and storage requirements for a web cache, express the system goals as a mathematical optimization problem, and solve for the optimal extent of replication that achieves the desired system goals with minimal overhead. We describe the design and implementation of a new content distribution network based on this concept, called CobWeb. CobWeb can achieve a target lookup latency while minimizing network and storage overhead, minimize access time while keeping bandwidth usage below a set limit, and alleviate ""flash crowd"" effects by rapidly replicating popular objects through fast and highly adaptive replica management. We outline the architecture of the CobWeb system, describe its novel optimization algorithm for intelligent resource allocation, and compare, through simulations and a physical deployment on PlanetLab, CobWeb's informed, analysis-driven replication strategy to existing approaches based on passive caching and heuristics.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5705,Static Score Bucketing in Inverted Indexes,"Maintaining strict static score order of inverted lists is a 
heuristic used by search engines to improve the quality of query results when the entire inverted lists cannot be processed. This heuristic, however, increases the cost of index generation and requires time-consuming index build algorithms. In this paper, we study a new index organization based on static score bucketing. We show that this new technique significantly improves in index build performance while having minimal impact on the quality of search results. We also provide upper bounds on the quality degradation and verify experimentally the benefits of the proposed approach.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5706,"Corona: A High Performance Publish-Subscribe System for the World Wide 
Web","Despite the abundance of frequently changing information, the Web 
lacks a publish-subscribe interface for delivering updates to clients. The use of naive polling for update detection leads to poor performance and limits scalability, as clients do not detect updates quickly and servers face high loads imposed by active polling. This paper describes Corona, a publish-subscribe system for the Web that provides high performance and scalability through optimal resource allocation. Users register interest in web pages through existing instant messaging services. Corona monitors the subscribed web pages, detects updates efficiently by allocating polling load among cooperating peers and disseminates them quickly to the clients. A distributed optimization engine ensures that Corona achieves the best update performance without exceeding load limits on content servers. Large scale simulations and measurements from Planet-Lab deployment, described in this paper, demonstrate that Corona achieves orders of magnitude improvement in update performance at a modest cost.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5707,"Implementing the Render Cache and the Edge-and-Point Image On Graphics 
Hardware","The render cache and the edge-and-point image (EPI) are techniques 
that permit high quality rendering at interactive rates of models illuminated with complex ray traced techniques, combining sparse sampling and discontinuities-respecting interpolation. The image reconstruction is decoupled from the samples generation process and permits the use of arbitrary shaders to gather shading samples.  Although the system uses seemingly familiar graphics operations, their behavior differ in subtle and interesting ways from the regular graphics hardware use.  This work presents a multi-pass rendering algorithm that brings the render cache and EPI image generation processes to programmable graphics hardware utilizing their newest capabilities. Its implementation permits substantial performance gains and leverages the CPU workload, allowing more time to be spent on the samples generation.  It discusses the performance achieved, optimizations and limitations with the current generation hardware as well as possibilities for future improvements.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5708,"Design, analysis, implementation and improvements in Quicksort",Table of Contents: (1) SORTING ALGORITHMS ... (2) THE QUICKSORT ... (3) PARTITIONING ... (4) PERFORMANCE OF QUICKSORT ... (5) ANALYSIS ... (6) RANDOMIZATION ... (7) SORTING ALGORITHMS (8) COMPLEXITY OF QUICK SORT ... (9) IMPROVEMENT STRATEGIES ... (10) CODE IN C,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5709,"Heuristics Considered Harmful or Using Mathematical Optimization for 
Resource Management in Distributed Systems","Distributed systems often pose difficult to resolve resource 
management problems. These problems typically involve the partitioning of a critical resource, such as bandwidth, storage, or computational elements, between competing tasks. Traditionally, such problems are resolved using custom, domain-specific heuristics. Yet heuristics are neither robust to uctuations in load characteristics nor do they enable the system designer to reason definitively about the emergent properties of the system after deployment. In this paper, we argue for a more principled approach to resource management in distributed systems. Namely, we propose that resource allocation problems are ideally suited for mathematical optimization. We outline a gen- eral approach based on analytical modeling, optimization, and practical implementation. We describe how we have applied this technique to several diverse domains, to yield qualitative improvements in performance and achieve strong guarantees.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5710,A Causal Logic of Events in Formalized Computational Type Theory,"We provide a logic for distributed computing that has the 
explanatory and technical power of constructive logics of computation. Inparticular, we establish a proof technology that supports correct-by-construction programming based on the notion that concurrent processes can be extracted from proofs that specifications are achievable.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5711,An Experimental Study of the Skype Peer-to-Peer VoIP System,"Despite its popularity, relatively little is known about the traf- 
fic characteristics of the Skype VoIP system and how they differ from other P2P systems. We describe an experimental study of Skype VoIP traffic conducted over a one month period, where over 30 million datapoints were collected regarding the population of online clients, the number of supernodes, and their traffic characteristics. The results indicate that although the structure of the Skype system appears to be similar to other P2P systems, particularly KaZaA, there are several significant differences in traffic. The number of active clients shows diurnal and work-week behavior, correlating with normal working hours regardless of geography. The population of supernodes in the system tends to be relatively stable; thus node churn, a significant concern in other systems, seems less problematic in Skype. The typical bandwidth load on a supernode is relatively low, even if the supernode is relaying VoIP traffic. The paper aims to aid further understanding of a signifi- cant, successful P2P VoIP system, as well as provide experimental data that may be useful for design and modeling of such systems. These results also imply that the nature of a VoIP P2P system like Skype differs fundamentally from earlier P2P systems that are oriented toward file-sharing, and music and video download applications, and deserves more attention from the research community.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5712,Privacy via Pseudorandom Sketches,"Imagine a collection of individuals who each possess private data 
that they do not wish to share with a third party.  This paper considers how individuals may represent and publish their own data so as to simultaneously preserve their privacy and to ensure that it is possible to extract large-scale statistical behavior from the original unperturbed data.  Existing techniques for perturbing data are limited by the number of users required to obtain approximate answers to queries, the richness of preserved statistical behavior, the privacy guarantees given and/or the amount of data that each individual must publish. This paper introduces a new technique to describe parts of an individual's data that is based on pseudorandom sketches.  The sketches guarantee that each individual's privacy is provably maintained assuming one of the strongest definitions of privacy that we are aware of: given unlimited computational power and arbitrary partial knowledge, the attacker can not learn any additional private information from the published sketches. However, sketches from multiple users that describe a subset of attributes can be used to estimate the fraction of users that satisfy any conjunction over the full set of negated or unnegated attributes. We show that the error of approximation is independent of the number of attributes involved and only depends on the number of users available. An additional benefit is that the size of the sketch is minuscule: $\lceil \log\log O(M)\rceil $ bits, where $M$ is the number of users. Finally, we show how sketches can be combined to answer more complex queries.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5713,Pbit and other list sorting algorithms,"Pbit, besides its simplicity, is definitely the fastest list sorting 
algorithm. It considerably surpasses all already known methods. Among many advantages, it is stable, linear and be made to run in place. I will compare Pbit with algorithm described by Donald E. Knuth in the third volume of ''The Art of Computer Programming'' and other (QuickerSort, MergeSort) list sorting algorithms.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5714,Enabling Large Scale Coherency Among Mathematical Texts,"Mathematical and program-code text is unique because significant 
portions of it can be anchored to counterparts in formal logical theories that are implemented by computer systems. These systems check formal proofs for correctness and trace logical dependencies among assertions. When elements of expository text, such as definitions and theorems, are formally linked to their implemented counterparts, we call the texts semantically anchored. Such texts exhibit considerable depth and authority. It is possible to leverage substantial investments made by governments, research laboratories, corporations, and universities in creating large collections of computerchecked and interactively-generated formal mathematics, making this research investment, these collections, accessible to an extended community of authors, researchers, students and teachers involved with mathematics. We advocate extending common authoring tools (text editors as opposed to formal proof development tools) so that they can easily produce semantically anchored documents suitable for dissemination along with the formal mathematics to which they are anchored; some texts would be newly authored, while others would be static textbased resources improved by anchoring. These tools will enable authors to create these documents by drawing on a large already existing and growing collection of formal material. We expect that anchored documents will enable interconnected collections where the computers support exact common reference among concepts and thus greatly facilitate collaborative contributions to online collections and provide large-scale coherency among mathematical texts.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5715,"A Graph-Based Approach towards Discerning Inherent Structures in a 
Digital Library of Formal Mathematics","As the amount of online formal mathematical content grows, for 
example through active efforts such as the Mathweb [21], MOWGLI [4], Formal Digital Library, or FDL [1], and others, it becomes increasingly valuable to find automated means to manage this data and capture semantics such as relatedness and significance.  We apply graph-based approaches, such as HITS, or Hyperlink-Induced Topic Search, [11] used for World Wide Web document search and analysis, to formal mathematical data collections.  The nodes of the graphs we analyze are theorems and definitions, and the links are logical dependencies.  By exploiting this link structure, we show how one may extract organizational and relatedness information from a collection of digital formal math.  We discuss the value of the information we can extract, yielding potential applications in math search tools, theorem proving, and education.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5716,Independence From Obfuscation: A Semantic Framework for Diversity,"A set of replicas is diverse to the extent that all implement the 
same functionality but differ in their implementation details. Diverse replicas are less prone to having vulnerabilities in common, because attacks typically depend on memory layout and/or instruction-sequence specifics. Recent work advocates using mechanical means, such as program rewriting, to create such diversity. A correspondence between the specific transformations being employed and the attacks they defend against is often provided, but little has been said about the overall effectiveness of diversity per se in defending against attacks. With this broader goal in mind, we here give a precise characterization of attacks, applicable to viewing diversity as a defense, and also show how mechanically-generated diversity compares to a well-understood defense, strong typing.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5717,Optimal Shortcuts for Balanced Search Trees,"We present an alternative to tree rebalancing for improving the 
expected search cost in weighted binary search trees. This alternative is based on the insertion of shortcut links between nodes in the search tree. We propose several shortcut models and give polynomial time algorithms to find the best shortcuts for two of these models.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5718,"Phase transitions and other phenomena in graphs grown with preferential 
attachment","We study a model of grown graph where a vertex is added at each time 
step, then an edge is added with probability $\delta$.   Callaway et al. showed that when both end vertices of the edge are   chosen uniformly at random, the critical probability of edges   $\delta_c$ to get a component which grows linearly with the number   of vertices (a giant component) was \sfrac 1/8, smaller than in a   comparable static graph.   We derive a formula giving $\delta_c$ as a function of the initial   self-attractiveness of vertices in a growth model where one end of   the edge is chosen with preferential attachment. This number   decreases even more as the self-attractiveness increases. For a   self-attractiveness of one (value generally accepted for the web   graph), it takes less than one edge for every twelve vertices to get   a component whose size grows linearly with the number of vertices.   This explains why graphs with more edges, such as the   web-graph, or connectivity graphs   of peer-to-peer networks, are so well connected and so well   resilient to the deletion of edges.   We also show how to derive a formula giving the size of this giant   component as function of the number of edges and the initial   attractiveness.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5719,Some Results on the SmallWorld Model,"Jon Kleinberg published simulations exhibiting an interesting 
asymmetric behaviour in networks close to being small-world. We prove this behaviour and fully characterise the phenomena. Newman et al. had a slightly different model, with hierarchies modelling the distance between nodes. Their simulations show that two hierarchies is the optimum. We analyse the concept of hierarchies in the Kleinberg model, better suited to computer networks, and we prove that in fact one hierarchy is the optimum.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5720,Topology Search over Biological Databases,"We introduce the notion of a data topology and the problem of 
topology search over databases. A data topology summarizes the set of all possible relationships that connect a given set of entities. Topology search enables users to search for data topologies that relate entities in a large database, and to effectively summarize and rank these relationships. Using topology search over a biological database, users can ask, for example, {\em how} transcription factor proteins are related to DNAs in humans.  However, detecting topologies in large databases is a difficult problem because entities can be connected in multiple ways. In this paper, we formalize the notion of data topologies, develop efficient algorithms for computing data topologies based on user queries, and evaluate our algorithms using a real biological database.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5721,Information-Flow Security for Interactive Programs,"Interactive programs allow users to engage in input and output 
throughout execution.  The ubiquity of such programs motivates the development of models for reasoning about their information-flow security, yet no such models seem to exist for imperative programming languages. Further, existing language-based security conditions founded on noninteractive models permit insecure information flows in interactive imperative programs.  This paper formulates new strategy-based information-flow security conditions for a simple imperative programming language that includes input and output operators. The semantics of the language enables a fine-grained approach to the resolution of nondeterministic choices. The security conditions leverage this approach to prohibit refinement attacks while still permitting observable nondeterminism.  Extending the language with probabilistic choice yields a corresponding definition of probabilistic noninterference.  A soundness theorem demonstrates the feasibility of statically enforcing the security conditions via a simple type system.  These results constitute a step toward understanding and enforcing information-flow security in real-world programming languages, which include similar input and output operators.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5722,PTrie: Priority Queue based on multilevel prefix tree,"Tree structures are very often used data structures. Among ordered 
types of trees there are many variants whose basic operations such as insert, delete, search, delete-min are characterized by logarithmic time complexity. In the article I am going to present the structure whose time complexity for each of the above operations is O(M/K + K), where $M$ is the size of data type and $K$ is constant properly matching the size of data type. Properly matched $K$ will make the structure function as a very effective Priority Queue. The structure size linearly depends on the number and size of elements. PTrie is a clever combination of the idea of prefix tree -- Trie, structure of logarithmic time complexity for insert and delete operations, doubly linked list and queues.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5723,Normalization of IZF with Replacement,"IZF is a well investigated impredicative constructive version of 
Zermelo-Fraenkel set theory. Using set terms, we axiomatize IZF with Replacement, which we call IZF_R, along with its intensional counterpart IZF_R^-. We define a typed lambda calculus corresponding to proofs in IZF_R^- according to the Curry-Howard isomorphism principle. Using realizability for IZF_R^-, we show weak normalization of the calculus by employing a reduction-preserving erasure map from lambda terms to realizers. We use normalization to prove disjunction, numerical existence, set existence and term existence properties. An inner extensional model is used to show the properties for full, extensional IZF_R.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5724,Latency- and Bandwidth-Minimizing Optimal Failure Detectors,"Failure detectors are fundamental building blocks in distributed 
systems. Multi-node failure detectors, where the detector is tasked with monitoring other nodes, play a critical role in overlay networks and peer-to-peer systems. In such networks, failures need to be detected quickly and with low overhead. Achieving these properties simultaneously poses a difficult tradeoff between detection latency and resource consumption. In this paper, we examine this central tradeoff, formalize it as an optimization problem and analytically derive the optimal closed form formulas for multi-node failure detectors. We provide two variants of the optimal solution for optimality metrics appropriate for two different deployment scenarios. The latency-minimizing failure detector (LM-OFD) achieves the lowest average failure detection latency given a fixed bandwidth constraint for system maintenance. The bandwidth-minimizing failure detector (BM-OFD) will meet a desired detection latency target with the least amount of bandwidth consumed. We evaluate our optimal results with node lifetimes chosen from bimodal and power-law distributions, as well as real-world trace data from PlanetLab hosts that spans five months. Compared to standard failure detectors in wide use, our approach reduces failure detection latencies by 40% on average for the same bandwidth consumption, or conversely, reduce the amount of bandwidth consumed by 30% for the same failure detection latency.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5725,Complexity Oblivious Network Management,"Networks are hard to manage and in spite of all the so called 
holistic management packages, things are getting worse. We argue that this is an outcome of two fundamental flaws in the existing architecture: the management plane depends on the data plane and the complexity of the ever-evolving data plane encumbers the management plane. Consequently, addressing these flaws can make the network amenable to management. In this paper, we present Complexity Oblivious Network Management (CONMan), a network architecture in which the management plane does not depend on the data plane and all data plane protocols expose a generic management interface. This restricts the operational complexity of protocols to their implementation and allows the management plane to achieve high level policies in a structured fashion. Our preliminary experience with building the CONMan interface of a couple of protocols and using them for real world management tasks indicates the architecture's potential to alleviate the management troubles of the Internet.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5726,Chunkyspread: Heterogeneous Unstructured End System Multicast,"In order to maximize throughput in end-system multicast, it is 
necessary to have fine-grained control over the transmit load of each participating member. This both avoids bottlenecks where members are overloaded, and allows heterogeneous members to contribute as much transmit capacity as they are able or willing to. In this paper, we describe and simulate an unstructured endsystem multicast protocol called Chunkyspread that provides members with fine-grained control over their transmit load, scales well, has relatively low latencies, and can tolerate high membership churn. Chunkyspread is designed as a flexible framework that easily incorporates different constraints and optimizations. For instance, it is straightforward to add tit-for-tat or path disjointness as constraints to the system. This paper demonstrates the performance of Chunkyspread through extensive simulations, and provides partial validation of these simulations on Emulab. It also provides detailed comparisons with Splitstream, a structured heterogeneous end-system multicast protocol. The simulations show that Chunkyspread provides far better control over transmit load than Splitstream, while exhibiting comparable or better latency and responsiveness to churn.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5727,An Experiment in Deploying Next Generation Network Protocols,"This paper presents IP(dmux) -  a network-layer infrastructure that 
serves as a general-purpose deployment vehicle for next-generation network protocols. For each new network protocol, IP(dmux) provides a network-level access path between any end-user and the (approximately) closest router supporting the new protocol. IP(dmux) thus ensures that even partial deployments of new protocols are easily accessible by the global Internet user population. We present the design and implemention of IP(dmux) which we then use to experiment with three next-generation IP architectures - IPv6, FRM (a new protocol for global network-layer multicast) and i3 (a rendezvous-based network architecture). Our experiences suggest new networklayer architectures can easily leverage IP(dmux) to aid their deployment. Moreover, our evaluation through simulation, measurement and wide-area deployment indicates that even small-sized IP(dmux) deployments can yield reasonable endto- end performance for partially deployed next generation architectures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5728,Understanding IP Anycast,"In this paper we present the first detailed analysis of IP anycast 
as used in the anycasting of the root-servers. The main results of our study are:  The anycasting of an IP prefix does not have any unfavorable interactions with the routing system. Hence, IP anycast offers very good affinity2 - this alleviates concerns regarding running connection oriented services on top of anycast.  IP Anycast, by itself, does not offer proximity in terms of metrics such as latency. IP Anycast's backwards compatibility derives from the fact that it is transparent to existing routing protocols, but this transparency also implies that in many cases inter-domain routing, which was designed with unicast path-selection in mind, chooses anycast locations which are not close to the source. We also present deployment schemes 1the problems include scalability by the number of anycast groups, difficulty of deployment etc.; these have restricted the use of IP anycast to critical infrastructure services 2tendency of subsequent packets of a connection to be delivered to the same target that might allow anycast to achieve good latency based proximity",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5729,An Axiomatization of Arrays for Kleene Algebra with Tests,"The formal analysis of programs with arrays is a notoriously 
difficult problem due largely to aliasing considerations. In this paper we augment the rules of Kleene algebra with tests (KAT) with rules for the equational manipulation of arrays in the style of schematic KAT. These rules capture and make explicit the essence of subscript aliasing, where two array accesses can be to the same element. We prove the soundness of our rules, as well as illustrate their usefulness with several examples, including a complete proof of the correctness of heapsort.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5730,An Abstract Semantics for Atoms in Nuprl,"We provide a supervaluating semantics for treating Atoms abstractly 
in Computational Type Theory, specifically for Nuprl logics. It supports a principled explanation for desirable gaps in provability without positing novel kinds of entities, nor relying in any way upon constructivity of the logic. Beyond that, though, we justify a rule that allows inference by renaming Atom values, and explore the impact of introducing this new rule upon notational definition as used in the logics.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5731,"What's ""Next""?","Event processing systems have wide applications ranging from 
monitoring RSS feeds to managing events from RFID readers, and there exists much work on them in the literature.  Many competing temporal models for event systems have been proposed, with no consensus on which  approach is best.  In this paper we determine the important properties  for such temporal models.  Our approach is to define a very general  temporal model capable of representing time in all of the major event systems.  We introduce axioms motivated by the time stamp ordering relation and the semantics of the successor operator, which is present in all event systems.  Only two of our axioms are controversial; the remaining axioms are satisfied by all event systems. We consider the temporal models obtained using our full set of axioms, and the models that result when one or the other of our controversial axioms is weakened.  In one case we see that there is no acceptable temporal model.  In the other two cases, we show that the resulting temporal model is effectively unique up to isomorphism, leaving us with only two different models. Finally, we argue that one of the two models is better than the other when both naturalness of semantics and efficiency of  implementation are considered.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5732,An Incremental Model for Combinatorial Minimization,"Traditional optimization algorithms are concerned with static input, 
static constraints, and attempt to produce static output of optimal value. Recent literature has strayed from this conventional approach to deal with more realistic situations in which the input changes over time. Incremental optimization is a new framework for handling this type of dynamic behavior. We consider a general model for producing incremental versions of traditional covering problems along with several natural incremental metrics. Using this model, we demonstrate how to convert conventional algorithms into incremental algorithms with only a constant factor loss in approximation power. We introduce incremental versions of min cut, edge cover, and (k, r)-center and present some hardness results. Lastly, we discuss how the incremental model can help us more fully understand online problems and their corresponding algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5733,Network Distance Estimation with Guarantees for All Node Pairs,"An active line of research in the networking community studies the 
distance matrix defined by the node-to-node latencies in the Internet and, in particular, provides a number of quite successful distributed approaches that approximately reconstruct these distances from observations. In such algorithms it is feasible to measure distances among only a linear or near-linear number of node pairs; the rest of the distances are simply not available. The most common framework for Internet measurements of this type is a beacon-based approach: one chooses randomly a constant number of nodes ('beacons') in the network, each node measures its distance to all beacons, and one then has access to only these measurements for the remainder of the algorithm. To obtain theoretical insight into these recent Internet measurement studies, [Kleinberg et al. FOCS'04] formulated a concrete distance reconstruction problem, termed ""triangulation"", where distances from a given node to beacons form a short node label, and the unobserved distances are inferred from these labels using triangle inequality. While several significant results have been obtained in this framework, all these results include a notion of slack: they provide no guarantees for a small fraction of node pairs. Essentially, for any given positive $\epsilon$ and $\delta$, one can reconstruct all but an $\epsilon$-fraction of distances with multiplicative error at most $1+\delta$, using only a constant number of beacons. In this paper we obtain triangulation-style guarantees \emph{for all node pairs}: we reconstruct all distances with multiplicative error at most $1+\delta$, with only a poly-logarithmic load on each participating node. Our guarantees are for growth-constrained metrics, a well-studied family of metrics which have been proposed as a reasonable abstraction of Internet latencies.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5734,"Octant: A Comprehensive Framework for the Geolocalization of Internet 
Hosts","This paper outlines a novel, comprehensive framework for 
geolocalization, that is, determining the physical location of Internet hosts based on network measurements. The core insight behind this framework is to pose the geolocalization problem formally as one of error-minimizing constraint satisfaction, to create a system of constraints by deriving them aggressively from network measurements, and to solve the system using cheap and accurate geometric methods. The framework is general and accommodates both positive and negative constraints, that is, constraints on where the node can or cannot be, respectively. It can reason in the presence of uncertainty, enabling it to gracefully cope with aggressively derived constraints that may contain errors. Since the solution space is represented geometrically as a region bounded by Bezier curves, the framework yields an accurate set of all points where the target may be located. Preliminary results on PlanetLab show promise; the framework can localize the median node to within 22 mi., a factor of three better than previous approaches, with little error.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5735,Selection and Analysis of Minimal Sets of Enzyme Levels and Regulatory Structures for Optimization of Microbial Overproduction Using Large-Scale Kinetic Models of Cellular Systems,"We introduce a hybrid deterministic/stochastic optimization modeling framework to identify minimal sets of enzyme levels and enzyme regulatory structures to meet significant overproduction requirements using large-scale kinetic models of microbial metabolism and essential protein machinery.
 Specifically, a simulated annealing algorithm is used to navigate through the discrete space of enzyme levels and regulatory structures, while a sequential quadratic programming method is utilized to identify optimal enzyme levels and regulatory kinetic parameters. The framework is demonstrated on a large-scale and chemically-detailed kinetic model of central metabolism in Escherichia coli (wild-type strain W3110) for the optimization of the glucose uptake through the phosphotransferase system (PTS) and serine biosynthesis. 
Computational results show that by optimally modulating enzyme levels and carefully altering enzyme regulatory properties, a stable 8-fold increase in the PTS uptake rate and a stable 22-fold increase in serine biosynthesis can be achieved. Importantly, substantial improvements in the targeted fluxes can be predicted by manipulating only small subsets of enzyme levels and regulatory structures. 
For example, the modulation of only three enzyme levels leads to a flux increase, which is almost 50% of the best predictions, and the manipulation of only six enzyme levels already leads to a flux increase of 80% of the best predictions. Remarkably, by optimally modulating 10 enzyme levels, the total central metabolism's enzyme overexpression capability is reached and any further increase in the targeted fluxes can be only possible if the pathway regulation is additionally altered, though at the expense of the loss of the pathway's steady state stability properties (i.e., no steady state can exist or oscillatory regimes may be encountered). 
The developed framework has also demonstrated a strong synergism between the redesign of control architectures for tightly regulated reaction steps (e.g., phosphofructokinase) and the overexpression of those enzymes which lack any type of regulatory properties (e.g., glyceraldehyde-3-phosphate dehydrogenase). 
Although the nonlinear optimization predictions are found in a good agreement with Metabolic Control Analysis (MCA) and large control coefficients can be indicative of the corresponding ""rate limiting"" enzymes and critical feedback regulatory parameters, the non-linear stable optimization predictions could not be found from the MCA alone. 
The proposed optimization framework thus provides a new versatile modeling strategy and computational tool for systematic optimal elucidation of minimal sets of controlling enzymes and their critical regulatory properties with broad implication in biotechnological studies.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5736,"Characterization of XML Functional Dependencies and their Interaction 
with DTDs","With the rise of XML as a standard model of data exchange, XML 
functional dependencies (XFDs) have become important to areas such as key analysis, document normalization, and data integrity. XFDs are more complicated than relational functional dependencies because the set of XFDs satisfied by an XML document depends not only on the document values, but also the tree structure and corresponding DTD. In particular, constraints imposed by DTDs may alter the implications from a base set of XFDs, and may even be inconsistent with a set of XFDs. In this paper we examine the interaction between XFDs and DTDs. We present a sound and complete axiomatization for XFDs, both alone and in the presence of certain classes of DTDs. We show that these DTD classes form an axiomatic hierarchy, with the axioms at each level a proper superset of the previous. Furthermore, we show that consistency checking with respect to a set of XFDs is feasible for these same classes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5737,Making Distributed Computation Trustworthy by Construction,"Trustworthy computing systems must provide data confidentiality and 
data integrity, and must be available. This paper shows that these security properties can be provided by construction, by compiling high-level, security-typed source code into explicitly distributed, security-typed target code.  This code transformation provably preserves the confidentiality, integrity, and availability properties of the source. A key technical contribution is the new target language, which describes distributed computation. In this language, any well-typed program satisfies noninterference properties that ensure confidentiality and integrity. Further, the language supports the distribution and replication of code and data using quorum replication, which enables simultaneous enforcement of integrity and availability. A novel timestamp scheme handles out-of-order accesses by concurrent distributed threads without creating covert channels.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5738,Distance Estimation and Object Location via Rings of Neighbors,"We consider four problems on distance estimation and object location 
which share the common flavor of capturing global information via informative node labels: low-stretch routing schemes, distance labeling, searchable small worlds, and triangulation-based distance estimation. Focusing on metrics of low doubling dimension, we approach these problems with a common technique called ""rings of neighbors"", which refers to a sparse distributed data structure that underlies all our constructions. Apart from improving the previously known bounds for these problems, our contributions include extending Kleinberg's small world model to doubling metrics, and a short proof of the main result in [Chan et al., SODA 2005]. Doubling dimension is a notion of dimensionality for general metrics that has recently become a useful algorithmic concept in the theoretical computer science literature.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5739,"Stackelberg thresholds in network routing games or The value of 
altruism","We study the problem of determining the minimum amount of flow 
required to be centrally controlled in a Stackelberg routing game in order to improve the social cost of a Nash equilibrium. We consider the special case of routing on a parallel link graph with linear delays and give a closed form expression for the above quantity.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5740,"Linear Time Algorithms Based on Multilevel Prefix Tree for Finding 
Shortest Path with Positive Weights and Minimum Spanning Tree in a Networks","In this paper I present general outlook on questions relevant to the 
basic graph algorithms; Finding the Shortest Path with Positive Weights and Minimum Spanning Tree. I will show so far known solution set of basic graph problems and present my  own. My solutions to graph problems  are characterized by their linear worst-case time complexity. It should be noticed that the algorithms which compute the Shortest Path and Minimum Spanning Tree problems not only analyze the weight of arcs (which is the main and often the only criterion of solution hitherto known algorithms) but also in case of identical path weights they select this path which walks through as few vertices as  possible. I have presented algorithms which use priority queue based on multilevel prefix tree -- PTrie. PTrie is a clever combination of the idea of prefix tree -- Trie, the structure of logarithmic time complexity for insert and remove operations, doubly linked list and queues. In C++ I will implement linear worst-case time algorithm computing the Single-Destination Shortest-Paths problem and I will explain its usage.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5741,Metric Embeddings with Relaxed Guarantees,"We consider the problem of embedding finite metrics with ""slack"": we 
seek to produce embeddings with small dimension and distortion while allowing a (small) constant fraction of all distances to be arbitrarily distorted. This definition is motivated by recent research in the networking community, which achieved striking empirical success at embedding Internet latencies with low distortion into low-dimensional Euclidean space, provided that some small slack is allowed. Answering an open question of [Kleinberg, Slivkins, and Wexler, IEEE FOCS 2004], we show that provable guarantees of this type can in fact be achieved in general: any finite metric can be embedded, with constant slack and constant distortion, into constant-dimensional Euclidean space. We then show that there exist stronger embeddings into L1 which exhibit ""gracefully degrading"" distortion: these is a single embedding into L1 that achieves distortion at most O(log 1/epsilon) on all but at most an epsilon-fraction of distances, *simultaneously* for all epsilon greater than 0. We extend this with distortion  O(log 1/epsilon)^{1/p} to maps into general Lp, p greater than or equal to 1 for  several classes of metrics, including those with bounded doubling dimension and those arising from the shortest-path metric of a graph with an excluded minor. Finally, we show that many of our constructions are tight, and give a general technique to obtain lower bounds for epsilon-slack embeddings from lower bounds for low-distortion embeddings.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5742,Getting the Most Out of Ensemble Selection,"We investigate four previously unexplored aspects of ensemble 
selection, a procedure for building ensembles of classifiers. First we test whether adjusting model predictions to put them on a canonical scale makes the ensembles more effective.  Second, we explore the performance of ensemble selection when different amounts of data are available for ensemble hillclimbing.  Third, we quantify the benefit of ensemble selection's ability to optimize to arbitrary metrics. Fourth, we study the performance impact of pruning the number of models available for ensemble selection. Based on our results we present improved ensemble selection methods that double the benefit of the original method.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5743,Plagiarism Detection in arXiv,"We describe a large-scale application of methods for finding 
plagiarism and self-plagiarism in research document collections. The methods are applied to a collection of 284,834 documents collected by arXiv.org over a 14 year period, covering a few different research disciplines.  The methodology efficiently detects a variety of problematic author behaviors, and heuristics are developed to reduce the number of false positives.  The methods are also efficient enough to implement as a real-time submission screen for a collection many times larger.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5744,Cluster Ensembles for Network Anomaly Detection,"Cluster ensembles aim to find better, more natural clusterings by 
combining multiple clusterings.  We apply ensemble clustering to anomaly detection, hypothesizing that multiple views of the data will improve the detection of attacks.  Each clustering rates how anomalous a point is; ratings are combined by averaging or taking either the minimum, the maximum, or median score.  The evaluation shows that taking the median prediction from the cluster ensemble results in better performance than single clusterings.  Surprisingly, averaging the individual predictions a) leads to worse performance than that of individual clusterings, and b) performs identically to taking the minimum prediction from the ensemble.  This counter-intuitive result stems from asymmetric prediction distributions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5745,"Maintaining Structural Invariants in Shape Analysis with Local 
Reasoning","This paper presents a novel shape analysis algorithm with local 
reasoning that is designed to analyze heap structures with structural invariants, such as doubly-linked lists.  The algorithm abstracts and analyzes one single heap cell at a time. In order to maintain the structural invariants, the analysis uses a local heap abstraction that models the sub-heap consisting of one cell and its immediate neighbors.  The proposed algorithm can successfully analyze standard doubly-linked list manipulations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5746,Meta Clustering,"Clustering is ill-defined.  Unlike supervised learning where labels 
lead to crisp performance criteria such as accuracy and squared error, clustering quality depends on how the clusters will be used.  Devising clustering criteria that capture what users need is difficult. Most clustering algorithms search for one optimal clustering based on a pre-specified clustering criterion. Once that clustering has been determined, no further clusterings are examined.  Our approach differs in that we search for many alternate reasonable clusterings of the data, and then allow users to select the clustering(s) that best fit their needs.  Any reasonable partitioning of the data is potentially useful for some purpose, regardless of whether or not it is optimal according to a specific clustering criterion.  Our approach first finds a variety of reasonable clusterings.  It then clusters this diverse set of clusterings so that users must only examine a small number of qualitatively different clusterings.  In this paper, we present methods for automatically generating a diverse set of alternate clusterings, as well as methods for grouping clusterings into meta clusters.  We evaluate meta clustering on four test problems, and then apply meta clustering to two case studies. Surprisingly, clusterings that would be of most interest to users often are not very compact clusterings.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5747,Worst-Case Background Knowledge in Privacy,"Recent work has shown the necessity of considering an attacker's 
background knowledge when reasoning about privacy in data publishing.  However, in practice, the data publisher does not know what background knowledge the attacker possesses.  Thus, it is important to consider the worst-case.  In this paper, we initiate a formal study of worst-case background knowledge.  We propose a language that can express any background knowledge about the data.  We provide a polynomial time algorithm to measure the amount of disclosure of sensitive information in the worst case, given that the attacker has at most k pieces of information in this language.  We also provide a method to efficiently sanitize the data so that the amount of disclosure in the worst case is less than a specified threshold.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5748,A Normalizing Intuitionistic Set Theory with Inaccessible Sets,"We propose a set theory strong enough to interpret powerful type 
theories underlying proof assistants such as LEGO and also possibly Coq, which at the same time enables program extraction from constructive proofs. For this purpose, we axiomatize impredicative constructive version of Zermelo-Fraenkel set theory IZF with Replacement and $\omega$-many inaccessibles, which we call IZF_{R\omega}. Our axiomatization of IZF_{R\omega} utilizes set terms, an inductive definition of inaccessible sets and mutually recursive nature of equality and membership relations. It allows us to define a weakly-normalizing typed lambda calculus \lambda Z_\omega corresponding to proofs in IZF_{R\omega} according to the Curry-Howard isomorphism principle. We use realizability to prove the normalization theorem, which provides basis for extracting programs from IZF_{R\omega} proofs.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5749,"Birthdays, Broadcasts, and Boolean Algebras: Probabilistic Boolean 
Algebras and Applications","In the area of extremal finite set theory there are many 
combinatorial  results concerning the selection of m k-element sets.  This type of  set selection can also be viewed as a boolean algebra.  In this paper we  consider a probabilistic construction of this boolean algebra,  concentrating on the structure and properties such an algebra may form,  particularly the structure of the algebra's atoms.  The results are then  applied to a generalization of the popular birthday problem, where the  event of interest is now whether all selected sets have a unique element;  we find an upper bound on the probability of this event.  We also extend  the definition of the generalized birthday problem to model content  protection protocols.  While these protocols are widely used in digital  media rights management, they are insufficiently analyzed due to a lack of  such an underlying model.  We focus on the event that revoking the rights  of multiple pirate users inadvertently causes the rights of other,  authorized users to be unjustly revoked;  we give an exact formula for the  probability of this event.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5750,"Topology Search over Biological Databases Topology Search over 
Biological Databases","We introduce the notion of a data topology and the problem of 
topology search over databases. A data topology summarizes the set of all possible relationships that connect a given set of entities. Topology search enables users to search for data topologies that relate entities in a large database, and to effectively summarize and rank these relationships. Using topology search over a biological database, users can ask, for example, {\em how} transcription factor proteins are related to DNAs in humans.  However, detecting topologies in large databases is a difficult problem because entities can be connected in multiple ways. In this paper, we formalize the notion of data topologies, develop efficient algorithms for computing data topologies based on user queries, and evaluate our algorithms using a real biological database.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5751,TRUST-TECH based Neural Network Training,"Supervised learning using artificial neural networks has numerous 
applications in various domains of science and engineering. Efficient training mechanisms in a neural network play a vital role in deciding the network architecture and the accuracy of the classifier. Most popular training algorithms tend to be greedy and hence get stuck at the nearest local minimum of the error surface. To overcome this problem, some global methods (like multiple restarts, genetic algorithms, simulated annealing etc.) for efficient training make use of stochastic approaches in combination with local methods to obtain an effective set of training parameters. Due to the stochastic nature and lack of effective fine tuning capability, these algorithms often fail to obtain an optimal set of training parameters. In this paper, a new method to improve the subspace parameter search capability of training algorithms is proposed. This new method takes advantage of TRUST-TECH (TRansformation Under STability-reTaining Equilibrium CHaracterization) to compute neighborhood local minimum of the error surface. The proposed approach obtains multiple local optimal solutions surrounding the current local optimal solution in a systematic manner. Empirical results on different machine learning datasets indicate that the proposed algorithm outperforms current algorithms available in the literature.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5752,Memory Leak Analysis by Contradiction,"We present a novel leak detection algorithm. To prove the absence of 
a memory leak, the algorithm assumes its presence and runs a backward heap analysis to disprove this assumption. We have implemented this approach in a memory leak analysis tool and used it to analyze several routines that manipulate linked lists and trees. Because of the reverse nature of the algorithm, the analysis can locally reason about the absence of memory leaks. We have also used the tool as a scalable, but unsound leak detector for C programs. The tool has found several bugs in larger programs from the SPEC2000 suite.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5753,Firebreak: An IP Perimeter Defense Architecture,"After many years of research, the Distributed Denial of Service 
(DDoS) problem remains essentially unsolved, both in industry and in research. Industry solutions rely primarily on beefing up the bandwidth near the attack target, and/or on intercepting traffic at proxies while keeping the target IP address secret. The former approach is expensive, and the latter amounts to ""security through obscurity"". Existing research solutions, on the other hand, have so far proven economically infeasible. We propose an architecture, called the firebreak, based on IP-level indirection. With firebreak, target IP addresses are simply unreachable from ISP customer networks and endhosts. Rather, IP packets are addressed to proxies deployed near the edge using IP anycast, and from there are tunneled using the target IP addresses. This use of IP indirection, as well as the use of IP anycast and tunneling to deploy firebreak, is the main research contribution of firebreak. This paper describes the firebreak architecture, discusses its pros and cons, and suggests directions for future work",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5754,"Extracting the Resolution Algorithm from a Completeness Proof for the 
Propositional Calculus","We prove constructively that for any propositional formula $\phi$ in 
Conjunctive Normal Form, we can either find a satisfying assignment of true and false to its variables, or a refutation of $\phi$ showing that it is unsatisfiable. This refutation is a resolution proof of $\lnot \phi$. From the formalization of our proof in Coq, we extract Robinson's famous resolution algorithm as a Haskell program correct by construction. The account is an example of the genre of highly readable formalized mathematics.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5755,"Properties Framework and Typed Endpoints for Scalable Group 
Communication","Group communication is a powerful tool that simplifies the 
development of dependable systems, but widespread adoption of the paradigm has been limited. The main problem is that existing systems lack important forms of scalability and clean OS embeddings that can sustain high performance. QuickSilver is a new platform designed to enable casual use of groups on a massive scale. Our approach relies on a new way of constructing hierarchical, scalable protocols. Groups are accessed via typed communication endpoints; an underlying properties framework promotes flexibility and modularity.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5756,QuickSilver Scalable Multicast,"Reliable multicast is useful for replication and in support of 
publish-subscribe notification. However, many of the most interesting applications give rise to huge numbers of multicast groups with heavily overlapping sets of receivers, large groups, or high rates of dynamism. Existing multicast systems scale poorly in one or more of these respects. This paper describes QuickSilver Scalable Multicast (QSM), a platform exhibiting significantly improved scalability. Key advances involve new ways of handling time and scheduling, adaptive response to observed traffic patterns, and better handling of disturbances.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5757,"The Power of Indirection: Achieving Multicast Scalability by Mapping 
Groups to Regional Underlays","Reliable multicast is a powerful primitive, useful for data 
replication, event notification (publish-subscribe), fault tolerance and other purposes. Yet many of the most interesting applications give rise to huge numbers of heavily overlapping groups, some of which may be large. Existing multicast systems scale scale poorly in one or both respects. We propose the QuickSilver Scalable Multicast protocol (QSM), a novel solution that delivers performance almost independent of the number of groups and introduces newmechanisms that scale well in the number of nodes with minimal performance and delay penalties when loss occurs. Key to the solution is a level of indirection: a mapping of groups to regions of group overlap in which communication associated with different protocols can be merged. The core of QSM is a new regional multicast protocol that offers scalability and performance benefits over a wide range of region sizes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5758,Securing BGP Using External Security Monitors,"Security modifications to legacy network protocols are expensive and 
disruptive. This paper outlines an approach, based on external security monitors, for securing legacy protocols by deploying additional hosts that locally monitor the inputs and outputs of each host executing the protocol, check the behavior of the host against a safety specification, and communicate using an overlay to alert other hosts about invalid behavior and to initiate remedial actions. Trusted computing hardware provides the basis for trust in external security monitors. This paper applies this approach to secure the Border Gateway Protocol, yielding an external security monitor called N-BGP. N-BGP can accurately monitor a BGP router using commodity trusted computing hardware. Deploying N-BGP at a random 10% of BGP routers is sufficient to guarantee the security of 80% of Internet routes where both endpoints are monitored by N-BGP. Overall, external security monitors secure the routing infrastructure using trusted computing hardware and construct a security plane for BGP without having to modify the large base of installed routers and servers.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5759,Identity Trail: Covert Surveillance Using DNS,"The Domain Name System (DNS) was originally designed with the 
assumption that the DNS will return the same answer to any given query regardless of who may have issued the query, and that all data in the DNS is thus visible. Such an assumption can no longer be justified for private Internet hosts, particularly mobile laptops and PDAs. IP addresses in the DNS reveal a host's geographic location and corporate affiliation to anyone that is interested without the host's knowledge or consent. This paper identifies an attack that allows anyone on the Internet to covertly monitor mobile devices to construct detailed profiles including user identity, daily commute patterns, and travel itineraries. We identify a growing number of users vulnerable to this attack (two million and climbing), and covertly monitor over one hundred thousand of them. We demonstrate the feasibility and severity of such an attack in today's Internet. We further propose shortterm and long-term defenses for the attack.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5760,Stability Region based Methods for Learning and Discovery,"Many problems that arise in machine learning and data mining domains 
deal with nonlinearity and quite often demand users to obtain global optimal solutions rather than local optimal ones. Several algorithms had been proposed in the optimization literature and inherited by the machine learning community. Popularly known as the {\it initialization problem}, the ideal set of parameters required will significantly depend on the initial values given by the user. In this paper, we propose stability region based methods for systematically exploring the subspace of the parameters to obtain the neighborhood local optimal solutions. The proposed algorithm takes advantage of TRUST-TECH (TRansformation Under STability-reTaining Equilibria CHaracterization) to compute neighborhood local optimal solutions on the nonlinear surface in a systematic manner using stability regions. Our method explores the dynamic and geometric characteristics of stability boundaries of a nonlinear dynamical system corresponding to the nonlinear function of interest. Basically, our method coalesces the advantages of the traditional local optimizers with that of the dynamic and geometric characteristics of the stability regions of the corresponding nonlinear dynamical system of the log-likelihood function. Two phases namely, the local phase and the stability region phase, are repeated alternatively in the parameter space to achieve improvements in the quality of the solutions. The local phase obtains the local maximum of the nonlinear function and the stability region phase helps to escape out of the local maximum by moving towards the neighboring stability regions. The stability region based algorithms are applied to three important machine learning problems in: (1) Unsupervised learning - model-based clustering, (2) Pattern discovery - motif finding problem and (3) Supervised learning - training artificial neural networks. Our algorithms were tested on both synthetic and real datasets and the advantages of using this stability region based framework are clearly manifested. This framework not only reduces the sensitivity to initialization, but also allows the flexibility for the practitioners to use various global and local methods that work well for a particular problem of interest.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5761,Automatic Proof Generation in Kleene Algebra with Tests,"Kleene algebra (KA) is the algebra of regular events.  Familiar 
examples of Kleene algebras include regular sets, relational algebras, and trace algebras.  A Kleene algebra with tests (KAT) is a Kleene algebra with an embedded Boolean subalgebra.  The addition of tests allows one to encode while programs as KAT terms, thus the equational theory of KAT can express (propositional) program equivalence.  More complicated statements about programs can be expressed in the Hoare theory of KAT, which suffices to encode Propositional Hoare Logic. In this paper, we prove the following results.  First, there is a PSPACE transducer which takes equations of Kleene Algebra as input and outputs Hilbert-style proofs of them in an equational implication calculus.  Second, we give a feasible reduction from the equational theory of KAT to the equational theory of KA.  Combined with the fact that the Hoare theory of KAT reduces efficiently to the equational theory of KAT, this yields an algorithm capable of generating proofs of a large class of statements about programs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5762,Distance Coloring,"Given a graph G=(V,E), a (d,k)-coloring is an assignment of a color 
from {1, 2, ..., k} to each vertex of V such that any two vertices within distance d of each other are assigned different colors. We determine the complexity of the (d,k)-coloring problem for all d and k, and enumerate some interesting properties of (d,k)-colorable graphs. Our main result is the discovery of a dichotomy between polynomial and NP-hard instances; for fixed d greater than or equal to 2, the distance coloring problem is polynomial time for k less than or equal to 3d/2 and NP-hard for k greater than 3d/2.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5763,"A Unified Platform for Data Driven Web Applictions with Automatic 
Client-Server Partitioning","Data-driven web applications are structured into three tiers with   
different programming models at each tier. This division forces   developers to manually partition application functionality across   the tiers, resulting in complex logic, suboptimal partitioning, and   expensive re-partitioning of applications.   In this paper, we introduce a unified platform for automatic   partitioning of data-driven web applications. Our approach is based   on Hilda, a high-level   declarative programming language with a unified data and programming   model for all the layers of the application. Based on run-time   properties of the application, Hilda's run time system automatically   partitions the application between the tiers to improve response   time while adhering to memory or processing constraints at the   clients. We evaluate our methodology with traces from a real   application and with TPC-W, and our results show that automatic   partitioning outperforms manual partitioning without the associated   development overhead.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5764,"A Unified Platform for Data Driven Web Applictions with Automatic 
Client-Server Partitioning","Data-driven web applications are usually structured in three tiers 
with   different programming models at each tier. This division forces   developers to manually partition application functionality across   the tiers, resulting in complex logic, suboptimal partitioning, and   expensive re-partitioning of applications.   In this paper, we introduce a unified platform for automatic   partitioning of data-driven web applications. Our approach is based   on Hilda, a high-level   declarative programming language with a unified data and programming   model for all the layers of the application. Based on run-time   properties of the application, Hilda's run time system automatically   partitions the application between the tiers to improve response   time while adhering to memory or processing constraints at the   clients. We evaluate our methodology with traces from a real   application and with TPC-W, and our results show that automatic   partitioning outperforms manual partitioning without the associated   development overhead.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5765,EM-Style Geo-Cuts Segmentation for MRI Brain Images,"Segmentation of MRI brain images has great clinical and academic 
importance. The overlap of MR intensities of different tissue types and the vast amount of thin structures in brain images make segmentation of MRI brain images difficult. In this paper, we present an EM-style geo-cuts-based segmentation method to over come these challenges. We classify the brain images into three tissue types: white matter, gray matter, and CSF. We iteratively classify the voxels and calculate the intensity profile. We use region bias and automatic seed setting combined with intensity profile induced Riemannian metrics for the classification of voxels. We then use this classification to re-estimate the intensity profile. Experimentally, our method gives very good performance on both synthetic images with ground truth segmentation and real images with the segmentation of white matter and CSF improved over the widely used EMS method.",,application/msword,Technical Report
oai:ecommons.cornell.edu:1813/5766,Quantifying Information Flow with Beliefs,"To reason about information flow, a new model is developed that 
describes how attacker beliefs change due to the attacker's observation of the execution of a probabilistic (or deterministic) program.  The model enables compositional reasoning about information flow from attacks involving sequences of interactions.  The model also supports a new metric for quantitative information flow that measures accuracy of an attacker's beliefs. Applying this new metric reveals inadequacies of traditional information flow metrics, which are based on reduction of uncertainty. However, the new metric is sufficiently general that it can be instantiated to measure either accuracy or uncertainty. The new metric can also be used to reason about misinformation; deterministic programs are shown to be incapable of producing misinformation.  Additionally, programs in which nondeterministic choices are made by insiders, who collude with attackers, can be analyzed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5767,Walnut: using NUTSS to harden services against DDOS attacks,"Protecting the bottleneck link of an internet services against 
denial of service attacks is a difficult problem. The NUTSS architecture can be used to protect the bottleneck link for private services whose authentication can be replicated, provided that a NAT can be installed at the upstream end of this link. This paper analyzes the proposed defense and argues that it has a low run-time cost and offers substantial security benefits.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5768,Efficient Keyword Search over Virtual XML Views,"Emerging applications such as personalized portals, enterprise 
search and web integration systems often require keyword search over semi-structured views. However, traditional information retrieval techniques are likely to be expensive in this context because they rely on the assumption that the set of documents being searched is materialized. In this paper, we present a system architecture and algorithm that can efficiently evaluate keyword search queries over virtual (unmaterialized) XML views. An interesting aspect of our approach is that it exploits indices present on the base data and thereby avoids materializing large parts of the view that are not relevant to the query results. Another feature of the algorithm is that by solely using indices, we can still score the results for queries over the virtual view, and the resulting scores and rank order are the same as if the view was materialized.  Our performance evaluation using the INEX data set in the Quark open-source XML database system indicates that the proposed approach is scalable and efficient.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5769,Secure web applications via automatic partitioning,"Web applications are now critical infrastructure. To improve the 
user interface, some application functionality is typically implemented as client-side JavaScript code.  Currently there are no good methods for deciding when it is secure to move code and data to the client side. Swift is a new, principled approach to building web applications that are secure by construction.  Application code is written as Java-like code annotated with information flow policies. This code is automatically partitioned between JavaScript code running in the browser, and Java code running on the server. Code and data are placed on the client side where possible.  Security-critical code is placed on the server and user interface code is placed on the client.  Code placement is constrained by high-level, declarative information flow policies that strongly enforce the confidentiality and integrity of server-side information. Web applications are hard to build because code and data needs to be partitioned to make them responsive. They are also hard to build because code and data need to be partitioned for security. Because of the connection (and tension) between the two problems, Swift addresses both at once, automatically partitioning  application code while also providing assurance that the resulting placement is secure and efficient.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5774,Typed Memory Management in a Calculus of Capabilities,"Region-based memory management is an alternative to standard tracing garbage collection that makes potentially dangerous operations such as memory deallocation explicit but verifiably safe.  In this article, we present a new compiler intermediate language, called the Capability Calculus, that supports region-based memory management and enjoys a provably safe type system.  Unlike previous region-based type systems, region lifetimes need not be lexically scoped and yet the language may be checked for safety without complex analyses. Therefore, our type system may be deployed in settings such as  extensible operating systems where both the performance and safety  of untrusted code is important. The central novelty of the language is the use of static capabilities to specify the permissibility of various operations, such as memory access and deallocation.  In order to ensure capabilities are relinquished properly, the type system tracks aliasing information using a form of bounded quantification.  Moreover, unlike previous work on region-based type systems, the proof of soundness of our type system is relatively simple, employing only standard syntactic techniques.   In order to show our language may be used in practice, we show how to translate a variant of Tofte and Talpin's high-level type-and-effects system for region-based memory management into our language.  When combined with known region inference algorithms, this translation provides a way to compile source-level languages to the Capability Calculus.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5775,Fractal Symbolic Analysis for Program Transformations (*new file*),"Restructuring compilers use dependence analysis to prove that  the meaning of a program is not changed by a transformation.  A  well-known limitation of dependence analysis is that it  examines only the memory locations read and written by a  statement, and does not assume any particular interpretation  for the operations in that statement. Exploiting the semantics  of these operations enables a wider set of transformations to  be used, and is critical for optimizing important codes such as  LU factorization with pivoting. Symbolic execution of programs enables the exploitation of such semantic properties, but it is intractable for all but the  simplest programs. In this paper, we propose a new form of  symbolic analysis for use in restructuring compilers. Fractal  symbolic analysis compares a program and its transformed  version by repeatedly simplifying these programs until symbolic  analysis becomes tractable, ensuring that equality of simplified programs is sufficient to guarantee equality of the original  programs. We present a prototype implementation of fractal  symbolic analysis, and show how it can be used to optimize the  cache performance of LU factorization with pivoting.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5776,Tiling Imperfectly-nested Loop Nests (REVISED),"Tiling is one of the more important transformations for enhancing locality of reference in programs. Tiling of  perfectly-nested loop nests (which are loop nests in which all assignment statements are contained in the innermost loop) is well understood. In practice, most loop nests are imperfectly-nested, so existing compilers heuristically try to find a sequence of transformations that convert such loop nests into perfectly-nested ones but not always succeed. In this paper, we propose a novel approach to tiling imperfectly-nested loop nests. The key idea is to embed the iteration space of every statement in the imperfectly-nested loop nest into a special space called the product space.  The set of possible embeddings is constrained so that the resulting product space can be legally tiled. From this set we choose embeddings that enhance data reuse. We evaluate the effectiveness of this approach for dense numerical linear algebra benchmarks, relaxation codes, and the tomcatv code from the SPEC benchmarks.  No other single approach in the literature can tile all these codes automatically.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5777,Scalable Certification of Native Code: Experience from Compiling toTALx86,"Certifying compilation allows a compiler to produce annotations that prove that target code abides by a specified safety policy.  An independent verifier can check the code without needing to trust the compiler.  For such a system to be generally useful, the safety policy should be expressive enough to allow different compilers to effectively produce certifiable code. In this work, we use our experience in writing a certifying compiler to suggest general design principles that should allow concise yet expressive certificates.  As an extended example, we present our compiler's translation of the control flow of Popcorn, a high-level language with function pointers and exception handlers, to TALx86, a typed assembly language with registers, a stack, memory, and code blocks.  This example motivates techniques for controlling certificate size and verification time. We quantify the effectiveness of techniques for reducing the overhead of certifying compilation by measuring the effects their use has on a real Popcorn application, the compiler itself.  The selective use of these techniques, which include common-subexpression elimination of types, higher-order type abbreviations, and selective re-verification, can change certificate size and verification time by well over an order of magnitude.  We consider this report to be the first quantitative study on the practicality of certifying a real program using a type system not specifically designed for the compiler or source language.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5778,Investigations in Geometric Subdivisions: Linear Shattering andCartographic Map Coloring,"> We consider three computational geometry problems: shattering, coloring > cartographic maps and Bruce's suntan lotion problem. >  > A subdivision ${\cal S}\subseteq\Re^d$ {\em shatters} a set of $n$ > objects if each object is contained within the closure of its own cell > of ${\cal S}$.  We consider the problem of shattering polyhedra with > $N$ total vertices using an arrangement of hyperplanes.  We show that > finding a minimum shattering of points in $\Re^2$ is \NP-Complete.  A > restricted version using axes-parallel hyperplanes is also > \NP-Complete. The actual number of shattering hyperplanes required > varies between $O(n^{1/d})$ and $n-1$.  We present algorithms that > produce locally optimal solutions with at most $n-1$ shattering > hyperplanes. For $\Re^2$, we achieve $O(n^2\log{n}+N^2)$ time > complexity. We have implemented a simplified version.  For > $\Re^d,d\ge3$, we have an $O(N^d(n+\log{N}))$ time algorithm. We give > an $O(N^4)$ time approximation algorithm which guarantees a solution > within a factor of $1+\ln{n}$ of optimal for $\Re^2$.  Detecting > whether a set of line segments is shatterable is shown to be > \3SUM-Hard. >  > We consider cartographic map coloring for use in Geographical > Information Systems.  The published proofs of the famous four-color > theorem yield impractical polynomial-time algorithms.  Instead, we > implemented Thomassen's linear-time five-coloring algorithm.  Political > maps often require generalizations to the standard four-coloring > problem.  We allow each country to have $m$ disjoint pieces, which is > Heawood's $m$-pire problem.  We also count node adjacency between > countries; such adjacency graphs are known as map graphs.  If $k$ > regions meet at a point, we conjecture for $k\ge5$ that > $\lfloor\frac{3}{2}k\rfloor$ colors suffice. By combining $m$-pires with > node adjacency and islands, we can model actual GIS instances.  We > implemented Br{\'e}laz's $Dsatur$ heuristic, since no specific algorithm > exists for coloring our resulting {\em cartographic graphs}. >  > Given convex polygon \P, let \D1, \D2\ be disks centered on \P's > boundary with radii $r_1$ and $r_2$, chosen so that > $\P\subseteq\D1\cup\D2$ and $r_1+r_2$ is minimized.  Bruce's Suntan > Lotion problem asks for the disks' locations and sizes.  We describe the > optimal cover for a triangle when $r_2=0$ and generalize the solution to > convex polygons; the minimum covering disk can be found in linear time. > We show the best one-disk solution is always optimal; no superior > two-disk solution exits. >",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5779,IRM Enforcement of Java Stack Inspection,"Two implementations are given for Java's stack-inspection access-control policy.  Each implementation is obtained by generating an inlined reference monitor (IRM) for a different formulation of the policy.  Performance of the implementations is evaluated, and one is found to be competitive with Java's less-flexible, JVM-resident implementation.  The exercise illustrates the power of the IRM approach for enforcing security policies.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5780,Alias Types for Recursive Data Structures (Extended Version),"Linear type systems permit programmers to deallocate or explicitly recycle memory, but they are severly restricted by the fact that they admit no aliasing.  This paper describes a pseudo-linear type system that allows a degree of aliasing and memory reuse as well as the ability to define complex recursive data structures.  Our type system can encode conventional linear data structures such as linear lists and trees as well as more sophisticated data structures including cyclic and doubly-linked lists and trees.  In the latter cases, our type system is expressive enough to represent pointer aliasing and yet safely permit destructive operations such as object deallocation.  We demonstrate the flexibility of our type system by encoding two common compiler optimizations: destination-passing style and Deutsch-Schorr-Waite or ``link-reversal'' traversal algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5781,Compiling Imperfectly-nested Sparse Matrix Codes with Dependences,"We present compiler technology for generating sparse matrix code from (i) dense matrix code and (ii) a description of the indexing structure of the sparse matrices.  This technology embeds statement instances into a Cartesian product of statement iteration and data spaces, and produces efficient sparse code by identifying common enumerations for multiple references to sparse matrices.  This approach works for imperfectly-nested codes with dependences, and produces sparse code competitive with hand-written library code.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5782,A Decision-Theoretic Approach to Resource Allocation in WirelessMultimedia Networks,"The allocation of scarce spectral resources to support as many user applications as possible while maintaining reasonable quality of service is a fundamental problem in wireless communication.  We argue that the problem is best formulated in terms of decision theory.  We propose a scheme that takes decision-theoretic concerns (like preferences) into account and discuss the difficulties and subtleties involved in applying standard techniques from the theory of Markov Decision Processes (MDPs) in constructing an algorithm that is decision-theoretically optimal. As an example of the proposed framework, we construct such an algorithm under some simplifying assumptions. Additionally, we present analysis and simulation results that show that our algorithm meets its design goals. Finally, we investigate how far from optimal one well-known heuristic is. The main contribution of our results is in providing insight and guidance for the design of near-optimal admission-control policies.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5783,Query Processing with Heterogeneous Resources,"In emerging systems, CPUs and memory are integrated into active disks, controllers, and network interconnects. Query processing on these new multiprocessor systems must consider the heterogeneity of resources among the components. This leads to the more general problem of how to deal with performance heterogeneity in parallel database systems. We study database query processing techniques that increase the leverage of heterogeneous resources. We show that the traditional algorithms used in shared-nothing parallel databases fail to utilize non-uniform resources. Uniform resource usage across non-uniform components leads to resource bottlenecks. We describe a class of new execution techniques that balance the usage of system resources using non-uniform intra-operator parallelism. We show that these techniques improve performance on heterogeneous architectures by allowing trade-offs between the various resources. Traditional techniques are subsumed as a special case for symmetric architectures. We show a formal model that maps out the new execution space of alternative processing techniques. A simplified cost model allows analytic performance evaluation of the alternative techniques. The proposed new execution paradigm is an extension of the classical dataflow paradigm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5784,A Study of Group Rekeying,"In this paper we study the key management problem, in the context of Group Communication Systems (GCS).  GCSs are mid-sized systems scaling up to 100 members.  We present a side-by-side comparison  of three ways of managing keys, studying bandwidth and latency.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5785,Agent Technology Applied to Adaptive Relay Setting for Multi-TerminalLines,"Abstract: This paper discusses the adaptation of the settings of distance relays for multi-terminal lines employing agents. Agents are software processes capable of searching for information in  networks, interacting with pieces of equipment and performing  tasks on behalf of their owners (relays). Results illustrating  the performance of the adaptive method proposed compared to  conventional fixed settings are presented. It is shown that the  digital relays and agents acting within a communication  structure (also called middleware) can alter adaptive settings  to ensure correct performance over a wide variety of operation  conditions, without the need of an additional communication link. The proposed relaying scheme can also be utilized for first zone clearing over the entire line.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5786,Link Accessibility in Electronic Journal Articles,"D-Lib is an electronic journal which has been available since 1995. Many of the articles in D-Lib contain references that are accompanied by URLs.  Of interest is how valid these URLs are after some time goes by.  An analysis of all the references within D-Lib articles shows that 85% of the 5 1/2 years of references remain accessible.  However, by plotting the % accessible against date of the article, it is clear that link rot increases with age.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5787,A Probabilistically Correct Leader Election Protocol for Large Groups,"This paper presents a scalable leader election protocol for large process groups with a weak membership requirement. The underlying network is assumed to be unreliable but characterized by probabilistic failure rates of processes and message deliveries. The protocol trades correctness for scale, that is, it provides very good probabilistic guarantees on correct termination in the sense of the classical specification of the election problem, and of generating a constant number of messages, both independent of group size. After formally specifying the probabilistic properties, we describe the protocol in detail. Our subsequent mathematical analysis provides probabilistic bounds on the complexity of the protocol. Finally, the results of simulation show that the performance of the protocol is satisfactory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5788,Set Reconciliation with Nearly Optimal Communication Complexity,"We consider a fundamental problem that arises in the context of gossip   protocols.  Specifically, we consider the problem of efficiently   reconciling two similar sets held by different hosts while minimizing the   communication complexity.  We provide two surprisingly simple and efficient   protocols that exhibit tractable computational complexity and nearly   optimal communication complexity.  These protocols can be adapted to work   over a broadcast channel, allowing many clients to reconcile with one host   based on a broadcasted signal.\note{We keep on bouncing back and forth on     whether the ``a''s are necessary.  I like it better without, but it's not     a big deal.}  Thus, an arbitrary number of clients each of whose data   differs from that of the host by no more than $N$ bits can be reconciled by   a single broadcast of $O(N)$ bits, independent of the the number of clients   and independent of the size of the data sets.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5789,Left-looking to Right-looking and vice versa: An Application of FractalSymbolic Analysis to Linear Algebra Code Restructuring,"We have recently developed a new program analysis strategy called fractal symbolic analysis that addresses some of limitations of techniques such as dependence analysis.  In this paper, we show how fractal symbolic analysis can be used to convert between left-looking and right-looking versions of three kernels of central importance in computational science: Cholesky factorization, LU factorization with pivoting, and triangular solve.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5790,"Speeding Up Short Data Transfers: Theory, Architectural Support, andSimulation Results","Today's Internet traffic is dominated by short Web data transfers. Such a workload is well known to interact poorly with the TCP protocol.  TCP uses the slow start procedure to probe the network for bandwidth both at connection start up and upon restart after an idle period.  This usually requires several roundtrips and is inefficient when the duration of a transfer is short.  In this paper, we propose a new technique, which we call TCP/SPAND, to speed up short data transfers. In TCP/SPAND, network performance information is shared among many co-located hosts to estimate each connection's fair share of the network resources. Based on such estimation and the transfer size, the TCP sender determines the optimal initial congestion window size. Instead of doing slow start, it uses a pacing scheme to smoothly send out the packets in its initial congestion window. We use extensive simulations to evaluate the performance of the resulting system. Our results show that TCP/SPAND significantly reduces latency for short transfers even in presence of multiple heavily congested bottlenecks. Meanwhile, the performance benefit does not come at the expense of degrading the performance of connections using the standard TCP. That is, TCP/SPAND is TCP friendly.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5791,An Event-Aware Model for Metadata Interoperability,"We describe the ABC modeling work of the Harmony Project. The ABC model provides a foundation for understanding interoperability of individual metadata modules  as described in the Warwick Framework  and for developing mechanisms to translate among them.  Of particular interest in this model is an event, which facilitates understanding of the lifecycle of resources and the association of metadata descriptions with points in this lifecycle.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5792,Accommodating Simplicity and Complexity in Metadata: Lessons from theDublin Core Experience,"The Dublin Core Metadata Element Set (DCMES) grew out of a recognized need for improved resource discovery of web resources.  Initial work on the DCMES focused on the requirement of simplicity: ""ordinary"" users should be able to formulate descriptive records based on a relatively simple schema  (fifteen free-text elements).  Over the years there has been a movement within the Dublin Core community to use the DCMES for more complex and specialized resource description tasks and, correspondingly, develop mechanisms for incorporating such complexity within the basic element set.  This work has generally been called qualified Dublin Core.  We examine the notion of accommodating complexity in a simple metadata model and argue that the dual requirements are incompatible.  We discuss the role of events and processes in more expressive metadata and how simple resource-centric models, such as DCMES, are not equipped to express these semantics",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5793,Understanding the End-to-End Performance Impact of RED in aHeterogeneous Environment,"Random Early Detection (RED) is the recommended active queue management scheme for rapid deployment throughout the Internet. As a result, there have been considerable research efforts in studying the performance of RED. However, previous studies have often focused on relatively homogeneous environment.  The effects of RED in a heterogeneous environment are not thoroughly understood. In this paper, we use extensive simulations to explore the interaction between RED and various types of heterogeneity, as well as the impact of such interaction on the user-perceived end-to-end performance. Our results show that overall RED improves performance at least for the types of heterogeneity we have considered.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5794,A Graph Based Algorithm for Bayesian Object Recognition,"We introduce an approach to feature-based object recognition, using maximum a posteriori (MAP) estimation under a Markov random field (MRF) model. Our approach assumes that both the location of the model and a  configuration of matching features are not directly observable and  have to be estimated. We consider a wide class of priors that explicitly  model dependencies between individual features of an object.   These priors capture phenomena such as the fact that unmatched features due to partial occlusion are generally spatially correlated rather than independent. Our algorithm uses an efficient graph cut technique to  resolve technical difficulties introduced by dependencies between the features. The method allows hierarchical search space pruning to find the location of the model. A special case of our framework yields a particularly efficient  approximation method.  We call this special case {\em spatially coherent  matching} (SCM). The SCM method operates directly on the image feature map,  rather than relying on the graph-based methods used in the general framework.  Interestingly, in the extreme case of completely independent features our general Bayesian framework reduces to Hausdorff matching. We present some Monte Carlo experiments showing that models accounting for dependencies between the features can yield substantial improvements over  Hausdorff matching for cluttered scenes and partially occluded objects.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5795,Fast Firewall Implementations for Software-based Routers,"Routers must perform packet classification at high speeds to efficiently implement functions such as firewalls.  The classification can be based on an arbitrary number of prefix and range fields in the packet header.  The classification required for firewalls is beyond the capabilities offered by standard Operating System classifiers such as BPF~\cite{MJ93}, DPF~\cite{EK96}, PathFinder~\cite{BGS94} and others.  In fact, there are theoretical results that show the general firewall lassification problem has poor worst case cost: for searching over $N$ arbitrary filters using $k$ packet fields, either the worst-case search time is $\Omega((\log N)^{k-1})$ or the worst-case storage is $O(N^{k})$. In this paper, we re-examine two basic mechanisms that have been dismissed in the literature as being too inefficient: backtracking search and set pruning trees. We find using real databases that the time for backtracking search is much better than the worst case bound; instead of $\Omega((logN)^{k-1})$, the search time is only roughly twice the optimal search time\footnote{\scriptsize The height of the multiplane trie is regarded as optimal search time throughout the paper, unless otherwise specified.}.  Similarly, we find that set pruning trees (using a DAG optimization) have much better storage costs than the worst case bound; it has memory requirements similar to the RFC scheme of Gupta and McKeown~\cite{GM99}.  We also propose several new techniques to further improve the two basic mechanisms.  Our major ideas are a novel compression algorithm, the ability to trade smoothly between backtracking and set pruning, and algorithms to effectively make use of hardware if hardware is available.  We quantify the performance gain of each technique using real databases. We show that on real firewall databases our schemes, with the accompanying optimizations, are close to optimal in time and storage.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5796,On the Placement of Web Server Replicas,"Recently there has been an increasing deployment of content distribution networks (CDNs) that offer hosting services to Web content providers.  CDNs deploy a set of servers distributed throughout the Internet and replicate provider content across these servers for better performance and availability than centralized provider servers.  Existing work on CDNs has primarily focused on techniques for efficiently redirecting user requests to appropriate CDN servers to reduce request latency an d balance load.  However, little attention has been given to the development of placement strategies for Web server replicas to further improve CDN performance. In this paper, we explore the problem of Web server replica placement in detail.  We develop several placement algorithms that use workload information, such as client latency and request rates, to make informed placement decisions.  We then evaluate the placement algorithms using both synthetic and real network topologies, and real Web server traces, and show that the placement of Web replicas is crucial to CDN performance.  We also address a number of practical issues when using these algorithms, such as their sensitivity to imperfect knowledge about client workload and network topology, the stability of the input data, methods for obtaining the input, and the scalability of the algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5797,Modeling Decisions for Digital Content,"The organization of digital information poses unique challenges not only due to rapidly evolving data formats and software, but also because digital content may be dynamic, distributed, or executable.  Managers of digital information need flexible, extensible architectures that facilitate maintainability as well as accessibility and long-term utility of content.  However, the flexibility of these architectures presents difficult organizational, or modeling, decisions.  To explore these modeling decisions and their consequences, we introduce four dimensions of digital content modeling:  aggregation, interfaces, transformations and indirection.  We discuss these dimensions individually and also examine their interaction; in essence, this paper examines general design patterns for digital content modeling.  As new and powerful architecture evolve, it is vital that information mangers understand and consider these design decisions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5798,The Bernoulli Generic Matrix Library,"We have implemented the Bernoulli generic programming system for sparse matrix computations. What distinguishes it from existing generic sparse matrix libraries is that we use (i) a high-level matrix abstraction for writing generic matrix programs, (ii) a low-level matrix abstraction for describing the indexing structure and properties of sparse matrices formats, and (iii) restructuring compiler technology to transform the high-level generic programs into concrete implementations that efficiently access sparse matrices using the low-level abstraction.      This paper describes the Bernoulli Generic Matrix Library (BGML). The BGML is the C++ implementation of these high-level and low-level abstractions. Within our system, it serves as the ``glue'' between user's sparse matrix format implementations and the restructuring sparse compiler. In this paper, we present the interfaces of the BGML and give examples of their use.  Because of its role, it is critical that the BGML not impose much of an overhead on the compiler generated code. We discuss the implementation techniques that we had to use to get the most performance from the BGML.  We also discuss the difficulties that we encountered in using available C++ compilers on the BGML.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5799,Dependent Intersection: A New Way of Defining Records in Type Theory,"Record types are an important tool for programming and dependent record types are proven to be very useful for program specification and verification. Unfortunately all known embedding of the dependent record type in the type theory had some imperfections. In this paper we present a new type constructor, dependent intersection that allows us to define records that combine the most advantages of previously known approaches, while avoiding most of their disadvantages.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5800,Confidentiality and Integrity with Untrusted Hosts: Technical Report,"Several security-typed languages have recently been proposed to enforce security properties such as confidentiality or integrity by type checking. We propose a new security-typed language, SPL@, that addresses two important limitations of previous approaches. First, existing languages assume that the underlying execution platform is trusted; this assumption does not scale to distributed computation in which a variety of differently trusted hosts are available to execute programs. Our new approach, secure program partitioning, translates programs written assuming complete trust in a single executing host into programs that execute using a collection of variously trusted hosts to perform computation.  As the trust configuration of a distributed system evolves, this translation can be performed as necessary for security. Second, many common program transformations do not work in existing security-typed languages; although they produce equivalent programs, these programs are rejected because of apparent information flows. SPL@ uses a novel mechanism based on ordered linear continuations to permit a richer class of program transformations, including secure program partitioning. This report is the technical companion to [ZM00].  It contains expanded discussion and extensive proofs of both the soundness and noninterference theorems mentioned in Section 3.3 of that work.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5801,Locality Enhancement Of Imperfectly-nested Loop Nests,"Most numerical applications using arrays require extensive program transformation in order to perform well on current machine architectures with deep memory hierarchies. These transformations ensure that an execution of the application exploits data-locality and uses the caches more effectively. The problem of exploiting data-locality is well understood only for a small class of applications -- for programs in which all statements are present in the innermost loop of a loop-nest (called perfectly-nested loops). For such programs, statement instances can be mapped to an integer lattice (called the iteration space), and important transformations can be modelled as unimodular transformations of the iteration space. This framework has permitted the systematic application of transformations like loop-permutation, skewing and tiling in order to enhance locality in perfectly-nested loops.   In dealing with programs that do not fall into this category, current compilers resort to ad-hoc techniques to find the right sequence of transformations. For some important benchmarks, no technique is known that will discover the right sequence of transformations. In my thesis, I propose a technique that extends the framework for perfectly-nested loops to general programs.  The key idea is to embed the iteration space of every statement in the program into a special iteration space called the product space. The product space can be viewed as a perfectly-nested loop nest, so this embedding generalizes techniques like code sinking and loop fusion that are used in ad hoc ways in current compilers to produce perfectly-nested loops from imperfectly-nested ones. In contrast to these ad hoc techniques however, embeddings are chosen carefully to enhance locality.  The product space is then transformed further using unimodular transformations, after which fully permutable loops are tiled, and code is generated. Code can also be generated to emulate block-recursive versions of the original program. I demonstrate the effectiveness of this approach for dense numerical linear algebra benchmarks, relaxation codes, and the tomcatv code from the SPECfp95 benchmark suite.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5802,Tactic-Based Modeling of Cognitive Inference on Logically StructuredNotation,"Computational (algorithmic) models of high-level cognitive inference tasks such as logical inference, mathematical inference, and decision making can have both theoretical and practical impact. They can improve our theoretical understanding of how people think and also provide practical direction for applications such as automated reasoning systems, systems attuned to user-interaction in decision-critical environments, and computer-aided education. To support those benefits, cognitive models need to be detailed, compositional, based in well-understood mathematics, and, to whatever extent possible, descriptively accurate.  We introduce a new, interdisciplinary approach that could be used to develop cognitive models of high-level inference with these properties. Two significant aspects of this approach are tactics and eyetracking  methods. Tactics are used to express high-level inferences in fully formalized mathematics for automated theorem proving systems; eyetracking methods provide insight into real-time and microcognitive information processing by permitting analysis of the visual attention of people performing cognitive tasks. Combining tactics and eyetracking methods with traditional techniques from applied logic, artificial intelligence, and cognitive science can result in more deeply detailed and accurate cognitive models. We demonstrate the feasibility of this new approach to modeling by describing its application to a calculational logic system that supports schematic reasoning via metalinguistic operations (such as textual substitution) without resorting to higher-order logic. We discuss several computational, psychological, and pedagogical insights that resulted from this approach, and we present a detailed, tactic-based model of calculational logic inference. Specific results include: an explanation of calculational logic as a formalized metalogic; a tactic-based implementation of calculational logic inference; some pedagogical observations on the teaching of calculational logic; and experimental results that demonstrate that eyetracking methods can provide insight into theorem proving that could not be achieved by studies of written work alone.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5803,Set Reconciliation with Nearly Optimal Communication Complexity,"We consider the problem of efficiently reconciling two similar sets held by different hosts while minimizing the communication complexity.  This type of problem arises naturally from gossip protocols used for the distribution of information. We describe an aproach to set reconciliation based on the encoding of sets as polynomials. The resulting protocols exhibit tractable computational complexity and nearly optimal communication complexity. Also, these protocols can be adapted to work over a broadcast channel, allowing many clients to reconcile with one host based on a single broadcast, even if each client is missing a different subset.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5804,A Randomized Error Recovery Algorithm for Reliable Multicast,"An efficient error recovery algorithm is essential for reliable multicast in large groups.  Tree-based protocols (RMTP, TMTP, LBRRM) group receivers into local regions and select a repair server for performing error recovery in each region.  Hence a single server bears the entire responsibility of error recovery for a region.  In addition, the deployment of repair servers requires topological information of the underlying multicast tree, which is generally not available at the transport layer. This paper presents RRMP, a randomized reliable multicast protocol which improves the robustness of tree-based protocols by diffusing the responsibility of error recovery among all members in a group.  The protocol works well within the existing IP multicast framework and does not require additional support from routers.  Both analysis and simulation results show that the performance penalty due to randomization is low and can be tuned according to application requirements.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5805,Optimizing Buffer Management for Reliable Multicast,"Reliable multicast delivery requires that a multicast message be received by all members in a group.  Hence certain or all members need to buffer messages for possible retransmissions.  Designing an efficient buffer management algorithm is challenging in large multicast groups where no member has complete group membership information and the delivery latency to different members could differ by orders of magnitude. We propose an innovative two-phase buffering algorithm, which explicitly addresses variations in delivery latency seen in large multicast groups.  The algorithm effectively reduces buffer requirements by adaptively allocating buffer space to messages most needed in the system and by spreading the load of buffering among all members in the group.  Simulation results demonstrate that the algorithm has good performance.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5806,IP Paging Service for Mobile Hosts,"In wireless networks, mobile hosts must update the network with their current location in order to get packets delivered to them. Paging facilitates efficient power management at the mobile host by allowing the host to update the network less frequently at the cost of providing the network with only approximate location information. The network determines the exact location of a mobile host through paging before delivering packets destined to the mobile host.  In current circuit-switched wireless networks, paging is implemented as a special purpose functionality in a centralized component inside the network. Given the emergence of different packet-switched wireless networks, we propose a novel router service called IP paging. This enables one common IP-based infrastructure to support different wireless interfaces such as CDMA, GPRS, Wireless LAN, etc.  In this paper, we present the design, implementation, and detailed performance evaluation, using measurements and simulation, of three IP-based paging protocols for mobile hosts.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5808,An Architecture for Reference Linking,"The Digital Library Research Group at Cornell has Reference Linking as one of its projects. Typical projects within in the group take an object-oriented approach to handling digital information.  To support reference linking, therefore, we designed a scheme whereby reference linking information is extracted from archives by {\em surrogate} objects and then presented to client applications or users by means of a well-defined API.  This paper describes that architecture, the API, and how the API might be supported in the Dienst protocol.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5809,Automatic Extraction of Reference Linking Information from OnlineDocuments,"The Web, with its explosive growth, is becoming an efficient resource for up-to-date information for the scientific researcher. Informal online archives are repositories for technical reports.  Proceedings are more and more commonly published on the Web. The collection of online journals is growing. Indeed, a good number of online journals are ""born digital"". Many researchers simply put their papers up on their own web site. The large volume of online material makes it quite desirable to be able to access cited documents immediately from the citing paper.  Implementing this direct access is called ""reference linking"". Some reference linking services exist today. A number of commercial publishers, recognizing the significant value-added nature of reference linking, have banded together to form the CrossRef organization. The CrossRef publishers share their metadata, which enables them to interlink their journals.  This metadata is not, however, available without a fee to organizations or individuals outside of CrossRef. The vast majority of online scholarly literature is accompanied by little or no metadata.  Since it is desirable to link up this literature as well, the problem of automatically reference linking online scholarly literature in the absence of metadata and author intervention is a problem very much worth considering. This paper explores this problem in detail, and presents some algorithms for extracting metadata from online texts and linking full-text documents together. The extent to which reference linking of the online literature can be done automatically is therefore the main topic of this paper.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5810,The Architecture and Performance of Security Protocols in the EnsembleGroup Communication System,"Ensemble is a Group Communication System built at Cornell and the Hebrew universities. It allows processes to create process groups within which scalable reliable fifo-ordered multicast and point-to-point communication are supported. The system also supports other communication properties, such as causal and total multicast  ordering, flow control, etc. This paper describes the security protocols and infrastructure of Ensemble. Applications using Ensemble with the extensions described here benefit from strong security properties. Under the assumption that trusted processes will not be corrupted, all communication is secured from tampering by outsiders. Our work extends previous work performed in the Horus system (Ensemble's predecessor) by adding support for multiple partitions, efficient rekeying, and application defined security policies. Unlike Horus, which used its own security infrastructure with non-standard key distribution and timing services, Ensemble's security mechanism is based on off-the shelf authentication systems, such as PGP and Kerberos. We extend previous results on group rekeying, with a novel protocol that makes use of diamond-like data structures. Our Diamond protocol  allows the removal of untrusted members within milliseconds.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5811,Using AVL Trees for Fault Tolerant Group Key Management,"In this paper we describe an efficient algorithm for the management of group-keys for Group Communication Systems.  Our algorithm is based on the notion of key-graphs, previously used for managing keys in large IP-multicast groups. The standard protocol requires a centralized key-server that has knowledge of the full key-graph. Our protocol does not delegate this role to any one process. Rather, members enlist in a collaborative effort to create the group key-graph. The key-graph contains n keys, of which each member learns log_2n. We show how to balance the key-graph, a result that is applicable to the centralized protocol. We also show how to optimize our distributed protocol and provide a performance study of its capabilities.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5812,Compiling for Runtime Code Generation (Extended Version),"Cyclone is a programming language that provides explicit support for dynamic specialization based on runtime code generation.  To   generate specialized code quickly, our Cyclone compiler uses a   template based strategy in which pre-compiled code fragments are   stitched together at runtime.  To achieve good performance, the   pre-compiled fragments must be optimized.  This paper describes   a principled approach to achieving such optimizations.  In   particular, we generalize standard flow-graph intermediate   representations to support templates, define a formal mapping from   (a subset of) Cyclone to this representation, and describe a   data-flow analysis framework that supports standard optimizations.   This extended version contains two mappings to the   intermediate representation, a less formal one that emphasizes the   novelties of our translation strategy and a purely functional one   that is better suited to formal reasoning.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5813,A Language-Based Approach to Security,"Language-based security leverages program analysis and program rewriting to enforce security policies. The approach promises efficient enforcement of fine-grained access control policies and depends on a trusted computing base of only modest size. This paper surveys progress and prospects for the area, giving overviews of in-lined reference monitors, certifying compilers, and advances in type theory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5814,Myhill-Nerode Relations on Automatic Systems and the Completeness ofKleene Algebra,It is well known that finite square matrices over a Kleene algebra again form a Kleene algebra.  This is also true for infinite matrices under suitable restrictions.  One can use this fact to solve certain infinite systems of inequalities over a Kleene algebra.  Automatic systems are a special class of infinite systems that can be viewed as infinite-state automata.  Automatic systems can be collapsed using  Myhill-Nerode relations in much the same way that finite automata can.  The Brzozowski derivative on an algebra of polynomials over a Kleene algebra gives rise to a triangular automatic system that can be solved using these methods.  This provides an alternative method for proving the completeness of Kleene algebra.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5815,"Scalability, Throughput Stability and Efficient Buffering in ReliableMulticast Protocols","This study investigates the issues of scalability, throughput stability and efficient buffering in reliable multicast protocols.  The focus is on a new class of scalable reliable multicast protoco, PBcast that is based on an epidemic loss recovery mechanism.  The protocol offers scalability, throughput stability and a bimodal delivery guarantee as the key features.  A theoretical analysis study for the protocol is already available.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5816,COCA: A Secure Distributed On-line Certification Authority,"COCA is a fault-tolerant and secure on-line certification authority that has been built and deployed both in a local area network and in the Internet.  Replication is used to achieve availability; proactive recovery with threshold cryptography is used for digitally signing certificates in a way that defends against mobile adversaries which attack, compromise, and control one replica for a limited period of time before moving on to another.  Relatively weak assumptions characterize environments in which COCA's protocols will execute correctly.  No assumption is made about execution speed and message delivery delays; channels are expected to exhibit only intermittent reliability; and with 3t+1 COCA servers up to t may be faulty or compromised.  The result is a system with inherent defenses to certain denial of service attacks because, by their very nature, weak assumptions are difficult for attackers to invalidate.  In addition, traditional techniques, including request authorization, resource management based on segregation and scheduling different classes of requests, as well as caching results of expensive cryptographic operations further reduce COCA's vulnerability to denial of service attacks.  Results from experiments in a local area network and the Internet allow a quantitative evaluation of the various means COCA employs to resist denial of service attacks.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5817,Automated Analysis of Fault-Tolerance in Distributed Systems,"A method for automated analysis of fault-tolerance of distributed systems is presented.  It is based on a stream model of computation augmented with approximation constructs, and this facilitates efficient analysis. Analyses of a protocol for fault-tolerant moving agents and a reliable broadcast protocol ilustrate the method.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5818,Intuitionistic Linear Logic and Partial Correctness,We formulate a Gentzen-style sequent calculus for partial correctness that subsumes propositional Hoare Logic.  The system is a noncommutative Intuitionistic Linear Logic.  We prove soundness and completeness over relational and trace-based models.  As a corollary we obtain a complete sequent calculus for inclusion and equivalence of regular expressions.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5819,Efficient Error Recovery For Reliable Multicast,Multicast is an efficient mechanism for distributing data from one sender to multiple receivers.  Many applications need a reliable multicast service which is not provided by the existing IP multicast protocol.  Providing such a service on a large scale requires efficient algorithms for error recovery. This dissertation presents a randomized reliable multicast protocol called RRMP which has demonstrably achieved several good properties. The protocol eliminates message implosion by diffusing the responsibility of error recovery among all members in the group and improves the robustness of the system against process failures.  It provides good local recovery by dynamically organizing members into an error recovery hierarchy according to their geographic locations.  It optimizes buffer management through an innovative two-phase buffering algorithm that explicitly addresses the variances in delivery latency for large multicast groups.  The algorithm reduces buffer requirements by adaptively allocating buffer space to messages most needed in the system and by spreading the load of buffering among all members in the group.  The key idea of RRMP is to use randomization as a powerful technique to achieve high robustness and efficiency in reliable multicast communications. The RRMP protocol works well within the existing IP multicast framework and does not require additional support from network routers.  Both analysis and experimental results show that the performance penalty due to randomization is low and can be tuned according to application requirements.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5820,Quotation and Reflection in Nuprl and Scheme,"Relationships between the concepts of proof systems and programming languages are known.  Some are well demonstrated in systems like Coq and Nuprl, but other aspects have not been fully implemented, such as reflection.  I believe that the true context in which such ideas are becoming useful is when they are implemented, this ``implementation as understanding'' principle is the reason some parts of the following text contain code pieces.  This should take the form of a logical environment with reflection mechanisms, Nuprl is a good choice since it is used for connecting logic and programming languages. Therefore, the first step towards creating such an implementation should be taken: pinpointing what should be done, and how.  This paper is an attempt to do this.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5821,Automata on Guarded Strings and Applications,"Guarded strings are like ordinary strings over a finite alphabet P, except that atoms of the free Boolean algebra on a set of atomic tests B alternate with the symbols of P.  The regular sets of guarded strings play the same role in Kleene algebra with tests as the regular sets of ordinary strings do in Kleene algebra. In this paper we develop the elementary theory of finite automata on guarded strings, a generalization of the theory of finite automata on ordinary strings.  We give several basic constructions, including determinization, state minimization, and an analog of Kleene's theorem. We then use these results to verify a conjecture on the complexity of a complete Gentzen-style sequent calculus for \partial correctness.  We also show that a basic result of the theory of Boolean decision diagrams (BDDs), namely that minimal ordered BDDs are unique, is a special case of the Myhill-Nerode theorem for a class of automata on guarded strings.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5822,Minimal CDMA Recoding Strategies in Power-Controlled Ad-Hoc WirelessNetworks,"The problem of Code Division Multiple Access (CDMA) code assignment to eliminate primary and hidden collisions in multihop packet radio networks has been widely researched in the past. However, very little work has been done on the very realistic *distributed, dynamic* version of the transmitter-oriented code assignment (TOCA) problem in an ad-hoc network where mobiles use CDMA technology. None of the existing dynamic TOCA CDMA algorithms in literature are efficient, in terms of maximum code index assigned in the network, or number of times a mobile has to change its code. We present a set of local and distributed *recoding* strategies for the TOCA CDMA problem in an ad-hoc network where mobiles can arbitrarily 1) connect and disconnect, 2) move about, and 3) increase or decrease their transmission power - all these may need some mobiles to be recoded, to avoid new collisions. Our strategies, unlike those proposed earlier in literature, guarantee *minimal recoding*, that is, given a current network-wide code assignment and one of the above events, our strategies change the codes of the minimum number of mobiles needed to eliminate all collisions. Minimal recoding can be very important in reducing the effect of frequent code changes on the performance and criticality of distributed applications. Further, among all possible minimal recoding strategies in a class, most of our strategies are also (provably) *optimal* in terms of the maximum code index assigned in the network.  Performance results that evaluate our dynamic minimal strategies are also presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5823,Reference Linking the Web's Scholarly Papers,"Along with the explosive growth of the Web has come a great increase in on-line scholarly literature. Thus the Web is becoming an efficient source of up-to-date information for the scientific researcher, and more and more researchers are turning to their computers to keep current on results in their field. Not only is Web retrieval usually faster than a walk to the library, but the information obtained from the Web is potentially more current than what appears in printed publications. The increasing proportion of on-line scholarly literature makes it possible to implement functionality desirable to all researchers -- the ability to access cited documents immediately from the citing paper. Implementing this direct access is called ""`reference linking"". While many authors insert explicit links into their papers to support reference linking, it is by no means a universal practice. The approach taken by the Digital Library Research Group at Cornell employs ""value-added surrogates"" to enhance the reference-linking behavior of Web documents. Given the URL of an on-line paper, a surrogate object is constructed for that paper. The surrogate fetches the content of the document and parsesit to automatically extract reference linking data.  Applications can then use the surrogate to access this reference linking data, encoded in XML, via a well-defined Java API. We use this API to reference link the D-Lib magazine, an on-line journal of technical papers relating to digital library research.   Currently we are (automatically) extractingreference linking  information from the papers in this journal with 80%  accuracy.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5824,Anonymous Gossip: Improving Multicast Reliability in Mobile Ad-HocNetworks,"In recent years, a number of applications of ad-hoc networks have been proposed.  Many of them are based on the availability of a robust and reliable multicast protocol. In this paper, we address the issue of reliability and propose a scalable method to improve packet delivery of multicast routing protocols and decrease the variation in the number of packets received by different nodes.  The proposed protocol works in two phases.  In the first phase, any suitable protocol is used to multicast a message to the group, while in the second concurrent phase, the gossip protocol tries to recover lost messages.  Our proposed gossip protocol is called Anonymous Gossip(AG) since nodes need not know the other group members for gossip to be successful.  This is extremely desirable for mobile nodes, that have limited resources, and where the knowledge of group membership is difficult to obtain.  As a first step, anonymous gossip is implemented over MAODV without much overhead and its performance is studied.  Simulations show that the packet delivery of MAODV is significantly improved and the variation in number of packets delivered is decreased.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5825,Computing Visual Correspondence with Occlusions via Graph Cuts,"Several new algorithms for visual correspondence based on graph cuts have recently been developed. While these methods give very strong results in practice, they do not handle occlusions properly.  Specifically, they treat the two input images asymmetrically, and they do not ensure that a pixel corresponds to at most one pixel in the other image.  In this paper, we present two new methods which properly address occlusions, while preserving the advantages of graph cut algorithms.  We give experimental results for stereo as well as motion, which demonstrate that our methods perform well both at detecting occlusions and computing disparities.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5826,Formally Verifying Hybrid Protocols with the Nuprl Logical ProgrammingEnvironment,We describe a generic switching protocol for the construction of hybrid   protocols and prove it correct with the Nuprl proof development system.  We   introduce the concept of meta-properties to characterize communication   properties that can be preserved by switching and identify switching   invariants that an implementation of the switching protocol must satisfy    in order to work correctly.      Our work shows how a theorem prover with a rich specification language can   contribute to the design and implementation of verifiably correct adaptive   protocols and that it can have a large impact when being engaged at the   earliest stages of the design.,,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5827,Towards Fault-Tolerant and Secure On-line Services,"Integrating fault tolerance and security is crucial for building trustworthy on-line services. Such integration is studied in this dissertation through the design and implementation of COCA (Cornell On-line Certification Authority), a fault-tolerant and secure on-line certification authority.  COCA maintains a service private key to sign the responses it sends to clients, and achieves availability using replicated servers that employ threshold cryptography and store shares of the service private key.  Periodic share refreshing, coupled with periodic recovery of server states, defends against so-called mobile adversaries which move from one server to another. COCA is designed for a weak system model:  no assumptions are made about server speed or message delay, and communications are assumed to employ links that are intermittent. The result is a service with reduced vulnerability to attacks because, by their nature, weaker assumptions are more difficult for adversaries to invalidate.  COCA further employs an array of defense mechanisms specific to denial of service attacks.  COCA runs both on a local area network and on the Internet.  Performance measurements of COCA under simulated denial of service attacks demonstrate the effectiveness of COCA's defenses.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5828,Toward a Theory of Information Preservation,"Digital preservation is a pressing challenge to the library community.   In this paper, we describe the initial results of our efforts towards understanding digital (as well as traditional) preservation problems from first principles.  Our approach is to use the language of mathematics to formalize the concepts that are relevant to preservation.  Our theory of _preservation spaces_ draws upon ideas from logic and programming  language semantics to describe the relationship between concrete objects and their information contents.  We also draw on game theory to show how objects change over time as a result of uncontrollable  environment effects and directed preservation actions.  In the second half  of this paper, we show how to use the mathematics of universal algebra as  a language for objects whose information content depends on many components.  We use this language to describe both migration and emulation strategies for digital preservation.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5829,An Architecture for Automatic Reference Linking (Extended Version),"Along with the explosive growth of the Web has come a great increase in on-line scholarly literature. More and moNot only is Web retrieval usually faster than a walk to the library, but the information obtained from the Web is generally more current than what appears in printed publications. The increasing proportion of on-line scholarly literature makes it possible to implement functionality desirable to all researchers -- the ability to access cited documents immediately from the citing paper. Implementing this direct access is called ""reference linking"". While many authors insert explicit hyperlinks into their papers to support reference linking, it is by no means a universal practice. The approach taken by the Digital Library Research Group at Cornell employs ""value-added surrogates"" as a generalizable mechanism for providing reference-linking behavior in Web documents.  Given the URL of an on-line document, a surrogate object is constructed for that paper, which then processes document's content to extract reference linking data.  The surrogate then exposes the reference linking data through a well-defined API, permitting the construction of reference linking services by external clients. We present two examples of the many possible reference linking  applications buildable on this API. We also describe a metric that measures the API's performance; currently we are (automatically) extracting reference linking information from HTML papers with more than 80",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5830,The Document Representation Problem: An Analysis of LSI and IterativeResidual Rescaling,"Important text analysis problems in information retrieval and natural language processing, such as document clustering and automatic text summarization, require accurate measurement of inter-document similarity.  The goal of this work is to find methods for automatically creating document representations in which inter-document similarity measurements correspond to human judgment.   We present a new model for the task of creating document  representations.  From this model, we derive a new analysis of  Latent Semantic Indexing (LSI), which is one of the successful approaches that has been studied extensively.   In particular, we show a precise relationship between LSI's performance and the uniformity of the underlying distribution of documents over topics.   As a consequence, we propose a novel alternative method called Iterative Residual Rescaling (IRR), that, crucially, compensates for distributional non-uniformity.  Experiments over a variety of practically-encountered settings and with several evaluation metrics validate our theoretical prediction and confirm the effectiveness of IRR in comparison to LSI.  We also propose several extensions including a new document sampling method to scale IRR up to large document collections.   Comparison with random sampling provides further empirical evidence that performance can be improved by counteracting  non-uniformity.   Finally, we present a system for multi-document summarization based on IRR, which demonstrates that IRR can be immediately useful in applications.  We show that IRR works as a framework to find a tightly connected (and therefore interpretable) set of coherent texts, and effectively present them to the user.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5831,Kleene Algebra with Tests and Program Schematology,"The theory of flowchart schemes has a rich history going back to Ianov (1960); see Manna (1974) for an elementary exposition.  A central question in the theory of program schemes is scheme equivalence.  Manna presents several examples of equivalence proofs that work by simplifying the schemes using various combinatorial transformation rules.  In this paper we present a purely algebraic approach to this problem using Kleene algebra with tests (KAT).  Instead of transforming schemes directly using combinatorial graph manipulation, we regard them as a certain kind of automaton on abstract traces.  We prove a generalization of Kleene's theorem and use it to construct equivalent expressions in the language of KAT.  We can then give a purely equational proof of the equivalence of the resulting expressions.  We prove soundness of the method and give a detailed example of its use.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5832,Eager Class Initialization for Java,"We describe a static analysis method on Java bytecode to determine class initialization dependencies.  This method can be used for eager class loading and initialization.  It catches many initialization circularities that are missed by the standard lazy implementation.  Except for contrived examples, the computed initialization order gives the same results as standard lazy initialization.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5833,Secure Program Partitioning,"This paper presents secure program partitioning, a language-based technique for protecting confidential data during computation in distributed systems containing mutually untrusted hosts. Confidentiality and integrity policies can be expressed by annotating programs with security types that constrain information flow; these programs can then be partitioned automatically to run securely on heterogeneously trusted hosts. The resulting communicating subprograms collectively implement the original program, yet the system as a whole satisfies the security requirements of participating principals without requiring a universally trusted host machine.  The experience in applying this methodology and the performance of the resulting distributed code suggest that this is a promising way to obtain secure distributed computation. This Technical Report is an expanded version of the published paper ``Untrusted Hosts and Confidentiality: Secure Program Partitioning.''  The main difference between the two is Appendix A, which contains a correctness proof for the control-transfer protocols described in Section 5.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5834,The Price of Anarchy with Polynomial Edge Latency,"We consider the problem of routing traffic to optimize the performance of a congested network.  We are given a network, a rate of traffic between each pair of nodes, and a latency function for each edge specifying the time needed to traverse the edge given its congestion; the objective is to route  traffic such that the sum of all travel times---the total  latency---is minimized. In many settings, it is not possible to implement an optimal assignment of routes.  In the absence of regulation by some central authority, we assume that each network user routes its traffic on the minimum-latency path available to it, given the network congestion caused by the other users.  In general such a ``selfishly motivated'' assignment of traffic to paths will not minimize the total latency; hence, this lack of regulation carries the cost of decreased network performance. In this paper, we prove that if the latency of each edge is a polynomial function of degree at most $p$ of the edge congestion, then the total latency of the routes chosen by selfish network  users is at most $[1 - p \cdot (p+1)^{-(p+1)/p}]^{-1} = \Theta(\frac{p}{\ln p})$ times the minimum possible total  latency.  A simple example shows that this result is best  possible for all values of $p$.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5835,Gossip-Based Ad Hoc Routing,"Many ad hoc routing protocols are based on(some variant of) flooding. Despite various optimizations, many routing messages  are propagated unnecessarily. We propose a gossiping-based  approach to reduce the overhead of the routing protocols. In large networks, Gossiping exhibits bimodal behavior in sufficiently large networks: in some executions, the gossip dies out quickly and hardly any node gets the message; in the remaining executions, a substantial fraction of the nodes gets the message. The fraction of executions in which most nodes gets the message depends on the gossiping probability and the topology of the network. In the networks we have considered, using gossiping probability between 0.6 and 0.8 suffices to  ensure that almost every node gets the message in almost every execution. For large networks, this simple gossiping protocol uses up to 35% fewer messages than flooding, with improved performance. Gossiping can also be combined with various optimizations of flooding to yield further benefits. Simulations show that adding gossiping to AODV results in significant performance improvement, even in networks as small as 150 nodes only. We expect that the improvement should be even more significant in larger networks.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5836,Efficient Computation of Interprocedural Control Dependence,"Control dependence information is useful for a wide range of software maintenance and testing tasks.  For example, program slicers use it to determine statements and predicates that might affect the value of a particular variable at a particular program location. In the intraprocedural context an optimal algorithm is known for computing control dependence which unfortunately relies critically on the underlying intraprocedural postdominance relation being tree-structured. Hence, this algorithm is not directly applicable to the interprocedural case where the transitive reduction of the postdominance relation can be a directed acyclic graph (DAG), with nodes having multiple immediate dominators. In this paper we present two efficient, conceptually simple algorithms for computing the interprocedural postdominance relation that can be used to compute interprocedural control dependence. For an interprocedural control flow graph $G=(V,E)$, our reachability based algorithm takes time and space $O(|V|^2 + |V||E|)$.  Unlike other algorithms, it does not perform confluence operations on whole bit-vectors and can be tuned to concentrate on the interprocedural rather than intraprocedural relations in a program thus allowing it to scale better to larger programs.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5837,Automatic Code Placement Alternatives for Ad-Hoc And Sensor Networks,"Developing applications for ad-hoc and sensor networks poses significant challenges.  Many interesting applications in these domains entail collaboration between components distributed throughout an ad-hoc network.  Defining these components, optimally placing them on nodes in the ad-hoc network and relocating them in response to changes is a fundamental problem faced by such applications.  Manual approaches to code and data migration are not only platform-dependent and error-prone, but also needlessly complicate application development.  Further, locally optimal decisions made by applications that share the same network can lead to globally unstable and energy inefficient behavior. In this paper we describe the design and implementation of a distributed operating system for ad-hoc and sensor networks whose goal is to enable power-aware, adaptive, and easy-to-develop ad-hoc networking applications.  Our system achieves this goal by providing a single system image of a unified Java virtual machine to applications over an ad-hoc collection of heterogeneous nodes.  It automatically and transparently partitions applications into components and dynamically finds a placement of these components on nodes within the ad-hoc network to reduce energy consumption and increase system longevity.  This paper outlines the design of our system and evaluates two practical, power-aware, online algorithms for object placement that form the core of our system.  We demonstrate that our algorithms can increase system longevity by a factor of four to five by effectively distributing energy consumption, and are suitable for use in an energy efficient operating system in which applications are distributed automatically and transparently.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5838,Tolerating Malicious Gossip,"A  new class of gossip protocols is presented to diffuse updates securely.  The protocols rely on annotating updates with the path along which they travel.  To avoid a combinatorial explosion in the number of such annotated updates, rules are employed to choose which updates to keep.  Different sets of rules lead to different protocols.  Results of simulated executions of a collection of such protocols are described---the protocols would appear to be practical, even in large networks.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5839,Existential Types for Imperative Languages: Technical Results,"This technical report contains the full type-safety proof for the language presented in the paper \emph{Existential Types for Imperative   Languages}, originally submitted for publication in October 2001. Because this report should be read only after the paper, effectively as an appendix, we do not repeat the motivation, examples, and informal presentation contained there. Also refer to the paper for related work and a bibliography.  We do repeat the figures and definitions so that this report comprises a self-contained proof.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5840,"Cyclone User's Manual, Version 0.1.3","The current version of this manual should be available at http://www.cs.cornell.edu/projects/cyclone/ and http://www.research.att.com/projects/cyclone/.  The version here describes Cyclone Version 0.1.3, although minor changes may have occurred before the release.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5841,Formal Type Soundness for Cyclone's Region System,"Cyclone is a polymorphic, type-safe programming language derived   from C\@.  The primary design goals of Cyclone are to let   programmers control data representations and memory management   without sacrificing type-safety.  In this paper, we focus on the   region-based memory management of Cyclone and its static typing   discipline.  The design incorporates several advancements, including   support for region subtyping and a coherent integration with stack  allocation and a garbage collector.  To support separate   compilation, Cyclone requires programmers to write some explicit   region annotations, but uses a combination of default annotations,   local type inference, and a novel treatment of region effects to   reduce this burden.  As a result, we integrate C idioms in a   region-based framework.  In our experience, porting legacy C to Cyclone has required altering about 8\% of the code; of the   changes, only 6\% (of the 8\%) were region annotations.      This technical report is really two documents in one: The first part   is a paper submitted for publication in November,   2001.  The second part is the full formal language and type-safety  proof mentioned briefly in the first part.  If you have already read   a version of, ``Region-Based Memory Management in Cyclone'', then   you should proceed directly to Section 9.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5842,What Energy Functions can be Minimized via Graph Cuts?,"Many problems in computer vision can be naturally phrased in terms of energy minimization.  In the last few years researchers have developed a powerful class of energy minimization methods based on graph cuts.  These techniques construct a specialized graph, such that the minimum cut on the graph also minimizes the energy.  The minimum cut in turn is efficiently computed by max flow algorithms.  Such methods have been successfully applied to a number of important vision problems, including image restoration, motion, stereo, voxel occupancy and medical imaging.  However, each graph construction to date has been highly specific for a particular energy function.  In this paper we address a much broader problem, by characterizing the class of energy functions that can be minimized by graph cuts, and by giving a general-purpose construction that minimizes any energy function in this class.  Our results generalize several previous vision algorithms based on graph cuts, and also show how to minimize an interesting new class of energy functions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5843,A TACOMA Retrospective,"For seven years, the TACOMA project has investigated the design and implementation of software support for mobile agents.  A series of prototypes has been developed, with experiences in distributed applications driving the effort.  This paper describes the evolution of these TACOMA prototypes, what primitives each supports, and how the primitives are used in building distributed applications.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5844,A Theory of Second-Order Trees,"This report describes a theory of second-order trees, that is, finite and infinite trees where nodes of the tree can bind variables that appear further down in the tree. Such trees can be used to provide a natural and intuitive interpretation for type systems with equirecursive types and binding constructs like universal and existential quantifiers. The report defines the set of binding trees, and a subset of these called regular binding trees. These are similar to the usual notion of regular trees, but generalized to take into account the binding structure. Then the report shows how to interpret a second-order type system with recursive quantifiers as binding trees, and gives a sound and complete axiomatisation of when two types map to the same tree. Finally the report gives a finite representation for trees called tree automata, and gives a construction for deciding when two automata map to the same tree. To tie everything together, the report defines a mapping from types to automata, thus giving a decision procedure for when two types map to the same tree.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5845,On Two Letters versus Three,"If A is a context-free language over a two-letter alphabet, then the set of all words obtained by sorting words in A and the set of all permutations of words in A are context-free.  This is false over alphabets of three or more letters.  Thus these problems illustrate a difference in behavior between two- and three-letter alphabets.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5846,TAF: A Temporal Adaptation Framework for Hybrid Routing in Mobile AdHoc Networks,"A central challenge in ad hoc networks is the design of routing protocols that can adapt their behavior to frequent and rapid changes at the network level. Choosing between reactive, proactive, or hybrid routing regimes and selecting appropriate configuration parameters for a chosen protocol are difficult tasks. This paper introduces a framework, called TAF, for seamlessly adapting between proactive and reactive routing protocols. This general framework enables a proactive and reactive protocol to coexist on the same network, provides a low-overhead mechanism by which these two routing strategies can be combined at fine grain and proposes an analytical model for automatically adjusting protocol parameters. Combined, this mechanism and model enable a protocol within our framework to find a near-optimal mix of proactive and reactive routing strategies for the mobility rate and traffic patterns observed on the network. We examine the application of this temporal adaptation framework to the construction of three specialized ad hoc rout- ing protocols. These protocols minimize packet overhead, achieve a targeted loss rate, and minimize routing latency using the TAF framework. In all three cases, hybrid protocols based on the TAF framework perform as well as or better than a proactive (TORA) and a reactive (AODV) protocol.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5847,Bursty and Hierarchical Structure in Streams,"A fundamental problem in text data mining is to extract meaningful structure from document streams that arrive continuously over time.  E-mail and news articles are two natural examples of such streams, each characterized by topics that appear, grow in intensity for a period of time, and then fade away. The published literature in a particular research field can be seen to exhibit similar phenomena over a much longer time scale.  Underlying much of the text mining work in this area is the following intuitive premise --- that the appearance of a topic in a document stream is signaled by a ``burst of activity,'' with certain features rising sharply in frequency as the topic emerges. The goal of the present work is to develop a formal approach for modeling such ``bursts,'' in such a way that they can be robustly and efficiently identified, and can provide an organizational framework for analyzing the underlying content.  The approach is based on modeling the stream using an infinite-state automaton, in which bursts appear naturally as state transitions; in some ways, it can be viewed as drawing an analogy with models from queueing theory for bursty network traffic. The resulting algorithms are highly efficient, and yield a nested representation of the set of bursts that imposes a hierarchical structure on the overall stream.  Experiments with e-mail and research paper archives suggest that the resulting structures have a natural meaning in terms of the content that gave rise to them.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5848,Equational Verification of Cache Blocking in LU Decomposition using Kleene Algebra with Tests,"In a recent paper of Mateev et al. (2001), a new technique for program analysis called fractal symbolic analysis was introduced and applied to verify the correctness of a series of source-level  transformations for cache blocking in LU decomposition with partial pivoting. It was argued in that paper that traditional techniques are inadequate because the transformations break definition-use dependencies. We show how the task can be accomplished purely equationally using Kleene algebra with tests.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5849,Quotient Types --- a Modular Approach,"In this paper we introduce a new approach to defining quotient types in type theory. We suggest replacing the existing monolithic rule set by a modular set of rules for a specially chosen set of primitive operations. This modular formalization of quotient types turns out to be very powerful and free of many limitations of the traditional monolithic formalization. To illustrate the advantages of the new formalization, we show how the type of collections (that is known to be very hard to formalize using traditional quotient types) can be naturally formalized using the new primitives. We also show how modularity allows us to reuse one of the new primitives to simplify and enhance the rules for the set types.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5850,Computational Inductive Definability,"It is shown that over any countable first-order structure, IND programs with dictionaries accept exactly the Pi-1-1 relations.  This extends a result of Harel and Kozen (1984) relating IND and Pi-1-1 over countable structures with some coding power, and provides a computational analog of a result of Barwise, Gandy, and Moschovakis (1971) relating the Pi-1-1 relations on a countable structure to a certain family of inductively definable relations on the hereditarily finite sets over that structure.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5851,On Fixed-Parameter Tractability of Some Routing Problems,"Disjoint Paths is the problem of finding paths between given pairs  of terminals in a graph such that no vertices are shared between paths. We  analyze fixed-parameter tractability of several new Disjoint Paths-like routing  problems motivated by congestion control in computer networks.  In one model we  are interested in finding paths between $k$ pairs of terminals such that the  first edge of each path is not shared with any other path. We prove that this  problem is fixed-parameter tractable on directed graphs, in contrast to  Disjoint Paths that are known to be NP-hard even for $k=2$. We improve our  algorithm for two special cases: when the graph is acyclic and when all sources  lie in distinct nodes. We consider extensions: a second-node-disjoint analog  and a slightly generalized version of SAT. Another model,  bottleneck-edge-disjoint paths, is a generalization of Disjoint Paths. For  directed acyclic graphs, we show that bottleneck-edge-disjoint paths is  $W[1]$-hard and hence unlikely to be fixed-parameter tractable. We give an  algorithm that runs in time $n^{O(k)}$. These two results easily extend to  Unsplittable Flows.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5852,Malicious Code Detection for Open Firmware,"Malicious boot firmware is a largely unrecognized but significant  security risk to our global information infrastructure.  Since boot firmware  executes before the operating system is loaded, it can easily circumvent any  operating system-based security mechanism.  Boot firmware programs are  typically written by third-party device manufacturers and may come from various  suppliers of unknown origin.  In this paper we describe an approach to this  problem based on load-time verification of onboard device drivers against a  standard security policy designed to limit access to system resources.  We also  describe our ongoing effort to construct a prototype of this technique for Open  Firmware boot platforms.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5853,APSS:  Proactive Secret Sharing in Asynchronous Systems,"APSS, a proactive secret sharing (PSS) protocol for asynchronous  systems, is derived and proved correct.  A PSS protocol enables a set of secret  shares to be periodically refreshed with a new, independent set, thereby  thwarting so-called mobile adversary attacks.  APSS tolerates certain attacks  that PSS protocols for synchronous systems cannot, because protocols for  asynchronous systems are inherently less vulnerable to denial of service  attacks, which slow processor execution or impede message delivery and thus  violate the defining assumptions of a synchronous system.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5854,JMatch: Java plus Pattern Matching,"The JMatch language extends Java with \emph{iterable abstract pattern matching}, pattern matching that is compatible with the data abstraction features of Java and makes iteration abstractions convenient.  JMatch has ML-style deep pattern matching, but patterns can be abstract; they are not tied to algebraic data constructors.  A single JMatch method may be used in several modes; modes may share a single implementation as a boolean formula. Modal abstraction simplifies specification and implementation of abstract data types. This paper describes the JMatch language and its  implementation. (updated April 20, 2005).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5855,On the Elimination of Hypotheses in Kleene Algebra with Tests,"The validity problem for certain universal Horn formulas of Kleene  algebra with tests (KAT) can be efficiently reduced to the equational theory.   This reduction is known as elimination of hypotheses.  Hypotheses are used to  describe the interaction of atomic programs and tests and are an essential  component of practical program verification with KAT.  The ability to eliminate  hypotheses of a certain form means that the Horn theory with premises of that  form remains decidable in PSPACE.  It was known (Cohen 1994, Kozen and Smith  1996, Kozen 1997) how to eliminate hypotheses of the form q=0.  In this paper  we show how to eliminate hypotheses of the form cp=c for atomic p.  Hypotheses  of this form are useful in eliminating redundant code and arise quite often in  the verification of compiler optimizations (Kozen and Patron 2000).",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5856,Automated Computational Complexity Analysis,"Program synthesis is the machine-assisted construction of provably  correct programs from formal high-level specifications.  Automated synthesis  tools appeared soon after the introduction of theorem provers in the 1960s and,  owing to a revived interest in the field during the 1990s, have now matured to  a state in which they are routinely used in projects outside of research  laboratories.  Despite this success, however, program synthesis remains  challenged by broadening demands for program quality, as for the next  generation of synthesis tools the main focus shifts from program correctness to  program efficiency. This thesis introduces our approach to automated  computational complexity analysis and certification of higher-order functional  programs as a means to resource-conscious program synthesis. First, we develop  a general framework for expressing higher-order computational complexity of  functional programs.  Our compositional calculus is based on complexity  annotations of an open-ended operational semantics and defines the complexity  of a function as the cost of reducing the function term applied to a symbolic  argument.  Higher-type arguments are assigned a canonical computational  skeleton whose decomposition exposes their internal structure. Second, we  present algorithms that automatically generate and solve parameterized  higher-type recurrence equations expressing the complexity of recursive  functions.  The recurrence generator uses symbolic evaluation to derive  equations for primitive and general recursive terms.  The recurrence solver  reduces these equations to systems of unparameterized first-order recurrence  equations that can be solved by conventional methods.  A collection of  simplification heuristics eliminates intractable functions by approximation.  Third, we formalize our calculus and automate the construction of formal proofs  that assert the correctness of the symbolic evaluation result.  Proofs use a  basic term reflection mechanism to reason intensionally about term evaluation  at the meta-level. The Automated Complexity Analysis System implementation  demonstrates the viability of our approach.  The system uses the Nuprl proof  development system and the Mathematica computer algebra system to compute the  time complexity of Nuprl proof extracts.  It has been able to identify  automatically infeasible synthesized code whose manual discovery had taken many  days previously.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5857,Halting and Equivalence of Schemes over Recursive Theories,"Let S be a fixed first-order signature.  In this note we consider  the following decision problems. (i) Given a recursive ground theory T over S,  a program scheme p over S, and input values specified by ground terms  t1,...,tn, does p halt on input t1,...,tn in all models of T? (ii) Given a  recursive ground theory T over S and two program schemes p and q over S, are p  and q equivalent in all models of T? When T is empty, these two problems are  the classical halting and equivalence problems for program schemes,  respectively.  We show that problem (i) is r.e.-complete and problem (ii) is  Pi-0-2-complete.  Both these problems remain hard for their respective  complexity classes even if T is empty and S is restricted to contain only a  single constant, a single unary function symbol, and a single monadic  predicate.  It follows from (ii) that there can exist no relatively complete  deductive system for scheme equivalence.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5858,Some Results in Dynamic Model Theory,"First-order structures over a fixed signature S give rise to a  family of trace-based and relational Kleene algebras with tests defined in  terms of Tarskian frames.  A Tarskian frame is a Kripke frame whose states are  valuations of program variables and whose atomic actions are state changes  effected by variable assignments x := e, where e is an S-term.  The Kleene  algebras with tests that arise in this way play a role in dynamic model theory  akin to the role played by Lindenbaum algebras in classical first-order model  theory. Given a first-order theory T over S, we exhibit a Kripke frame U whose  trace algebra Tr U is universal for the equational theory of Tarskian trace  algebras over S satisfying T, although U itself is not Tarskian in general.   The corresponding relation algebra Rel U is not universal for the equational  theory of relation algebras of Tarskian frames, but it is so modulo  observational equivalence.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5859,Polyglot: An Extensible Compiler Framework for Java,"Polyglot is an extensible compiler framework that supports the easy  creation of compilers for languages similar to Java, while avoiding code  duplication.  The Polyglot framework is useful for domain-specific languages,  exploration of language design, and for simplified versions of Java for  pedagogical use. We have used Polyglot to implement several major and minor  modifications to Java; the cost of implementing language extensions scales well  with the degree to which the language differs from Java.  This paper focuses on  the design choices in Polyglot that are important for making the framework  usable and highly extensible.  Polyglot source code is available.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5860,Meta Clustering,"Most clustering methods search for one optimal partitioning of the  data.  Often it is better to search for many different clusterings of the data  and present the user with a means of efficiently navigating between them.  We  present two algorithms for generating many alternate clusterings:  Sample-and-Merge and Component Reweighting.  We then use clustering at a meta  level to organize these different base-level clusterings.  This {\em  MetaClustering} partitions the base-level clusterings into groups of similar  clusterings.  We demonstrate MetaClustering on a synthetic data set, and on a  real protein data set.  The results show that the algorithms are effective at  generating qualitatively different clusterings, and at organizing these  clusterings so that similar ones are grouped together.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5861,Abstract Identifiers and Textual Reference,"Here are three proposals concerning the structure and maintenance of  formal, inter-referential,  digitally stored texts: (1) include abstract atomic  identifiers in texts, (2) identify these  identifiers with references to text  objects, and (3) keep among the texts records of computationally  substantiated  claims about those texts.  We use ``formal'' in a narrow sense approximating  computer-checkable.   We are informed by informal symbolic practices used in  mathematical text and program source text,  which we hope to enhance and  exploit explicitly; the basic management problem is how to alter  texts {\em  rather} {\em freely} without ruining the bases for claims depending upon them,   which becomes an issue of accounting for various dependencies between texts. We  are {\em not} here proposing the use of abstract structured text; nonetheless,  experience  using it in Nuprl4 has led us to appreciate the benefits of  distinguishing abstract form from  concrete presentation, and also has shown us  the cognitive and practical {\em un}importance of  just which identifiers occur  in abstract structured texts when texts are mediated by a system that  realizes  concrete presentation.   Abstract treatment of identifiers involves concrete  realization during communications  between ``text servers'' and their clients.   The benefit of treating identifiers abstractly  is a radical avoidance of name  collision, even at runtime, and is important for claims about  texts that are  based upon program execution.  The notion of text collections and equivalence   of text collections modulo change of identifiers is made precise by the second  proposal. The complete identification of abstract identifiers with reference  values is discussed,  addressing the issues of dangling pointers, the  association of ordinary symbolic identifiers  with meaningful defining texts,  the ``flatness'' of the pointer space, and the perhaps  counterintuitive  collapse of two abstract name spaces into one.   The notion of ``certification  system'' is introduced as a formalization of generic computationally  defined  claims about texts, emphasizing the diversity of clients who may not agree on a  common ``logic''. The notion of a certificate whose computational meaning, in  the context of the texts it refers to,  is completely specified (although  perhaps non-deterministic), and the notion of a certificate further  being  deterministic, are introduced and elaborated with regard to their epistemic  value.  What it means  to give certificate texts the force of factual records,  and mechanisms to accomplish this, are discussed. Scenarios for practically  exploiting identifier abstractness and fully deterministic certificates are   considered, involving the combination of partially independently developed  texts and the experimental modification  of texts in a collection.  The  importance of implementing multiple certification systems is articulated.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5862,Network Failure Detection and Graph Connectivity,"We consider a model for monitoring the connectivity of a network  subject to node or edge failures. In particular, we are concerned with  detecting \emph{$(\vareps, k)$-failures}: events in which an adversary deletes  up to $k$ network elements (nodes or edges), after which there are two sets of  nodes $A$ and $B$, each at least an $\vareps$ fraction of the network, that are  disconnected from one another. We say that a set $D$ of nodes is an $(\vareps,  k)$-detection set if, for any $(\vareps, k)$-failure of the network, some two  nodes in $D$ are no longer able to communicate; in this way, $D$ ``witnesses''  any such failure. Recent results show that for any graph $G$, there is an  $(\vareps, k)$-detection set of size bounded by a polynomial in $k$ and  $\vareps$, independent of the size of $G$. In this paper, we expose some  relationships between bounds on detection sets and the edge-connectivity  $\lambda$ and node-connectivity $\kappa$ of the underlying graph. Specifically,  we show that detection set bounds can be made considerably stronger when  parametrized by these connectivity values. We show that for an adversary that  can delete $\lambda$ edges, there is always an $(\vareps, \lambda)$-detection  set of size at most $\freps$, and an $(\vareps, \lambda)$-detection set of  minimum size can be computed in polynomial time. A crucial point is that this  bound is independent not just of the size of $G$ but also of the value of  $\lambda$. Our bounds extend to adversaries that can delete up to $k \lambda$  edges for $k > 1$. We also show an analogous bound of $O(\frac{1}{\vareps})$ on  the size of detection sets for adversaries that can delete $\kappa$ nodes. Our  algorithm for $(\vareps, \lambda)$-edge failures is based on the cactus  representation of all minimum edge-cuts of a graph; for node failures, we  develop a novel approach for working with the much more complex set of all  minimum node-cuts of a graph.",,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/5863,Discrete Hedging Under Piecewise Linear Risk-Minimization,"In an incomplete market it is usually impossible to eliminate the  intrinsic risk of an option. In this case, quadratic-risk minimization is often  used to determine a hedging strategy. However, it may be more natural to use  piecewise linear risk-minimization. We investigate hedging strategies using  piecewise linear risk-minimization. We illustrate that this criterion for  risk-minimization may lead to smaller expected total hedging cost and  significantly different, possibly more desirable, hedging strategies from those  of quadratic risk-minimization. The distributions of the total hedging cost and  risk show that hedging strategies obtained by piecewise linear  risk-minimization have a larger probability of small cost and risk, though they  also have a very small probability of larger cost and risk. Comparative  numerical  results are provided. We also prove that the value processes of  these hedging strategies satisfy put-call parity.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5864,On the Recognition of Primes by Automata,"A study of the problem of recognizing the set of primes by automata is presented. A simple algebraic condition is derived which shows that neither the set of primes nor any infinite subset of primes can be accepted by a pushdown or finite automaton. In view of this result an interesting open problem is to determine the ""weakest"" automaton which can accept the set of primes. It is shown that the linearly bounded automaton can accept the set of primes, and it is conjectured that no automaton whose memory grows less rapidly can recognize the set of primes. One of the results shows that if this conjecture is true, it cannot be proved by the use of arguments about the distribution of primes, as described by the Prime Number Theorem. Some relations are established between two classical conjectures in number theory and the minimal rate of memory growth of automata which can recognize the set of primes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5865,Translation Networks and Function Composition,Translation Networks and Function Composition,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5866,A Comparison Between Manual and Automatic Indexing Methods,"The effectiveness of conventional document indexing is compared with that achievable by fully-automatic text processing methods. Evaluation results are given for a comparison between the MEDLARS search system used at the National Library of Medicine, and the experimental SMART system, and conclusions are reached concerning the design of future automatic information systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5867,The Use of Standardized Documentary Data in AutomaticInformation Dissemination,"It is likely that future operating information retrieval systems may be based on automatic information analysis methods instead of manual indexing, and on search procedures which allow the user to interact with the system during the search process. The effectiveness of the required analysis and search operations depends to some extent on the availability in machine readable form of standardized information concerning the make-up and content of each stored document. An author-prepared standard manuscript documentation unit, furnished with each manuscript, may simplify the information retrieval and dissemination operations, and improve their effectiveness. The design of such a documentation unit is covered and its use is explained for indexing, classification, vocabulary normalization, searching, and retrieval.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5868,The Representation and Transformation of Functions,"A new approach to the study of programming languages is developed, which emphasized the sequence of information structures generated by a program during its execution. In section 1 a class of models called information structure models is developed for characterizing computations as sequences of transformations of information structures. The notion of binding time is introduced and different binding strategies for programming languages are considered. Section 2 considers the representation of functions by symbol tables and analyzes a number of examples of such functions, such as assemblers and macro systems. Section 3 introduces a very simple programming language for funcitn evaluation known as the lambda calculus, and considers information structure models for alternative evaluation strategies in the lambda calculus. Section 4 shows that ALGOL computations can be specified as information structure models with the same basic characteristics as lambda calculus computations but with a richer set of primitives, and indicates how languages such as PL/I can be characterized as information structure models.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5869,Concepts and Structures in Programming Languages,"These notes develop a set of concepts for describing program structures which arise in programming languages. These concepts are then used to discuss FORTRAN, ALGOL, macro languages, languages with definitional facilities, SNOBOL4, and LISP from a unifying point of view. The central concept is that of an information structure model. Emphasis is placed on the sequence of information structures generated by programs of a programming language during their execution.  Section 1 considers program representation, interpretation, and compilation. Section 2 introduces the concept of an information structure model for characterizing classes of computations. Sections 3 and 4 show that computers and programming languages are examples of information structure models. Sections 5 and 6 respectively consider the information structures associated with FORTRAN and ALGOL programs during their execution. Section 7 shows how syntax and semantics may be specified for information structure models and introduces the notion of an interpreter-interpreter. Section 8 develops information structure models for macro languages. Section 9 introduces the concept of binding time and discusses declarations and definitional facilities in programming languages. Sections 10 and 11 consider information structure models for SNOBOL4 and LISP.  Computer science may be defined as the study of representation and transformation of information structures. The present approach is concerned with the representation of programs as information structures and with the transformations of these structures during execution, and directly reflects the above definition of computer science.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5870,DPL:  A Language for Instruction in Concepts Basic to Data Processing and Management Information Systems,DPL:  A Language for Instruction in Concepts Basic to Data Processing and Management Information Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5871,A Recursive Relation for the Determinant of a Pentadiagonal Matrix,"A recursive relation is developed for the determinant of a pentadiagonal matrix $S$ which satisfies $s_{i,j} \neq 0$ for $|i-j|=1$. When $S$ is symmetric, one has a six-term recursive relation. An example is given to illustrate its use in the computation of eigenvalues.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5872,On the Equivalence and Containment Problems for Context-Free Languages,"Let $G$ and $G_{0}$ be context-free grammars. Necessary and sufficient conditions on $G_{0}$ are obtained for the decidability of $L(G_{0}) \subseteq L(G)$. It is also shown that it is undecidable for which $G_{0},L(G) \subseteq L($G_{0})$ is decidable. Furthermore, given that $L(G) \subseteq L($G_{0})$ is decidable for a fixed $G_{0}$, there is no effective procedure to determine the algorithm which decides $L(G) \subseteq L($G_{0})$. If $L(G_{0})$ is a regular set, $L(G)=L(G_{0})$ is decidable if and only if $L(G_{0})$ is bounded. However, there exist non-regular, unbounded $L(G_{0})$ for which $L(G) = L(G_{0})$ is decidable.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5873,Refinement of Hierarchies of Time Bounded Computations,"It is shown that for any ""slowly growing"" time function $T(n)$ and any $\epsilon > 0$ there exists a computation which can be performed by a multitape Turing machine in time $T(n)\log^{\epsilon}T(n)$ and cannot be performed by any multitape Turing machine in time $T(n)$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5874,Two Memory Bounds for the Recognition of Primes by Automata,Two Memory Bounds for the Recognition of Primes by Automata,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5875,On Newton-Like Iteration Functions: General Convergence Theorems and a Specific Algorithm,On Newton-Like Iteration Functions: General Convergence Theorems and a Specific Algorithm,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5876,A Quadratically Convergent Newton-Like Method Based Upon Gaussian-Elimination,A Quadratically Convergent Newton-Like Method Based Upon Gaussian-Elimination,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5877,DPL:  A Language for Instruction in CONTEMPORARY DATA PROCESSING CONCEPTS,"The Data Processing Language (DPL) id designed with two aims. The first is to aid in teaching the concepts and techniques of contemporary data processing systems to those who need an appreciation of the field, but who do not need to become trined programmers. The second is to test a new method for organizing and programming large systems which share a common data base among several simultaneous users.  The criteria for a contemporary data processing language are set forth and DPL is shown to meet them. These include remote terminal management, handling of shared data bases, file and device oriented input and output, and standard arithmetic and text processing features. In addition, simple syntax and extensive error detection and correction features fulfill important requirements of instructional computing systems.  Interrupts are the basis for the new method of systems organization. The DPL programmer can specify conditions when interrupts should be generated, e.g., when the relation $X+Y=34$ is true, and can specify the routine which should be called to process each interrupt. The DPL monitoring system detects the occurrence of these conditions and generates the interrupts. Some of these variables involved in conditions which can generate interrupts may be in files. The programmer can attach to those files the interrupt processing routines and the interrupt conditions. When the file is read in, the system begins monitoring these attached interrupt conditions and may execute the attached interrupt processing routines, which are called file tags, even though the user who placed the tags on the file is no longer in control. Several interrupts may be generated as the result of the execution of a single DPL statement, and interrupts may be generated while executing an interrupt processing routine. Therefore, an algorithm is presented which schedules the execution of the interrupt processing routines.  A management information system may thus be composed of two parts: a data base of tagged files, and a supervisor program which handless interaction with remote terminals and performs background tasks. This new organization is shown to have value both for its instructional clarity and for designing and programming large integrated information systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5878,Relevance Assessments and Retrieval System Evaluation,"Two widely used criteria for evaluating the effectiveness of information retrieval systems are, respectively, the recall and the precision. Since the determination of these measures is dependent on a distinction between documents which are relevant on the one hand, and documents which are not relevant on the other to a given query set, it has sometimes been claimed that an accurate, generally valid evaluation cannot be based on recall and precision. A study was made to determine the effect of variations in relevance assessments on the average recall and precision values used to measure retrieval effectiveness. Using a collection of 1200 documents in information science for test purposes, it is found that large scale differences in the relevance assessments do not produce significant variations in average recall and precision. It thus appears that properly computed recall and precision data may represent effectiveness indicators which are generally valid for many distinct user classes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5879,A LISP Interpreter in SNOBOL4,A LISP Interpreter in SNOBOL4,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5880,Computational Complexity of One-Tape Turing Machine Computations,"This paper is concerned with the quantitative aspects of one-tape Turing machine computations. It is shown, for instance, that there exists a sharp time bound which must be reached for the recognition of non-regular sets of sequences. It is shown that the computation time can be used to characterize the complexity of recursive sets of sequences and several results are obtained about this classification. These results are then applied to the recognition speed of context-free languages and it is shown, among other things, that it is recursively undecidable how much time is required to recognize a non-regular context-free language on a one-tape Turing machine. Several unsolved problems are discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5881,CUPL - An Approach to Introductory Computing Instruction,CUPL is a second-generation language and processor designed specifically for introductory instruction in computer programming. It combines a severely simple syntax (based loosely on PL/I) and very extensive tutorial and diagnostic assistance by the processor. The processor is core-resident and compiles very rapidly. The result is an effective instructional system that can be used for large numbers of students with modest demands on computer capacity. Technically CUPL is interesting for the error-correctinng capability of the compiler and the provision of direct operations for matrix algebra.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5882,Automatic Content Analysis in Information Retrieval,"The content analysis problem is first introduced, and some of the standard analysis procedures used in information retrieval are reviewed. The principal content analysis methods incorporated into the automatic SMART document retrieval system are then briefly examined and their effectiveness for information retrieval is discussed. Included in the system are word stem matching procedures, synonym recognition, phrase recognition, syntactic analysis, statistical term association techniques, and hierarchical expansion methods.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5883,Automated Language Processing,"This study covers recent developments in automatic text processing, including syntactic, semantic, and statistical language analysis methods. The emphasis is on applications in the areas of machine translation, information retrieval, and question answering. Recent on-line text processing methods, using man-machine interaction are covered in some detail, as are certain simple, syntactic analysis methods incorporated into a number of experimental information retrieval systems. An evaluation is made of the syntactic analysis methods, and their importance in a retrieval environmentt is discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5884,Tape Reversal Bounded Turing Machine Computations,"This paper studies the classification of recursive sets by the number of tape reversals required for their recognition on a two-tape Turing machine with a one-way input tape. This measure yields a rich hierarchy of tape reversal limited complexity classes and their properties and ordering are investigated. The most striking difference between this and the previously studied complexity measures lies in the fact that the ""speed-up"" theorem does not hold for slowly growing tape reversal complexity classes. These differences are discussed, and several relations between the different complexity measures and languages are established.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5885,Search and Retrieval Experiments in Real-Time Information Retrieval,"Future operating document retrieval systems may be based on fully-automatic information analysis methods instead of manual indexing, and on real-time search procedures which allow the user to interact with the system during the search process. Performance characteristics are first given for fully-automatic information retrieval systems, and comparisons are made with presently operating partly-manual systems. Thereafter, various user-controlled search strategies are described, and the potential of these strategies in improving systems performance is discussed. The evaluation results for the real-time retrieval procedures are used to derive design criteria for future automatic information systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5886,The Structure of SNOBOL4,"The SNOBOL4 programming language was developed by Griswold, Poage and Polonski (1). It combines facilities available in problem oriented languages with string manipulation facilities, pattern matching facilities and facilities for compilation during execution. The present description attempts to accomplish three objectives. It is an introduction to SNOBOL4 for the programmer with previous programming experience in some programming language but not necessarily previous experience with SNOBOL3. It is intended also to provide dynamic insights into the mechanisms for statement execution, and to describe source language structures in terms of the information structures to which they give rise during execution. It is felt that dynaamic insights into the way in which source statements are executed help not only the system programmer but also the average user.  This description is based on reference 1 and on two very worthwhile days of discussion with the authors of SNOBOL4 at Holmdel. The author is indebted also to John Kelly for fruitful discussion of aspects of SNOBOL4 and for proofreading the manuscript.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5887,Dynamic File Organization and Heuristic SearchStrategies in Information Retrieval,"A great deal of effort has been devoted in recent years to the evaluation of automatic or semi-automatic information retrieval systems. Recent evaluation results indicate that the search effectiveness presently achieved, or likely to be achievable in the foreseeable future, is much smaller than expected by a majority of the potential user population. Furthermore, theoretical advances in language analysis and data organization promise only relatively modest future improvements. The most significant advances in retrieval effectiveness are likely to be obtained by using adaptive techniques to extract information from the user population during the search process, leading to an improved organization of the data space and to more effective search and retrieval operations. Various user feddback techniques are described producing either modifications in the user queries i such a way as to bring these queries closer to existing groups of relevant documents, or modifications in the document space to bring relevant documents closer to the corresponding search requests. The feedback and space modification techniques are examined in detail, and the resulting efficiencies in the remote and retrieval operations are described. Descriptive Terms: Information retrieval, document retrieval, user feedback, relevance feedback, request modifications, document modifications, document grouping, clustering, adaptive search method, cluster searches, search effectiveness.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5888,The Four-Cubes Four-Color Problem or Instant Insanity,The Four-Cubes Four-Color Problem or Instant Insanity,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5889,Spelling Correction and Systems Programming,"Several specialized techniques are shown to make the incorporation of spelling correction algorithms into compilers and operating systems efficient. These include the use of syntax and semantics information, restricted keyword and symbol table organizations, and consideration of only a limited class of spelling errors. The number of debugging runs per program has been cut down by using systems which perform spelling correction, saving both programmer and machine time.  Key Words and Phrases: spelling correction, error correction, debugging, compilers, operating systems, diagnostics, error detection, misspelling, lexical analysis, systems programming.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5890,Upward and Downward Diagonalization over Axiomatic Complexity Classes,"This report considers special cases of the question """"What conditions on u() and t() guarantees that $R^{\Phi}_{t}() \neq $R^{\Phi}_{u}()$?"" where $R^{\Phi}_{t}()$ is the class of recursive functions whose $\Phi$ complexity is bounded by t(). In particular the condition $\stackrel{inf}{n\rightarrow\infty} \frac{t(n)}{u(n)} = 0$ and $\stackrel{lim}{n\rightarrow\infty} \frac{t(n)}{u(n)} = 0$ are examined, and it is shown that certain results of Hartmanis, Stearns and Hennis are in one sense the best possible. It is then shown that the diagonalization techniques used in results of this type are of two different sorts, upward and downward. The differences are made precise and very general conditions are found under which each type applies. These conditions widely generalize several well-known results for time and tape complexity measures. In the final section, the report considers some properties of a special class of names for complexity classes.  The techniques used in Lemma 3.3 and Theorems 5.1 and 7.1 are new and promise wider application. Also, new results of Borodin and McCreight and Meyer are used, but otherwise the methods are those of Blum.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5891,An Interrupt Based Organization for Management Information Systems,"A programming structure, language constructs, and supervisorry system organization are proposed for the design and coding of large shared data base systems. The bases for this organization are a generalized interrupt structure and the newly introduced concept of ""file tagging"", which is the process of associating program structures and interrupt generating conditions with items in the data base. An algorithm for resolving conflicts which arise in scheduling the interrupt processing routines is presented. DPL, a programming language and supervisory system in which these concepts are implemented, is used to illustrate the new organization which is proposed for management information systems. Keywords and phrases: management information systems, integrated data processing, supervisors, interrupts, monitoring systems, supervisory systems, interrupt scheduling, parallel processing.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5892,Parsing of Graph-Representable Pictures,"This paper describes a syntax-directed picture analysis system based on a formal picture description scheme. The system accepts a description of a set of pictures in terms of a grammar generating strings in a picture description language; the grammar is explicitly used to direct the analysis or parse, and to control the calls on pattern classification routines for primitive picture components. Pictures are represented by directed graphs with labelled edges, where the edges denote elementary picture components and the graph connectivity mirrors the picture component connectivity; blank and don't care ""patterns"" allow the description of simple relations between visible patterns. The bulk of the paper is concerned with the picture parsing algorithm which is an n-dimensional analog of a classical top-down string parser, and an application of an implemented system to the analysis of spark chamber film. The potential benefits of this approach, as demonstrated by the application, include ease of implementation and modification of picture processing systems, and simplification of the pattern recognition problem by automatically taking advantage of contextual information.  Key Phrases: picture processing, picture parsing, picture description, picture analysis, pattern recognition, top-down analyzer, graph representable pictures, syntax directed analysis, picture language, picture grammar, graphics language.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5893,The Operator Gap,"This paper continues investigations pertaining to recursive bounds on computing resources (such as time or memory) and the amount by which these bounds must be increased if new computations are to occur within the new bound. The paper proves that no recursive operator can increase every recursive bound enough to reach new computations. In other words, given any general recursive operator F[], there is an arbitrarily large recursive t() such that between bound t() and bound F[t()]() there is a gap in which no new computation runs. This demonstrates that the gap phenomenon first discovered by Borodin for composition is a deeply intrinsic property of computational complexity measures. Moreover, the Operator Gap Theorem proved here is shown to be the strongest possible gap theorem for general recursive operators. The proof involves a priority argument but is sufficiently self-contained that it can easily be read by a wide audience.  The paper also discusses interesting connections between the Operator Gap Theorem and McCreight and Meyer's important result that every complexity class can be named by a function from a measured set.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5894,Automatic Text Analysis,Effective automatic methods are now available to replace conventional document indexing and classification.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5895,On the Equivalence of Mechanical Evaluation Strategies,Two mechanical evaluation strategies are shown to correctly implement the $\lambda$-K-calculus and to be equivalent.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5896,On the Feasibility of Voice Input to an On-Line Computer Processing System,"An on-line digital computer processing system is considered in which an ordinary telephone is the complete terminal device, input to the computer being provided as a sequence of spoken words, and output to the user being audio responses from the machine. The feasibility of implementing such a system with a FORTRAN-LIKE algebraic compiler as the object processor is considered. Complete details of a specific word recognition program are given. This technique depends on three simplifying restrictions, namely, a ""small"" vocabulary set, ""known"" speakers, and a ""moment of silence"" between each input word. Experimental results are presented giving error rates for different experimental conditions as well as the machine resources required to accomodate several users at a time. The results show that at this time it is both economically and logically feasible to handle at least 40 users at a time with an IBM 360/65 computer.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5897,Evaluation Problems in Interactive Information Retrieval,"Interactive retrieval procedures are normally based on rapidly accessible files. Special storage organizations and file search techniques are used, and the system user is made to fulfill an important role during the retrieval process. In the present study, the interactive retrieval environment is briefly examined. The special problems which arise in the evaluation of interactive retrieval are then discussed, and methods are described for evaluating partial file searches and user feedback techniques. Evaluation resultss obtained with the SMART system are presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5898,Interactive Information Retrieval,"The advent of time-sharing computer organizations and input-output console equipment has made it possible to experiment with interactive information handling methods in which the user takes on important functions both in planning and in executing information searches. The principal interactive text storage and retrieval processes are briefly reviewed, including text editing, text analysis and indexing, query formulation, and information searching. The user's role is stressed in each case, and particular attention is paid to interactive search procedures in which both the user queries and the stored information files become altered as a result of the user-system interaction. Evaluation results obtained with the SMART retrieval system are exhibited for some of the proposed methodology.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5899,Computational Complexity and the Existence of Complexity Gaps,Computational Complexity and the Existence of Complexity Gaps,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5900,On the Automatic Calculation of Solutions - Different from Those Previously Obtained - of Nonlinear Systems of Equations,"Given a system of N nonlinear (algebraic or transcendental) real equations in N real unknowns, there exist a variety of numerical methods which obtain solutions of those equations. This paper presents two methods which are used to find further simple solutions - in addition to those already known a priori or from an earlier calculation. These methods have the advantage of keeping away from solutions previously calculated, saving the computer user the wasted effort entailed in converging to already known, perhaps uninteresting solutions points. The technique can also be used in avoiding previously found extreme points in function minimization. Many problems have ""magnetic zeros"", zeros which are converged to almost regardless of the starting guesses used. These magnetic zeros often mask out the zeros of real interest. The methods discussed are particularly effective in avoiding convergence to such magnetic zeros. Results of computer experiments ar presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5901,A Note on One-way and Two-way Automata,The purpose of this note is to show that there exist non-regular languages whose memory requirements for recognition by one-way and two-way automata differ by a double exponential and that this difference cannot be exceeded.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5902,On Minimizing the Number of Multiplications Necessary for Matrix Multiplication,"This paper develops an algorithm to multiply a px2 matrix by a 2xn matrix in $\lceil (3pn+max(n,p))/2 \rceil$ multiplications for matrix multiplication without commutativity. The algorithm minimizes the number of multiplications for matrix multiplication without commutativity for the special cases p=1 or 2, n=1,2, $\cdots$ and p = 3, n = 3. It is shown that with commutativity fewer multiplications are required.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5903,On the Local Convergence of Broyden's Method for NonlinearSystems of Equations,The purpose of this paper is to present an alternate to the proof given in [3] of the local convergence of Broyden's method. The result was stated there as a simple corollary of a Kantorovich-type theorem for the method. Here we allow ourselves to assume the existence of a root for the system of equations in question and as a result we are able to slightly relax the requirements on the partial derivatives of the system and greatly simplify the proof. We will confine the description of the method to bare essentials and refer the reader to [1] or [3] for more details.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5904,On the Local Convergence of Nonlinear Successive Overrelaxation and Related Methods,On the Local Convergence of Nonlinear Successive Overrelaxation and Related Methods,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5905,On the Convergence of Broyden's Method for Nonlinear Systems of Equations,On the Convergence of Broyden's Method for Nonlinear Systems of Equations,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5911,Comments on Prevention of System Deadlocks,"Habermann's method of deadlock preventative is discussed, where deadlock is defined as a system state from which resource allocations to certain processes is not possible. It is shown that the scheduler may introduce deadlocks which Habermann's method does not prevent. Effective deadlock is defined as the situation where certain processes do not receive their resource requests. It is shown that deadlock prevention does not imply effective deadlock prevention. A method of effective deadlock prevention is given.  Key Words and Phrases: multiprogramming, time-sharing, scheduling, resource allocation, deadlock, interlock, deadly embrace, knotting.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5912,The Use of Lists in the Study of Undecidable Problems in         Automata Theory,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5913,Subrecursive Programming Languages for $\Re^{n}$,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5914,On the Efficiency of Programs in Subrecursive Formalisms,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5915,An Error Analysis for Functions of Qualitative Attributes        with Application to Information Retrieval,"The use of overlapping, non-hierarchical classifications in information retrieval is considered. It is assumed that the population of objects to be classified is such that only a subset of the classes satisfying the classificatory criterion may be found. The effect of this assumption on the measurement of classification stability is considered. As a step towards the determination of stability, a general technique is presented for deriving the expectation of a statistical function of the similarities between the objects of the population. It is assumed that the objects are describable in terms of two-state attributes which are susceptible independently and equiprobably to error with an assignable probability. Two commonly encountered similarity functions are treated in detail. The techniques disclosed are applicable, in principle, to classification algorithms, whether hierarchical or non-hierarchical, which utilize a similarity matrix giving the similarities between pairs of objects described by two-state independent attributes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5916,A New Algorithm for Nonlinear Least Squares Curve Fitting,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5917,On the Size of Programs in Subrecursive Formalisms,"This paper gives an overview of subrecursive hierarchy theory as it relates to computational complexity and applies some of the concepts to questions about the size of programs in subrecursive programming languages. The purpose is three-fold, to reveal in simple terms the workings of subrecursive hierarchies, to indicate new results in the area, and to point out ways that the fundamental ideas in hierarchy theory can lead to interesting questions about programming languages. A specific application yields new information about Blum's results on the size of programs and about the relationship between size and efficiency.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5918,An Overview of the Theory of Computational Complexity,"The purpose of this paper is to outline the theory of computational complexity which has emerged as a comprehensive theory during the last decade. This theory is concerned with the quantitative aspects of computations and its central theme is the measuring of the difficulty of computing functions. The paper does not attempt to give an exhaustive survey but instead presents the basic concepts, results and techniques of computational complexity from a new point of view from which the ideas are more easily understood and fit together as a coherant whole.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5919,Unsolvability Considerations in Computational Complexity,"The study of Computational Complexity began with the investigation of Turing machine computations with limits on the amounts of tape or time which could be used. Later a set of general axioms for measures of computation was presented and this instigated much study of the properties of these general measures. Many interesting results were shown, but the general axioms allowed measures with undesirable properties and several attempts have been made to tighten up the axioms so that only desirable measures will be defined.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5920,Some Minimal Properties of the Trapezoidal Rule,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5921,Selective Security Capabilities in ASAP - A File Management System,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5922,On the Time Required to Detect Cycles and Connectivity in Directed Graphs,"It is shown that when a directed graph is represented as a binary connection matrix, the problem of finding the shortest path between two nodes of a directed graph, and the problem of determining whether the directed graph has a cycle require at least $O(n^{2})$ operations. Thus the presently known best algorithms are optimal to within a multiplicative constant.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5923,Simulation of the Job Shop Process,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5924,The Stability of Classifications of Binary Attribute Data,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5925,The Weakening of Taxonomic Inferences by Homological Errors,"In the past decade there has been a growing concern in devising classification algorithms which are applicable to large bodies of data. Such algorithms are characterized necessarily by a sacrifice of statistical sophistication for a gain in computational simplicity. Accordingly, inferences drawn from taxonomic studies in which these algorithms have been employed may be affected by accidental and poorly understood features of such algorithms. An error analytic technique is presented which reduces this possibility. It is applicable to many of the classification algorithms currently in use. The combinatorial problems encountered in the error analysis are discussed and a computationally viable method for their solution is formulated. The technique is illustrated by an experiment with a small set of data.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5926,"The ""Generality"" Effect and the Retrieval Evaluation forLarge Collections","The retrieval effectiveness of large document collections is normally assessed by using small subsections of the file for test purposes, and extrapolating the data upward to represent the results for the full collection. The accuracy of such an extrapolation unhappily depends on the ""generality"" of the respective collections. In the present study the role of the generality effect in retrieval system evaluation is assessed, and evaluation results are given for the comparison of several document collections of distinct size and generality in the areas of documentation and aerodynamics.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5927,On Scheduling Meetings,"We commment on the problem of assigning papers to time-slots to minimize the time needed for a technical meeting. We claim that this problem is, in abstract, the problem of discovering a minimal coloring of a conflict graph. This approach contrasts with that of Joseph E. Grimes in [1].  Key words and phrases: allocation, conflict matrix, connected component, scheduling, spanning tree, undirected linear graph, graph node coloring, graph vertex coloring.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5928,Register Allocation in Assembly Language,"This paper describes a scheme for using the facilities of a macro assembler to aid in allocating program variables to local-memory registers. The scheme allows the programmer to write the entire program before making any register-allocation decisions. The scheme requires that the programmer make explicit his assumptions about register ordering and usage, thus improving documentation.  Key Words and phrases: register allocation, register assignment, symbolic register names, macro assembler, variable allocation, scalar variable equivalence, graph coloring.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5929,Computational Complexity of Random Access Stored Program Machines,"In this paper we explore the computational complexity measure defined by running times of programs on random access stored program machines, RASP'S. The purpose of this work is to study more realistic complexity measures and to provide a setting and some techniques to explore different computer organizations. The more interesting results of this paper are obtained by an argument about the size of the computed functions. For example, we show (without using diagonalization) that there exist arbitrarily complex functions with optimal RASP programs whose running time cannot be improved by any multiplicative constant. We show, furthermore, that these optimal programs cannot be fixed prodecures and self-modifying programs. The same technique is used to compare computation speed of machines with and without built in multiplication. We conclude the paper with a look at machines with associative memory and distributed logic machines.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5930,Finiteness Assumptions and Intellectual Isolation         of Computer Scientists,"We investigate the consequences of assuming integer variables of algorithmic languages to be finite vs. infinite in number and/or range. We suggest that different groups of computer scientists use different postulates about algorithmic languages. This leads to difficulty in communication, since the assumptions are usually unstated.  Key words and phrases: Algol vs. FORTRAN, finiteness assumptions, intellectual isolation, integer variable range, memory finiteness, finite word size.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5931,The Solution of Nonlinear Operator Equations by A-Stable Integration Techniques,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5932,Size Arguments in the Study of Computation Speeds,"In this paper we use arguments about the size of the computed functions to investigate the computation speed of Turing machines. It turns out that the size arguments yield several new results which we have not been able to obtain previously by diagonalization. For example, we show that for arbitrarily complex running times $T(n)$ there exist functions which can be computed on a one-tape Turing machine in time $T(n)$ but not in time $t(n)$ provided $\stackrel{\lim}{n \rightarrow \infty} \frac{t(n)}{T(n)}=0$. The same result is also shown to hold for many-tape machines. We show furthermore, that there exist arbitrarily complex computations for which one-tape machines are slower than two-tape machines by a factor equal to the logarithm of the computation time of the two-tape machine. We conclude by discussing several other computational complexity measures and compare results obtained by diagonalization and size arguments.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5933,Common Phrases and Minimum-Space Text Storage,"A method for saving storage space for text strings, such as compiler diagnostic messages, is described. The method relies on hand-selection of a set of text-strings which are common to one or more messages. These phrases are then stored only once. The storage technique gives rise to a mathematical optimization problem: determine how each message should use the available phrases to minimize its storage requirement. This problem is non-trivial when phrases which overlap exist. However, we present a dynamic programming algorithm which solves the problem in time which grows linearly with the number of characters in the text.  Keywords and Phrases: diagnosic messages, error messages, common phrases, minimum space, text storage, optimization, dynamic programming.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5934,The Effect of Algebraic Structure on the Computational Complexity of        Matrix Multiplication,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5935,Automatic Processing of Current Affairs Queries,"The SMART system is used for the analysis, search, and retrieval of news stories appearing in Time magazine. A comparison is made between the automatic text processing methods incorporated into the SMART system and a manual search using the classified index to Time. The results indicate that equivalent retrieval results are obtainable when both the manual and the automatic searches are carried out in a feedback mode.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5936,Interrupt-Driven Programming,"In ""An Interrupt Based Organization for Management Information Systems"" (1), the author of that paper proposes a new form of interrupt, a Boolean expression of variables in the program, as a natural extension from the present interrupt structure. His paper describes a software implementation; this note shows how his system could easily be implemented in hardware, with a corresponding decrease in system overhead. Keywords and Phrases: Interrupts, Interrupt scheduling, supervisors, monitors, debugging, program checkout, parallel processing, associative memories, microprogramming.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5937,An Algorithm for Coloring the Nodes of a Graph,"We study the problem of coloring the nodes of a graph such that two nodes joined by an arc are assigned different colors. An algorithm is presented which requires $~n^{3}$ time, where the graph contains $n$ nodes. This algorithm yields near-minimal colorings. The algorithm is based on the ""coalescence"" and ""free coalescence"" of nodes to yield simpler graphs. Based on these same operations, we derive an exhaustive search which examines at most $2^{m}$ cases, where $m$ arcs appear in the complement of the graph to be colored.  Key words and phrases: Graph coloring, graph node coloring, graph vertex coloring.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5938,"Classification, Relevance, and Information Retrieval",NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5939,A Multiprogramming System for Education and Research,"A novel multiprogramming case study which has proven useful in operating systems education and research is presented. The operating system and its unusual hypothetical machine are specified. The paper then describes experience with the case study as a class project involving hardware simulation, and systems design and implementation; and as a research tool for testing neww ideas in operating systems primitives and design methodologies. It is concluded that case studies of this type will be widely used in the future.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5940,Numerical Approximations to Expectations of Functions of         Binary Sequences Subject to Error,"There is growing interest in devising non-statistical classification algorithms for multivariate populations. Statistical algorithms are avoided either because they are too costly, or because an adequate statistical model for the population does not exist (e.g. use of trainable linear machines in pattern recognition). Such algorithms may be sensitive (unstable) to errors in their data. The particular case of populations of objects characterised by binary attributes susceptible to independent and equiprobable errors is examined. The determination of stability requires the prior computation of the expectation of a statistical function of the object-pair similarities. The order and convergence of a numerical approximation for determining these expectations with prescribed accuracy is examined in the sub-asymptotic case in which normality does not occur. A number of results are given.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5941,Enumeration of the Elementary Circuits of a Directed Graph,"An algorithm to enumerate all the elementary circuits of a directed graph is presented. The algorithm uses back-tracking with lookahead to avoid unnecessary work, and it has a time bound of $O ((V+E)(C+1))$ when applied to a graph with $V$ vertices, $E$ edges, and $C$ elementary circuits. Keywords: Algorithm, circuit, cycle, graph",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5942,On the Efficiency of a Good but Not Linear Set Union Algorithm,"Consider two types of instructions for manipulating disjoint sets. FIND(x) computes the name of the (unique) set containing element x. UNION(A,B,C) combines sets A and B into a new set named C. We examinee a known algorithm for implementing sequences of these instructions. We show that if f(n) is the maximum time required by any sequence of n instructions, $k_{1} n \alpha (n) \leq f(n) \leq k_{2} n \log^{*}(n)$ for some constants $k_{1}$ and $k_{2}$, where  $\log^{*}(n) = \min\{i|\log^{i}(n) \leq 1\}$ and $\alpha(n)$ is a recursively defined function which satisfies $\alpha(n) \rightarrow \infty$ as $n \rightarrow \infty$. Thus the set union algorithm is $O(n \log^{*}(n))$ but not $O(n)$.  Keywords and phrases: algorithm, complexity, equivalence, partition, set union, tree.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5943,Constructive Mathematics and Automatic Program Writers,"One point made here is that formal constructive mathematics can be interpreted as a ""high-level"" programming language; another point is that there are good reasons for doing so.  Among them is the fact that a theoretical basis for automatic program writers (APW's) becomes especially perspicuous (in such a context the problem of assigning meaning to programs a la Floyd [6] is the inverse of program writing). Another reason is that such an interpretation reveals a number off interesting mathematical problems in the theory of computing.  While making these points we find occasion to present new observations on the completeness and efficiency of automatic program writers and to formulate a specific example of what we call von Neumann's principle on the logical complexity of systems. We apply the principle in the automatic program writing context and discuss its more general ramifications about the intelligibility of programs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5944,The Combinatorial Decomposition of Stability Problems         in Non-Statistical Classification Theory,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5945,The Symbolic Computation of Functions of Sequences over Finite Alphabets with Given Transition Probabilities by Sequence Length Independent Algorithms,"A special case of the problem discussed in this paper occurs in connection with non-statistical classification and is introduced from this point of view. The special case concerns the computation of expectations of statistical functions of the ""distance"" between pairs of fixed length sequences over a binary alphabet with given a priori state transition probabilities. The general problem involves an extension to alphabets of arbitrary order and the comparison of an arbitrary number of fixed length sequences. Given a set of sequences, it is shown that for a large class of functions exact computation may be carried out by an algorithm whose computation time is independent of the length of the sequences. It is further shown that results for all functions of this class may be derived from a small number of basis functions. Two methods for computing basis functions are given. Basis functions for the commonly encountered special case involving pairs of binary sequences are given explicitly.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5946,On Some Methods Based on Broyden's Secant Approximation to the Hessian,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5947,Synchronization and Simulation in Operating System Construction,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5948,Generating Machine Code for High-Level Programming Languages,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5949,A Proposal for Compile-Time Facilities,"A novel, simple scheme for providing compile-time facilities to PL/I programmers is proposed. The scheme emphasizes language unity and implementation ease at the expense of syntactic nicety. A similar approach is possible in high-level languages other than PL/I, assuming they include adequate character string processing facilities. This paper describes the scheme, and attempts to analyze its advantage and shortcomings.  Keywords and Phrases: macros, macro processing, compile-time facilities, compile time macros, compiler macros, high level language macros.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5950,A Characterization of Superlinear Convergence and its Application to Quasi-Newton Methods,"Let F be a mapping from real n-dimensional Euclidean space into itself. Most  practical algorithms for finding a zero of F are of the form $x_{k+1} = x_{k} - B_{k}^{-1_{Fx_{k}}}$ where $\{B_{k}\}$ is a sequence of non-singular matrices. The main result of this paper is a characterization theorem for the superlinear convergence to a zero of F of sequences of the above form. This result is then used to give a unified treatment of the results on the superlinear convergence of the Davidon-Fletcher-Powell method obtained by Powell for the case in which exact line searches are used, and by Broyden, Dennis, and More for the case without line searches. As a by-product, several results on the asymptotic behavior of the sequence $\{B_{k}\}$ are obtained.   An interesting aspect of these results is that superlinear convergence is obtained without any consistency conditions; i.e. without requiring that the sequence $\{B_{k}\}$ converge to the Jacobian.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5951,Programming by Induction,"A technique for creating programs, called programming by induction, is described. The term is used because of the similarity between programming by induction and proving a theorem by induction.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5952,Design and Implementation of a Diagnostic Compiler for PL/I,"PL/C is a compiler for a dialect for PL/I. The design objective was to provide a maximum degree of diagnostic assistance in a batch processing environment. For the most part this assistance is implicit and is provided automatically by the compiler. The most remarkable characteristic of PL/C is its perseverance -- it completes translation of every program submitted and continues execution until a user-established error limit is reached. This requires that the compiler repair errors encountered during both translation and execution, and the design of PL/C is dominated by this consideration.  PL/C also introduces several explicit user-controlled facilities for program testing. Some are conventional, providing a convenient high-level trace and dump capability. An experimental version of PL/C also permits the user to controllably reverse the direction of program execution and to write routines that are asynchronously invoked when an arbitrary condition becomes true. To accomodate these extensions to PL/I without abandoning compatibility with the IBM compiler, PL/C permits `pseudo-comments' - constructions whose contents can optionally be considered either source text or comment.  In spite of th ediagnostic effort PL/C is a fast and efficient processor. It effectively demonstrates that compilers can provide better diagnostic assistance than is customarily offered, even when a sophisticated source language is employed, and that this assistance need not be prohibitively costly.  Key Words and Phrases: Compilers, Debugging, PL/I",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5953,On Decreasing the Computing Time for Modular Arithmetic,"In this paper it is shown that by suitably modifying Garner's algorithm for applying the Chinese Remainder Theorem to optimally employ the fast multiplication techniques of Schonhage and Strassen, one can often decrease the computing time of algebraic algorithms employing modular (congruence, residue) arithmetic.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5954,"On the Matrix Polynomial, Lamda-Matrix and Block Eigenvalue Problems","A matrix $S$ is a solvent of the matrix polynomial $M(X) \equiv X^{m} + A_{1}X^{m-1} + \cdots + A_{m}$, if $M(S) = \stackrel{0}{=}$, where $A_{1}, X$ and $S$ are square matrices. We present some new mathematical results for matrix polynomials, as well as a globally convergent algorithm for calculating such solvents. In the theoretical part of this paper, existence theorems for solvents, a generalized division, interpolation, a block Vandermonde, and a generalized Lagrangian basis are studied. Algorithms are presented which generalize Traub's scalar polynomial methods, Bernoulli's method, and eigenvector powering. The related lambda-matrix problem, that of finding a scalar $\lambda$ such  that $I \lambda^{m} + A_{1} \lambda^{m-1} + \cdots + A_{m}$ is singular, is examined along with the matrix polynomial problem. The matrix polynomial problem can be cast into a block eigenvalue formulation as follows. Given a matrix $A$ of order mn, find a matrix $X$ of order n, such that $AV=VX$, where $V$ is a matrix of full rank. Some of the implications of this new block eigenvalue formulation are considered.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5955,The Application of Variational Inequalities to Complementarity         Problems and Existence Theorems,"If $F : C \rightarrow R^{n}$ is a continuous (nonlinear) mapping on a closed, convex subset $C$ of $R^{n}$, it is shown that very weak coercivity conditins on $F$ guarantee the existence of a solution $x^{*} in $C$ to the variational inequality $(x-x^{*}, Fx^{*}) \geq 0$ for each $x$ in $C$. By restricting the shape of $C$, it is shown that $x^{*}$ solves different problems, and in each case we are able to obtain new existence results. If $C$ is a cone $K$, the $x^{*}$ is a solution to the complementarity problem: Find an $x^{*}$ in $K$ such that $Fx^{*}$ belongs to the polar of $K$ and $(x^{*}, Fx^{*})=0$. In this case it is possible to generalize some of the feasibility results available in the linear theory and to give an iterative scheme for finding $x^{*}. If $C$ is similar to a simplex then $x^{*}$ turns out to be a solution of nonlinear inequalities in the preorder induced by a cone, while if $C$ or $K$ is $R^{n}$, then $Fx^{*} =0$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5956,Algorthms for Rational Function Arithmetic Operations,"Despite recent advances in speeding up many arithmetic and algebraic algorithms plus an increased concern with algorithm analysis, no computing time study has ever been done for algorithms which perform the rational function arithmetic operations. Mathematical symbol manipulation systems which provide for operations on rational functions use algorithms which were initially given by P. Henrici in 1956. In this paper, these algorithms are precisely specified and their computing times analyzed. Then new algorithms based on the use of modular arithmetic are developed and analyzed. It is shown that the computing time for adding and taking the derivative of univariate rational functions is 2 orders of magnitude faster using the modular algorithms. Also, the computing time for rational function multiplication will be one order of magnitude faster using the modular algorithm. The new method is generalized to the multivariate case and extensive empirical results are given.  Keywords: Rational functions, modular arithmetic, arithmetic oeprations,  algebraic algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5957,Toward a Polynomial Bound on DP:  A Special Case,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5958,A Linear Algorithm for Testing Equivalence of Finite Automata,An algorithm is given for determining if two finite automata with start states are equivalent. The asymptotic running time of the algorithm is bounded by a constant times the product of the number of states of the larger automaton with the size of the input alphabet.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5959,A New Comparison Between Conventional Indexing (MEDLARS) andAutomatic Text Processing (SMART),"A new testing process is described designed to compare conventional retrieval (MEDLARS) and automatic text analysis methods (SMART). The results obtained with a collection of documents chosen independently of either SMART or MEDLARS indicate that a simple automatic extraction of keywords from document abstracts produces a 30 to 40 percent loss compared with MEDLARS indexing. A replacement of the unranked Boolean searches used in MEDLARS by the standard ranked output normally provided by SMART reduces the loss to between 15 and 20 percent. When an automatically generated word control list or a thesaurus is used as part of the SMART analysis, the results are comparable in effectiveness to those obtained by the intellectual MEDLARS indexing. Finally, the incorporation of user feedback procedures into SMART furnishes an improvement over the normal MEDLARS output of 15 to 30 percent. One concludes again that no technical justification exists for maintaining controlled, manual indexing in operational retrieval environments.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5960,Automatic Correction of Syntax Errors in Programming Languages,"A very substantial fraction of the time and efforts required to develop a program is devoted to the removal of errors. In order to simplify this task, a model to automatize the correction of syntax errors is developed. It is the first model which is both formal and fairly realistic to appear in the literature.  The notion of error is defined and studied formally. Then, using this definition, a systematic error-correction process is modelled. This process makes local corrections over clusters of errors, using the context around the errors to determine the corrections and to insure that the different local corrections performed on the string do not interfere with one another. The error-correction process can be naturally embedded in many left-to-right syntax checking processes. It uses the recognizer both to detect errors and to find possible corrections.  The process has two modes: a ``standard mode'' used for syntax checking and an ``error-correction mode'' used for determining the context of a cluster of errors and for finding all possible corrections of these errors. In the ``standard mode'', the syntax is checked at the same speed as if no error-correction mechanism is implemented. Thus, for programs which contain no errors, no price is paid for the presence of this mechanism. The ``error-correction mode'' consist of two phases: the backward move which locates the left context of the cluster, and the forward move which construct possible corrections and locates the right context of the cluster.  This process seems the most natural way to perform left-to-right syntax checking and error correction.  Some techniques for efficiently finding the range of the backward move  are developed.  The formal model is not practical when using the conventional context-free description of programming languages. In order to make it more practical, the notion of bracketed context-free language is introduced and proposed as a model for the syntax fo programming languages. Then, heuristic restrictions on the type of errors corrected are discussed. They may lead to a simpler process. In particular, assuming that brackets are corrected only when no other correction is possible, and that errors in deep levels of nesting (with respect to the point where the errors are detected) are neglected, it is shown how the process can be used to correct syntax errors in programming languages.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5961,A Unified View of the Complexity of Evaluation and Interpolation,"Four problems are considered: 1) from an n-precision integer compute its residues modulo n single precision primes; 2) from an n-degree polynomial compute its values at n points; 3) from n residues compute the unique n-precision integer congruent to the residues; 4) from n points compute the unique interpolating polynomial through those points. If $M(n)$ is the time for n-precision integer multiplication, then the time for problems 1 and 2 is shown to be $M(n) \log n$ and for problems 3 and 4 to be $M(n)(\log n)^{2}$. Moreover, it is shown that each of the four algorithms are really all instances of the same general algorithm. Finally, it is shown how preconditioning or a change of domain will reduce the time for problems 3 and 4 to $M(n)(\log n)$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5962,A Fast Method for Interpolating Preconditioning,"Given $n$ points $(x_{i},y_{i})$ the best algorithms for finding the unique interpolating polynomial $G(x)$ such that $G(x_{i})=y_{i}$ take $O(n^{2})$ arithmetic operations. If the $(x_{i}$ are known in advance then an algorithm for finding $G(x)$ is presented which takes only $O(n(\log n)^{3})$ steps. Also, it is shown how to precompute certain functions of the $x_{i}$, in $O(n^{2})$ steps, such that this restricted interpolation algorithm can be easily used. Finally, it is shown that speeding up the general interpolation problem is possible if one can solve a simpler problem, namely to find a polynomial $G(x)$ such that $G(x_{i})=0$ for $1 \leq i \leq j$ and $G(x_{i})=1$ for $j+1 \leq i \leq n$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5963,A Proposal for an Interactive Version of PL/C,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5964,On the Implementation of Security Measures in Information Systems,"The security of an information system maay be modelled by a matrix whose elements are decision rules and whose row and column indices are users and data items respectively. A set of four functions are used to access this matrix at translation and execution time. Distinguishing between data dependent and data independent decision rules enables one to perform much of the checking of security once at translation time rather than repeatedly at execution time. The model is used to explain security features of several existing systems, and serves as a framework for a proposal for general security system implementation within today's languages and operating systems. Keywords: security, privacy, access control confidentiality, operating systems, access management, data banks, management information systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5965,"Picture Graphs, Grammars, and Parsing","This paper is concerned with the syntactic description and analysis of pictures when graphs are employed as the primary description formalism. The present state of development, a number of significant open problems, and the advantages and limitations of this approach are discussed under the following three headings: (a) representation of pictures by graphs, (b) graph languages and grammars, and  (c) parsing of graphs and pictures. In (a) we investigate transformations from pictures to graphs based on n-ary relations $(n \geq 1)$ that exist among picture components, both at the primitive pattern level and among higher level subpictures; n-ary relations are reduced when $n>2$ or expanded when $n=1$ to binary relations. Several grammatical schemes for generating graph descriptions are then evaluated with respect to their descriptive adequacy, complexity, and practical and theoretical tractability. Syntax-directed analysis of graphss and pictures is treated from two points of view - how to parse efficiently and how to enlist the descriptive mechanism as an aid in the difficult lower level pattern recognition tasks. The latter point is particularly emphasized with the aim of promoting a more systematic approach to contextual recognition.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5966,Nonlinear Generalizations of Matrix Diagonal Dominance         with Application to Gauss-Seidel Iterations,"A new class of nonlinear mappings is introduced which contains, in the linear case, the strictly and irreducibly diagonally dominant matrices as well as other classes of matrices introduced by Duffin and Walter. We then extend some of the properties of the above mentioned matrices to these weakly $\Omega$-diagonally dominant functions, and point out their connection to the M- and P- functions studied by Rheinboldt, and More and Rheinboldt, respectively. Finally, new convergence theorems for the nonlinear Jacobi and Gauss-Seidel iterations are presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5967,"Reversible Execution as a Diagnostic Tool,"" (preliminary draft)",NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5968,An Algorithm for Extracting Phrases in a Space-Optimal Fashion,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5969,Loop Schemata,"We define a class of program schemata arising from the subrecursive programming language Loop. In this preliminary report on Loop schemata we show how to assign functional expressions to these schemata (as one aspect of the problem of assigning meaning to these programs), and we outline a solution to the schemata equivalence problem. Schemata equivalence is reduced to questions about formal expressions. Certain subcases of the problem are easily shown solvable, and although we claim that the general problem is solvable, we do not present the complete solution here because of its complexity.  Key Words and Phrases: program, program schemata, Algol, universal programming language, Loop language, subrecursive language, computable function, primitive recursive function, functional, general recursive functional, equivalence problem, unsolvability.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5970,ser's Manual for the SMART Information Retrieval System,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5971,Subrecursive Programming Languages II: On Program Size,"Programming languages which express programs for all computable (recursive) functions are called universal, those expressing programs only for a subset are called subrecursive programming languages, SPL's.

M. Blum has shown that for certain SPL's any universal programming language (UPL) contains programs which are arbitrarily shorter and nearly as efficient as the shortest SPL program for the same function. We offer new proofs of this theorem to make the relationship. between size and efficiency more revealing and to show that finitely often efficiency is the price of economy of size. From the new proof we derive refinements of the basic theorem. In particular we consider the size-efficiency exchange for the task of computing constants, and derive a measure of the relative expressive power of SPL's. The results are illustrated with some new programming language models.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5972,Computers and Society: A Proposed Course for Computer Scientists,"The purpose of this paper is to describe a course concerned with both the effects of computers on society and the responsibilities of computer scientists to society. The impact of computers is divided into five components: political, economic, cultural, social, and moral; the main partt of the paper defines each component and presents examples of the relevant issues. In the remaining portions, we discuss the possible formats for such a course, give a topic by topic outline, and list a selected set of references. It is hoped that the proposal will make it easier to initiate courses on this subject. Keywords: Computers and society, social implications, course proposal.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5973,Algorithms for Nonlinear Problems Which Use DiscreteApproximations to Derivatives,"The most desirable algorithms for nonlinear programming problems call for obtaining the gradient of the objective and the Jacobian of the constraint function. The analytic form is often impossible and almost always impractical to obtain. The usual expedient is to use difference quotients to approximate the partial derivatives. This paper is concerned with the theoretical and practical ramifications of such modifications to basic algorithms. Among the methods surveyed are steepest descent, Stewart's modifications of the Davidon-Fletcher-Powell method, the Levenberg-Marquardt method, Newton's method, and the nonlinear reduced gradient method. Numerical results are included in the presentation. Key Words and Phrases: Nonlinear function minimization, numerical  differentiation, nonlinear programming.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5974,"Subrecursive Programming Language III, The Multiple        Recursive Functions, $\Re^{n}$","The characterization of program structure is an elusive aspect of the theory of programming languages. Contingent on such a characterization is an interesting study of the trade-off relationships between program structure and efficiency, between structure and intelligibility, between structure and size, and so forth.  One promising definition of program structure is suggested by the studies of the structure of recursion schemata pursued by logicians in the 1930's. In this paper we carry over some of these ideas to programming and present new computer-oriented definitions of certain well-known classes of recursive functions, namely the multiple recursive,$\Re^{n}$ , function of Peter. The treatment will facilitate discussions of ultra-complex functions when the need arises. Surprisingly, the need to discuss them does arise frequently at least for doubly recursive function when teaching results about primitive recursive functions and the various languages for computing them. Students want examples of non-primitive recursive functions and computations. Theoreticians also want simple examples of functions which have high structural as well as computational complexity. $\Re^{2}$ functions and the languages given here serve these purposes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5975,On the Number of Multiplications Required to Compute         Quadratic Functions,This is a study of the number of multiplications required for the evaluation of quadratic functions in n variables. Several sufficient conditions are presented for a requirement of j multiplications. A procedure is given for generating the optimal program for any quadratic function over a non-commutative ring. An application of these results solves an open problem possed by Knuth. Necessary and sufficient conditions are found for real and complex functions to require $j$ multiplications.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5976,Dynamic Document Processing,"The current role of computers in automatic document processing is briefly outlined, and some reasons are given why the early promise of library automation and of the mechanization of documentation processes has not been fulfilled.  A new dynamic document environment is then outlined in which clustered files are searched, and information is retrieved following an interactive user-controlled search process. Methods are described for an automatic query modification based on user needs, and for a continuous reorganization of the stored information as a function of earlier file processing and of normal collection growth. The proposed procedures provide powerful tools for information retrieval and for the control of dynamic library collections in which new items are continually added and old ones are retired.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5977,The Role of Partitioning in the Numerical Solution of Sparse Systems.,,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5978,Finding a Maximum Clique,"An algorithm for finding a maximum clique in an arbitrary graph is described. The algorithm has a worst-case time bound of $k(1.286)^{n}$ for some constant $k$, where $n$ is the number of vertices in the graph. Within a fixed time, the algorithm can analyze a graph with 2 3/4 as many vertices as the largest graph which the obvious algorithm (examining all subsets of vertices) can analyze. Keywords: Algorithm, Clique, Graph, Independent Set.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5979,A Characterization of Superlinear Convergence and its Application to Quasi-Newton Methods,"Let F be a mapping from real n-dimensional Euclidean space into itself. Most  practical algorithms for finding a zero of F are of the form $x_{k+1} = x_{k} - B_{k}^{-1_{Fx_{k}}}$ where $\{B_{k}\}$ is a sequence of non-singular matrices. The main result of this paper is a characterization theorem for the superlinear convergence to a zero of F of sequences of the above form. This result is then used to give a unified treatment of the results on the superlinear convergence of the Davidon-Fletcher-Powell method obtained by Powell for the case in which exact line searches are used, and by Broyden, Dennis, and More for the case without line searches. As a by-product, several results on the asymptotic behavior of the sequence $\{B_{k}\}$ are obtained.   An interesting aspect of these results is that superlinear convergence is obtained without any consistency conditions; i.e. without requiring that the sequence $\{B_{k}\}$ converge to the Jacobian.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5980,Subrecursive Program Schemata I and III. Undecidable Equivalence Problems and II. Decidable EquivalenceProblems,"The study of program schemata and the study of subrecursive programming languages are both concerned with limiting program structure in order to permit a more complete analysis of algorithms while retaining sufficiently rich computing power to allow interesting algorithms. In this paper we combine these approaches by defining classes of subrecursive program schemata and investigating their equivalence problems. Since the languages are all subrecursive, any scheme written in any one of them must halt (as long as we assume the basic functions and predicates are all total). Hence equivalence of schemes is the first question of interest we can ask about these languages. We consider schematic versions of various subrecursive programming languages similar to the Loop language. We distinguish between Pre-Loop and Post-Loop languages on the basis of whether the exit condition in an iteration loop is tested before iteration, as in Algol (Pre-), or after iteration, as in FORTRAN (Post-). We show that at the program level all these languages have the same computing power (the primitive recursive functions) and all have unsolvable equivalence problems (of arithmetic degree $\Pi^{0}_{1}$). But at the level of schemes, Pre-Loop has an unsolvable equivalence problem, while at least one formulation of Post-Loop has a solvable equivalence problem. If L is a programming language or scheme language, then we denote by E(L)  the equivalence problem in L. The basic languages considered are: Loop ($\equiv$ Pre-Loop) - Loop language for primitive recursive functions. Post-Loop - Post-Loop language for primitive recursive functions. Loop$_{\Diamond}$ - Loop language with restricted conditionals. L [D, ()] - Loop schemata over D with identity. L$_{\Diamond}$ [D, ()] - Loop schemata with conditionals. PL [D, ()] - Post-Loop schemata over D. PL$_{\Diamond}$ [D, ()] - Post-Loop schemata with conditionals. P - Program (flowchart) schemata. P$_{d}$ - Program schemata with DO-statements. In contrast to (pure) Loop schemata studied previously by the first author, some of these languages contain the identity function so that a pure data transfer, $X \leftarrow Y$, is possible. Moreover, the equivalence algorithms given here are for the special case of linear schemes (to be defined below) with monadic function variables. Linear schemes are designated by placing L before the name of the more general class, thus LL for linear Loop, LPL for linear Post-Loop, etc. In all schemes considered here the functions are monadic, so no special designation of function rank is provided. It is well known that E(P) is recursively unsolvable and E(P) $\in \Pi^{0}_{2}$. We show that E(Loop), E(Post-Loop), E(L$_{\Diamond}$) (both with and without the pure data transfer), and E(L) are recursively unsolvable, while E(LPL) is recursively solvable. The extension of the equivalence algorithm for LPL to polyadic functions appears at present to be a tedious but straightforward modification to the monadic algorithm. We are hopeful that a simpler and more generally applicable technique will emerge for demonstrating solvability or unsolvability of this class of equivalence problems. The algorithm and proofs given here are but a crude first step in delimiting this problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5981,Algorithms for Shortest Paths,"New algorithms are presented for the general all pairs and single source shortest path problems and for the single source problem restricted to nonnegative arc weights. The new algorithms are faster on sparse networks than algorithms previously known. In addition, new results are presented on the behavior of well-known algorithms, two of which have exponential running times under surprisingly innocuous conditions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5982,Program Schemes with Pushdown Stores,"We attempt to characterize classes of schemes allowing pushdown stores, building on an earlier work by Constable and Gries [1]. We study the effect (on the computational power) of aloowing one, two, or more pushdown stores, both with and without the ability to detect when a pds is empty. A main result is that the use of using one pds is empty. A main result is that the use of using one pds is computationally equivalent to allowing recursive functions. We also study the effect of adding the ability to do integer arithmetic, and multi-dimensional arrays. Keywords: Program schemes, schemata, pushdown stores, stacks, recursion, programming languages.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5983,Bounded Context Parsable Grammars,"In this paper we extend Floyd's notion of parsing by bounded context to define the Bounded Context Parsable Grammars, a class of recursive subsets of context free grammars for which we can construct linear time parsers. it is shown that the set of languages of the grammars thus defined properly contains the set of deterministic languages without the empty sentence.  Keywords and Phrases: bounded context grammars, linear time parsers,  deterministic context free languages.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5984,The Efficient Calculation of Powers of Polynomials,"Suppose we are given a polynomial $P(x_{1},\ldots,x_{r})$ in $r \geq 1$ variables, let $m$ bound the degree of $P$ in all variables $x_{i}, l \leq i \leq r$, and we wish to raise $P$ to the $n^{th}$ power, $n>1$. In a recent paper which compared the iterative versus the binary method it was shown that their respective computing times were $O(m^{2r}n^{r+1})$ versus $O((mn)^{2r})$ when using single precision arithmetic. In this paper a new algorithm is given whose computing time is shown to be $O((mn)^{r+1)$. Also if we allow for polynomials with multiprecision integer coefficients, the new algorithm presented here will be faster by a factor of $m^{r-1}n^{r}$ over the binary method and faster by a factor of $m^{r-1}$ over the iterative method. Extensive empirical studies of all three methods show that this new algorithm will be superior for polynomials of even relatively small degree, thus guaranteeing a practical as well as a useful result.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5985,The Application of Symbolic Mathematics to a Singular         Perturbation Problem,"A basic technique for the numerical solution of ordinary differential equations is to express them as a singular perturbation problem. However, computational studies indicate that the resultant matrix equations which must be solved are often highly ill-conditioned. In this paper a particular singular perturbation problem which was shown to be ill-conditioned using 8 numerical methods is solved by symbolic techniques. These techniques lead both to an analytic proof of the solution plus to the precise knowledge of the asymptotic behavior of the solution vector as it converges. The difficulties encountered in solving the problem symbolically are discussed. Then several conclusions are drawn about the merits of a symbolic versus a numeric approach when applied to the solution of linear systems. Finally some advice and warnings to both the user and the designer of symbol manipulation systems are given concerning their goals and expectations when large matrix equations are to be solved.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5986,A Polynomial Bound on the Complexity of the Davis-PutnamAlgorithm Applied to Symmetrizable Propositions,"The problem considered is the relation of minimal computation space to minimal computation time; more specifically, it is desired to determine the time complexity of the tautology problem for propositional logic; the space complexity is known to be linear. This is of special interest in view of Stephen Cook's p-reducibility theorem (May, 1971 ACM Symposium). Algorithms considered are the analytic tableau method, which appears to be inalterably exponential in space and time, and the Davis-Putnam algorithm, part of a resolution procedure introduced in JACM in 1960. Although the algorithm as stated has been shown to be exponential, the known examples are disposed of by (1) locally optimizing the choice of elimination variable and (2) using the subsumption rule (absorption rule), which asserts that if any clause is identical to a subclause of another clause, the larger clause may be deleted. An algebraic notation is developed which makes it clear that Davis and Putnam's Rules 1 and 2 are special cases of Rule 3 plus local optimization and subsumption. The algebraic notation consists of using vectors to represent clauses; the $i^{th}$ element of the vector is equal to +, -, 0, or 1, according as the $i^{th}$ variable occurs positively, negatively, or not at all. This notation is used in an APL computer program; by using 01,10,00, and 11 to represent +, -, 0, and 1, the program can be written entirely in terms of APL logical operators on arrays, with loops needed only because of size limitations, at a considerable savings in time and space compared to a list representation of the formula, for up to about twenty variables. The proof in brief of the polynomial special-case bound: Call a DNF formula ``reduced'' if the subsumption rule will delete no clauses; call it ``symmetric'' if it is invariant (as a set of clauses) under interchange of variable names. For any clause $R$, let $R^{+}$ be the number of positive literals in $R$ and $R{-}$ the number of negated literals. Call $(R^{+},R^{-})$ the (clause-)type of $R$. A symmetric formula $A$ then satisfies the property that if $(R^{+},R^{-})$ is the type of some clause in $A$, then every clause of type $(R^{+},R^{-})$ is also a clause of $A$. An algebra of clause-types is developed; it is easily shown that if $r=(R^{+},R^{-})$ and $s=(S^{+},S^{-})$ are unequal types of a reduced symmetric DNF formula (RSDNF), then either $R^{+} greater than S^{+}$ and $R^{-} less than  S^{-}$, or $R^{+} less than S^{+}$ and $R^{-} greater than S^{-}$. The former pair is denoted $``r \ogeq s''; \ogeq$ is a strict ordering of clause-types, which is total for RSDNF's. If $r \ogeq s$ and for no $p$ of $E$ is $r \ogeq p \ogeq s$, say $r$ adj $s$ (in $E$). Denote by PROD(A) the result of one iteration of the Davis-Putnam algorithm with subsumption. Let $E$ be and RSDNF in $V$ variables. The $t$ is a type of PROD(E) if either (1) $t$ is a type of $E$ (with $t^{+} + t^{-} \leq V-1)$, and for no $x$ or $y$ is $(t^{+} + 1, x)$ or $(y, t^{-} + 1)$ a type of $E$; or (2) $t=(r^{+} -1, s^{-} -1)$, with $r$ adj $s$ in $E$. It is further shown that if $r$ adj $s$ in PROD(E), then either $r^{+} = s^{+} +1$, or $s^{-} =r^{-} +1$, or $(r^{+} -1, s^{-} -1)$ is not a type of PROD(PROD(E)). A simple combinatorial argument then shows that each type of PROD(PROD(E)) has fewer clauses than some type of PROD(E). The polynomial bound is then immediate, since there are at most $V+1$ types in any RSDNF formula in $V$ variables, and the number of varialbles decreases with each iteration, and there can be at most $V$ iterations. The extension to symmetrizable is trivial.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5987,"Some Related Problems from Network Flows, Game Theory and        Integer Programming",We consider several important problems for which no polynomially time bounded algorithm is known. These problems are shown to be related in that a polynomial algorithm for one implies a polynomial algorrithm for the others.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5988,A Model for Adaptive Problem Solving Applied to Natural        Language Acquisition,"Adaptive Problem Solving is the application of artificial intelligence learning techniques to practical problems. The approach taken in studying Adaptive Problem Solving is three-fold. First, to develop a model for Adaptive Problem Solving in order to specify the processes involved in computer learning, as well as the interaction between these processes. Second, theoretically well-founded, practical algorithms are developed for each of these learning processes. Third, as an application of this theory, the Natural Language Acquisition Problem is formulated in terms of the adaptive model.  The specification of algorithms to perform the learning processes leads to the development of the Bandwidth Heuristic Search, an extension of the heuristic search, that includes many practical considerations without forfeiting any theoretical capabilities. A modification of this algorithm, the Bandwidth Heuristic Search for MIN/MAX trees is shown to be superior to the alpha-beta minimax process.  The model is applied to the Natural Language Acquisition Problem in order to force an encounter with several critical problems involved with computer learning. The Natural Language Acquisition Problem is the problem of providing a robot the adaptive mechanisms sufficient to learn to converse with a human teacher using natural language. The robot first learns the lexicon of the language by correlating the teacher's description of the robot's actions with the robot's internal description. Then the robot infers a grammar that reflects the structure of the teacher's sentences. At this point the robot can begin conversing using a natural language. The linguistic capability of the robot includes the ability to disambiguate lexical and structural ambiguities, and the ability to formulate full sentence replies. After several learning sessions the robot converses in English using nested dependent clauses.  This adaptive linguistic system successfully copes with many of the critical problems involved in computer learning and serves as an example of an adaptive program in which the learning, rather than yielding only minor improvements, provides the primary basis for successful performance.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5989,Computing Partitions with Applications to the Knapsack Problem,"Given $r$ numbers $s_{1}, \ldots, s_{r}$, algorithms are investigated for finding all possible combinations of these numbers which sum to $M$. This problem is a particular instance of the 0-1 unidimensional knapsack problem. All of the usual algorithms for this problem are investigated both in terms of asymptotic computing times and storage requirements, as well as average computing times. We develop a technique which improves all of the dynamic programming methods by a square root factor. Using this improvement a variety of new heuristics and improved data structures are incorporated for decreasing the average behavior of these methods. The resulting algorithms are then compared on a wide set of data. It is then shown how these improvements can be applied to various versions of the knapsack problem.  Key words and Phrases: partitions, knapsack problem, dynamic programmiing, integer optimization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5990,Program Schemata and Information Flow:  A Study of Some        Aspects of the Schema Power of Data Structures,"The concept of a program schema, which represents the skeleton of a computer program, is important for its potential and actual applicability to code optimization, to understanding the behavior of programs using various control and data structure features, and to developing a theory of information flow as related to program form and power. In this study tow storage devices, the tape and the queue, are considered, and their effect on the schema power hierarchy explored. The behavior and relative capability of each one of the various types of tapes and queues is discussed in the light of the ways in which information is allowed to move, according to the inherent characteristics of the devices. Main results include the facts that addition of a single tape unit to the simplest schema class P gives no additional power, and that the basic cyclic nature of queues and the persistence of data on tapes are important power determinants.  An attempt is made to bridge the gap between schema theory and actual programs not only by studying models of actual storage units but also by allowing an arbitrarily long (but finite) input stream. Such an extension generally upsets the onion-like power inclusions of the finite input hierarchy because of the calculations possible on the implicitly-input arbitrary integer, which is the number of inout values. The information flow characteristics of the data structures associated with a particular schema class may allow such an arbitrary input to be viewed exactly once, exactly twice, or in general m times, and such distinctions give rise to differences in computational power.  Requirements insuring that the interconnection of schemata form a schema with the union of the capabilities of the subschemata are considered. The hierarchy of schemata without the identity assignment is also studied, and it is demonstrated that in the simplest class $P$ and the universal class $P_{Ae}$ no loss of power results from prohibiting identity assignments. Discussion of the as-yet-unsolved problem of the power of the class $P_{(2b,0)}$ and its associated derivatives is presented. A summary of prospects for developing program schema research in several different potentially practical directions concludes the work.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5991,Decidable Pairing Functions,"In Chapter I of this paper we show that the usual, textbook pairing functions have decidable first-order theories. This will be done by exhibiting an infinite axiomatization of certain pairing functions which we characterize as ``acyclic except for $\triangle$''. This condition is satisfied by the usual pairing functions. We then use a technique of Ehrenfeucht and Fraisse to show that the decision problem for such a pairing function is effectively reduced to the decision problem for the function restricted to $\triangle$.  In contrast to the decidability of the first-order theories of certain pairing functions, we show that the weak second-order and monadic second-order theories of these pairing functions are undecidable.  In Chapter II we show how to extend the first-order Ehrenfeucht game to a second-order game. Using this extended game, we show that the monadic second-order theory of an equivalence relation is decidable.  Some of the results of Chapter I were announced in [16].",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5992,"The ""Almost All"" Theory of Subrecursive Degrees is Decidable","We use constructive measure theory to show the decidability pf the ""almost all"" theory of subrecursive degrees. The formulas of this theory are built up using the constant 0 standing for the minimum degree, the functions $\cup,\cap$ standing for the join and meet of two degrees respectively, the relation $\leq$ standing for the reducibility-ordering, the logical connectives ""ampersand"", $\neg$ and the quantifier (almost $\forall$ a). An efficient decision procedure is described.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5993,Proposals for a Dynamic Library,"The current library environment is first examined, and an attempt is made to explain why the standard approaches to the library problem have been less productive than had been anticipated. A new design is then introduced for modern library operations based on a two-fold strategy: on the input side, the widest possible utilization should be made of cooperative and shared operations, whereas dynamic, user-controlled procedures should be used for the subsequent internal processes. The dynamic environment applies in particular to the maintenance of the indexing vocabulary, the organization of the stored information files, the performance of search and retrieval operations, and the control of the library collection necessitated by document growth and retirement. Some experimental results are included as an illustration for the proposed dynamic operations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5996,Final Report on NSF Research Grant Automata and Computational        Complexity 1968-1972,"This report summarizes the results obtained in research supported by the National Science Foundation Grant AUTOMATA AND COMPUTATIONAL COMPLEXITY. The report lists the problem areas considered, the publications resulting from this work and gives an outline of the more recent research results which have not yet been published.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5997,On the Computation of Powers of a Class of Polynomials,"A general class of polynomials is defined which includes as subcases sparse and dense polynomials. For any polynomial $P$ within this class a host of algorithms are analyzed for computing $P^{n}$. While the Homomorphism algorithm is superior on dense polynomials it is shown that for sufficiently sparse polynomials, iteration is more efficient. A simple rule that takes linear time is given for deciding when it is advisable to use either one of these algorithms.  Keywords: Polynomial Powers, sparse polynomials, modular algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5998,Partial Pivoting Strategies for Symmetric Matrices,"Partial pivoting strategies for the decomposition of symmetric matrices are discussed for solving symmetric (indefinite) systems of linear equations and for calculating the signature of symmetric matrices, in both the full and the sparse band cases.  Keywords: diagonal pivoting, symmetric, indefinite, linear equations,  signature, sparse, band.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/5999,Duality Applied to the Complexity of Matrix Multiplication and Other Bilinear Forms,The paper considers the complexity of bilinear forms in a noncommutative ring. The dual of a computation is defined and applied to matrix multiplication and other bilinear forms. It is shown that the dual of an optimal computation gives an optimal computation for a dual problem. An nxm by mxp matrix product is shown to be the dual of an nxp by pxm or an mxn by nxp matrix product implyiing that each of the matrix products requires the same number of multiplications to compute. Finally an algorithm for computing a single bilinear form over a noncommutaative ring with a minimum number of multiplications is derived by considering a dual problem.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6000,"Partitioning, Tearing, and Modification of Sparse Linear Systems","The computational complexity of partitioning sparse matrices is developed graph-theoretically. The results are used to study tearing and modification, and to show that single-element tearing of symmetric systems is rarely advantageous when the torn system is solved by elimination.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6001,Single-Element Tearing and Modification of Sparse Symmetric Systems,"Tearing and modification obtains the ssolution of a linear system synthetically by first solving a slightly different (""torn"") system and then modifying that solution. We show that single-element tearing of symmetric systems is rarely advantageous when the modified system is solved by elimination, and we classify those systems for which it is advantageous.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6002,Describing an Algorithm by Hopcroft,"We give an algorithm, its correctness proof, and its proof of execution time bound, for finding the sets of equivalent states in a deterministic finite state automaton. The time bound is $K\cdotm\cdot\n\cdot\\log n$ where $K$ is a constant, $m$ the number of input symbols, and $n$ the number of states. Hopcroft [3] has already published such an algorithm. The main reason for this paper is to illustrate the use of communicating an algorithm to others using a structured, top-down approach. We have also been able to improve on Hopcroft's algorithm by reducing the size of the algorithm and correspondingly complicating the proof of the running time bound.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6003,Triangular Factorization and Inversion by Fast Matrix Multiplication,"The fast matrix multiplication algorithm by Strassen is used to obtain the triangular factorization of a permutation of any non-singular matrix of order n in ""greater than"" C sub{1}n sup{log sub{2}7} operations, and hence the inverse of any non-singular matrix in ""greater than"" C sub{2}n sup{log sub{2}7} operations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6005,Experiments in Multi-Lingual Information Retrieval,A comparison was made of the performance in an automatic information retrieval environment of user queries and document abstracts available in natural language form in both English and French. The results obtained indicate that the automatic indexing and retrieval techniques actually used appear equally effective in handling the query and document texts in both languages.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6006,On the Power of Arrays In Universal Languages,"A language with arrays but with no conditional statement is shown to be universal under ""simulation"", a relation on programs frequently encountered in the practical computing world. Any r.e. set can be enumerated by a program (in this language) whose flow chart is a single loop which contains no alternate execution paths normally thought necessary for computation in general. A related result is shown for any general program, thus characterizing selection in arrays as at least as powerful as conditional branching in programs. These results are related to important results in schemata.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6007,"On the Time and Tape Complexity of Languages, I",We investigate the relationship between the classes of languages accepted by deterministic and nondeterministic polynomial time bounded Turing machines and the relationship between the classes of languages accepted by deterministic polynomial time bounded and by nondeterministic polynomial tape bounded Turing machines. In both cases we study generators of the nondeterministic class that generate it by operations that the deterministic class is closed under.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6008,Testing Flow Graph Reducibility,"Many problems in program optimizationn have been solved by applying a technique called interval analysis to the flow graph of the program. A flow graph which is susceptible to this type of analysis is called reducible. This paper describes an algorithm for testing whether a flow graph is reducible. The algorithm uses depth-first search to reveal the structure of the flow graph and a good method for computing disjoint set unions to determine reducibility from the search information. When the algorithm is implemented on a random access computer, it requires $O(E \log^{*} E)$ time to analyze a graph with E edges, where $log^{*} x=\min\{i|\log^{i}x \leq 1\}$. The time bound compares favorably with the $O(E \log E)$ bound of a previously known algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6009,On the Substitution of Polynomial Forms,"The problem of devising efficient algorithms for computing $Q(x_{1},\ldots,x_{r-1},P(x_{1},\ldots,x_{r-1}))$ where $P$ and $Q$ are multivariate polynomials is considered. It is shown that for polynomials which are completely dense an algorithm based upon evaluation and interpolation is more efficient than Horner's method. Then various characterizations for sparse polynomials are made and the subsequent methods are re-analyzed. In conclusion, a test is devised which takes only linear time to compute and by which a decision can automatically be made concerning whether to use a substitution algorithm which exploits sparsity or one which assumes relatively dense inputs. This choice yields the method which takes the fewest arithmetic operations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6010,The Equivalence Problem for Regular Expressions with        Intersection is Not Polynomial in Tape,"We investigate the complexity of several predicates on regular sets. In  particular, we show:  1) the equivalence and emptiness problem for regular expressions using only the operators -, $\cup$, ., and $\cap$ are p-complete.  2) the emptiness problem for regular expressions using the operators -, $\cup$, ., $\cap$ and * is tape-hard;  3) the emptiness problem for regular expressions using the operators -, $\cup$, ., $\cap$ and 2 is tape-hard;  4) the equivalence problem for regular expressions using the operators  -, $\cup$, ., $\cap$ and * is not polynomial in tape; and   5) the equivalence problem for regular expressions using the operators  -, $\cup$, ., $\cap$ and 2 requires exponential time.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6011,Efficient Planarity Testing,"This paper describes an efficient algorithm to determine whether an arbitrary graph G can be embedded in the plane. The algorithm may be viewed as an iterative version of a method originally proposed by Auslander and Parter and correctly formulated by Goldstein. The algorithm uses depth-first search and has O(V) time and space bounds, where V is the number of vertices in G. An Algol implementation of the algorithm successfully tested graphs with as many as 900 vertices in less than 12 seconds.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6012,Complexity of Sparse Elimination,"This paper surveys some of the recent research on the applications of the algebraic and combinatorial properties of Gaussian elimination on sparse matrices.  Keywords: sparse matrix, Gaussian elimination, graph theory, computational complexity, triangulation, optimal ordering, optimum ordering, grid graph, band matrix.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6013,Communication Within Structured Operating Systems,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6014,Generalized Bottom-Up Parsing,"In this thesis we present a decision procedure for testing the correctness of a broad class of bottom-up parsing machines. Motivated by the work of Colmerauer and Williams, we allow our parsers to find any simple phrase (not necessarily the leftmost) in the input string. Such a parser can be implemented on an automaton using two puchdown stores and can in fact produce a complete parse for an input string in linear time with respect to the length of the input. Certain restrictions are necessary in order for the method to work, but nevertheless it is sufficiently general to handle most existing classes of parsers. Moreover, the adjustment of certain parameters to this decision procedure gives rise in a natural way to such classes of grammars as the LR(k) class of Knuth, the BRC class of Floyd and the BCP class of Williams. Further adjustment of these parameters suggests other, more general, classes of parsable grammars which we investigate here for the first time. Among these new classes of grammars is one first suggested by Knuth and given the name LR(k,t). This class is a generalization of the LR(k) method and intuitively is that class of grammar for which it is possible, in any sentential form, to find one of the t leftmost simple phrases given only that portion of the string to the left of the phrase and the first k characters to its right. We give an exact construction for parsers of this class and present the surprising fact that these grammars can be parsed using a deterministic pushdown automaton. We also investigate a class herein called $LR(k,\infty)$ in which we completely relax the condition that the selected phrase be in any certain location. This latter class, which represents the ultimate left to right bottom-up parser, is shown to be too general to have ""nice"" decidability properties. A final class of grammars investigated is designated FPFAP(k), that is, the class of grammars which are parsable in a left to right fashion by a finite state automaton using k characters of lookahead. This class is shown to lie strictly between the LR(k,t) and $LR(k,\infty)$ classes. We conclude by demonstrating the relationship between these and other classes of grammars, not only from the point of view of the grammars themselves, but also with regard to the classes of languages induced by the grammars.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6015,The LBA Problem and its Importance in the Theory of Computing,"In this paper we study the classic problem of determining whether the deterministic and non-deterministic context-sensitive languages are the same or, equivalently, whether the languages accepted by deterministic and non-deterministic linearly bounded automata are the same. We show that this problem is equivalent to several other natural problems in the theory of computing and that the techniques used on the LDA problem have several other applications in complexity theory. For example, we show that there exists a hardest-tape recognizable non-deterministic context-sensitive language $L_{1}$, such that $L_{1}$ is a deterministic context-sensitive language if and only if the deterministic and non-deterministic context-sensitive languages are the same. We show furthermore, that many decision problems about sets described by regular expressions are instances of these tape-hardest recognizable context-sensitive languages. Thus, it follows that non-determinism in Turing machine computations (using at least linear tape) can not save memory over deterministic Turing machine computations if and only if the equivalence of regular expressions can be decided by a deterministic linearly bounded automaton. It also follows that the equivalence of regular expressions can be decided by a non-deterministic linearly bounded automaton if and only if the family of context-sensitive languages is closed under complementation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6016,On the Specification of Term Values in Automatic Indexing,"The existing practice in automatic indexing is reviewed, and it is shown that the standard theories for the specification of term values (or weights) are not adequate. New techniques are introduced for the assignment of weights to index terms, based on the characteristics of individual document collections. The effectiveness of some of the proposed methods is evaluated.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6017,Classes of Functions and Feasibility Conditions in Nonlinear        Complimentarity Problems,"Given a mapping $F$ from real Euclidean n-space into itself, we investigate the connection between various known classes of functions and the nonlinear complementarity problem: Find and $x^{*} \geq 0$ such that $ F x^{*} \geq 0$ and is orthogonal to $x^{*}$. In particular, we study the extent to which the existence of a $u \geq 0$ with $F $u \geq 0$ (feasible point) implies the existence of a solution to the nonlinear complementarity problem, and extend, to nonlinear mappings, known results in the linear complementarity problem on P-matrices, diagonally dominant matrices with nonnegative diagonal elements, matrices with off-diagonal non-positive entries, and positive semidefinite matrices.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6018,On the Problem of Finding Natural Computational Complexity Measures,"To develop an abstract theory which deals with the quantitative aspects of computing we need a deeper understanding of how to define ""natural"" computational complexity measures axiomatically. To this end, this paper summarizess the principal properties which hold for some natural complexity measures but not for all measures and which have been proposed as desirable properties of natural measuress. The paper discusses the nature of these properties, studies their interrelations and their possible values towards defining natural computational complexity measures. A number off open problems are discussed and directions for further research are suggested.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6019,Gaussian Elimination with Pivoting is Optimal,"V. Strassen discovered that two matrices of order 2 could be multiplied using 7 multiplications and 18 additions of numberss and has shown that two matrices of order n could be multiplied in less than $4 \cdot 7 n^{\log_{2}7}$ operations, an operation being defined as a multiplication, division, subtraction or addition. Also he has shown that the classical Gaussian elimination is not optimal by giving an algorithm to compute the inverse of a nonsingular matrix with certain principal submatrices nonsingular in less than $5 \cdot 64 n^{\log_{2}7}$ operations. In other words, Strassen's algorithm provides no room for pivoting. J. Bunch and J. Hopcroft have got rid of the above anomaly and have shown how to obtain the triangular factorization of a permutation of a nonsingular matrix in less than $2 \cdot 44 n^{\log_{2}7}$ operations and the inverse in less than$6 \cdot 83 n^{\log_{2}7}$ operations. In this thesis it is shown, using the results of Strassen and Bunch and Hopcroft, that Gaussian elimination with pivoting is optimal in the sense that the bound for the number of operations required to do Gaussian elimination is the least for ""sufficiently large"" systems of equations. Also expressions are derived for the various coefficients in the bounds for the various procedures that arise in solving linear systems of equations with the general assumption that two matrices of order u could be multiplied in p multiplications and q additions of numbers.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6021,Price Scheduling in a Time-Sharing Queueing System,"This thesis deals with a time-sharing system in which users may join after paying an appropriate toll and are subjected to service and waiting charges. The form of an optimal joining policy that minimizes the expected loss of users who may join the system at some of its queues is derived, and is shown to be a control-limit policy with a single control number for every possible entry queue; a newly arriving user will join the minimal-priority entry queue that is not filled up to its contrl number. Tolls and charges that maximize the average expected revenue of the system, as well as the control numbers, are determined for a round-robin time-sharing system. A multi-entrance foreground-background time-sharing system with random entrance is analyzed and the characteristics of the system, such as expected waiting times and expected number of waiting users in each queue, are given. It is shown that when the entry into this system is based on tolls and charges, there exists a set of prices (and associated control numbers) that maximizes the discounted expected revenues of the system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6022,On Simple Goedel Numberings and Translations,In this paper we consider Goedel numberings (viewed as simple models for programming languages) into which all other Goedel numberings can be translated very easily. Several such classes of Goedel numberings are defined and their properties are investigated. We also compare these classes of Goedel numberings to optimal Goedel numberings and show that translation into optimal Goedel numberings can be computationally arbitrarily complex.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6023,On Computing the Determinant of Matrices with Polynomial Entries,"We consider the problem of computing the determinant of a matrix of polynomials. Four algorithms are compared: expansion by minors, Gaussian elimination over the integers, a method based on evaluation and interpolation, and a procedure which computes the characteristic polynomial of the matrix. Each method is analyzed with respect to its computing time and storage requirements using several models for polynomial growth. The results show which method is preferable for a given computational model. In addition to these asymptotic results, the analysis is exactly done for certain especially small, yet practical and important cases. Key Words: determinants, matrix of polynomials, Gaussian elimination, expansion by minors, characteristic polynomial.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6024,Theory of Indexing and Classification,"Given a written text in natural language, it is convenient to represent the information content of the text by one or more entities, variously known as concepts, keywords, or terms. It is desired to choose ""good"" terms which collectively reflect the information content as accurately as possible. A characterization is given of discriminating (good) and non-discriminating (bad) terms, based on the document frequencies of occurrence and the distribution of frequencies of the terms in the documents (texts) of a given document collection. Based on this characterization, reasons are presented for the success and/or the failure of some well-known indexing methods, namely thesaurus construction, ""weighting"" of the rare terms, and the deletion of non-discriminating terms. A method, which converts non-discriminating terms to discriminating terms is described. Experiments are performed to show that the new method is of practical use. In order to improve the content analysis (indexing) further, term classes are constructed using a process known as pseudoclassification. It is shown that the to construct term classes through discriminating terms. Experiments using the new method are performed on two document collections in medicine and aerodynamics. For both collections, the new method yields substantial improvements over the method of the deletion of non-discriminating terms. In Chapter III, the idea of a term class is formalized and generalized. Techniques from the theory of algorithms are used to examine the computational complexity of certain useful methods for the automatic construction of term classes. It is shown that any algorithm which maximizes the number of relevant documents that are retrieved (recall) and the number of irrelevant documents that are rejected (precision) under some pre-assigned term classes is polynomial complete (likely to take exponential amount of computer time). Four heuristic methods which decrease the computaational time for the automatic construction of term classes using a ""pseudo-classification"" process are presented. Experiments with these methods and their variations produce surprisingly good results. Chapter IV deals with the clustering of documents. A new clustering method which makes use of the query formulations previously processed by the system is presented. The proposed method clusters the requests in the form of a tree. From that tree, a corresponding tree of documents is constructed. The resulting clusters have the following useful properties. (1) The clusters are independent of the order in which the documents are processed. (2) Overlapping of clusters is allowed in that documents may appear in more than one class or cluster (3) Not all the documents need to be clustered. The new clustering method is then compared with other automatic classification procedures, namely the Single-Link Method, Dattola's Method, Rocchio's Method and Bonner's Method with repect to systems effectiveness, systems efficiency, and computer time required for clustering. Both theoretical and experimental results seem to indicate that the new method is superior to the olded methods. Chapter V summarizes the resultss obtained in this thesis and indicates  possible future research areas. Many of the more tedious or difficult proofs in different parts of the thesis  are included in Appendices I, II, and III.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6025,On the Time and Tape Complexity of Languages,"We investigate the following: (1) the relationship between the classes of languages accepted by  deterministic and nondeterministic polynomial time bounded Turing machines; (2) the relationship between the classes of languages accepted by  deterministic and nondeterministic linear bounded automata; (3) sufficient conditions for undecidability of linguistic predicates; and  (4) the time and space complexity of several predicates on the regular sets. We show that the set $\{ R | R$ is a $(\cup, ^{.}, *, \caap)$ regular expression and $L(R) = \{0,1\}*\}$ is not recognizable by any polynomial space bounded Turing machine. We also find conditions which guarantee that any predicate on the regular sets satisfying them is as hard to decide as emptiness or equivalence.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6026,Analysis of Sparse Elimination,An error analysis is presented for Gaussian elimination when the matrix is arbitrarily sparse. Error analyses for elimination on band matrices and full matrices follow as special cases.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6027,An Algorithm for Determining Whether the Connectivity of a Graph is at Least k,"The algorithm presented in this paper is for testing whether the connectivity of a large graph of $n$ vertices is at least $k$. First the case of undirected graphs is discussed, and then it is shown that a variation of this algorithm works for directed graphs. The number of steps the algorithm requires, in case $k less than \sqrt{n}$, is bounded by $O(kn^{3})$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6028,Computational Complexity and Nondeterminism in Flowchart Programs,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6029,A Constructive Theory of Recursive Functions,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6030,On the Relation of Refinement Between Algorithms,"We define a class of tree schemata and a notion of refinement between trees (finite or infinite). These concepts allow us to talk about different ""ways to program an algorithm"" and the ""structure"" of an algorithm. We obtain as a special case certain concepts such as ""approximation"", ""convergence"" and ""fixed point semantics"" recently employed by Scott to describe the semantics of flow diagrams. We concentrate in this paper on relating our concepts to Scott's.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6031,Contribution to the Theory of Indexing,"An attempt is made to characterize the usefulness of terms occurring in stored documents and user queries as a function of their frequency characteristics across the documents of a collection. It is found that the best terms are those having medium frequency in the collection and skewed frequency distributions. Correspondingly, terms exhibiting either very high or very low document frequency are not as useful. To improve the indexing vocabulary, it becomes necessary to group low frequency terms into classes, and to break up high frequency terms by forming phrases. An indexing theory is described based on term frequency considerations, and a new phrase generation method is introduced. The resulting improvements in the indexing vocabulary are evaluated.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6032,Functional Schemas with Nested Predicates,"A class of (monadic) functional schemas with nested predicates is defined. It is shown that termination, divergence and freedom problems for these schemas are decidable. It is proved that when the schemas are more general the freedom problem is undecidable. A procedure is given for deleting the identity function from the schema's definition at the cost of increasing $k$ by 1 when $k$ is the maximum depth of nesting.  Part of our results extend results of [1] about schemas without nesting. Our algorithm for checking freedom is not a natural extension of theirs. Furthermore, using our algorithm for schemas without nesting yields a much more efficient way of deciding freedom than the algorithm suggested in [1].  Keywords and Phrases: monadic functional schemas, nested predicates, decision problems, equivalence, freedom, polynomial time, DPDA.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6033,On Scolnik's Proposed Polynomial-Time Linear Programming Algorithm,"At a recent symposium, Hugo Sccolnik expressed some ideas leading to an algorithm which he thought might solve the linear programming problem in polynomial time. We examine the algorithm and find that it often fails to solve the linear programming problem, even in the special cases considered by Scolnik. We conclude that the algorithm probably cannot be modified to work properly.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6034,Computational Complexity of Formal Translations,"The purpose of this paper is to define a mathematical model for the study of quantitative problems about translations between universal languages and to investigate such problems. The results derived in this paper deal with the efficiency of the translated algorithms, the optimality of translations and the complexity of the translation process between different languages. Keywords: universal languages, Goedel numberings, translations, complexity  of translations, optimality, length of translated programs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6035,Polynomial Complete Consecutive Information Retrieval Problems,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6036,On the Computational Complexity of Program Schemata,"An ordering called ""faster"" is defined on the class of iterative program  schemata. It is in good accordance with the intuition of ""better"" applied  to program schemata. Many of the commonly used optimization techniques yield  ""faster"" programs in this sense. For Ianov schemata the relation ""faster""  is decidable, but even on strong equivalence classes the ordering may be very  complicated. For iterative program schemata there is a certain kind of  speedup. Whereas there is an arbitrary slowdown for programs, slowdown for  program schemata is limited.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6037,Dividing a Graph into Triconnected Components,"An algorithm for dividing a graph into triconnected components is presented.  When implemented on a random access computer, the algorithm requires  $O(V+E)$ time and space to analyze a graph with $V$ vertices and $E$ edges.  The algorithms is both theoretically optimal to within a constant factor and  efficient in practice. Keywords: articulation point, connectivity, depth-first search, graph,  separability, separation, triconnectivity.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6038,Polynomial and Abstract Subrecursive Classes,"We define polynomial time computable operator. Our definition generalizes  Cook's definition to arbitrary function inputs. Polynomial classes are defined  in terms of these operators; the properties of these classes are investigated.  Honest polynomial classes are generated by running time. They possess a  modified Ritchie-Cobham property. A polynomial class is a complexity class if  it is honest.  Starting from the observation that many results about subrecursive classes  hold for all reducibility relations (e.g. primitive recursive in, elementary  recursive in), which were studied so far, we define abstract subrecursive  reducibility relation. Many results hold for all abstract subrecursive  reducibilities.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6039,Partitions Generators,"Several algorithms for generating partitions of positive numbers are given.  First, an algorithm for generating all the partitions is given, then  algorithms for generating of all partitions in which all terms are smaller  than a given n, between n and m, and partitions of n to a given k. Each of the  algorithms produces the whole sequence in a time proportional to the length of  that sequence; moreover, each new partition is produced in no more than a  constant number of steps independent on the parameters of the algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6040,A Continuous Analogue Analysis of Nonlinear Iterative Methods,"This paper applies the asymptotic stability theory for ordinary differential  equations to Gavurin's continuous analogue of several well-known nonlinear  iterative methods. In particular, a general theory is developed which extends  the Ortega-Rheinboldt concept of consistency to include the widely used  finite difference approximations to the gradient as well as the finite  difference approximation to the Jacobian in Newton's method. The theory is  also shown to be applicable to the Levenberg-Marquardt methods.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6041,On the Computational Complexity of Scheme Equivalence,"We consider the computational complexity of several decidable problems about  program schemes and simple programming languages. In particular, we show that  the equivalence problem for Ianov schemes is NP-complete, but that the  equivalence problem for strongly free schemes, which approximate the class of  Ianov schemes which would actually be written, can be solved in time quadratic  in the size of the scheme.  We also show that many other simple scheme classes or simple restricted  programming languages have polynomially complete equivalence problems. Some  are complete for the same reason that Ianov schemes are complete and some are  complete for other reasons.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6042,A Note on Program Development,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6043,A Theory of Indexing,"THe content analysis, or indexing problem, is fundamental in information  storage and retrieval. Several automatic procedures are examined for the  assignment of significance values to the terms, or keywords, identifying the  documents of a collection. Good and bad index terms are characterized by  objective measures, leading to the conclusion that the best index terms are  those with medium document frequency and skewed frequency distributions.  A discrimination value model is introduced which makes it possible to  construct effective indexing vocabularies by using phrase and thesaurus  transformations to modify poor discriminators - those whose document frequency  is too high, or too low - into better discriminators, and hence more useful  index terms. Test results are included which illustrate the effectiveness of the theory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6044,Two Way Deterministic Pushdown Automaton Languages and Some        Open Problems in the Theory of Computation,"We consider some of the important unsolved problems in the theory of  computation concerning the relationship between deterministic and  nondeterministic computations, and between tape and time bounded computations.  For each such problem we find an equivalent problem concerning two way  deterministic pushdown automaton languages. This is the first time many of  the open problems have been reduced to questions about one class of automata.  Keywords and phrases: Two way deterministic pushdown automata, open problems,  determinism versus nondeterminism, space bounded computations, time bounded  computations, Turing machines, multihead pushdown automata, two way counter  machines, auxiliary pushdown machines.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6045,On the Power of Multiplication in Random Access Machines,"We consider random access machines with a multiplication operation, having the  added capability of computing logical operations on bit vectors in parallel.  The contents of a register are considered both as an integer and as a vector  of bits and both arithmetic and boolean operations may be used on the same  register. We prove that, counting one operation as a unit of time and  considering the machines as acceptors, deterministic and nondeterministic  polynomial time acceptable languages are the same, and are exactly the  languages recognizable in polynomial tape by a Turing machine. We observe  that the same measure on machines without multiplication is polynomially  related to Turing machine time - thus the power of multiplication on this  model characterizes the difference between Turing machine tape and time  measures. We discuss other instruction sets and their power.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6046,Programming Language Semantics Using Extensional         $\lambda$-Calculus Models,"We prove a theorem which provides an intuitive understanding of the meaning of  $\lambda$-terms in Scott's extensional $\lambda$-calculus models. This allows  us to use those models for the definition of high-level programming languages.  In order to illustrate this we define a programming language which includes  blocks and (arbitrary recursive) procedures. Two aspects justify this  approach. First of all, the logical properties of those (typeless)  $\lambda$-calculus models are appealing for a formalization similar to LCF  [6] which formalizes typed $\lambda$-calculus models. Secondly, not having  the type restrictions that LCF imposes allows us to define the semantics of  high-level programming languages in the spirit of ""mathematical semantics""  [12] (which is usually based on recursively defined domains), thus the  semantic nature of syntactic constructs can be exhibited clearly.  Keywords: Mathematical semantics, Programming Languages, $\lambda$-calculus  Models, typed, typeless, extensional, Logic, LCF.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6047,More Remarks on Scolnik's Approach to Linear Programming,"This report briefly discusses certain points in Hugo Scolnik's letter (Spring  1974) to the SIGMAP membership, then examines whether superfluous constraints  are responsible for the difficulties in Scolnik's approach to linear  programming, and finally discusses possible starting heuristics, based on  Scolnik's approach, for the simplex algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6048,A Theory of Term Importance in Automatic Text Analysis,"Most existing automatic content analysis and indexing techniques are based on  word frequency characteristics applied largely in an ad hoc manner.  Contradictory requirements arise in this connection, in that terms exhibiting  high occurence frequencies in individual documents are often useful for high  recall performance (to retrieve many relevant items), whereas terms with low  frequency in the whole collection are useful for high precision (to reject  nonrelevant items).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6049,Computability on Continuous Higher Types and its Role in the Semantics of Programming Languages,This paper is about mathematical problems in programming language semantics and their influence on recursive function theory. In the process if constructing computable Scott models of the lambda calculus we examine the concepts of deterministic and non-deterministic effective operators of all finite types and continuous deterministic and non-deterministic partial computable operators on continuous inputs of all finite types. These are new recursion theoretic concepts which are appropriate to semantics and were inspired in part by Scott's work on continuity.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6050,On the Structure of Feasible Computations,"During the last four years research on the lower level computational complexity has yielded a rich set of interesting results which have revealed deep and unexpected connections between various problems and thus brought new unity to this area of computer science. This work has also yielded new techniques and insights which are likely to have further applications, and it has identified some very central problems in the quantitative theory of computing. The purpose of this paper is to give the reader an overview of these developments, an insight into some of these results and applications, as well as an appreciation of the unity and structure which has emerged in this area of research.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6051,Potential Capabilities in Algol-Like Programs,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6052,Program Predictability and Data Security,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6053,On the Power of Multiplication in Random Access Machines,"We consider random access machines with a multiplication operation, having the added capability of computing logical operations on bit vectors in parallel. The contents of a register are considered both as an integer and as a vector of bits and both arithmetic and boolean operations may be used on the same register. We prove that, counting one operation as a unit of time and considering the machines as acceptors, deterministic and non-deterministic polynomial time acceptable languages are the same, and are exactly the languages recognizable in polynomial tape by Turing machines. We observe that the same measure on machines without multiplication is polynomially related to Turing machine time - thus the added computational power due to multiplication in random access machines is equivalent to the computaitonal power which polynomially tape-bounded Turing machine computations have over polynomially time-bounded computations. Therefore, in this formulation, it is not harder to multiply than to add if and only if PTAPE=PTIME for Turing machines. We also discuss other instruction sets for random access machines and their computational power.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6054,COPS - A Mechanism for Computer Protection,"A computer protection mechanism is a set of tools for controlling the actions of computations and safeguarding stored information. This paper describes a new mechanism, COPS, which is a kernel of data structures, primitive operations, and a monitor and is used to specify and enforce the capabilities of actors (processes and procedures). COPS can be used to implement a variety of security policies and systems and to enhance software reliability. Its tools are sufficient to solve problems in the areas of isolation, controlled sharing, restricted access, mutually suspicious interaction, and confinement.  Key Words and phrases: protection, kernel, operating system, security, access  control.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6055,On the Global Convergence of Broyden's Method,"We consider Broyden's 1965 method for solving nonlinear equations. If the mapping is linear, then a simple modification of this method guarantees global and Q-superlinear convergence. For nonlinear mappings it is shown that the hybrid strategy for nonlinear equations due to Powell leads to R-superlinear convergence provided the search directions from a uniformly linearly indepenent sequence. We then explore this last concept and its connection with Broyden's method. Finally, we point out how the above results extend to Powell's symmetric version of Broyden's method.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6056,"Quasi-Newton Methods, Motivation and Theory","This paper is an attempt to motivate and justify quasi-Newton methods as useful modifications of Newton's method for general and gradient nonlinear systems of equations. References are given to ample numerical justification; here we give an overview of many of the important theoretical results and each is accompanied by sufficient discussion to make the results and hence the methods plausible. Key Words and Phrases: unconstrained minimization, nonlinear simultaneous  equations, update methods, quasi-Newton methods.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6057,A Vector Space Model for Automatic Indexing,"In a document retieval, or other pattern matching environment where stored entities (documents) are compared with each other, or with incoming patterns (search requests), it appears that the best indexing (property) space is one where each entity lies as far away from the others as possible; that is, retrieval performance correlates inversely with space density. This result is used to choose an optimum indexing vocabulary for a collection of documents. Typical evaluation results are shown demonstrating the usefulness of the model.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6058,"Modes, Values and Expressions",NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6059,A Class of Derivative-Free Algorithms for Unconstrained Minimization,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6060,An O(nloglogn) On-line Algorithm for the Insert-Exact Min Problem,"Integers within the range 1,...,n are inserted in a set, and on several occasions the minimal element is extracted from the set. We present an algorithm to executee a sequence of O(n) of these instrucitions on-line in time O(nloglogn) on a Random Access Machine. The instruction repertoire can be extended by instructions like allmin(i) (delete all elements not greater than i), extract max, or predecessor (i) (find the largest element less than i), without disturbing the O(loglogn) processing time per item.  Whereas the off-line insert-extract min problem is known to be reducible to the on-line union-find problem, we prove that the off-line insert-allmin problem is equivalent to the off-line union-find problem, hence the off-line problems have faster algorithms.  As an application we show that our algorithm can be used to process a sequence of O(n) instructions of the types: ""split an interval"", ""unite two adjacent intervals"", and ""find the interval currently containing element j"", on-line in time O(nloglogn).  Keywords: set-manipulation, Analysis of Algorithms, binary tree.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6061,2.25 N-Lower Bound on the Combinational Complexity of Boolean Functions,"Consider the combinational complexity L(f) of Boolean functions over the basis $\Omega = \{f|f:\{0,1\}^{2} \rightarrow \{0,1\}\}$. A new Method for proving linear lower bounds of size 2n is presented. Combining it with methods presented in [7] and [9], we establish for a special set of functions $f^{n}:\{0,1\} : 2.25n \leq L(f) \leq 6n$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6062,On the Complexity of Resolution Procedures for Theorem Proving,We study several procedures for theorem proving based on the resolution principle. We consider (1) Davis Putnam procedure; (2) regular resolution; (3) unrestricted resolution; (4) resolution with extension; and (5) several versions of bounded resolution. The powers of these procedures are compared. Exponential lower bounds are proved for the run-time of some of them.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6063,Independence Results in Computer Science,"In this note we show that instances of problems which appear naturally in  computer science cannot be answered in formalized set theory. We show, for  example, that some relativized versions of the famous P = NP problem cannot be  answered in formalized set theory, that explicit algorithms can be given  whose running time is independent of the axioms of set theory, and that one  can exhibit a specific context-free grammar G for which it cannot be proven in  set theory that $L(G) = \sum^{\*}$ or $L(G) \neq \sum^{\*}$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6064,Equational Propositional Logic,"We formalize equational propositional logic, prove that it is sound and complete, and compare the equational-proof style with the more traditional Hilbert style.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6065,Low-Latency Communication over ATM Networks using Active Messages,"Recent developments in communication architectures for parallel machines have made significant progress and reduced the communication overheads and latencies by over an order of magnitude as compared to earlier proposals. This paper examines whether these techniques can carry over to clusters of workstations connected by an ATM network even though clusters use standard operating system software, are equipped with network interfaces optimized for stream communication, do not allow direct protected user-level access to the network, and use networks without reliable transmission or flow control. In a first part, this paper describes the differences in communication characteristics between clusters of workstations built from standard hardware and software components and state-of-the-art multiprocessors. The lack of flow control and of operating system coordination affects the communication layer design significantly and requires larger buffers at each end than on multiprocessors. A second part evaluates a prototype implementation of the low-latency Active Messages communication model on a Sun workstation cluster interconnected by an ATM network. Measurements show application-to-application latencies of about 20 microseconds for small messages which is roughly comparable to the Active Messages implementation on the Thinking Machines CM-5 multiprocessor.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6066,Optimal Message Logging Protocols \\ (Preliminary Version),"Message logging protocols are an integral part of a technique for implementing processes that can recover from crash failures. All message logging protocols require that the state of a recovered process be consistent with the states of the other processes. This consistency requirement is usually expressed in terms of {\em orphan processes\/}, surviving processes whose states are inconsistent with the recovered state of a crashed process. Orphans are either avoided through careful logging or are eliminated through a somewhat complex recovery protocol.  We give a specification of the consistency property ""no orphan processes"". From this specification, we describe how different existing classes of message logging protocols (namely {\em optimistic}, {\em pessimistic}, and a class that we call {\em causal}) implement this property. We then propose a set of metrics to evaluate the performance of message logging protocols, and characterize the protocols that are {\em optimal} with respect to these metrics. We give several examples of optimal message logging protocols that can tolerate $f$ overlapping failures and recoveries for a parameter $f: 1 \le f \le n$, and discuss the tradeoffs that arise in the implementation of these protocols.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6068,Proving Safety Properties of Hybrid Systems,"We propose a methodology for the specification, verification, and design of hybrid systems. The methodology consists of the computational model of Concrete Phase Transition Systems, the specification language  of Hybrid Temporal Logic (HTL), the graphical system description language of Hybrid Automata, and a proof system for verifying that hybrid automata satisfy their HTL specifications.     The novelty of the approach lies in the continuous-time logic, which allows specification of both point-based and interval-based properties (i.e., properties which describe changes over an interval)  and provides direct references to derivatives of variables, and in the proof system that supports verification of point-based and interval-based properties. The proof rules demonstrate that sound and convenient induction rules can be established for continuous-time logics. The proof rules are illustrated on several examples.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6069,Aspects of the Computational Content of Proofs,"In this thesis, we explore three aspects of the computational content of proofs.  These are: a computational interpretation of the metatheory of intuitionistic propositional logic, an extension of this approach to intuitionistic predicate logic, and a computational interpretation of classical sequent proofs. We begin with a study of the computational aspects of validity, provability, and completeness for intuitionistic propositional logic.  We give a constructive proof of completeness of Kripke models for intuitionistic propositional calculus, such that the computational content of the proof is a form of the tableau algorithm.  Since the evidence for provability we construct is actually a term in typed $\lambda$-calculus, we can interpret this result as a formal relationship between Kripke semantics and realizability semantics.  We also show how a formal proof of the completeness theorem in Nuprl could be used to add the tableau decision procedure for provability to Nuprl's collection of proof techniques via reflection.  We then explore how these results could be generalized to the metatheory of intuitionistic predicate logic.  To do this, we develop some machinery for representing infinite Kripke models in type theory using co-inductive types.  Although provability in intuitionistic predicate logic is undecidable, we can still prove a constructive theorem in the metatheory which has computational content.  We also show that using classical logic in part of the proof does not destroy the computational content of the proof.  Finally, we examine the computational aspects of classical sequent proofs.  We show how the interpretation of nonlocal control operators as the computational content of classical axioms allows us to prove a completeness result for intuitionistic predicate logic with a depth-first-search tableau procedure as the computational content of the proof. Using the nonlocal control operator \cc\ as the the computational interpretation of the classical axiom we define a method for extracting programs from classical sequent proofs in propositional logic.  We give a proof-theoretic account of continuations and their behaviour in this context, and prove a number of properties of the extraction.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6070,Preserving Privacy in a Network of Mobile Computers,"Even as wireless networks create the potential for access to information from mobile platforms, they pose a problem for privacy. In order to retrieve messages, users must periodically poll the network. The information that the user must give to the network could potentially be used to track that user. However, the movements of the user can also be used to hide the user's location if the protocols for sending and retrieving messages are carefully designed. In this paper we will describe a set of protocols that we have developed to allow a user with a mobile computer to communicate without compromising privacy.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6071,On Global Convergence of A Trust Region and Affine Scaling Methodfor Nonlinearly Constrained Minimization,"A nonlinearly constrained optimization problem can be solved by the exact penalty approach involving nondifferentiable functions $\sum_{i} |c_i(x)|$ and $\sum_{i}\max(0,c_i(x))$. In \cite{Li94a}, a trust region affine scaling approach based on a 2-norm subproblem is proposed for solving a nonlinear $l_1$ problem. The (quadratic) approximation and the trust region subproblem are defined using affine scaling techniques. Explicit sufficient decrease conditions are proposed to obtain a limit point satisfying complementarity, dual feasibility, and second order optimality. In this paper, we present the global convergence properties of this new approach.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6072,A Trust Region and Affine Scaling Method for Nonlinearly ConstrainedMinimization,"A nonlinearly constrained minimization problem can be solved by the exact penalty approach involving nondifferentiable functions $\sum_{i} |c_i(x)|$ and $\sum_{i}\max(0,c_i(x))$. In this paper, a trust region approach based on a 2-norm subproblem is proposed for solving a nonlinear $l_1$ problem. The (quadratic) approximation and the trust region subproblem are defined using affine scaling techniques. Explicit sufficient decrease conditions based on the approximations are suggested for obtaining a limit point satisfying complementarity, Kuhn-Tucker conditions, and second order necessary conditions. The global convergence analysis of the method is presented in \cite{Li94b}.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6073,Efficient Program Analysis Using Dependence Flow Graphs,"Program analysis plays a major role in advanced compilers, yet traditional approaches to data flow analysis are quite time consuming. Prior techniques for speeding up data flow analysis have either exploited program structure or have used alternate ""sparse"" dependence representations to avoid performing unnecessary work.  No general method exploiting both program structure and sparsity has emerged.   We present a new framework for program analysis using dependence flow graphs (DFGs), an intermediate representation derived from dataflow machine graphs.  DFGs integrate data and control dependences in a way that supports general and efficient program analysis while avoiding the problems of previous dependence representations.  In particular, our approach simultaneously exploits program structure, sparsity of data flow systems, and data structure reuse to speed up analysis.   At the heart of our method is a new program decomposition based on identifying single-entry single-exit (SESE) regions of the control flow graph (CFG).  We show that finding SESE regions is equivalent to the problem of finding control dependence regions, and we develop optimal linear-time algorithms for these problems.  The nesting relationship of SESE regions is recorded in a data structure called the program structure tree (PST).  Since each SESE region is a control flow graph in its own right, we can speed up many CFG algorithms by applying them independently to each SESE region in a divide-and-conquer manner. Additionally, SESE regions can be categorized according to their local structure (e.g. as if-then-else or loop regions), and this local structure may be exploited by applying simple syntactic methods according to the region kind.   Hierarchical program structure is used in solving global data flow problems by first solving local problems within progressively larger SESE regions.  The global solution is then propagated to enclosed regions in a top-down pass over the PST.  Sparsity is exploited within each data flow problem by avoiding propagation of data flow values through SESE regions that do not effect the data flow solution.  We show that the sparsity found in common scalar optimizations is captured precisely by dependence flow graphs; the DFG is then viewed as a reusable ""basis set"" of sparse graphs.  Since sparsity is based on SESE regions of the PST, we may exploit structure and sparsity simultaneously.   By solving data flow systems using the DFG, we avoid the cost of rediscovering structure and sparsity for each problem instance.  In this case, the cost of building the dependence flow graph is amortized over many related data flow problems.  Such data structure reuse is essential to realizing the full potential of sparse data flow methods.  However, reuse adds the additional burden of maintaining the DFG as the program is transformed during optimization.  Using the PST, we derive practical incremental algorithms for updating both the DFG and the PST itself.   We demonstrate the value of our approach through measurements taken from an optimizing FORTRAN compiler that uses the program structure tree and dependence flow graph as its internal representation.  From our experiments, we conclude that sparse methods hold great potential for speeding up data flow analysis, but that reusing and incrementally updating a sparse representation is the key to realizing this potential.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6074,A Notation for Computer Aided Mathematics,"The NuPrl4 term structure and editor display mechanism are used to provide unambiguous notations for use in the  the development of computer supported mathematical arguments. These notations are used to provide a natural statment of a theorem in Hamiltonian dynamics, anchored in a computationally unambiguous representation, that can be made explicit  if required.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6075,Larchant-RDOSS: a distributed shared persistent memory  and its garbage collector,"Larchant-RDOSS is a distributed shared memory that persists on reliable storage across process lifetimes.  Memory management is automatic: including consistent caching of data and of locks, collecting objects unreachable from the persistent root, writing reachable objects to disk, and reducing store fragmentation.  Memory management is based on a novel garbage collection algorithm, that approximates a global trace by a series of local traces, with no induced I/O or locking traffic, and no synchronization between the collector and the application processes.  This results in a simple programming model, and expected minimal added application latency. The algorithm is designed for the most unfavorable environment (uncontrolled programming language, reference by pointers, distributed system, non-coherent shared memory) and should work well also in more favorable settings.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6076,Set Constaints and Logic Programming,"Set constraints are inclusion relations between expressions denoting sets of ground
 terms over a randed alphabet.  They are the main ingredient in set-based
 program analysis[3,4,12,13,17,20,21,22,26].  In this paper we describe
 a constraint logic programming language CLP(SC) over set constraints
 in the style of Jaffar and Lassez[15].  The language subsumes ordinary logic
 programs over an IIerbrand domain.  We give an efficient unification
 algorithm and operational, declarative, and fixpoint semantics.  We show
 how the language can be applied in set-based program analysis by
 deriving explicitly the monadic approximation of the collecting semantics
 of IIeintze and Jaffar[12,13].",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6077,Operating System Support for Mobile Agents,"An ""agent"" is a process that may migrate through a computer network in order to satisfy requests made by its clients.  Agents implement a computational metaphor that is analogous to how most people conduct business in their daily lives: visit a place, use a service (perhaps after some negotiation), and then move on.  Thus, for the computer illiterate, agents are an attractive way to describe network-wide computations.  Agents are also useful abstractions for programmers who must implement distributed applications.  This is because in the agent metaphor, the processor or ""place"" the computation is performed is not hidden from the programmer, but the communications channels are.  Most current research on agents has focused on language design and application issues.  The TACOMA project (Tromso And COrnell Moving Agents) has, instead, focused on operating system support for agents and how agents can be used to solve problems traditionally addressed by operating systems.  We have implemented prototype systems to support agents using UNIX and using Tcl/Tk on top of Horus.  This paper outlines insights and questions based on that experience.  We discuss abstractions needed by an operating system to support agents, and discuss some problems that arise in connection with electronic commerce involving agents.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6078,COMPILING FOR NUMA PARALLEL MACHINES,"A common feature of many scalable parallel machines is non-uniform memory access (NUMA) --- data access to local memory is much faster than to non-local memories.  In addition, when a number of remote accesses must be made, it is usually more efficient to use block transfers of data rather than to use many small messages.  Almost every modern processor is designed with a memory hierarchy organized into several levels -- each smaller and faster than the level below. In general, the effective use of parallel machines requires careful attention to the following issues: (1) exposing and exploiting parallelism; (2) accessing local memory instead of remote memory; (3) using block transfers for remote accesses; (4) reusing data in the cache; and (5) load balancing.  We have built a system called {\em Pnuma} for programming NUMA machines. We make the following contributions: First, we propose a parallelization scheme for both parallelism and data locality. Second, we develop a framework based on {\em non-singular} matrices and integer lattice theory for the systematic development of loop transformations.  Program transformations, such as loop restructuring, are critical to achieving high performance.  The framework can be used in parallelizing compilers for both coarse-grain and fine-grain parallel architectures.  We have implemented a loop restructuring tool-kit called {\em Lambda} based on this framework. Third, using this loop transformation framework, we develop algorithms for improving memory locality.  The memory locality algorithm restructures loop nests to expose opportunities for parallel execution and for block transfers, while keeping data accesses local wherever possible.  Fourth, for cache locality, we introduce a new simple cache model based on {\em reuse distances\/}, which is more precise than the existing {\em reuse vector space} model.  We develop a new loop transformation technique that optimizes directly on reuse distances, so that no exhaustive search is necessary. Fifth, we use our loop transformation framework to improve parallelism as well.  We develop a unified algorithm for parallelism, memory locality and cache locality.  System evaluations have been conducted on a multiprocessor machine without cache (BBN GP1000), a uniprocessor workstation with cache (HP 9000/720) and a multiprocessor machine with caches (KSR1), using programs from linear algebra, NASA benchmarks and SIMPLE hydrodynamics benchmark.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6079,An Affine Scaling Algorithm for Minimizing Total Variation in ImageEnhancement,"A computational algorithm is proposed for image enhancement based on total variation minimization with constraints. This constrained minimization problem is introduced by Rudin et al \cite{osher1,osher3,osher2} to enhance blurred and noisy images.  Our computational algorithm solves the constrained minimization problem directly by adapting the affine scaling method for the unconstrained $l_1$ problem \cite{CL89}. The resulting computational scheme, when viewed as an image enhancement process, has the feature that it can be used in an interactive manner in situations where knowledge of the noise level is either unavailable or unreliable.  This computational algorithm can be implemented with a conjugate gradient method. It is further demonstrated that the iterative enhancement process is efficient.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6080,Completeness Results for Recursive Data Bases,"We consider infinite recursive (i.e., computable) relational data bases. Since the set of computable queries on such data bases is not closed under even simple relational operations, one must either make do with a very modest class of queries or considerably restrict the class of allowed data bases. We define two query languages, one for each of these possibilities, and prove their completeness. The first is the language of quantifier-free first-order logic, which is shown to be complete for the non-restricted case. The second is an appropriately modified version of Chandra and Harel's language QL, which is proved complete for the case of ``highly symmetric"" data bases, i.e., ones whose set of automorphisms is of finite index for each tuple-width. We also address the related notion of BP-completeness.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6081,GMRES vs. ideal GMRES,"\begin{abstract} \noindent The GMRES algorithm minimizes $\norm{p(A)b}$ over  polynomials $p$ of degree $n$ normalized at $z=0$. The ideal  GMRES problem is obtained if one considers minimization of  $\norm{p(A)}$ instead. The ideal problem forms an upper bound  for the worst-case true problem, where the GMRES norm  $\norm{p_b(A)b}$ is maximized over $b$.  In work not yet published, Faber, Joubert, Knill and Manteuffel have shown that this upper bound need not be attained, constructing a $4 \times 4$ example in which  the ratio of the true to ideal GMRES norms is $0.9999$. Here,  we present a simpler $4 \times 4$ example in which the ratio  approaches zero when a certain parameter tends to zero.  The same example also leads to the same conclusion for Arnoldi vs. ideal Arnoldi norms.  \end{abstract}",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6082,Complete Orthogonal Decomposition for Weighted Least Squares,"Consider a full-rank weighted least-squares problem in which the weight matrix is highly ill-conditioned.  Because of the ill-conditioning, standard methods for solving least-squares problems, QR factorization and the nullspace method for example, break down.  G. W. Stewart established a norm bound for such a system of equations, indicating that it may be possible to find an algorithm that gives an accurate solution.  S. A. Vavasis proposed a new definition of stability that is based on this result.  He also proposed the NSH algorithm for solving this least-squares problem and showed that it satisfies the new definition of stability.  This paper describes a complete orthogonal decomposition algorithm to solve this problem and shows that it is also stable. This new algorithm is simpler and more efficient than the NSH method.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6083,Efficient Message Passing Interface (MPI) for Parallel Computing onClusters of Workstations,"Parallel computing on clusters of workstations and personal computers has very high potential, since it leverages existing hardware and software. Parallel programming environments offer the user a convenient way to express parallel computation and communication. In fact, recently, a Message Passing Interface (MPI) has been proposed as an industrial standard for writing ""portable"" message-passing parallel programs. The communication part of MPI consists of the usual point-to-point communication as well as collective communication. However, existing implementations of programming environments for clusters are built on top of a point-to-point communication layer (send and receive) over local area networks (LANs) and, as a result, suffer from poor performance in the collective communication part.  In this paper, we present an efficient design and implementation of the collective communication part in MPI that is optimized for clusters of workstations. Our system consists of two main components: the MPI-CCL layer that includes the collective communication functionality of MPI and a User-level Reliable Transport Protocol (URTP) that interfaces with the LAN Data-link layer and leverages the fact that the LAN is a broadcast medium. Our system is integrated with the operating system via an efficient kernel extension mechanism that we developed. The kernel extension significantly improves the performance of our implementation as it can handle part of the communication overhead without involving user space. We have implemented our system on a collection of IBM RS/6000 workstations connected via a 10Mbit Ethernet LAN. Our performance measurements are taken from real scientific applications that run in a parallel mode by means of the MPI. The hypothesis behind our design is that system's performance will be bounded by interactions between  the kernel and user space rather than by the bandwidth delivered by the LAN Data-Link Layer. Our results indicate that the performance of our MPI Broadcast (on top of Ethernet) is about twice as fast as a recently published software implementation of broadcast on top of ATM.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6084,Rational Spaces and Set Constraints,"Set constraints are inclusions between expressions denoting sets of ground terms.  They have been used extensively in program analysis and type inference. In this paper we investigate the topological structure of the spaces of solutions to systems of set constraints. We identify a family of topological spaces called {\em rational spaces}, which formalize the notion of a topological space with a regular or self-similar structure, such as the Cantor discontinuum or the space of runs of a finite automaton.  We develop the basic theory of rational spaces and derive generalizations and proofs from topological principles of some results in the literature on set constraints.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6085,Notes on Proof Outline Logic,"Formulas of Proof Outline Logic are program texts annotated with assertions. Assertions may contain control predicates as well as terms whose values depend on previous states, making the assertion language rather expressive. The logic is complete for proving safety properties of concurrent programs. A deductive system for the logic is presented. Solutions to the mutual exclusion and readers/writers problems illustrate how the logic can be used as a tool for program development.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6086,A New Trust Region algorithm for Equality Constrained Optimization,We present a new trust region algorithms for solving nonlinear equality constrained optimization problems. At each iterate a change of variables is performed to improve the ability of the algorithm to follow the constraint level sets. The algorithm employs $L_{2}$ penalty functions for obtaining global convergence. Under certain assumptions we prove that this algorithm globally converges to a point satisfying the second order necessary  optimality conditions; the local convergence rate is quadratic. Results of preliminary numerical experiments are presented.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6087,Defining and Manipulating Symbolic Bit Flags in Assembly Language,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6088,A Really Temporal Logic,"We introduce a temporal logic for the specification of real-time systems.  Our logic, TPTL, employs a novel quantifier construct for referencing time:  the freeze quantifier binds a variable to the time of the local  temporal context. TPTL is both a natural language for specification and a suitable formalism  for verification. We present a tableau-based decision procedure and a model  checking algorithm for TPTL. Several generalizations of TPTL are shown to be  highly undecidable.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6089,Data Types for Very High Level Programming Languages,"Very high level programming languages (higher than PL/I, Algol 60, etc.)  attempt to free the programmer from providing details and let him concentrate  on the algorithm for the problem at hand. The importance of very high level  programming languages is further emphasized by decreasing machine costs,  increased programming costs and the desire to have programs that are well  structured, easy to understand and prove correct. Very high level languages  provide powerful control structures and data structures that allow the  problem to be specified in a natural manner.  In this dissertation, we propose several ways of raising the level of a  language. The different types of for iteration statements are consolidated  into one general for statement. This, along with a new type, the domain of an  array, provides us with an easy way of processing arrays; nested iteration  statements are no longer necessary. The syntactic list and array generators  and the concept of overloading make programming more flexible.  The current notion that a data type is a set of values together with basic  operations on that set leads us to conclude that formal parameter types need  not be explicitly stated. Given a formal parameter X with operations  $z_{1}, z_{2},\ldots, z_{n}$ being performed on it within the procedure, one  should be able to supply, as an actual parameter in a call, a variable of any  type that has the operations $z_{1}, z_{2},\ldots, z_{n}$ defined on it. For  example, this concept allows us to write one procedure that finds the maximum  value of the elements of an array of any dimension and any element or index  type.  Grids are arrays that can have any shape. Grid elements need not be contiguous  i.e. grids can have holes in them. For example, grids can be trapezoidal,  parabolic, rectangular with a hole or pyramid-like. Programs written using  grids are more general than those written using arrays and/or functions to  simulate non-array shapes. To alter an existing program to work for another  grid shape one need only modify the grid declaration suitably, leaving the  rest of the program intact. Programs are smaller, semantically clearer and  have a more natural problem representation. Grids may be used to represent  sparse matrices. Data security is achieved by allowing parts of grids pass as  parameters to be readd only or completely masked out. Grids have been  implemented as an extension to Fortran.  Using Pascal as the base language, we show by series of examples from  numerical analysis, data processing, engineering etc., how the above concepts  raise the level of a programming language and how they blend together  naturally and systematically. Efficient ways of implementing them are also  discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6090,Selective Partial Access to a Database,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6091,"Effective Automatic Indexing Using Single Terms, Term Phrases and Thesaurus Class Assignments","In a retrieval environment, indexing is the task which consists in the  assignment to stored records and incoming information requests of content  identifiers capable of representing record or query content. It is known that  effective content identifiers (index terms) must exhibit the correct level of  specificity in a given collection environment. Terms that are too broad must  be rendered specific by being utilized as term phrases, while narrow terms  must be broadened by supplying synonymous or related terms normally extracted  from a thesaurus. Formal proofs are given in the present study of the retrieval effectiveness of  indexing policies using single terms, term phrases and thesaurus class  assignments for puposes of content representation. Keywords and Phrases: automatic information retrieval, automatic indexing,  content analysis, term phrases, thesaurus classes, term addition, term  deletion, retrieval evaluation, recall and precision.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6092,A New Modular Interpolation Algorithm for Factoring Multivariate Polynomials,"In this paper, we present a technique that uses a new interpolation scheme to  reconstruct a multivariate polynomial factorization from a number of  univariate factorizations. Whereas other interpolation algorithms for  polynomial factorization depend on various extensions of the Hilbert  irreducibility theorem, our approach is the first to depend only upon the  classical formulation. The key to our technique is the interpolation scheme  for multivalued black boxes originally developed by Ar et. al. [1]. We feel  that this combination of the classical Hilbert irreducibility theorem and  multivalued black boxes provides a particularly simple and intuitive approach  to polynomial factorization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6093,Mesh Generation With Provable Quality Bounds,"We consider the problem of generating a triangulation of provable quality for  two and three dimensional polyhedral regions. That is, we seek a  triangulation, allowing additional vertices called Steiner points, such that  the triangular or tetrahedral elements have a bound on their shape. In three  dimensions we also seek an upper bound on the number of tetrahedra in the  triangulation. These triangulation algorithms find application in mesh  generation for finite element methods. The polyhedral region must be bounded  and well defined, but may have holes of arbitrary complexity.   In three dimensions, we assume there are no restrictions on where we may place  Steiner points. Our triangulation is optimal in the following two senses.  First, our triangulation achieves the best possible aspect ratio up to a  constant factor, which is our bound on element shape. Second, for any other  triangulation of the same region into $m$ triangles with bounded aspect ratio,  our triangulation has size $n = O(m)$. Such a triangulation is desired as an  initial mesh for a finite element mesh refinement algorithm. Previous three  dimensional triangulation schemes either worked only on a restricted class of  input, or did not guarantee well-shaped tetrahedra, or were not able to bound  the output size. We build on some of the ideas presented in previous work by  Bern, Eppstein and Gilbert, who have shown how to triangulate a two  dimensional polyhedral region with holes, with similar quality and optimality  bounds. In two dimensions, we assume the restriction that we may introduce Steiner  points on the polygon's interior, but not on its boundary. Of all  triangulations satisfying this restriction, our triangulation has the maximum  minimum angle, up to a constant factor. This is the first known algorithm for  this problem with provably optimal element shape. The algorithm solves several  subproblems of mesh generation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6094,Process Membership in Asynchronous Environments,"The development of reliable distributed software is simplified by the ability  to assume a fail-stop failure model. We discuss the emulation of such a  model in an asynchronous distributed environment. The solution we propose,  called Strong-GMP, can be supported through a highly efficient protocol, and  has been implemented as part of a distributed systems software project at  Cornell University. Here, we focus on the precise definition of the problem,  the protocol, correctness proofs and an analysis of costs. Keywords: Asynchronous computation; Fault detection; Process membership;  Fault tolerance; Process group.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6095,The Trainset Railroad Simulation,A prototype real-time process control application is described. A simulator  for this application is available--its interface is specified.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6096,Temporal Proof Methodologies for Timed Transition Systems,"We extend the specification language of temporal logic, the corresponding  verification framework, and the underlying computational model to deal with  real-time properties of reactive systems. The abstract notion of timed  transition systems generalizes traditional transition systems conservatively:  qualitative fairness requirements are replaced (and superseded) by  quantitative lower-bound and upper-bound timing constraints on transitions.  This framework can model real-time systems that communicate either through  shared variables or by message passing and real-time issues such as timeouts,  process priorities (interrupts), and process scheduling. We exhibit two styles for the specification of real-time systems. While the  first approach uses time-bounded versions of the temporal operators, the  second approach allows explicit references to time through a special clock  variable. Corresponding to the two styles of specification, we present and  compare two different proof methodologies for the verification of timing  requirements that are expressed in these styles. For the  bounded-operator style, we provide a set of proof rules for establishing  bounded-invariance and bounded-response properties of timed transition  systems. This approach generalizes the standard temporal proof rules for  verifying invariance and response properties conservatively. For the   explicit-clock style, we exploit the observation that every time-bounded  property is a safety property and use the standard temporal proof rules for  establishing safety properties.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6097,Solving $L_{p}$-Norm Problems and Applications,"The $l_{p}$ norm discrete estimation problem min$_{x\in\Re^{n}} \Vert b-A^{T}  x\Vert^{p}_{p}$ has been solved in many data analysis applications, e.g.  geophysical modeling. Recently, a new globally convergent Newton method  (called GNCS) has been proposed for solving $l{p}$ problems with 1 $\leq p  \leq$ 2 [5]. This method is much faster than the widely used IRLS method when  1 $\leq p \leq$ 1.5 and comparable to it when $p greater than $ 1.5. In this paper,  modification is made to the line search prodedure so that the GNCS method is  applicable for $l_{p}$ problems with 1 $\leq p less than \infty$. The global  convergence results for $l_{1}$ problems are obtained under weaker  assumptions than required in [2]. In addition, the usefulness of  $l_{p}$ norm solution with 1 $\leq p \leq$ 2 is demonstrated by applying  the GNCS algorithm to a synthetic geophysical tomographic inversion problem.  Additional numerical results are included to support the efficiency of GNCS. Key Words: linear regression, discrete estimation, tomographic inversion,  IRLS, GNCS, linear programming, Newton method. Subject Classification: AMS/MOS: 65H10, 65K05, 65K10.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6098,On the Robustness of Herlihy's Hierarchy,"A wait-free hierarchy maps object types to levels in $Z^{+} \cup \{ \infty \}$, and has the following property: if a type $T$ is at level $N$,  and $T'$ is an arbitrary type, then there is a wait-free implementation of  an object of type $T'$, for $N$ processes, using only registers and objects  of type $T$. The infinite hierarchy defined by Herlihy is an example of a  wait-free hierarchy. A wait-free hierarchy is robust if it has the  following property: if $T$ is at level $N$, and  $\cal S$ is a finite set of  types belonging to levels $N$ -- 1 or lower, then there is no wait-free  implementation of an object of type $T$, for $N$ processes, using any number  and any combination of objects belonging to the types in $\cal S$.  Robustness implies that there are no clever ways of combining weak shared  objects to obtain stronger ones. Contrary to what many reserchers believe [AGTV92, AR92, Her91a], we prove  that Herlihy's hierarchy is not robust. We then define some natural variants  of Herlihy's hierarchy, which are also infinite wait-free hierarchies. With  the exception of one, which is still open, these are not robust either. We  conclude with the open question of whether non-trivial robust wait-free  hierarchies exist.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6099,Putting Time into Proof Outlines,A logic for reasoning about timing properties of concurrent programs is presented.   The logic is based on Hoare-style proof outlines and can handle maximal parallelism as well as certain resource-constrained execution environments. The correctness proof for a mutual exclusion protocol that uses execution timings in a subtle way illustrates the logic in action. A soundness proof using structual operational semantics is outlines in the appendix.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6100,Approaches to Passage Retrieval in Full Text Information Systems,"Large collections of full-text documents are now commonly used in automated  information retrieval. When the stored document texts are long, the retrieval  of complete documents may not be in the users' best interest. In such  circumstances, efficient and effective retrieval results may be obtained by  using passage retrieval strategies designed to retrieve text excerpts of  varying size in response to statements of user interest. New approaches are described in this study for implementing selective passage  retrieval systems, and identifying text passages responsive to particular  user needs. An automated encyclopedia search system is used to evaluate the  usefulness of the proposed methods.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6101,A Theorem Proving Based Methodology for Software Verification,"We have developed an effective methodology for using a proof development  system to prove properties about functional programs. This methodology  includes techniques such as hiding implementation details and using higher  order theorems to structure proofs and aid in abstract reasoning. The methodology was discovered and refined while verifying a logic synthesis  tool with the Nuprl proof development system. The logic synthesis tool,  $Pbs$, implements the weak division algorithm. $Pbs$ consists of approximately  1000 lines of code implemented in a functional subset of Standard ML. It is a  proven and usable implementation of a hardware synthesis tool. The program  was verified by embedding the subset of SML in Nuprl and then verifying the  correctness of the implementation of $Pbs$ in the Nuprl logic.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6102,On the Reachability Problem for 5-Dimensional Vector Addition Systems,"The reachability set for vector addition systems of dimension less than or  equal to five are shown to be effectively computable semilinear sets. Thus  reachability, equvalence and containment are decidable up to dimension 5. An  example of a non-semilinear reachability set is given for dimension 6. Keywords and phrases: Vector addition system, Petri net, semilinear set,  algorithms, decidability.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6103,Pseudospectra of the Convection-Diffusion Operator,"The spectrum of the simplest 1D convection-diffusion operator is a discrete  subset of the negative real axis, but the pseudospectra are regions in the  complex plane that approximate parabolas. Put another way, the norm of the  resolvent is exponentially large as a function of the Peclet number  throughout a certain parabolic region. These observations have a simple  physical basis, and suggest that conventional spectral analysis for  convection-diffusion operators may be of limited value in some applications.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6104,Optimizing the Degree of Minimum Weight Spanning Trees,"This paper presents two algorithms to construct minimum weight spanning trees  with approximately minimum degree. The first method gives a spanning tree  whose maximum degree is $O(\delta^{*} + logn)$ where $\delta^{*}$ is the  minimum possible, and $n$ is the number of vertices. The second method gives  a spanning tree of degree no more than $k \cdot (\delta^{*} + 1)$, where $k$  is the number of distinct weights in the graph. Finding the exact minimum is  NP-hard.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6105,Virtually-Synchronous Communication Based on a Weak Failure Suspector,"Failure detectors (or, more accurately, Failure Suspectors - FS) appear to be  a fundamental service upon which to build fault-tolerant, distributed  applications. This paper shows that a FS with very weak semantics (i.e. that  delivers failure and recovery information in no specific order) suffices to  implement virtually-synchronous communication (VSC) in an asynchronous system  subject to process crash failures and network partitions. The VSC paradigm is  particularly useful in asynchronous systems and greatly simplifies building  fault-tolerant applications that mask failures by replicating processes. We  suggest a three-component architecture to implement virtually-synchronous  communication : 1) at the lowest level, the FS component; on top of it,  2a) a component that defines new views, and 2b) a component that reliably  multicasts messages within a view. The issues covered in this paper also lead  to a better understanding of the various membership service semantics  proposed in recent literature.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6106,Undecidability in Macroeconomics (Preliminary Draft),"In this paper, we study the difficulty of solving problems in economics. For  this purpose, we adopt the notion of undecidability from recursion theory. We  show that certain problems in economics are undecidable, i.e., cannot be  solved by a Turing Machine, a device that is at least as powerful as any  computational device that can be constructed [2]. In particular, we prove  that even in finite closed economies subject to a variable initial condition,  in which a social planner knows the behavior of every agent in the economy,  certain important social planning problems are undecidable. Thus, it may be  impossible to make effective policy decisions. Philosophically, this result formally brings into question the Rational  Expectations Hypothesis, which assumes that each agent is able to determine  what it should do if it wishes to maximize its utility. We show that even when  an optimal rational forecast exists for each agent (based on the information  currently available to it), agents may lack the ability to make these  forecasts. For example, Lucas [7] describes economic models as ""mechanical,  artificial world(s), populated by ... interacting robots"". Since any  mechanical robot can be at most as computationally powerful as a Turing  Machine, such economies are vulnerable to the phenomenon of undecidability.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6107,On Information Invariants in Robotics,"We consider the problem of determining the information requirements to perform  robot tasks, using the concept of information invariants. This paper  represents our attempt to characterize a family of complicated and subtle  issues concerned with measuring robot task complexity. We also provide a first  approximation to a purely operational theory that addresses a narrow but  interesting special case. We discuss several measures for the information complexity of a task: (a) How  much internal state should the robot retain? (b)How many cooperating agents  are required, and how much communication between them is necessary? (c) How  can the robot change (side-effect) the environment in order to record state or  sensory information to perform a task? (d) How much information is provided by  sensors? and (e) How much computation is required by the robot? We consider  how one might develop a kind of ""calculus"" on (a) - (e) in order to compare  the power of sensor systems analytically. To this end, we attempt to develop a  notion of information invariants. We develop a theory whereby one sensor can  be ""reduced"" to another (much in the spirit of computation-theoretic  reductions), by adding, deleting and reallocating (a) - (e) among  collaborating autonomous agents.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6108,An Interior Trust Region Approach for Nonlinear Minimization Subject to Bounds,"We propose a new trust region approach for minimizing a nonlinear function  subject to simple bounds. By choosing an appropriate quadratic model and  scaling matrix at each iteration, we show that it is not necessary to solve a  quadratic programming subproblem, with linear inequalities, to obtain an  improved step using the trust region idea. Instead, a solution to a trust  region subproblem is defined by minimizing a quadratic function subject only  to an ellipsoidal constraint. The iterates generated by these methods are  always strictly feasible. Our proposed methods reduce to a standard trust  region approach for the unconstrained problem when there are no upper or lower  bounds on the variables. Global and quadratic convergence of the methods is  established; preliminary numerical experiments are reported.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6109,Hybrid Automata: An Algorithmic Approach to the Specification and Verification of Hybrid Systems,"We introduce the framework of hybrid automata as a model and specification  language for hybrid systems. Hybrid automata can be viewed as a  generalization of timed automata, in which the behavior of variables is  governed in each state by a set of differential equations. We show that many  of the examples considered in the workshop can be defined by hybrid automata.  While the reachability problem is undecidable even for very restricted classes  of hybrid automata, we present two semidecision procedures for verifying  safety properties of piecewise-linear hybrid automata, in which all variables  change at constant rates. The two procedures are based, respectively, on  minimizing and computing fixpoints on generally infinite state spaces. We  show that if the procedures terminate, then they give correct answers. We  then demonstrate that for many of the typical workshop examples, the  procedures do terminate and thus provide an automatic way for verifying their  properties.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6110,Towards Refining Temporal Specifications into Hybrid Systems,"We propose a formal framework for designing hybrid systems by stepwise  refinement. Starting with a specification in hybrid temporal logic, we make  successively more transitions explicit until we obtain an executable system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6111,Parametric Real-Time Reasoning,"Traditional approaches to the algorithmic verification of real-time systems  are limited to checking program correctness with respect to concrete timing  properties (e.g., ""message delivery within 10 milliseconds""). We address  the more realistic and more ambitious problem of deriving symbolic constraints  on the timing properties required of real-time systems (e.g., ""message  delivery within the time it takes to execute two assignment statements""). To  model this problem, we introduce parametric timed automata - finite-state  machines whose transitions are constrained with parametric timing  requirements. The emptiness question for parametric timed automata is central to the  verification problem. On the negative side, we show that in general this  question is undecidable. On the positive side, we provide algorithms for  checking the emptiness of restricted classes of parametric timed automata.  The practical relevance of these classes is illustrated with several  verification examples. There remains a gap between the automata classes for  which we know that emptiness is decidable and undecidable, respectively, and  this gap is related to various hard and open problems of logic and automata  theory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6112,Tradeoffs in Implementing Primary-Backup Protocols,"One way to implement a fault-tolerant service is to replicate the state of a  server across a primary server and a set of backup servers. Clients make  requests to the primary, which then computes the response, informs the backup  of the state change, and then replies to the client. If the primary  subsequently fails then a backup takes over as a new primary. Informally, the primary-backup protocol is nonblocking if the primary need  not wait for acknowledgements from the backups before responding to the  client. While most primary-backup protocols are blocking, we argue that  non-blocking protocols can be constructed for most of the process and  communication failures that are expected to occur in future communications  systems. We then implement and measure the performance of two kinds of  nonblocking protocols--one based on point-to-point communication and one  based on broadcast--and compare the results with conventional blocking  primary-backup protocols.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6113,Generating Spectral Method Solvers for Partial Differential Equations,"A major cost in scientific computing is the creation of software that  performs the numerical computations. This paper presents preliminary results  on research to build a framework for automating the construction of numerical  solvers for differential equations. Within this framework, the scientific  computing problem is described using a very high level programming language  that captures the original differential equations in a natural fashion. A  sequence of code ""transformers"" are used to gradually refine the high level  description of the problem into a concrete, executable form. Numerical  techniques like the finite element method, the spectral method and the  Crank-Nicolson discretization scheme are encoded in these transformers and  once so encoded can be applied to a wide variety of different problems. This  framework provides a natural environment for coarse scale parallelization  based on relatively abstract properties of the specific equations and  methods.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6114,Adaptive Error Bracketing for Controlled-Precision Volume Rendering,"We present a new ray tracing approach to volume rendering in which the  low-albedo volume rendering integral for each ray is efficiently computed to  any prescribed accuracy. By bracketing the emission and absorption functions  along each ray with adaptively refined step functions, computation is directed  toward large sources of error and continued until a desired accuracy is  reached. As a result, coarse approximations can be used in regions that are  nearly uniform, of low emission, or of low visibility due to absorption by  material closer to the eye. Adaptive refinement for each ray is performed  using a hierarchical organization of the volume data; at each step, a part of the ray estimated to contribute large error is refined, and the approximate  integral is updated incrementally. Our current implementation operates on  regularly-spaced data samples combined with trilinear interpolation; however,  the concepts described apply to more general data topologies and  reconstruction filters.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6115,Fine Motion Planning for Dexterous Manipulation,"This thesis investigates the problem of dexterous manipulation; how can robots  affect the world around them by means of their end-effectors? Dexterous  manipulation is fundamental to robots operating intelligently and  independently in their environments and it is a special motion planning  problem. Since the general motion planning problem with uncertainty is NEXP-hard,  effort must be directed to defining classes of tasks that are tractable. We  consider the reorientation problem: for a given robot hand, an arbitrary  object, and a desired orientation with respect to the hand, find an algorithm  to synthesize a robust plan for the fingers that accomplishes the desired  reorientation. A reorientation algorithm devised for a robot hand should  satisfy several properties. First, it must be able to accomplish arbitrarily  large rotations. Second, since it must be implemented on a real device, it  should involve simple finger motions that can be computed fast. Third, since  the application domain is characterized by uncertainties that manifest  themselves as imprecisions in calculations and inaccuracies in control, it  must exhibit good stability properties. We propose algorithms for the  reorientation problem that satisfy these properties. The basic idea is to use  some of the robot fingers to constrain the motion of the object and others to  generate motion. This results in the idea of finger tracking as a high-level  primitive for manipulation. We also propose an algebraic framework for  manipulation that is theoretically well-founded and in which it is possible  to use systematically and effectively the differential equations describing  the interaction between objects in contact. Finally, we describe a simulator  for the reorientation of polyhedra by finger tracking.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6116,Discontinuity Meshing for Radiosity Image Synthesis,"The simulation of global illumination is one of the most fundamental problems  in computer graphics, with applications is a wide variety of areas. This  problem studies the light energy transfer between reflective surfaces in an  environment. Initially derived from the field of thermal engineering,  radiosity has emerged over the past several years as one of the most promising  solution methods. Despite having produced some of the most realistic-looking computer generated  images to date, radiosity methods have not yet met with widespread  acceptance. The main obstacle has been their need for very careful and time  consuming user intervention, without which, current techniques are prone to  generating a wide range of annoying visual artifacts. These artifacts are  generally due to poor surface meshing, resulting in insufficient sampling  density and ineffective sample placement. This thesis investigates the roots of this problem by taking a step back from  the traditional finite element formulation of radiosity and examining the more general integral equation formulation. An analysis of the radiance functions  described by this equation shows how umbra and penumbra boundaries as well as  other sharp changes in illumination actually correspond to discontinuities in  the radiance function and its derivatives. The results of this analysis have  led to the concept of discontinuity meshing, whereby accurate approximations  to the radiance functions are computed by explicitly representing their  discontinuities as boundaries in the mesh. This concept has been applied to the design of a discontinuity meshing  algorithm for polyhedral environments. The algorithm is embedded in a  progressive refinement radiosity system and uses piecewise quadratic  interpolation to reconstruct a smooth radiance function while preserving  discontinuities where appropriate. The radiosity solutions produced by the new algorithm are compared against a  photograph of a physical environment, an analytical solution, and a  conventional, yet state-of-the-art, radiosity system, and its performance on  architectural models of medium complexity is measured. The results are  remarkably accurate both numerically and visually. The new discontinuity  meshing algorithm drastically reduces, and in many cases eliminates, many of  the annoying artifacts typical of conventional radiosity meshes, producing  images of previously unattained quality. Moreover, the meshing is completely  automatic and produces solutions that are highly view-independent.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6117,Sorting Helps for Voronoi Diagrams,"It is well known that, using standard models of computation, it requires  $\Omega(n$ log $n$) time to build a Voronoi diagram for $n$ data points. This  follows from the fact that a Voronoi diagram algorithm can be used to sort.  But if the data points are sorted before we start, can the Voronoi diagram be  built any faster? We show that for certain interesting, although nonstandard  types of Voronoi diagrams, sorting helps. These nonstandard types Voronoi  diagrams use a convex distance function instead of the standard Euclidean  distance. A convex distance function exists for any convex shape, but the  distance functions based on polygons (especially triangles) lead to  particularly efficient Voronoi diagram algorithms - fast algorithms using  simple data structures. Specifically, a Voronoi diagram using a convex  distance function based on a triangle can be built in $O(n$ log log $n$) time  after initially sorting the $n$ data points twice. Convex distance functions  based on other polygons require more initial sorting.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6118,Near-Quadratic Bounds for the $L_{1}$ Voronoi Diagram of Moving Points,"Given a set of $n$ moving points in the plane, how many topological changes  occur in the Voronoi diagram of the points? If each point has constant  velocity then there is an upper bound of $O(n^{3})$ [Guibas, Mitchell and  Roos] and an easy lower bound of $\Omega(n^{2})$. It is widely believed that  the true upper bound should be close to $O(n^{2})$. We show this belief to be  true for the case of Voronoi diagrams based on the $L_{1}$ (or $L_{\infty}$)  metric; the number of changes is shown to be $O(n^{2} \alpha (n))$ where  $\alpha(n)$ grows so slowly it is effectively a small constant for all  reasonable values of $n$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6119,Consistent Failure Reporting in Reliable Communication Systems,The difficulty of developing reliable distributed software is an impediment  to applying distributed computing technology in many settings. This paper  reviews some common platforms for distributed software development and argues  that inconsistent failure reporting in communication mechanisms represents a  significant obstacle to reliability.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6120,A Lower Bound for Two-Server Balancing Algorithms,"We consider the class of balancing algorithms for two servers. Such  algorithms have appeared in a number of the early papers on this problem;  they are so named because they seek to ""balance"" the distance travelled  evenly among the servers. In this paper, we show a universal lower bound on  the competitive ratio of any balancing algorithm for two servers. The  lower bound is equal to (5 + $\sqrt{7}$)/2 ($\sim$ 3.82), and consequently  shows that no optimal on-line algorithm for two servers can be expressed as  a balancing algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6121,Resource Bounds and Combinations of Consensus Objects,"The shared-memory model of computation typically provides processes with an  arbitrary number of copies of the available object types; yet a simple  argument shows that any consensus protocol can only make use of some finite  subset of these. Thus we believe it is useful to consider the problem of  consensus from the point of view of resource bounds, determining whether  consensus can still be solved when the number of copies of the system's  shared objects is limited. This approach leads to a general technique which we  call the combination protocol, in which the number of processes that  can achieve consensus with a given object increases as more copies of it are  made available. Such a phenomenon brings up questions about the robustness of  Herlihy's consensus hierarchy, in that objects are being combined to  solve $n$-process consensus, even though no single copy can do so  individually. We show how the ideas in the combination protocol appear even in  situations where objects are not explicitly being combined with one another;  we also consider the general question of resource bounds in several known  consensus protocols. We analyze two such protocols that use seemingly similar  primitives, achieving a substantial improvement in one case and showing a  tight lower bound in the other.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6122,The Complexity of Set Constraints,Set constraints are relations between sets of terms. They have been used  extensively in various applications in program analysis and type inference. We  present several results on the computational complexity of solving systems of  set constraints. The systems we study form a natural complexity hierarchy  depending on the form of the language.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6123,The Primary-Backup Approach: Lower and Upper Bounds,"The most widely used approach to building replicated, fault-tolerant services  is the primary-backup approach. In this approach, the state of the service is  replicated across multiple servers, with one server designated as the primary  and the rest as backups. Clients send requests only to the primary. However,  in case the primary fails, one of the backups takes over as the new primary.  Ever since it was introduced in 1976 by Alsberg and Day, the primary-backup  approach has become the basis for building many practical fault-tolerant  services. However, despite the widespread use, the approach has not been  studied systematically, and little is known of the fundamental costs and  tradeoffs of using the approach under various kinds of failures. Thus, there  is a gap between theory and practice. In order to close this gap, this thesis  analyzes the primary-backup approach, both from the theoretical perspective of  specification, lower bounds and upper bounds, as well as from the practical  viewpoint of performance tradeoffs in protocols. We identify three key cost  metrics of primary-backup protocols--degree of replication, blocking time and  failover time--and then show lower and upper bounds on these metrics for a  hierarchy of failure models. We then implement an important subclass of our  primary-backup protocols, called 0-blocking protocols, and give performance  figures. In addition to leading to the development of new, more efficient  protocols, we believe that the work in this thesis has resulted in a better  understanding of the properties of existing primary-backup protocols.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6124,A Security Architecture for Fault-Tolerant Systems,Process groups are a common abstraction for fault-tolerant computing in  distributed systems. We present a security architecture that extends the  process group into a security abstraction. Integral parts of this architecture  are services that securely and fault-tolerantly support cryptographic key  distribution using novel techniques. We detail the design and implementation  of these services and the secure process group abstraction they support. We  also give performance figures for some common group operations.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6125,"Understanding Partitions and the ""No Partition"" Assumption","The paper discusses partitions in asynchronous message-passing systems. In  such systems slow processes and slow links can lead to virtual partitions that  are indistinguishable from real ones. This raises the following question: what  is a ""partition"" in an asynchronous system? To overcome the impossibility  of detecting crashed processes in an asynchronous system, our system model  incorporates a failure suspector to detect (possibly erroneously)  process failures. Based on failure suspicions we give a definition of  partitions that acccounts for real partitions as well as virtual ones. We show  that under certain assumptions about the process behavior, any incorrect  failure suspicion inevitably partitions the system. We then show how to  interpret the ""absence of partition"" assumption.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6126,Locality in Distributed Computing,"The topic of this thesis is the issue of locality in distributed computing. A first set of results in this thesis concerns the $\Delta$-vertex coloring  problem. They are all based on the following result. Let $G$ be a graph such  that $\Delta \geq 3, G$ is not a complete graph, and such that all of $G$  except one vertex $v$ is $\Delta$-colored. Then, it is possible to extend  this $\Delta$-coloring to all of $G$ by recoloring a path originating from $v$  of length at most $O(\log_{\Delta}n)$. This property allows us to develop several efficient algorithms for  $\Delta$-coloring. In particular, but not exclusively, in the distributed and  PRAM models of computation. It also implies a well-known result of Brooks as  a corollary. Another set of results concerns network decomposition - a basic notion in  distributed graph algorithms. We improve the bounds for computing a network  decomposition distributively and deterministically. Our algorithm computes an  $(n^{\epsilon(n)},n^{\epsilon(n)})$-decomposition in $O(n^{\epsilon(n)})$  time, where $\epsilon(n) = O(1/ \sqrt{\log n})$. We also show that the class of graphs $\cal G$ whose maximum degree is  $O(n^{\delta(n)}$, where $\delta(n) = O(1/\log \log n)$, is complete for the  task of computing a ($\log n, \log n)$-decomposition, in polylogarithmic in  $n$ time. Completeness is to be intended in the following sense: if we have  an algorithm $\cal A$ that computes a $(\log n, \log n)$-decomposition in  polylogarithmic in $n$ time for graphs in $\cal G$, then we can compute a  $(\log n, \log n)$-decomposition in polylogarithmic in $n$ time for all graphs. A last set of results concerns the edge coloring problem. We give a randomized  distributed algorithm to compute an edge coloring of a given network $G$,  that uses at most $1.6\Delta + \log^{2+\delta} n$ colors, for any  $\delta greater than 0$. The running time is $O(\log n)$ and the failure probability is  at most $\epsilon$, for any fixed $\epsilon greater than 0$. The algorithm is quite  simple but requires an interesting probabilistic analysis. At the core of the  analysis is an extension of the Chernoff-Hoeffding bounds, which are  fundamental tools used in estimating the tail probabilities of the sum of  Bernoulli-like trials.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6127,Randomized Distributed Edge Coloring via an Extension of the Chernoff-Hoeffding Bounds,"Certain types of routing, scheduling and resource allocation problems in a  distributed setting can be modeled as edge coloring problems. We present fast  and simple randomized algorithms for edge coloring a graph, in the synchronous  distributed point-to-point model of computation. Our algorithms compute an  edge-coloring of a graph $G$ with $n$ nodes and maximum degree $\Delta$ with  at most $(1.6 + \epsilon)\Delta + \log^{2+\delta} n$ colors with high  probability (arbitrarily close to 1), for any fixed $\epsilon,\delta greater than 0$. To analyze the performance of our algorithms, we introduce an extension of the  Chernoff-Hoeffding bounds, which are fundamental tools that are used  very frequently in estimating tail probabilities. However, they assume  stochastic independence among certain random variables, which may not always  hold. Our results extend the Chernoff-Hoeffding bounds to certain types of  random variables which are not stochastically independent. We believe that  these results are of independent interest, and merit further study.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6128,On the Complexity of Distributed Network Decomposition,"In this paper, we improve the bounds for computing a network decomposition,  which is a basic notion in distributed graph algorithms, distributively and  deterministically. Our algorithm computes an  $(n^{\epsilon(n)},(n^{\epsilon(n)})$-decomposition in $O(n^{\epsilon(n)})$  time, where $\epsilon(n)=O(1/ \sqrt{\log n})$. As a corollary we obtain improved deterministic bounds for distributively  computing several graph structures such as maximal independent sets and  $\Delta$-vertex colorings. We also show that the class of graphs $\cal G$ whose maximum degree is  $O(n^{\delta(n)})$, where $\delta(n)=O(1/\log \log n)$, is complete for the  task of computing a near-optimal decomposition, i.e., a  $(\log n \log n)$-decomposition, in $O($polylog$(n))$ time. This is a  corollary of a more general characterization, which pinpoints the weak points  of existing network decomposition algorithms. Completeness is to be intended  in the following sense: if we have an algorithm $\cal A$ that computes an  optimal decomposition in $O($polylog$(n))$ time for graphs in $\cal G$, then  we can compute an optimal decomposition in $O($polylog $(n))$ time for all  graphs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6129,"Randomness-Optimal Unique Element Isolation, With Applications to Perfect Matching and Related Problems","In this paper, we precisely characterize the randomness complexity of the  unique element isolation problem, a crucial step in the RNC algorithm for  perfect matching due to Mulmuley, Vazirani and Vazirani[21] and in several  other applications. Given a set $S$ and an unknown family  $\cal F \subseteq$ $2^{S}$ with $|\cal F| \leq$ $Z$, we present a scheme to  assign polynomially bounded weights to the elements of $S$, using only  $O(\log Z + \log |S|)$ ransom bits, such that the minimum weight set in  $\cal F$ is unique with high probability. This generalizes and improves the  results of Mulmuley, Vazirani and Vazirani who give a scheme which uses  $O(S \log S)$ random bits independent of $Z$. We also prove a matching lower  bound for the randomness complexity of this problem. This new weight  assignment scheme yields a randomness-efficient $RNC^{2}$ algorithm for  perfect matching which uses $O(\log Z + \log n)$ random bits where $Z$ is any  given upper bound on the number of perfect matchings in the input graph. This  generalizes the result of Grigoriev and Karpinski[11] who present an $NC^{3}$  algorithm when $Z$ is polynomially bounded and also gives an improvement on  the running time in this case. The worst-case randomness complexity of our  algorithm is $O(n \log (m/n))$ random bits, as opposed to the previous bound  of $O(m \log n)$ bits. Our technique also gives randomness-efficient  solutions for several problems in which the unique element isolation tool is  used, such as $RNC$ algorithms for variants of matching and basic problems on  linear matroids such as matroid intersection and matroid matching. We also  obtain a randomness-efficient alternative to the random reduction from $SAT$  to $USAT$, the language of uniquely satisfiable formulas, due to Valiant and  Vazirani[32]. This reduction can be derandomized in the case of languages in  $F ew P$ to yield new proofs of the results $F ew P \subseteq \oplus P$ and  $F ew P \subseteq C_{=} P$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6130,Pseudozeros of Polynomials and Pseudospectra of Companion Matrices,"It is well known that the zeros of a polynomial $p$ are equal to the  eigenvalues of the associated companion matrix $A$. In this paper, we take a  geometric view of the conditioning of these two problems and of the stability  of algorithms for polynomial zerofinding. The $\epsilon$-pseudozero set  $Z_{\epsilon}(p)$ is the set of zeros of all polynomials $\hat{p}$ obtained by  coefficientwise perturbations of $p$ of size $\leq \epsilon$; this is a  subset of the complex plane considered earlier by Mosier, and is bounded by a  certain generalized lemniscate. The $\epsilon$-pseudospectrum  $\Lambda_{\epsilon}(A)$ is another subset of C defined as the set of  eigenvalues of matrices $\hat{A}=A+E$ with $||E|| \leq\epsilon$; it is  bounded by a level curve of the resolvent of $A$. We find that if $A$ is  first balanced in the usual EISPACK sense, then $Z_{\epsilon||p||}(p)$ and  $\Lambda_{\epsilon||A||}(A)$ are usually quite close to one another. It  follows that the Matlab ROOTS algorithm of balancing the companion matrix,  then computing its eigenvalues, is a stable algorithm for polynomial  zerofinding. Experimental comparisons with the Jenkins-Traub (IMSL) and Madsen-Reid (Harwell) Fortran codes confirm that these three algorithms have  roughly similar stability properties. Key words: polynomial zeros, comapnion matrix, pseudospectrum.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6131,Alex - A Paradigm for Expressing and Compiling Matrix Functions,"This work presents formal and practical tools to support the Alex paradigm  for expressing and compiling matrix functions. Alex programs are recursive  definitions over matrices with the same flavor as the elegant FP languages of  Backus. Many useful matrix algorithms can be expressed in both FP and Alex  without any explicit index arithmetic. While FP is very difficult to compile  to fast numerical codes, we show that Alex functions admit compile-time  analyses and code generation techniques with efficient results. In  particular, we give a type system that expresses matrix sizes and shapes, a  sound and complete inference algorithm for these types, and a code generation algorithm that is space-efficient--storage is allocated only for user function  parameters and results. Finally, we give an algorithm that determines when it  is safe to replace call by value array parameters in the compiled code with  call by reference. A compiler using these techniques generates C code from  Alex programs which is at least as fast as code one would write by hand for  some small problems. We conclude with discussion of how the fundamental  techniques given here relate to previous work and how they should be extended  to a general functional language or incorporated as a feature of an existing  one.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6132,Decidability of Systems of Set Constraints with Negative Constraints,"Set constraints are relations between sets of terms. They have been used  extensively in various applications in program analysis and type inference.  Recently, several algorithms for solving general systems of positive set constraints have appeared. In this paper, we consider systems of mixed  positive and negative constraints, which are considerably more expressive than  positive constraints alone. We show that it is decidable whether a given such  system has a solution. The proof involves a reduction to a number-theoretic  decision problem that may be of independent interest.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6133,Principled Optimization of Functional Programs,"Automatic optimizers for computer programs work with a fixed list of rote  transformations, while human programmers can go on to derive new optimizations  from broad and intuitive principles if known transformations prove inadequate.  This dissertation investigates the possibility that principled optimization  can be automated, focusing on a single principle (the principle that programs  should not do anything unnecessary) and a single program domain (the domain of  purely functional, first-order programs). Three questions are explored: How  can the principle be formalized? How can violations of the principle be  detected? How can violations be repaired? The trace grammar is a new representation for first-order functional  programs. It permits a simple formal statement of the optimizing principle. A  trace grammar is a kind of graph grammar. An individual graph represents a  path of execution through the program, without any loops or conditionals. The  grammar for a program generates a language of graphs representing the possible  paths of execution through that program. Trace grammars provide unique  leverage for the twin problems of identifying and repairing violations of the  principle. Detecting violations of the principle is a problem in semantic analysis. A  new method of inference, the relational constraint method, helps make  this tractable. The method treats a trace graph as a system of constraints on  a lattice of binary relations, and uses those constraints to develop the  strongest relation it can find for each pair of values in the graph. Repairing violations is not easy: given an example of an unnecessary  computation performed by the program, one wants to modify the program so that  it never makes that mistake. This grammar thinning problem for trace  grammars corresponds to an interesting open problem on context-free grammars.  An (approximate) solution to this CFG problem yields an optimization technique  for trace grammars. An optimizer called Thinner is the proof-of-concept for these ideas. Using the  techniques outlined above, Thinner rediscovers a variety of common compiler  optimizations. It also finds other, more exotic transformations, including the  well-known Fibonacci reformulation. Thinner demonstrates the potential of the  principled approach as a high-powered optimizing tool.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6134,Stable Finite Elements for Problems With Wild Coefficients,"We consider solving an elliptic boundary value problem in the case that the  coefficients vary by many orders of magnitude over the domain. A linear  finite element method is used. It is shown that the standard method for  solving the resulting linear equations in finite-precision arithmetic can  give an arbitrarily inaccurate answer because of ill-conditioning in the  stiffness matrix. A new method for solving the linear equations is proposed.  This method is based on a ""mixed formulation"" and gives a numerically  accurate answer independent of the variation in the coefficients. The  numerical error in the solution of the linear system for the new method is  shown to depend on the aspect ratio of the triangulation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6135,Finding Regions Fast: Single Entry Single Exit and Control Regions in Linear Time,"Many compilation problems require computing the control dependence  equivalence relation which divides nodes in a control flow graph into  equivalence classes such that nodes are in the same class if and only if they  have the same set of control dependences. In this paper, we show that this  relation can be computed in $O(E)$ time by reducing it to a naturally stated  graph problem: in a strongly connected component, divide nodes into  equivalence classes such that every cycle passes through all or none of the  nodes in an equivalence class. Our algorithm does not require the computation  of the control dependence relation or of the postdominator relation - in  fact, it runs faster in practice than the best algorithms for either of these  problems. We also show that our algorithm can be used to determine the single  entry single exit regions of a control flow graph in $O(E)$ time.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6136,Selective Text Utilization and Text Traversal,"Many large collections of full-text documents are currently stored in  machine-readable form and processed automatically in various ways. These  collections may include different types of documents, such as messages,  research articles, and books, and the subject matter may vary widely. To  process such collections, robust text analysis methods must be used, capable  of handling materials in arbitrary subject areas, and flexible access must be  provided to texts and text excerpts of varying size. In this study, global text comparison methods are used to identify  similarities between text elements, followed by local context-checking  operations that resolve ambiguities and distinguish superficially similar  texts from texts that actually cover identical topics. A linked text structure  is then created that relates similar texts at various levels of detail. In  particular, text links are available for full texts, as well as text  sections, paragraphs, and sentence groups. The linked structures are usable  to identify important text packages, to traverse texts selectively both  within particular documents and between documents, and to provide flexible  text access to large text collections in response to various kinds of user  needs. An automated 29-volume encyclopedia is used as an example to illustrate  the text accessing and traversal operations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6137,Chernoff-Hoeffding Bounds for Applications with Limited Independence,"Chernoff-Hoeffding bounds are fundamental tools used in bounding the tail  probabilities of the sums of bounded and independent random variables. We  present a simple technique which gives slightly better bounds than these and  which, more importantly, requires only limited independence among the  random variables, thereby importing a variety of standard results to the case  of limited independence for free. Additional methods are also presented, and  the aggregate results are very sharp and provide a better understanding of the  proof techniques behind these bounds. They also yield improved bounds for  various tail probability distributions and enable improved approximation  algorithms for jobshop scheduling. The ""limited independence"" result implies  that weaker sources of randomness are sufficient for randomized algorithms  whose analyses use the Chernoff-Hoeffding bounds; further, it leads to  algorithms that require a reduced amount of randomness for any analysis which  uses the Chernoff-Hoeffding bounds, e.g., the analysis of randomized  algorithms for random sampling and oblivious packet routing.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6138,"PL/CT, Another Approach to Two Problems in Interactive PL/I",NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6139,The Group Membership Problem in Asynchronous Systems,"The thesis formally defines the class of Process Group Membership  Problems (GMP) for asynchronous systems. These problems involve maintaining  a list of processes belonging to the system, and updating it as processes  join (are started) and leave (terminate or fail). We investigate closely the  strongest member of the GMP class. Strong GMP presents this list in a  consistent manner to all processes using it: the sequence of joins and  leaves are identical. We show that despite prevalent beliefs, strong  consistency and efficiency are not conflicting goals. This should have  significant implications for distributed systems since the need for process  membership agreement arises in many canonical problems in distributed  computing. We present an inexpensive means (the S-GMP algorithm) of assuring  complete, system-wide agreement on process membership. We discuss the role of  process membership in distributed systems and how to use S-GMP to build  a Membership Resource Manager (MRM). The thesis also examines whether any weaker member of the GMP class suffices  to specify an MRM. In doing so we justify using Strong GMP over two much  weaker GMP instances in three important ways. First, by comparing Strong GMP  and its minimal solution with the weaker instances and their minimal  solutions, we arrive at the surprising result that Strong GMP is often  less expensive than the others, notably in executions in which  membership changes are frequent. Second, we show that a membership service  defined by Strong GMP is more robust, more responsive and more adaptable than  a membership service defined by weaker GMP instances. Third, we compare  membership services defined by the various GMPs according to the utility each  service provides higher-level, distributed applications. That is, ignoring  implementation costs, how useful are the different GMP consistency guarantees  as a platform on which to build distributed solutions to distributed  problems? We show that the consistency guarantees of Strong GMP make it (i.e.  and the membership service Strong GMP defines) more useful to higher-level  distributed applications. Finally, the thesis presents experimental results from implementing  S-GMP. The data demonstrate that a centralized Membership Resource  Manager is a non-intrusive service around which to design distributed systems  and provide system-wide consistency. The data quantify and help clarify the  tradeoffs between replication degree, overall system size and process failure  frequency. These initial results should guide future MRM design and  development.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6140,Simplical Mesh Generation With Applications,"Many problems in computer graphics and in engineering analysis require for  their solution the construction of a mesh of simple polytopal elements that  approximately fill the interior of an object or cover its boundary. The  simplest polytopes are the simplexes, and simplicial meshes have particular  advantages when solving interpolation problems, graphically rendering objects  approximated by boundary meshes, and in many other applications. Boxes are  often used where simplexes should be considered because the properties of  boxes are more familiar. This dissertation develops several techniques that aid in the construction of  simplicial meshes in any dimension. It presents the essential combinatorial  and geometric properties of simplexes, and presents simple techniques for  decomposing simplexes into smaller simple objects. It describes the simplicial  quadtree, a useful representation in the construction of simplicial meshes,  and presents a technique for converting an arbitrary simplicial quadtree into  a balanced quadtree, then into a triangulation. It also describes mesh  displacement, a technique for improving the quality of a boundary  triangulation while reducing its size. Several degenerate behaviors can arise  from mesh displacement, and the dissertation discusses methods for detecting  and compensating for these degeneracies. Simplicial mesh generation techniques can be applied to many kinds  of problems. To illustrate this, the final chapters describe the  implementation of a polygonalizer for algebraic sets and a system that applies  the operations of constructive solid geometry to sets defined algebraically.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6141,A Security Architecture for Fault-Tolerant Systems,"While there is considerable experience with addressing the needs for security  and fault-tolerance individually in distributed systems, much less is  understood about how to simultaneously address these needs in a single,  integrated solution. Indeed, the goals of security and availability have  traditionally been viewed as being in conflict, because replicationg data and  services for availability makes them inherently harder to protect. This thesis presents the design and implementation of a security architecture  for fault-tolerant systems, including a set of results that underpin this  architecture. We first present a methodology for balancing the aforementioned  tradeoff between security and availability in distributed services. Using our  techniques, a service can be replicated so that it will remain available and  correct despite the corruption of some servers and clients by a malicious  intruder. These results include the identification and prevention of a new  form of attack in which an intruder effects and exploits violations of  causality in the sequence of requests processed by the service.  Second, we bring this replication methodology and other novel techniques to  bear on an issue for which the conflict between security and availability is  particularly troublesome, namely cryptographic key distribution via trusted  services. We present authentication and time services that can securely and  fault-tolerantly support cryptographic key distribution in a wide range of  settings. Third, we present the design and implementation of our security architecture,  which employs these services. The architecture supports process groups --a common paradigm of fault-tolerant computing--as its primary security  abstraction, and provides tools to construct applications that are resilient  to benign failures and malicious attacks. We discuss the integration of this  architecture in the Horus system and focus on techniques to make group  communication secure and efficient. In the final contributions of the thesis, we further explore the importance of  detecting causal relationships for security. We present a framework for  examining attacks onaattempts to detect causal relationships. We also present  several algorithms to prevent these attacks in some situations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6142,Verification of Temporal Properties,"The paper presents a relatively complete deductive system for proving  branching time temporal properties of reactive programs. No deductive system  for verifying branching time temporal properties has been presented before.  Our deductive system enjoys the following advantages. First, given a  well-formed specification there is no need to translate it into a normal-form  specification since the system can handle any well-formed specification.  Second, given a specification to be verified, the proof rule to be applied is  easily determined according to the top level operator of the specification.  Third, the system reduces temporal verification to assertional reasoning  rather than to temporal reasoning.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6143,"Proceedings of the North American Process Algebra Workshop 1993 - Ithaca, NY","This contains the papers presented at the second North American Process Algebra Workshop, August 15, 1993, at Cornell University. Contents: * A Semantic Theory for ML Higher Order Concurrency Primitives (Dominique Bolignano and Mourad Debabi)  * An Operational Semantics of Value Passing (Rance Cleaveland) * An Information Flow Security Property for CCS (Riccardo Focardi and Roberto Gorrieri)  * Concurrent Kripke Structures (Vineet Gupta) * Specification of Instruction-Level Parallelism (Ed Harcourt and Jon Mauney and Todd Cook)  * Specification of Transition Systems with Negation (Remi Lissajoux)  * A Comparison of Simulation and Algebraic Techniques for Verifying Concurrent Systems (Nancy Lynch and Roberto Segala)  * A note on Model Checking Context Free Processes (S. Purushothaman Iyer) * State Refinement in Process Algebra (Andrew Uselton and Scott Smolka)  * Parametric Preorders for Process Description Languages (Daniel Yankelevich)",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6144,Fast Algorithms for $N$-body Simulation,"Many physical models require the simulation of a large number ($N$) of  particles interacting through pair-wise inverse square law forces. $N$-body  simulations are employed in fluid-dynamics, biochemistry, astrophysics,  electrodynamics and molecular dynamics. The computational problem is  intrinsically hard and these simulations are time-intensive. Existing algorithms exploit either the spatial proximity of particles or the  temporal proximity of states. In this thesis, we formally combine the two  approaches and present an algorithm with sequential time complexity  $O(N^{4/3})$ to integrate $N$ uniformly distributed particles in 3D over one  crossing time against the $O(N^{8/3})$ complexity of the direct method. Under  reasonable assumptions, our algorithm is optimal. The core of the algorithm  is the temporal multipole expansion of the field in terms of the space-time  coordinates of the field-point. We also present efficient parallel algorithms on the 2D and 3D Mesh and  Hypercube which amortize communication costs through temporal multipole  expansions. The parallel algorithms offer an order of magnitude improvement  over existing algorithms for even $10^{4}$ particles. A sequential implementation of the algorithm for two-dimensional $N$-body  systems shows the predicted asymptotic scaling. A parallel version on a  16-processor Intel iPSC/860 machine is also in conformance with theoretical  expectations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6145,Do the Pseudospectra of a Matrix Determine its Behavior?,"Let $A$ and $B$ be square matrices. It is shown that the condition  $(R) ||(zI-A)^{-1}|| = ||(zI -B)^{-1}||$ for all $z \in \complex$ is  equivalent to the condition $(P) ||p(A)|| = ||p(B)||$ for all polynomials $p$  if $|| \cdot ||$ is the Frobenius norm, but not if $|| \cdot ||$ is the 2-norm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6146,"Ready, Set, Go: Structural Operational Semantics for Linear-Time Process Algebras","We investigate the relationship between operational semantics, equational  semantics, and ready equivalence (a well-known relative of failure equivalence  and testing equivalence) in process algebra. We give a class of structural  operational semantic rules, called winterized rules, which define  operations respecting ready equivalence. The class of winterized rules is  surprisingly broad; it includes some copying operations which would seem  to violate ready equivalence. Membership in this class is decidable in  $O(n^{2})$ time. We show that for any process algebra defined by such rules  has complete equational axiom system. These methods - winterizability in  particular - apply mutatis mutandis to other linear-time process equivalences.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6147,Structural Operational Semantics for Weak Bisimulations,"In this study, we present rule formats for four main notions of bisimulation  with silent moves. Weak bisimulation is a congruence for any process algebra  defined by WB cool rules; we have similar results for rooted weak  bisimulation (Milner's ""observational equivalence""), branching bisimulation,  and rooted branching bisimulation. The theorems stating that, say,  observational equivalence is an appropriate notion of equality for CCS are  corollaries of the results of this paper. We also give sufficient conditions  under which equational axiom systems can be generated from operational rules.  Indeed, many equational axiom systems appearing in the literature are  instances of this general theory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6148,Lectures in Least Squares,These lecture notes arose out of the numerical analysis seminar given at  Cornell University in the Spring of 1976. The goal of the seminar was to  acquaint a variety of researchers and undergraduates with the field of least  squares computations. I hope the presentation will neither bore the expert nor  discourage the layman.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6149,Chain Models of Physical Behavior for Engineering Analysis and Design,"The relationship between geometry (form) and physical behavior (function)  dominates many engineering activities. The lack of uniform and rigorous  computational models for this relationship has resulted in a plethora of  inconsistent (and thus usually incompatible) computer aided design (CAD) tools  and systems, causing unreasonable overhead in time, effort, and cost, and  limiting the extent to which CAD tools are used in practice. It seems clear  that formalization of the relationship between form and function is a  prerequisite to taking full advantage of computers in automating design and  analysis of engineering systems.  We present a unified computational model of physical behavior that explicitly  links geometric and physical representations. The proposed approach  characterizes physical systems in terms of their algebraic-topological  properties: cell complexes, chains, and operations on them.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6150,Distributed ML: Abstractions for Efficient and Fault-Tolerant Programming,"Despite the availability, inherent parallelism, and potential fault tolerance  of networked workstations and microcomputers, most programmers do not write  distributed code. Those that do are often overwhelmed by the asynchrony,  concurrency, and tricky failure behaviour inherent in such systems. In this thesis, we describe the design and implementation of a new  programming language called Distributed ML. Distributed ML provides a  programming construct called a port group that hides the sources of  complexity listed above and can be implemented efficiently. Port groups are  intermachine multicast channels which provide membership and failure  information to application programmers. Although inherently asynchronous,  port groups guarantee the delivery of data sent through them and can order  such data in several different ways, thereby providing many of the assurances  of synchronous communication. Port groups are general-purpose communication  abstractions that can be used to transfer information between machines,  between processes on the same machine, and between threads within the same  process. In this thesis, we demonstrate that efficient distributed programs-even  highly available and fault-tolerant distributed programs-can be quickly  developed, easily reasoned about, and properly coded in a well-designed high  level programming language. First, we provide an implementation and  description of port groups in the context of the Concurrent ML concurrent  programming language, which is a superset of the Standard ML general-purpose  programming language. Second, we introduce a formal theory for relating the membership and ordering properties of port groups. Finally, we argue that our  implementation matches the formal specification.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6151,Unreliable Failure Detectors for Asynchronous Distributed Systems,"It is well-known that several fundamental problems of fault-tolerant  distributed computing, such as Consensus and Atomic Broadcast,  cannot be solved in asynchronous systems with crash failures. These  impossibility results stem from the lack of reliable failure detection in such  systems. To circumvent such impossibility results, we introduce the concept of  unreliable failure detectors that can make mistakes, and study the  problem of using them to solve Consensus (and Atomic Broadcast). It is easy to solve Consensus using a ""perfect"" failure detector (one that  does not make mistakes). But is perfect failure detection necessary to solve Consensus? We show that Consensus is solvable with unreliable failure  detectors, even if they make an infinite number of mistakes. This leads to the  following question: What is the ""weakest"" failure detector for solving  Consensus? We introduce a notion of algorithmic reducibility that allows us to  compare seemingly incomparable failure detectors. Using this concept, we show  that one of the failure detectors that we introduce here is indeed the  weakest failure detector for solving Consensus in asynchronous systems with a  majority of correct processes. We also show that Consensus and Atomic Broadcast are equivalent in  asynchronous systems. Thus all our results regarding the solvability of  Consensus using failure detectors, apply to Atomic Broadcast as well. The work in this thesis was funded by an IBM graduate fellowship and grants  from NSF, DARPA/NASA, the IBM Endicott Programming Laboratory, Siemens Corp.  and the Natural Sciences and Engineering Research Council of Canada.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6152,Techniques for Probabilistic Analysis and Randomness-Efficient Computation,"Randomness is well-recognized as an important computational resource in  theoretical computer science. Not only are there classical problems for which  the only known ""efficient"" solutions are randomized, but there are problems  for which randomness can be used to circumvent deterministic lower bounds.  However, standard tools available for probabilistic analysis such as the  Chernoff-Hoeffding bounds are not sufficiently powerful in all situations;  second, since there are no known ""true"" sources of randomness, there is a  need to develop general techniques for reducing/removing randomness from  randomized algorithms. This thesis addresses these two issues. Certain types of scheduling and resource allocation problems in a distributed  setting can be modeled as edge coloring problems. In Chapter 2, we present a  fast and simple randomized algorithm for edge coloring a graph, in the  synchronous distributed point-to-point model of computation. Our algorithm  computes an edge-coloring of a graph $G$ with $n$ nodes and maximum degree  $\Delta$ with at most $(1.6 + \epsilon) \Delta + O(\log^{2+\delta} n)$ colors  with high probability, for any fixed $\epsilon, \delta, greater than 0$. To analyze our  algorithm, we introduce techniques for proving upper bounds on the tails of  random variables, extending the Chernoff-Hoeffding (CH) bounds to some types  of dependent random variables. This is joint work with A. Panconesi [91].  In Chapter 3, we show that the CH bounds for the tails of the sums of bounded  and independent random variables $X_{1}, \ldots, X_{n}$ require only  limited independence among the $X_{i}$s. We show that if  $X_{1}, \ldots, X_{n}$ lie in [0,1] and are $k$-wise independent, then  $Pr(X \geq E[\sum_{i}X_{i}](1 + \delta))$ can be upper bounded by the CH  bound, if $k \geq \mu \cdot min\{\delta,\delta^{2}\}$. This leads to  algorithms that require a reduced amount of randomness for any analysis which  uses the CH bounds. This is joint work with J.P. Schmidt and A. Siegel [108]. In Chapter 4, we present an $RNC^{2}$ algorithm for the perfect matching  problem which uses $O(\log Z)$ random bits where $Z$ is any given upper bound  on the number of perfect matchings in the graph, generalizing results of  Grigoriev and Karpinski. Underlying our algorithm is a randomness-optimal  generalization of the Isolating Lemma of Mulmuley, Vazirani and Vazirani,  which also leads to other applications. This is joint work with S. Chari and  P. Rohatgi [26].",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6153,Register Renaming and Dynamic Speculation: an Alternative Approach,"In this paper, we present a novel mechanism that implements register  renaming, dynamic speculation and precise interrupts. Renaming of registers  is performed during the instruction fetch stage instead of the decode stage,  and the mechanism is designed to operate in parallel with the tag match logic  used by most cache designs. It is estimated that the critical path of the  mechanism requires approximately the same number of logic levels as the tag  match logic, and therefore should not impact cycle time.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6154,Systems of Set Constraints with Negative Constraints are NEXPTIME-Complete,"A system of set constraints is a system of expressions $E\subseteq F$ where  $E$ and $F$ describe sets of ground terms over a ranked alphabet. Aiken  et al. [AKVW93] classified the complexity of such systems. In [AKW93]  it was shown that if negative constraints $E\not\subseteq F$ were allowed,  then the problem is decidable. This was done by reduction to a Diophantine  problem, the Nonlinear Reachability Problem, which was shown to be decidable. We show that nonlinear reachability is NP-complete. By bounding the  reduction of [AKW93] we conclude that systems of set constraints, allowing  negative constraints, is NEXPTIME-complete.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6155,Schwarz-Christoffel Mapping in the 1980's,"An informal survey is presented of the numerical computation of  Schwarz-Christoffel maps (i.e., conformal maps from a disk in the complex  plane to a polygon) and their applications in science and engineering. It is  shown that many superficially different problems of conformal mapping and  potential theory can be reduced to Schwarz-Christoffel maps and then solved  by software such as the Fortran package SCPACK. This report, not for  publication, is a reproduction of a 1989 technical report from the Department  of Mathematics at the Massachusetts Institute of Technology.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6156,Formalizing Constructive Real Analysis,"This paper arises from a project with the Nuprl Proof Development System  which involved formalizing parts of real analysis, up through the intermediate  value theorem. Extensive development of the rational library was required as  the real library was being built, resulting in the addition of about 125  rational theorems. The real library now contains about 150 theorems and  includes enough basic results that further extensions of the library should be  quite feasible. This paper aims to illustrate how higher mathematics can be  implemented in a system like Nuprl, and also to introduce system users to the  library.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6157,Towards a Theory of Information Invariants for Cooperating Autonomous Mobile Robots,"In [Don4], we described a manipulation task for cooperating mobile robots  that can push large, heavy objects. There, we asked whether explicit local  and global communication between the agents can be removed from a family of  pushing protocols. In this paper, we answer in the affirmative. We do so by  using the general methods of [Don4] analyzing information invariants. We discuss several measures for the information complexity of the task:  (a) How much internal state should the robot retain? (b) How many cooperating agents are required, and how much communication between them is necessary? (c) How can the robot change (side-effect) the environment in order to record state or sensory information to perform a  task? (d) How much information is provided by sensors? and (e) How much  computation is required by the robot? To answer these questions, we develop a  notion of information invariants. We develop a technique whereby one sensor  can be constructed from others by adding, deleting, and reallocating  (a) - (e) among collaborating autonomous agents. We add a resource to  (a) - (e) and ask: (f) How much information is provided by the task  mechanics? By answering this question, we hope to develop information  invariants that explicitly trade-off resource (f) with resources (a) - (e).  The protocols we describe here have been implemented in several different  forms, and we will show a video reporting on experiments to measure and analyze information invariants using a pair of cooperating mobile robots for manipulation experiments in our laboratory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6158,Deriving Incremental Programs,"A systematic transformational approach is given for deriving incremental  programs from non-incremental programs. We exploit partial evaluation, other  static analysis and transformation techniques, and domain-specific knowledge  in order to provide a degree of incrementality not otherwise achievable by a  generic incremental evaluator. Illustrative examples using the transformation  approach are given.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6159,"Centering, Trust Region, Reflective Techniques for Nonlinear Minimization Subject to Bounds","Bound-constrained nonlinear minimization problems occur frequently in  practice. Most existing methods belong to an active set type which can be slow  for large scale problems. Recently, we proposed a new approach [7,6,8] which  generates iterates within the strictly feasible region. The method in [8] is a  trust region type and, unlike the existing trust region method for  bound-constrained problems, the conditions for its strong convergence  properties are consistent with algorithm implementation. A reflective  technique can be included in the method. In this paper, we motivate  techniques which are important for our new approach. Numerical experience on  some medium size problems is included.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6160,On Properties of Random Reductions,"Randomness is widely accepted as a powerful computational resource because  the most elegant and efficient solutions to several computational problems  are randomized. A recurrent theme in the theory of randomized computation is  the notion of a random reduction. Random reductions are similar to many-one  ($\leq^{P}_{m}$) reductions except for the fact that they are carried out by  probablistic transducers which may make errors with small probability. Such  reductions are used explicitly in many basic results in complexity theory and  implicitly in several randomized algorithms. This thesis investigates the properties of random reductions as a tool  towards understanding the power and limitations of randomness. We first prove  some startling results which indicate that random reductions can be quite  successful in reducing harder problems to simpler ones. We then propose the  thesis that in many situations there is a sharp {\em probability threshold}  which governs just how successful random reductions can be in this regard. As  evidence, we prove that for several complexity classes ${\cal C}$, under  standard assumptions, there exist corresponding {\em probability  thresholds\/} ${\cal C}_T$, such that random reductions with success  probability below ${\cal C}_T$ can reduce the hardest languages in ${\cal C}$  to simpler ones but reductions with success probability above ${\cal C}_T$   cannot do so. Based on these thresholds, we then propose a meaningful  definition of completeness under random reductions which resolves several  anomalies caused by the traditional definitions which did not place much  emphasis on the success probability. The results described above depend on standard but unproven  complexity-theoretic assumptions. In order to show that such behavior is  inherent to random reductions and not an artifact introduced by these  assumptions, we also prove that it is present in very high complexity classes  {\em without any assumptions}. In this thesis we also examine other basic  aspects of random reducibility. We prove several {\em absolute} separation  results between the notions of completeness under various polynomial-time  random reductions with different success probabilities and between various  random reductions and deterministic polynomial-time reductions. In addition,  we also prove new results on the consequences of having random reductions  from NP-complete sets to sparse sets.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6161,Robust Characterizations of Polynomials and Their Applications to Program Testing,"The study of self-testing and self-correcting programs leads to the search  for robust characterizations of functions. Here we make this notion precise  and show such a characterization for polynomials. From this characterization,  we get the following three applications: First, we can construct simple and  efficient self-testers for polynomial functions. Secondly, it provides results  in the area of coding theory, by giving extremely fast and efficient  error-detecting schemes for some well known codes. Thirdly, this  error-detection scheme plays a crucial role in recent results on hardness of  approximating some NP-optimization problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6162,The Local Nature of $\Delta$-Coloring and Its Algorithmic Applications,"Given a connected graph $G$ = ($V,E$) with $\mid$V$\mid$ = $n$ and  maximum degree $\Delta$ such that $G$ is neither a complete graph nor an odd  cycle, Brooks' theorem states that $G$ can be colored with $\Delta$ colors.  We generalize this as follows: let $G$ - $v$ be $\Delta$-colored; then,  $v$ can be colored by considering the vertices in an $O$(log$_{\Delta} n$)  radius around $v$ and by recoloring an $O$(log$_{\Delta} n$) length  ""augmenting path"" inside it. Using this, we show that $\Delta$-coloring $G$  is reducible in $O$(log$^{3}$ $n$/log $\Delta$) time to ($\Delta$ + 1)-vertex  coloring $G$ in a distributed model of computation. This leads to fast  distributed algorithms and a linear-processor $NC$ algorithm for  $\Delta$-coloring.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6163,The Definition of Numerical Analysis,This is a brief essay discussing perceptions and misperceptions of numerical  analysis. A common misperception is that numerical analysis is the study of  rounding errors. Even numerical analysts have been misled by this view.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6164,On The Convergence of Reflective Newton Methods for Large-Scale Nonlinear Minimization Subject to Bounds,"We consider a new algorithm, a reflective Newton method, for the problem of  minimizing a smooth nonlinear function of many variables, subject to upper  and/or lower bounds on some of the variables. This approach generates strictly  feasible iterates by following piecewise linear paths (""reflection"" paths)  to generate improved iterates. The reflective Newton approach does not require  identification of an ""activity set"". In this report we establish that the  reflective Newton approach is globally and quadratically convergent. Moreover,  we develop a specific example of this general reflective path approach  suitable for large-scale and sparse problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6165,A Multi-Resolution Technique for Comparing Images Using the Hausdorff Distance,"The Hausdorff distance measures the extent to which each point of a ""model""  set lies near some point of an ""image"" set and vice versa. In this paper we  describe an efficient method of computing this distance, based on a  multi-resolution tessallation of the space of possible transformations of the  model set. We focus on the case in which the model is allowed to translate  and scale with respect to the image. This four-dimensional transformation  space (two translation and two scale dimensions) is searched rapidly, while  guaranteeing that no match will be missed. We present some examples of  identifying an object in a cluttered scene, including cases where the object  is partially hidden from view.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6166,An Interior Newton Method for Quadratic Programming,"Quadratic programming represents an extremely important class of optimization  problem. In this paper, we propose a new (interior) approach for the general  quadratic programming problem. We establish that our new method is globally  and quadratically convergent - published alternative interior approaches do  not share such strong convergence properties for the nonconvex case. We also  report on the results of preliminary numerical experiments: the results  indicate that the proposed method has considerable practical potential.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6167,An Algorithm for Processing Program Transformations,An algorithm for processing program transformations as described by the  transform construct is presented. The algorithm constructs a coordinate  transformation of an abstract program based on a set of transforms and  transform directives applied to it.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6168,A Response to Cheriton and Skeen's Criticism of Causal and Totally Ordered Communication,No abstract supplied.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6169,An Accelerated Interior Point Method Whose Running Time Depends Only on $A$,"We propose a ""layered-step"" interior point (LIP) algorithm for linear  programming. This algorithm follows the central path, either with short steps  or with a new type of step called a ""layered least squares"" (LLS) step. The  algorithm returns the exact global minimum after a finite number of  steps-in particular, after $O(n^{3.5}c(A))$ iterations, where $c(A)$ is a  function of the coefficient matrix. The LLS steps can be thought of as  accelerating a path-following interior point method whenever  near-degeneracies occur. One consequence of the new method is a new  characterization of the central path: we show that it composed of at most  $n^2$ alternating straight and curved segments. If the LIP algorithm is  applied to integer data, we get as another corollary a new proof of a  well-known theorem by Tardos that linear programming can be solved in  strongly polynomial time provided that $A$ contains small-integer entries.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6170,Computing the Newtonian Graph (Extended abstract),"A polynomial $f\in \complex[z]$ defines a vector field $N_f(z) =   -f(z)/f'(z)$ on $\complex$.  Certain degenerate curves of flow in   $N_f$ give the edges of the Newtonian graph, as defined by   \cite{Sma85}.  These give a relation between the roots of $f$ and   $f'$, much similar to the linear order, when $f$ has real roots   only.    We give a purely algebraic algorithm to compute the Newtonian   graph and the basins of attraction in the Newtonian field.  The   resulting structure can be used to query whether two points in   $\complex$ are within the same basin of attraction.  This gives   us an algebraic approach to root-finding using Newton's method.   This method extends to rational functions and more generally to   any functions on $\complex$ whose flow is algebraic over   $\complex(e)$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6171,Implementing File Systems and Object Databases in a Microstorage Architecture,"A microstorage architecture consists of a microstorage kernel and  several storage servers. Each storage server implements a storage model that  defines a client's view of all the data in the system, how it is stored,  retrieved and manipulated. The storage servers are built on top of the  microstorage kernel and rely on it to perform the actual data storage and  retrieval. The microstorage kernel implements a mechanism and the storage  servers each implement specific policies defined by their storage models.  Several different storage servers, each implementing a different storage  model, may run concurrently over the microstorage kernel and all data in the  system is concurrently visible to all the different storage servers. Different  application programs, or different parts of the same application program, can  use different storage models to manipulate the same data. Microstorage  architectures provide a flexible interface and a smooth transition from  traditional file systems to more powerful object oriented storage models.  Existing applications continue to work correctly unchanged because they use a  storage server that implements a traditional file model while new applications  may gradually adopt more powerful storage models.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6172,An Algorithm for the Newton Resultant,"Given a system of $n+1$ generic Laurent polynomials, for $i \,=\, 1, \ldots, n+1$, $$\eqlabel(\InputSystem) f_i(\x) \quad = \quad \sum_{q\in \A_i} c_{iq} \,x^q; \qquad    q \,=\, (q_1,\ldots,q_n); \qquad \x^q \,=\, x_1^{q_1}x_2^{q_2}\cdots x_n^{q_n}; \eqno(\InputSystem) $$ with (finite) support sets $\A_i \subset L$, where $L$ is some affine lattice isomorphic to $\Z^n$; we consider algorithms for the {\it Newton resultant} $R(f_1,f_2, \ldots, f_{n+1})$.  This is the unique (up to sign) irreducible polynomial with coefficients in $\Z$ and monomials in the $c_{iq}$ which determines whether or not system~(\InputSystem) has common roots in the {\it algebraic torus} $(\C-\{0\})^n$.  The resultant depends only on the {\it Newton polytopes} $N_i \,:=\, conv(\A_i) \subset \R^n$ of the sets $\A_i$. Our terminology emphasizes the dependence on the combinatorics of the Newton polytopes.  The algebraic torus is the natural setting for us because we are interested in the properties of systems of polynomials which are invariant under symmetries of the affine lattice $L$, and translation by $q\in L$ corresponds to multiplication by $x^q$ at the level of polynomials.  Since $x^q$ may have negative exponents, we restrict to points none of whose coordinates are zero.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6173,Towards Accurate and Efficient Volume Rendering,"This thesis is concerned with improvements to algorithms for volume  rendering; a technique that provides scientists with the means for visual  exploration of three-dimensional data. Despite its numerous successes, and  its increasing use within the scientific community, state-of-the-art volume  rendering algorithms have many shortcomings. Difficulties include: ensuring  the accuracy of the rendered images, producing images with modest  computational resources, and rendering the diverse types of data that are  currently being produced. The work in this thesis was motivated by the demands of an ongoing visualization project in four-dimensional cardiac visualization. We present  solutions to some key problems in ensuring accuracy and in producing  algorithms that can scale to handle large datasets. Although the theoretical  work in this thesis applies to arbitrary data topologies, our implementations  have assumed that the data is defined by sample points on a regular  rectilinear grid. In the area of accuracy, we focus on the error that is introduced during  volume projection. This phase of the volume rendering process involves the  evaluation of the emission-absorption volume rendering line integral. This  thesis presents four techniques for controlled precision volume integration.  These schema depart from existing approaches in that they provide error  bounds along with the solutions they generate. In each case,  the error  analysis leads to an algorithm for evaluating the integral to any specified  tolerance. Our investigations into efficiency issues have resulted in two advances.  First, an adaptive error bracketing scheme is presented that builds on  the controlled precision volume integration methods. Using adaptive error  bracketing, the solution for a viewing ray is continually refined until a  user-specified error tolerance is met. The algorithm allows processing of the  data without imposing a strict front-to-back or back-to-front evaluation  order. Second, a suite of tools are presented that can be used to efficiently  compute perspective projections of volume data. These include a paging  strategy that is useful when a dataset is too large to fit into RAM memory  and a ray splitting technique for adaptive supersampling. The latter  technique ensures that all data features contribute to the final image while  avoiding overcomputation in regions close to the eyepoint.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6174,Developing Efficient Interpreters Based on Formal Language Specifications,"The paper reports on extensions to the MAX system enabling the generation and  refinement of interpreters based on formal language specifications. In these  specifications, static semantics is defined by an attribution mechanism that  allows to enrich syntax trees by control flow graphs. The dynamic semantics is  defined by evolving algebras, a framework that has been successfully used to  specify realistic programming languages. We apply the combined framework to a non-trivial example language and show how  the resulting language specification can be refined in order to improve the  efficiency of the generated interpreters. The framework provides enough  modularity and flexibility so that such refinements can be carried out by  local changes. We explain the implementation of the extensions to MAX and  discuss applications of the system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6175,Interprocedural Data Flow Analysis Based on Temporal Specifications,"This paper investigates the specification of data flow problems by temporal  logic formulas and proves fixpoint analyses correct. Temporal formulas are  interpreted w.r.t. programming language semantics given in the framework of  evolving algebras. This enables very high-level specifications, in particular  for history sensitive problems. E.g. the classical bit vector analyses can be  refined by using information about conditions in branches without having to  change their specifications. The general semantics framework makes the  approach directly applicable to realistic programming languages. We use the specifications to prove fixpoint implementations of data flow  analyses correct. As an example, we develop a powerful interprocedural  deadness analysis that uses constant information depending on the context  where the active procedure was called. By proving such a combination of  backward and forward analyses correct, we illustrate the use of specifications  in correctness proofs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6176,Condition Numbers for Polyhedra with Real Number Data,"We develop a condition-based complexity analysis for homogenous polyhedra  with real number data. We analyze the dependency of primal-dual interior point  algorithm efficiency on this condition number for finding a point in a  polyhedron. Key Words: polyhedron, interior point algorithms, condition-based  complexity.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6177,Good Features to Track,"No feature-based vision system can work until good features can be identified  and tracked from frame to frame. Although tracking itself is by and large a  solved problem, selecting features that can be tracked well and correspond to  physical points in the world is still an open problem. We propose a feature  selection criterion that is optimal by construction because it is based on how  the tracker works, as well as a feature monitoring method that can detect  occlusions, disocclusions, and features that do not correspond to points in  the world. These methods are based on a new tracking algorithm that extends  previous Newton-Raphson style search methods to work under affine image  transformations. We test performance with several simulations and experiments  on real images.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6178,Pictures and Trails: A New Framework for the Computation of Shape and Motion from Perspective Image Sequences,"This report presents a new framework for the computation of shape and motion  from a sequence of images taken under perspective projection. The framework  is based on two abstractions, the picture and trail loci, that  represent respectively the set of all pictures of the same scene and the set  of all trails that a point in the world can leave on the image for a given  camera trajectory. These abstractions lead to a remarkably clean relation  between perspective and orthography. Furthermore, image motion is described in  terms of angles between projection rays, thereby eliminating the need to  model camera rotation and leading to more stable results. A numerically sound,  global minimization method is developed, based on this framework, for the case  of a two-dimensional world, but all concepts also hold in three dimensions.  Experiments show that the method is rather immune to noise but critically  dependent on camera calibration.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6179,AML: Attribute Grammars in ML,"Attribute grammars are a valuable tool for constructing compilers and  building user interfaces. This paper reports on a system we are developing,  called AML (for Attribution in ML), which is an attribute grammar  toolkit for building such applications as language-based programming  environments using SML. This system builds on the proven technology of  efficient attribute evaluation, while using a higher-level foundation for the  implementation of interactive systems. It supports a general and uniform  platform for building applications that can manipulate attributed terms and  allow access to attribute values. We describe the design of the AML system,  its current implementation status, and our plans for the future.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6180,On the Intellectual Terrain Around NP,"In this paper, we view $P \stackrel{?}{=} NP$ as the problem which symbolizes  the attempt to understand what is and what is not feasibly computable. The  paper shortly reviews the history of the developments from Godel's 1956  letter asking for the computational complexity of finding proofs of theorems,  through computational complexity, the exploration of complete problems for NP  and PSPACE, through the results of structural complexity to the recent  insights about interactive proofs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6181,Real-Time System = Discrete System + Clock Variables,"How can we take a programming language off the shelf and upgrade it into  a real-time programming language? Programs such as device drivers and plant  controllers must explicitly refer and react to time. For this purpose, a  variety of language constructs-including delays, timeouts, and watchdogs-has  been put forward. We advocate an alternative answer, namely, to designate  certain program variables as clock variables. The value of a clock variable  changes as time advances. Timing constraints can be expressed, then, by  conditions on clock values. A single new language construct-the guarded wait  statement-suffices to enforce the timely progress of a program. Our presentation proceeds in two steps. First, we extend untimed systems  (Section 1) with clock variables (Section 2); then we introduce the guarded  wait statement (Section 3). The usage of clock variables and the guarded wait  statement is illustrated with real-time applications such as round-robin  (timeout-driven) scheduling, priority (interrupt-driven) scheduling, and  embedded process control (Section 4). Indeed, clock variables generalize  naturally to variables that measure environment parameters other than time  (Section 5). In keeping with an expository style, all references are  clustered in bibliographic remarks at the end of each section. We conclude by  pointing to selected literature on formal methods and support tools for our  approach to real-time programming (Section 6).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6182,Symbolic Model Checking for Real-Time Systems,"We describe finite-state programs over real-numbered time in a guarded-command  language with real-valued clocks or, equivalently, as finite automata with  real-valued clocks. Model checking answers the question which states of a  real-time program satisfy a branching-time specification (given in an  extension of CTL with clock variables). We develop an algorithm that computes  this set of states symbolically as a fixpoint of a functional on state  predicates, without constructing the state space. For this purpose, we introduce a $\mu$-calculus on computation trees over  real-numbered time. Unfortunately, many standard program properties, such as  response for all nonzero execution sequences (during which time diverges),  cannot be characterized by fixpoints: we show that the expressiveness of the  timed $\mu$-calculus is incomparable to the expressiveness of timed CTL.  Fortunately, this result does not impair the symbolic verification of  ""implementable"" real-time programs-those whose safety constraints are  machine-closed with respect to diverging time and whose fairness constraints  are restricted to finite upper bounds on clock values. All timed CTL  properties of such programs are shown to be computable as finitely  approximable fixpoints in a simple decidable theory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6183,Detecting Moving Objects With a Moving Camera by Comparing Edge Contours,"This paper introduces a method for detecting moving objects in a monocular  image sequence that is obtained using a moving camera. The method first  estimates the motion of the edge contours in a given image frame, by  recovering a transformation that best matches each edge contour with the edges  in the subsequent frame. Any contour that is not well accounted for by a  single transformation is split into subparts. The transformation of each edge  contour together with the relative spatial locations of the contours is used  to partition the image into regions with similar motions. Hypotheses about the  locations of possible moving objects are then made based on these motion  regions. One of the key aspects of the approach is that it is based on  estimating the motion of entire edge contours, as opposed to recovering a  velocity field that measures the motion of individual points. We present some  examples for image sequences taken of animate objects using a hand-held video  camera. Keywords: Motion estimation, motion segmentation, edge matching.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6184,Chain Models and Finite Element Analysis,"Algebraic-topological chains defined over finite cell complexes have been  proposed as a uniform computational means of representing physical objects,  systems and properties. In this article, we introduce CHAINS, an  algebraic-topological computer language for representing and computing the  properties of a wide variety physical systems. In particular, we develop a  CHAINS program that implements a finite element approximation to linear  elasticity. In the process we illustrate the relationship between finite  element analysis and the chain models methodology, showing that while finite  element analysis is a specific numerical approximation scheme, CHAINS is a  computer language for specifying and representing a variety of physical  systems and approximations, of which finite element computations are one  example.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6185,Visually-Guided Navigation by Comparing Two-Dimensional Edge Images,"We present a method for navigating a robot from an initial position to a  specified landmark in its visual field, using a sequence of monocular images.  The location of the landmark with respect to the robot is determined using  the change in size and location of the landmark in the image, as a function of  the motion of the robot. The landmark location is estimated after the first  three images are taken, and this estimate is refined as the robot moves. The  method can correct for errors in the robot motion, as well as navigate around  obstacles. The obstacle avoidance is done using bump sensors, sonar and dead  reckoning, rather than visual servoing. The method does not require prior  calibration of the camera. We show some examples of the operation of the  system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6186,Audio System for Technical Readings,"The advent of electronic documents makes information available in more than  its visual form - electronic information can now be display-independent. We  describe a computing system, ASTER, that audio formats electronic  documents to produce audio documents. ASTER can speak both literary texts  and highly technical documents (presently in LaTeX) that contain  complex mathematics. Visual communication is characterized by the eye's ability to actively access  parts of a two-dimensional display. The reader is active, while the display is  passive. This active-passive role is reversed by the temporal nature of oral  communication: information flows actively past a passive listener. This  prohibits multiple views - it is impossible to first obtain a high-level view  and then ""look"" at details. These shortcomings become severe when presenting  complex mathematics orally. Audio formatting, which renders information structure in a manner attuned to  an auditory display, overcomes these problems. ASTER is interactive, and the  ability to browse information structure and obtain multiple views enables  active listening.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6187,Algorithmic Investigations in P-Adic Fields,"This thesis is concerned with algorithmic investigations in p-adically closed  fields, of which Hensel's field of p-adic numbers is prototypical. The well  known analogies between the field of real numbers and the field of p-adic  numbers are supplemented from a computational standpoint. We resolve the complexity of the Decision Problem for Fields in the p-adic  case. We work in the new $n$th power formalism for p-adic fields where the  correspondence to the reals is most transparent. First we give an alternating  exponential time algorithm for deciding linear sentences in the theory of  p-adically closed fields. This also translates into a deterministic algorithm  running in exponential space or double exponential time. A deterministic  quantifier-elimination procedure for the linear fragment running in double  exponential time and space is also presented. Next we employ a quantitative  version of a Cell Decomposition Lemma due to Denef to give an alternating  exponential time decision procedure for the full theory. As usual this also  yields a deterministic decision procedure running in double exponential time  or in exponential space, and a quantifier elimination procedure running in  double exponential time and space. These complexity bounds are demonstrated  to be essentially optimal by proving matching lower bounds on the respective  problems. We give a simple algorithm to determine all roots among the p-adic integers  of a given polynomial equation. This algorithm is a purely symbolic (as  opposed to numerical) p-adic version of the classical Newton and Horner  iteration methods and has a natural parallel implementation. We also give  algorithms for some problems in valued fields and in p-adic semi-algebraic  geometry. Finally we give some additional elementary evidence to support the thesis  that certain cosets of $n$th powers are the proper p-adic analogues to signs  in the real case. This is done by showing that these coset representatives  display similar behavior with respect to functions and their derivatives, as  do the signs in the real case.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6188,A Generalization of Brooks' Theorem,"Given a connected graph $G = (V, E)$ with $n$ vertices and maximum degree  $\Delta$ such that $\Delta \geq$ 3 and $G$ is not a complete graph, Brooks'  theorem shows that $G$ is $\Delta$-colorable. We prove a generalization of  this theorem: assume inductively that all but one vertex $v$ is colored;  then, $v$ can be colored by considering the vertices (and their colors)  in just an $O$ (log $n$) radius around $v$. Our proof uses a probabilistic  technique to link the connectivity and diameter of ""almost-regular"" graphs,  which could have other applications too.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6189,A Reflective Newton Method for Minimizing a Quadratic FunctionSubject to Bounds on Some of The Variables.,"We propose a new algorithm, a reflective Newton method, for the minimization  of a quadratic function of many variables subject to upper and lower bounds  on some of the variables. The method applies to a general (indefinite)  quadratic function, for which a local minimizer subject to bounds is required,  and is particularly suitable for the large-scale problem. Our new method  exhibits strong convergence properties, global and quadratic convergence, and  appears to have significant practical potential. Strictly feasible points are  generated. Experimental results on moderately large and sparse problems  support the claim of practicality for large-scale problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6190,Tracking Non-Rigid Objects in Complex Scenes,"We consider the problem of tracking non-rigid objects moving in a complex  scene. We describe a model-based tracking method, in which two-dimensional  geometric models are used to localize an object in each frame of an image  sequence. The basic idea is to decompose the image of a solid object moving in  space into two components: a two-dimensional motion and a two-dimensional  shape change. The motion component is factored out, and the shape change is  represented by explicitly storing a sequence of two-dimensional models, one  corresponding to each image frame. The major assumption underlying the method  is that the two-dimensional shape of an object will change slowly from one  frame to the next. There is no assumption, however, that the two-dimensional  image motion in successive frames will be small. Thus, the method can track  objects that move arbitrarily far in the image from one frame to the next.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6191,Reasoning About Programs by Exploiting the Environment,A method for making aspects of a computational model explicit in the formulas  of a programming logic is given. The method is based on a new notion of  environment -- an environment augments the state transitions defined by a  program's atomic actions rather than being interleaved with them. Two simple  semantic principles are presented for extending a programming logic in order  to reason about executions feasible in various environments. The approach is  illustrated by (i) discussing a new way to reason in TLA and Hoare-style  programming logics about real-time and by (ii) deriving the first TLA and  Hoare-style proof rules for reasoning about schedulers.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6192,Decomposition of Algebraic Functions,"Functional decomposition--whether a function $f(x)$ can be written as a  composition of functions $g(h(x))$ in a nontrivial way--is an important  primitive in symbolic computation systems. The problem of univariate  polynomial decomposition was shown to have an efficient solution by Kozen and  Landau [8]. Dickerson [5] and von zur Gathen [11] gave algorithms for certain  multivariate cases. Zippel [13] showed how to decompose rational functions. In this paper, we address the issue of decomposition of algebraic functions.  We show that the problem is related to univariate resultants in algebraic  function fields, and in fact can be reformulated as a problem of resultant  decomposition. We give an algorithm for finding a nontrivial decomposition of  a given algebraic function if it exists. The algorithm involves genus  calculations and constructing transcendental generators of fields of genus  zero.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6193,A New Approach to Teaching Mathematics,"We propose a new approach to teaching discrete math: First, teach logic as a  powerful and versatile tool for discovering and communicating truths; then  use this tool in all other topics of the course. We spend 6 weeks teaching an  equational style of propositional and predicate calculus, thereby ensuring  that students gain a fluency in logical notation and some skill in its use.  We teach basic heuristics for developing proofs, and we relate such proofs to  more common informal proofs in mathematics. Then, we use logic extensively  and rigorously in teaching topics like set theory,  relations and functions,  a theory of integers, induction, combinatorics, and solving recurrence  relations. Success in teaching logic as a tool means that students lose their fear of  mathematics and formalism, gain a positive view of rigorous proofs, learn to  appreciate the use of syntactic manipulation, and begin using logic in other  areas of study. Our experiences in teaching discrete math at Cornell shows that such success is possible.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6194,Improved Data Structures for Fully Dynamic Biconnectivity,"We present fully dynamic algorithms for maintaining the biconnected components  in general and plane graphs. A fully dynamic algorithm maintains a graph during a sequence of insertions  and and deletions of edges or isolated vertices. Let $m$ be the number of  edges and $n$ be the number of vertices in a graph. The time per operation of  the best known algorithms are $O(\sqrt{n})$ in general graphs and $O(\log n)$  in plane graphs for fully dynamic connectivity and $O(\min\{m^{2/3}, n\})$ in  general graphs and $O(\sqrt{n})$ in plane graphs for fully dynamic  biconnectivity. We improve the later running times to $(\min\{\sqrt{m}\log n, n \})$ in general graphs and $O(\log^{2}n)$ in plane graphs. Our algorithm for  general graphs can also find the biconnected components of all vertices in  time $O(n)$. The update times in general graphs are amortized. This shows that  the biconnected components of a graph can be dynamically maintained almost as  efficiently as the connected components.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6195,Simulating Fail-Stop in Asynchronous Distributed Systems,"The fail-stop failure model appears frequently in the distributed systems  literature. However, in an asynchronous distributed system, the fail-stop  model cannot be implemented. In particular, it is impossible to reliably  detect crash failures in an asynchronous system. In this paper, we show that it is possible to specify and implement a failure  model that is indistinguishable from the fail-stop model from the point of  view of any process within an asynchronous system. We give necessary  conditions for a failure model to be indistinguishable from the fail-stop  model, and derive lower bounds on the amount of process replication needed to  implement such a failure model. We present a simple one-round protocol for  implementing one such failure model, which we call simulated fail-stop.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6196,Faster SVD for Matrices with Small $m/n$,"The singular values of a matrix are conventionally computed using either the  bidiagonalization algorithm by Golub and Reinsch (1970) when $m/n less than 5/3$, or  the algorithm by Lawson and Hanson (1974) and Chan (1982) when $m/n greater than 5/3.$  However, there is an algorithm that is faster and that does not involve a  discontinuous choice, as follows: in all cases, perform a QR factorization as  in Lawson-Hanson-Chan, but rather than do this right at the beginning, do it  after zeros have already been introduced in the first $j = 2n - m$ rows and  columns. The same technique applies when computing singular vectors, with one small  modification. If left singular vectors are needed, the new algorithm becomes  advantageous only when $m greater than 1.2661n$, and the best $j$ in this case is  $3n - m$. The benefits of the new algorithm appear in terms of classical scalar  floating-point operation counts; the effects of locality and parallelization  are not considered in the analysis.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6197,"Teaching Math More Effectively, Through the Design of Calculational Proofs","Lower-level college math courses usually avoid using formalism, in both  definitions and proofs. Later, when students have mastered definitions and  proofs written largely in English, they may be shown how informal reasoning  could be formalized, but the impression is left that such formalization would  not be worth the effort. The design of proofs is also not taught. Students see  proofs and may be asked to develop a few themselves, but there is little or no  discussion of principles or strategies for designing proofs. Few are happy with the results of these courses. Generally, students'  reasoning abilities are poor, even after several math courses. Many students  still fear math and notation, and the development of proofs remains a mystery  to most. In short, students are not being equipped with the tools needed to  employ mathematics in solving new problems. We believe that this statee of affairs can be improved. This article describes  our approach.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6198,Empirical Evidence of the Chaotic Behavior of the Hopfield-Tank TSP Model,"Since its introduction, the Hopfield-Tank model for the Traveling Salesman  Problem (TSP) has been surrounded by controversial evidence regarding its  viability as a model and its capabilities to produce good results to this hard  optimization problem. In this paper we investigate the reasons behind the  difficulty of obtaining verifiable results and the viability of the model, by  investigating the behavior the Hopfield-Tank neural network for the TSP has in  circumstances when it is expected to produce identical tours. Our  investigations strongly suggest that, when it is expected from the network to  converge in a predetermined tour, the neural network converges to almost  all possible tours when an insignificant perturbation to the initial  conditions is applied. The overall consequence of our findings regarding the  viability of the Hopfield-Tank model and the cause of the controversy  surrounding the Hopffield-Tank model for the TSP can be summarized by the following: The cause of the Hopfield-Tank neural network for the TSP  controversy and the difficulties in reproducing results is the chaotic  behavior of the model. The finding of useful results for the TSP using the  Hopfield-Tank network are purely casual and not to be attributed to the  viability of the model. In essence the Hopfield-Tank neural network for the  TSP is as viable as chaotic systems can be.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6199,Refinement for Fault-Tolerance: An Aircraft Hand-off Protocol,"Part of the Advanced Automation System (AAS) for air-traffic control is a  protocol to permit flight hand-off from one air-traffic controller to another.  The protocol must be fault-tolerant and, therefore, is subtle--an ideal  candidate for the application of formal methods. This paper describes a formal  method for deriving fault-tolerant protocols that is based on refinement and  proof outlines. The AAS hand-off protocol was actually derived using this  method; that derivation is given.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6200,A protocol and server for a distributed digital technical reportlibrary,"This paper describes {\bf Dienst} -- a Distributed Interactive Extensible Network Server for Techreports.  The Dienst protocol is based on the  World Wide Web protocol HTTP, and provides an object-oriented interface to a document model.  The document model allows one to access the document as a whole or by named sub-parts and it supports multiple formats for the document.  We have also implemented a gateway from a Web server that supports the Dienst protocol. Using a World Wide Web client (e.g. Mosaic), a user may search for documents at distributed sites, browse ""thumbnail"" (very small page) images, view the full documents, and print them.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6201,Systems Research in the Age of On-Line Coffee Houses,"For years, we have spoken of a golden era where high performance  ""super-computers"" will be available in local department stores and we will  be able to communicate with anyone and any organization we want via computer  networks. In the past, we have whimsically said that in this era, computing  systems will be used in dramatically different fashion than they are today.  That era is here now, with 60-80Mips computers available in local computer  shops, ""on-line"" coffee houses springing up in trendy neighborhoods and  National Public Radio broadcasting on the Internet for almost a year. And yet,  the way we used computers has not changed dramatically. Clearly, improved speech understanding and generation systems, vision systems  and other sophisticated I/O technologies will change our interaction with  computers. What will change the content of our interaction with computers?  What type of systems research will enable revolutionary changes in the use of  computers? In an attempt to provoke discussion about these topics, a talk was presented  several times during the spring semester 1994. A slightly different approach  to systems research was presented as well as a few new directions that are  being undertaken at Cornell. Hopefully, the ideas and questions raised by this  presentation will be of use to others. This technical report is rather rough and disorganized, consisting as it does  of slides from those talks and textual commentary. I felt it more valuable to  make the material available in a timely manner than to wait until the details  had been worked out, and the prose polished. It is an experiment and I am  interested in the reaction any readers have to this form of presentation. You  can also view a World Wide Web version of this document in: http://simlab.cs/cornell.edu/slides/systems/overview/html I am interested in any comments you might have, both on the content of this  report and how it is presented. Please send them to: rz@cs.cornell.edu.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6202,Lower Bounds for Dynamic Connectivity Problems in Graphs,"We prove lower bounds on the complexity of maintaining fully dynamic $k$-edge  or $k$-vertex connectivity in plane graphs and in $(k-1)$-vertex connected  graphs. We show an amortized lower bound of $\Omega(\log n/k(\log\log n  +  \log b))$ per edge insertion or deletion or per query operation in the cell  probe model, where $b$ is the word size of the machine and $n$ is the number  of vertices in $G$. We also show an amortized lower bound of  $\Omega(\log n/(\log\log n  + \log b))$ per operation for fully dynamic  planarity testing in embedded graphs. These are the first lower bounds for  dynamic connectivity problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6203,Logical Aspects of Set Constraints,"Set constraints are inclusion relations between sets of ground terms over a  ranked alphabet. They have been used extensively in program analysis and type  inference. Here we present an equational axiomatization of the algebra of set  constraints. Models of these axioms are called termset algebras. They  are related to the Boolean algebras with operators of Jonsson and Tarski. We  also define a family of combinatorial models called topological term  automata, which are essentially the term automata studied by Kozen, Palsberg,  and Schwartzbach endowed with a topology such that all relevant operations are  continuous. These models are similar to Kripke frames for modal or dynamic  logic. We establish a Stone duality between termset algebras and topological  term automata, and use time to derive a completeness theorem for a related  multidimensional modal logic. Finally, we prove a small model property by  filtration, and argue that this result contains the essence of several  algorithms appearing in the literature on set constraints.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6204,Schwarz-Christoffel Toolbox User's Guide,"The Scwarz-Christoffel Toolbox (SC Toolbox) is a collection of files for the  interactive computation and visualization of Schwarz-Christoffel conformal  maps in MATLAB version 4. The toolbox is a descendant of SCPACK, a Fortran  package developed by L. N. Trefethen in the early 1980's [9]. However, the SC  Toolbox has been written entirely in the MATLAB language, requires no  programming by the user, and has many capabilities not in SCPACK.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6205,Verifying Programs That Use Causally-Ordered Message-Passing,"We give an operational model of causally-ordered message-passing primitives.  Based on this model, we formulate a Hoare-style proof system for  causally-ordered delivery. To illustrate the use of this proof system and to  demonstrate the feasibility of applying invariant-based verification  techniques to algorithms that depend on causally-ordered delivery, we verify  an asynchronous variant of the distributed termination detection algorithm of  Dijkstra, Feijen, and van Gasteren.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6206,A Group Communication Approach for Mobile ComputingMobileChannel: an ISIS Tool for Mobile Services,"This paper examines group communication as an infrastructure to support  mobility of users, and presents a simple scheme to support user mobility by  means of switching a control point between replicated servers. We describe the  design and implementation of a set of tools, called MobileChannel, for use  with the ISIS system. MobileChannel is based on a combination of the two  replication schemes: the primary-backup approach and the state machine  approach. MobileChannel implements a reliable one-to-many FIFO channel, in  which a mobile client sees a single reliable server; servers, acting as a  state machine, see multicast messages from clients. Migrations of mobile  clients are handled as an intentional primary switch, and hands-offs or server  failures are completely masked to mobile clients. To achieve high performance,  servers are replicated at a sliding-window level. Our scheme provides a  simple abstraction of migration, eliminates complicated hand-off protocols,  provides fault-tolerance and is implemented within the existing group  communication mechanism.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6207,A Modular Approach to Fault-Tolerant Broadcasts and Related Problems,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6208,The Weakest Failure Detector for Solving Consensus,"We determine what information about failures is necessary and sufficient to  solve Consensus in asynchronous distributed systems subject to crash failures.  In [CT91], we proved that $\Diamond\cal W$, a failure detector that provides  surprisingly little information about which processes have crashed, is  sufficient to solve Consensus in asynchronous systems with a majority of  correct processes. In this paper, we prove that to solve Consensus, any  failure detector has to provide at least as much information as  $\Diamond\cal W$. Thus, $\Diamond\cal W$ is indeed the weakest failure  detector for solving Consensus in asynchronous systems with a majority of  correct processes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6209,A Globally Convergent Method for Nonlinear Programming,"Recently developd Newton and quasi-Newton methods for nonlinear programming  possess only local convergence properties. Adopting the concept of the damped  Newton method in unconstrained optimization, we propose a stepsize procedure  to maintain monotone decrease of an exact penalty function. In so doing, the  convergence of the method is globalized.  Keywords: nonlinear programming, global convergence, exact penalty function.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6210,The Sensitivity of the Matrix Exponential,"In this paper we examine how the matrix exponenetial $e^{At}$ is affected by  perterbations in A. Elementary techniques using log norms and the Jordan and  Schur factorizations indicate that $e^{At}$ is least sensitive when A is  normal. Through the formulation of an exponential condition number, insight  is gained into the connection between the condition of the eigensystem of A  and the sensitivity of $e^{At}$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6211,Analyzing Teams of Cooperating Mobile Robots,"In [Don4], we described a manipulation task for cooperating mobile robots that  can push large, heavy objects. There, we asked whether explicit local and  global communication between the agents can be removed from a family of  pushing protocols. In this paper, we answer in the affirmative. We do so by  using the general methods of [Don4] analyzing information invariants. We  discuss several measures for the information complexity of the task of pushing  with cooperating mobile robots, and we present a methodology for creating new  manipulation strategies out of existing ones. We develop and analyze  synchronous and asynchronous manipulation protocols for a small team of  cooperating mobile robots that can push large boxes. The protocols we describe  have been implemented in several forms on the Cornell mobile robots in our  laboratory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6212,Optimal Primary-Backup Protocols,"We give primary-backup protocols for various models of failure. These  protocols are optimal with respect to degree of replication, failover time,  and response time to client requests.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6213,Selective Use of Full-Text Databases,"Large files of natural-language text are now available for automatic  processing in machine readable form. Such text files may include documents  of textbook size, medium-size newspaper articles and short messages and mail  items, and the subject matter may be effectively unrestricted. Typically, the  stored material is not meant to be read sequentially from beginning to end.  Instead, a selective, diagonal reading strategy may be preferred which skips  among the text sections and paragraphs in accordance with individual user  needs. Methods are described in this study for analyzing text files covering  arbitrary subject matter, constructing links among text segments of varying  size in accordance with computed similarities between texts and defining text  traversal paths that are responsive to particular user needs. Such selective  text traversal is useful in retrieving information from textbooks and  instruction manuals and in consulting dictionaries, encyclopedias and other  collections of text items. Topics: Hypertext construction, automatic text linking, selective text  utilization, diagonal text traversal.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6214,Algorithms for On-Line Navigation,"We consider a number of problems faced by a robot trying to navigate inside  a simple polygon. Such problems are ""on-line""g in the sense that the robot  does not have access to the map of the polygon; it must make decisions as it  proceeds, based only on what it has seen so far. Specifically, we examine  algorithms for the related problems of exploration and search. We present a  5/4-competitive randomized algorithm for exploring a rectilinear polygon; the  only privious work here is the deterministic 2-competitive algorithm claimed  in Deng, Kameda and Papadimitrou. For the problem of searching for a  distinguished point in a polygon, we give a $\sqrt{3}$-competitive algorithm  for traversing a street, which improves on a result of Klein by more  than a factor of 3. Finally, the techniques we use in exploration and the  construction of search patterns are combined to give an algorithm for  searching an arbitrary and unknown rectilinear polygon; here, no constant  competitive ratio can be achieved, but our algorithm is within a constant  factor of optimal in the worst case.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6215,Relational Constraint: A Fast Semantic Analysis Technique,"Relational constraint is a new method for fast semantic analysis of  computer programs. It starts with a fixed, finite vocabulary of binary  relations; for each data type this vocabulary forms a complete lattice.  Relational constraint focuses on strengthening relations in this lattice,  developing the strongest correct statement it can about the relation between  any two objects in its universe. The relational constraint algorithm runs in  $O(n^{2})$ time. In this paper, we discuss the motivation for this research,  present the algorithm in detail, and show how it fits in the formal framework  of abstract interpretation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6216,Information Invariants for Distributed Manipulation,"In [Don4], we described a manipulation task for cooperating mobile robots that  can push large, heavy objects. There, we asked whether explicit local and  global communication between the agents can be removed from a family of  pushing protocols. In this paper, we answer in the affirmative. We do so by  using the general methods of [Don4] analyzing information invariants. We discuss several measures for the information complexity of the task: (a)  How much internal state should the robot retain? (b) How many cooperating  agents are required, and how much communication between them is necessary?  (c) How can the robot change (side-effect) the environment in order to record  state or sensory information to perform a task? (d) How much information is  provided by sensors? and (e) How much computation is required by the robot? To  answer these questions, we develop a notion of information invariants. We  develop a technique whereby one sensor can be constructed from others by  adding, deleting, and rellocating (a) - (e) among collaborating autonomous  agents. We add a resource to (a) - (e) and ask: (f) How much information is  provided by the task mechnics? By answering this question, we hope to develop  information invariants that explicitly trade-off resource (f) with resources  (a) - (e). The protocols we describe here have been implemented in several  different forms, and report on experiments to measure and analyze information  invariants using a pair of cooperating mobile robots for manipulation  experiments in our laboratory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6217,The Lambda Loop Transformation Toolkit (User's Reference Manual),"Loop transformations are becoming critical to exploiting parallelism and data  locality in parallelizing and optimizing compilers. This document describes  the Lambda loop transformation toolkit, an implementation of the non-singular  matrix transformation theory, which can represent any linear one-to-one  transformation. Lambda has a simple interface, and is independent of any compiler intermediate  representation. It has been used in parallelizing compilers for multiprocessor  machines as well as optimizing compilers for uniprocessor machines. Keywords: Parallel programming, parallelizing compilers, loop transformations,  linear transformations, nonsingular transformations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6218,Performance of the ISIS Distributed Computing Toolkit,"The ISIS Toolkit is a programming environment for building process-group  structured distributed software.  The system is widely used in settings  requiring high reliability, strong distributed consistency guarantees, and  highspeed communication.  In this paper, we describe experimental studies of  ISIS performance.  Our work explores the impact of hardware support for  multicast performance, with a focus on flow control mechanisms.  The use of  hardware multicast in ISIS has not been discussed elsewhere.  One conclusion  of the paper is that although ISIS performance is limited primarily by flow  control considerations, this type of hardware support can lead to significant  performance improvements for certain communication patterns.  A second  conclusion was that the ISIS flow-control problem is surprisingly difficult.   More work in this area, and on the underlying operating system communications  layer (UDP), could have significant impact on the system. Keywords and phrases:  Distributed computing, performance, process groups,  atomic broadcast, causal and total message ordering, cbcast, abcast, multiple  process groups, hardware multicast, IP multicast, virtual synchrony, fault- tolerance.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6219,A Polynomial-time Algorithm for the Change-Making Problem,"The change-making problem is the problem of representing a given value  with the fewest coins possible from a given set of coin denominations.  To  solve this problem for arbitrary coin systems is NP-hard [L].  We  investigate the problem of determining whether the greedy algorithm always  produces the optimal result for a given coin system.  Chang and Gill [CG]  show that this can be solved in time polynomial in the size of the largest  coin and in the number of coins.  Kozen and Zaks [KZ] give a more efficient  algorithm, and pose as an open problem whether there is an algorithm to solve  this problem which is polynomial in the size of the input. In this paper, we will derive such an algorithm.  We first obtain a  characterization of the smallest coounterexample (if there is one) for which  the greedy algorithm is not optimal. We then derive a set of $O(n^2)$  possible values (where $n$ is the number of coins) which must contain the  smallest counterexample. Each can be tested with $O(n)$ arithmetic  operations, giving us an $O(n^3)$ algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6220,On Program Transformations,"In understanding complex algorithms, the notions of encapsulation and  modularization have played a key role.  An algorithm is broken into several  parts or modules, and understanding of each part is independent of others.  In addition, each part contains details that are not needed by other parts and  so can be hidden from them. Programming languages provide support for encapsulation and modularization in  many different forms.  Early programming languages provided the procedure and  function as a means for modularization.  Later, files were introduced as a  means of modularizing programs.  More sophisticated mechanisms were then  introduced, like modules, packages, structures, and classes.  In all these  cases, the interface to a module remained the procedure or function call.   Programs that use such modules contain calls to functions and procedures for  communicating with a module.  Ideally, using the operations that are provided  by a module should be done in exactly the same way as using operations that  are provided by modules should be easy to intermix.  In addition, substituting one module for another that has the same functionality but different  implementation should involve a minimal amount of effort. Recently, a new programming language, Polya, has been designed, which  attempts to support modularization and at the same time incorporate the  operations that are provided by the modules in the programming language  itself.  This is done by a sophisticated type-definition facility and a  mechanism for transforming programs at the source-program level. This thesis studies mechanisms for program transformation at the source  program level, in the context of Polya.  Program transformation is  based on a set of transformation rules that prescribe how a part of a program  is to be transformed, and a set of directives that prescribe which program  variables are to be transformed. We first give an algorithm for processing program transformations as described by the transform construct.  The algorithm constructs a coordinate  transformation of an abstract program based on a set of transforms and  transform directives for transforming program variables.  We then study the  problem of transforming expressions that have compound types.  Both the type  constructor and the component expressions of the original expression may be  transformed.  No extra rules need be added  to the bodies of transforms that  transform the type constructor and the component expressions. In the sequel  we investigate the problem of transforming procedures and  functions that have parameters that need to be transformed.  Finally, the  problem of transforming program-transformation rules is studied. The program transformation techniques are applied to two well-known  algorithms.  The algorithms are source programs, which are subsequently  transformed to programs of conventional programming languages, and then  compiled and run.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6221,Robust Functional Equations with Applications to Self-Testing/Correcting,"The idea of self-testing/correcting programs, introduced in [BLR90], is a  powerful tool for attacking the problem of program correctness. However, one  of the main criticisms of this approach was that it seemed to have limited  scope, applying only to linear and low degree polynomial functions. This  paper provides results which show that the concept of self-testing/correcting  has much broader applications than we previously understood. We concentrate  on functions $f$ satisfying functional equations, in particular, those of the  form $\forall x,y~~ F[f(x-y), f(x+y), f(x),f(y)]=0$, where $F$ is an  algebraic function. We show that self-testers and self-correctors can be  found for many such functions, including $\tan{x},{1 \over {1+\cot{x}}}, {Ax \over {1-Ax}},\cosh{x}$. We make an initial attempt at characterizing  properties of functional equations that make them useful for self-testing and  self-correcting.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6222,Hybrid Verification by Exploiting the Environment,A method of verifying hybrid systems is given. Such systems involve state  components whose values are changed by continuous (physical) processes. The  verification method is based on proving that only those executions that  satisfy constraints imposed by an environment also satisfy the property of  interest. A suitably expressive logic then allows the environment to model  state components that are changed by physical processes.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6223,Model Checking Strategies for Linear Hybrid Systems,"Linear hybrid systems are dynamical systems whose variables change both discretely and continuously along piecewise linear trajectories; they are useful for modeling digital real-time programs that are embedded in analog environments. Model checking is an algorithmic technique for anlayzing finite- state systems that has recently been extended to certain infinite-state systems, including linear hybrid systems.  The method has been implemented in HyTech (The Cornell Hybrid Technology Tool), a symbolic model checker for linear hybrid systems.  We report on a new implementation and several experiments with HyTech. The core of HyTech is a semidecision procedure that, given a linear hybrid automaton describing a system and a temporal formula describing a requirement, computes the so-called target region-the linear set of system states that satisfy the requirement.  Unfortunately, the verification procedure may not return the target region using a reasonable amount of time and space, or it may not terminate in principle.  Thus we have reimplemented the model checker using more efficient data structures that represent linear state sets geometrically, as unions of convex polyhedra, and we have experimented with several strategies that are designed to improve the performance of the model checker further: we (1) simultaneously compute the target region from different directions, (2) encode data as finite-state control, (3) approximate the target region by dropping constraints, and (4) iteratively refine the approximation until sufficient precision is obtained.  Interestingly, symbolic model checking (fixpoint computation by iteration) and the polyhedral approximation strategies (3) can be viewed as the abstract interpretation of linear hybrid systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6224,Automatic Text Theme Generation and the Analysis of Text Structure,"Non-expository texts are not usually read from cover to cover. Readers are helped in such circumstances by providing selective access to text excerpts as needed.  Text themes can be identified representing areas of importance in a text, and summaries can be constructed automatically.  In this study, text theme generation and text summarization are related to text struture.  It is shown that useful text derivatives are obtainable for texts with diverse structural characteristics.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6225,A Gradient-Based Evidence Measure for Image Matching,"We present a simple yet powerful method to perform point-to-point matching  between two images.  The method uses an \it{evidence measure}, whose value for  a given displacement reflects both the similarity between two locations and the confidence in a correct match.  The measure is based on the gradient fields of the images, and can be computed quickly and in parallel.  Accumulating the  evidence measure for different displacements allows (1) stable computation of  correspondences without smoothing across motion boundaries, and (2) detection of dominant motions, which can serve as attention cues in active vision  systems.  The method works well both on highly textured images and on images  containing regions of uniform intensities, and can be used for a variety of  applications, including stereo vision, motion segmentation, and object  tracking.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6226,Implementing and Exploiting Static Speculation on Multiple Instruction Issue Processors,"Trends in processor architecture and design suggest that static speculation  will become a candidate for implementation on future high-performance  processors. In this dissertation, we shall examine issues related to the  implementation and exploitation of static speculation.   There are four primary results: 1) Precise Exceptions: Prior work in static speculation has not examined the  interaction between exception handling and speculative instructions in any  great detail. We investigate this interaction, exhibiting certain problematic  subtleties that arise, and show how they can be overcome. 2) Speculative Tagging: Earlier proposals for implementing speculative  instructions tended to have several drawbacks, including restricted  applicability. We introduce speculative tagging, a new, more general,  mechanism for specifying static speculation, and show it is possible to  optimize exception recovery through this mechanism. 3) Whole-DAG Scheduling: Recently, there has been some work on scheduling  regions of acyclic code larger than a basic block so as to take advantage of  static speculation. We describe another such algorithm, known as whole-DAG scheduling, that contains innovations that make it more flexible, and allow  it to use better heuristics. 4) Dynamic Speculation: The work on static speculation and exceptions  suggested an alternative approach to implementing dynamic speculation. This  approach results in simpler hardware than prior schemes, and is consequently  cheaper to implement and potentially has a lesser impact on cycle-time. Additionally, we report results of experimental studies measuring the effectiveness of whole-DAG scheduling. In it, we show, among other things, that our scheduling technique can result in near-optimal schedules, and that the selection heuristics we adopt are superior to those used in earlier algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6227,Lower bounds for the complexity of the Hausdorff distance,"The Hausdorff distance is a similarity measure defined between sets in the plane.  Algorithms to find the minimum distance as one set is transformed have been described, but few lower bounds are known.  We describe new lower bounds for the complexity of the directed Hausddorff distance.  We exhibit lower boundconstructions for both sets of points and sets of points and line segments, under translation, rigid motion, translation and scaling, and affine transformation.  The results for point sets can also be extended to the undirected Hausdorff distance.  As these lower bounds are for the complexity of the graph of the Hausdorff distance as a function of transformation, they do not necessarily bound functions which search this graph, but do give an indication of how complex the search may be.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6228,Design and Performance of Horus: A Lightweight Group Communications System,"The Horus project seeks to develop a communication system addressing the requirements of a wide variety of distributed applications.  Horus implements the group communications model providing (among others) unreliable or reliable FIFO, causal, or total group multicasts.  It is extensively layered and highly reconfigurable allowing applications to only pay for services they use.  This architecture enables groups with different communication needs to coexist in a single system.  The approach permits experimentation with new communication properties and incremental extension of the system, and enables us to support a variety of application-oriented interfaces. Our initial experiments show good performance.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6229,Efficient Hierarchical Radiosity in Complex Environments,"This thesis presents methods for speeding up the global illumination  computations by using bounds on error to eliminate work that is not needed  for a solution of a given accuracy.  This work makes the hieerarchical  radiosity approach feasible for complex environments. First, a new radiosity algorithm for efficiently computing global solutions  with respect to a constrained set of views is presented.  Radiosities of  directly visible surfaces are computed to high acccuracy, while those of  surfaces having only an indirect effect are computed to an accuracy  commensurate with their contribution.  The algorithm uses an adaptive  subdivision scheme that is guided by the interplay between two closely  related transport processes:  one propagating power from the light sources,  and the other propagating importance from the visible surfaces.  By  simultaneously refining approximate  solutions to the dual transport  equations, computation is significantly reduced in areas that contribute  little to the region of interest. This approach is very effective for  complex environments in which only a small fraction is visible at any time.   Our statistics show dramatic speedups over the fastest previous radiosity  algorithms for diffuse environments with details at a wide range of scales. A new approach for accelerating hierarchical  radiosity by clustering objects  is also presented.  Previous approaches constructed effective hierarchies by  subdividing surfaces, but could not exploit a hierarchical grouping on  existing surfaces.  This limitation resulted in an excessive number of  initial links in complex environments.  Initial linking is potentially the  most expensive portion of hierarchical radiosity algorithms, and constrains  the complexity of the environments that can be simulated.  The clustering  algorithm presented here operates by estimating energy transfers between  collections of objects which maintaining reliable error bounds on each  transfer.  Two methods of bounding the transfers are employed with different  tradeoffs between accuracy and time.  In contrast with the $O(s^2)$ time and  space complexity of the initial linking in previous hierarchical radiosity  algorithms, the new methods have complexities of $O(s$ log $s)$ and $O(s)$ for  both time and space.  Using these methods we have obtained speedups of two  orders of magnitude  for environments of moderate complexity while  maintaining comparable accuracy. Finally, the thesis describes a method for reconstructing the radiance  functions across the visible surfaces given a global solution to the energy  balance equations.  This approach greatly reduces artifacts resulting from  the choice of constant basis functions used for the global solution.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6230,Systematic Derivation of Incremental Programs,"A systematic approach is given for deriving incremental programs from non-incremental programs written in a standard functional programming language. We exploit a number of program analysis and transformation techniques and domain-specific knowledge, centered around effective utilization of caching, in order to provide a degree of incrementality not otherwise achievable by a generic incremental evaluator.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6231,Efficient Average-Case Algorithms for the Modular Group,The modular group occupies a central position in many branches of mathematical sciences.  In this paper we give average polynomial-time algorithms for the unbounded and bounded membership problems for finitely generated subgroups of the modular group.  The latter result affirms a conjecture of Gurevich [FOCS 1990].,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6232,Efficient Resolution of Singularities of Plane Curves,"We give a new algorithm for resolving singularities of plane curves. The algorithm is polynomial time in the bit complexity model, does not require factorization, and works over the rationals or finite fields.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6233,Uniform Actions in Asynchronous Distributed Systems,"We develop necessary conditions for the development of asynchronous distributed software that will perform {\em uniform} actions (events that if performed by any process, must be performed at all processes).  The paper focuses on {\em dynamic uniformity}, which differs from the classical problems in that processes continually leave and join the ongoing computation. Here, we first treat a static version of the problem (lacking joins), and then extend the results so obtained to also include joins.  Our results demonstrate that in contrast to Consensus, which cannot be solved in asynchronous systems with even a single faulty process, dynamic uniformity can be solved using a failure detection mechanism that makes bounded numbers of mistakes.  Because dynamic uniformity arises in systems that maintain safety within a ""primary partition"" of a network, our paper provides a rigorous characterization of the framework upon which several existing distributed programming environments are based.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6234,Accurate and Reliable Algorithms for Global Illumination,"The simulation of global illumination is one of the most fundamental problems in computer graphics, with applications in a wide variety of areas, such as architecture and lighting design, computer-aided design, and virtual reality. This problem concerns the transport of light energy between reflective surfaces in an environment. During the past decade, radiosity has become the method of choice for simulating global illumination in diffuse environments.  Despite much recent progress in efficiency and applicability of radiosity methods, there are several very important open issues remaining: 1) Radiosity images suffer from many visual artifacts, resulting from lack of reliable automatic discretization algorithms; and 2) Current radiosity algorithms do not provide the user with guaranteed bounds or reliable estimates of the approximation errors. As a result, current radiosity systems require very careful and time-consuming user intervention in the discretization process, and the accuracy of the resulting solutions can only be assessed by visual appearance.  This thesis presents new radiosity algorithms for diffuse polyhedral environments that address the open problems mentioned above. First, we have improved and combined together two recently developed radiosity approaches: hierarchical radiosity and discontinuity meshing. An improved hierarchical radiosity algorithm that is based on a discontinuity-driven subdivision strategy to achieve better numerical accuracy and faster convergence is used to compute the global distribution of light energy in an environment.  Then, a new algorithm based on discontinuity meshing uses the hierarchical solution to reconstruct a visually accurate approximation to the radiance function. Thus, results of high visual quality can be obtained even from coarse global illumination simulations. The solution is performed entirely in object-space, which enables users to ""walk"" through high-fidelity shaded virtual environments in real time, using appropriate display hardware.  Second, we have developed algorithms that compute a posteriori error bounds and estimates for local and total errors in hierarchical radiosity solutions. A conservative algorithm computes guaranteed upper bounds on the errors. A non-conservative algorithm is capable of computing more realistic error estimates more efficiently.  These error estimates are used in a new error-driven refinement strategy for hierarchical radiosity, resulting in faster convergence.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6235,RANDOMNESS AS A COMPUTATIONAL RESOURCE: ISSUES IN EFFICIENT COMPUTATION,"Probabilistic methods have become an integral part of theoretical computer science. Typically, the use of randomization leads to solutions which are simple, elegant and more efficient than deterministic algorithms. A new research paradigm in randomized computation is to treat random bits as a resource and design algorithms which use random bits efficiently. The motivations for this approach are that algorithms which use fewer random bits are easier to implement. Also, algorithms using very few random bits can be made deterministic. For several problems all known efficient deterministic algorithms are obtained by this process of derandomization.  We design new probabilistic techniques that are used to develop randomness--efficient algorithms for combinatorial optimization problems. The first problem we consider is the abstract problem of isolating one of a possibly exponentially sized set of feasible solutions to the input instance. This tool has been used previously to design  algorithms for problems such as perfect matching in graphs, basic problems on matroids and designing random reductions. We design a new technique to solve this problem that is more efficient in the usage of random bits. Using this we derive randomness efficient solutions for the various applications. The randomness complexity of our method is parametrized in terms of the number of feasible solutions. As corollaries we obtain deterministic solutions for special cases of these problems. This new randomness--efficient technique unifies all previously known results for these applications and in many cases gives  more efficient algorithms. We prove a strong lower bound which proves that our technique is optimal in the usage of random bits.    Another important tool is the concept of random sources whose distribution approximates that of a truly random source. We present a new construction of such sources that is specifically tailored to be  easily combined with the algorithmic design method of conditional probabilities. Using this we derive improved deterministic parallel algorithms for several combinatorial optimization problems.  We investigate the problem of constructing small sample spaces which satisfy given constraints. For several sets of constraints we present improved constructions of such sample spaces. These have obvious applications to randomness--efficient computation and obtaining deterministic algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6236,The Benefits of Relaxing Punctuality,Abstract,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6237,Issues in NP-Optimization and Approximation,"Optimization or finding the best solution for a problem amongst several  possible ones is one of the central themes in computing. In particular,  NP-optimization (NPO) problems, examples of which include such  well-known problems like Integer Programming and Traveling Salesperson  Problem, have proved to be of great practical and theoretical importance.  Different NPO problems exhibit starkly different properties and understanding  the structure of these problems and their classification has been a long- standing goal in theoretical computer science. This thesis investigates the properties of NPO problems in two  settings. In the first part of the thesis we investigate how the logical  expressibility of NPO problems relates to some of their computational  properties like approximability and self-improvement. In the second part we  study NPO problems in the context of a relativeloy new model called  the counterexample model. This allows us to achieve two objectives:  Firstly, it gives us a framework to study and analyze incremental  computation of optimal or near-optimal solutions in an abstract setting. This  is useful because, in practice, for most of the NPO problems, one has  to resort to inexact algorithms which work incrementally towards computing a  good solution. Secondly, it gives us a way to precisely formulate and study  questions about the structure of these problems which we believe are  fundamental from theoretical point of view - for example, how much does the  knowledge of one solution of a problem help in computing another solution?",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6238,Recursion as a Programming Tool,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6239,On Effective Speed-up and Long Proofs of Trivial Theorems in Formal Theories,"In this note we give a very simple proof which shows that in many interesting  formal mathematical theories, axiomatizable as well as decidable ones, for  every given formalization we can effectively find infinite subsets of  trivially true theorems which require as long proofs in the given formalism as  the hardest theorems of the theory. Thus showing that for these theories  every formalism is doomed to be blind to the triviality of infinite sets of  theorems, which can be found effectively. Furthermore, it follows that for all  (sufficiently large) constructable tape and time bounds there exists sets  whose recognition can be effectively speeded up on infinite subsets and that  such sets appear naturally, thus showing that for many concrete problems,  every algorithm can be effectively sped-up on infinite subsets.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6240,Thinning Context-Free Languages,"A thinning is a kind of transformation suggested by a practical problem in  program optimization. We're given a thinning example $\delta$, which is a  string with one or more symbols marked. To thin a language with respect to   this $\delta$ is to edit each word to reflect the observation that the marked  symbols of $\delta$ are unnecessary and should be omitted. In this paper we'll  explore thinnings of context-free languages. When $\delta$ is a fully-terminal string we'll define a language $L_{\delta} (G)$ formed by carrying out a thinning procedure on each word in $L(G)$. For  a large class of thinning examples--the class for which the language of  strings correctly marked for thinning is regular--we will demonstrate that  $L_{\delta}(G)$ is a context-free language and that there is an effective  procedure for generating a grammar $H$ for which $L(H)$ = $L_{\delta}(G)$. When $\delta$ may include non-terminals the problem is more difficult to  formalize: we'll define a language $L_{\delta}(G)$ formed by carrying out a  thinning procedure on each parse tree generated by $G$. This yields an  extension of the fully-terminal problem which is unsolved and seems very hard.  An easier problem follows from defining a language $L_{\Delta}(G)$ formed by  thinning the parse trees of $G$ with respect to a set of thinning-tree  examples instead of a single thinning-string example. We will develop an  effective procedure for generating a grammar $H$ for which  $L(H)$ = $L_{\Delta}$$(G)$. By choosing an appropriate thinning set $\Delta$,  we can use this method to get an approximate solution to the general problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6241,The Algorithmic Analysis of Hybrid Systems,"We present a general framework for the formal specification and  algorithmic analysis  of hybrid systems. A hybrid system consists of a discrete program with an  analog environment. We model hybrid systems as finite automata  equipped with variables that evolve continuously with time  according to dynamical laws. For verification purposes, we restrict  ourselves to linear hybrid systems, where all variables follow  piecewise-linear trajectories. We provide decidability and undecidability results for classes  of linear hybrid systems, and we show that standard program-analysis  techniques can be  adapted to linear hybrid systems. In particular, we consider symbolic  model-checking and minimization procedures that are based on the reachability analysis of an infinite state space. The procedures iteratively compute state sets that are definable as unions of convex polyhedra in multidimensional real space. We also present approximation techniques for dealing with systems for which the iterative procedures do not converge.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6242,Using White Space for Automated Document Structuring,"We present and analyze efficient algorithms for the automated recognition and interpretation of layout structures in electronic documents. The key idea is to use the patterns in the distribution of white space in a document to recognize and interpret its components. The recognition algorithm divides the document into a hierarchy of logical elements; the interpretation algorithms classify these divisions as base-text, tables, indented lists, polygonal drawings, and graphs.  We present experimental data and discuss an information access application. Our methodology allows the automatic markup of documents\footnote{For instance in the SGML format} and the creation of multi-level indices and browsing tools for electronic libraries.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6243,Testing Multivariate Linear Functions:Overcoming the GeneratorBottleneck,The problem of testing program correctness has received  considerable attention in computer science. One approach to this problem is the notion of self-testing programs  \cite{BlumLubyRubinfeld}. Self-testing usually becomes more costly in the case of testing multivariate functions. In  this paper we present efficient methods for self-testing multivariate linear functions. We then apply these methods  to several multivariate linear problems to construct efficient self-testers.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6244,Observations About the Development of Theoretical Computer Science,"This paper gives a personal account of some developments in automata theory  and computational complexity theory. Though the account is subjective and  deals primarily with the research areas of direct interest to the author, it  discusses the underlying beliefs and philosophy which guided this research as  well as the intellectual environment and the ideas and contacts which  influenced it. An attempt is also made to draw some general conclusions about  computer science research and to discuss the nature of theoretical computer  science.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6245,A Note on Natural Creative Sets and Goedel Numberings,"Creative sets (or the complete recursively enumerable sets) play an important  role in logic and mathematics and they are known to be recursively isomorphic.  Therefore, on the one hand, all the creative sets can be viewed as equivalent,  on the other hand, we intuitively perceive some creative sets as more  ""natural and simpler"" than others. In this note, we try to capture this  intuitive concept precisely by defining a creative set to be natural if all  other recursively enumerable sets can be reduced to it by computationally  simple reductions and show that these natural creative sets are all isomorphic  under the same type of computationally simple mappings. The same ideas are  also applied to define natural Goedel numberings.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6246,Modifications and Implementation of the Shor-Khachian Algorithm for Linear Programming,"We give some modifications of the recent Shor-Khachian algorithm for linear  programming and describe a numerically stable implementation. We are concerned  with practical problems where user-supplied bounds can usually be provided.  Our implementation allows constraint dropping and updates bounds on the  optimal value, and should be able to terminate with an indication of  infeasibility or with a provably good feasible solution in a moderate number  of iterations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6247,Implicational Complexity in Intuitionistic Arithmetic,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6248,Proof Theoretic Maximality of Logical Calculi,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6249,"Personal Keys, Group Keys and Master Keys",NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6250,Number of Quantifiers is Better than Number of Tape Cells,"We introduce a new complexity measure, $QN[f(n)]$, which clocks the size of  sentences from predicate calculus needed to express a given property.  Techniques from logic are used to prove sharp lower bounds in the measure.  These results demonstrate space requirements for computations and may provide  techniques for separating Time and Space complexity classes because we show   that:  $NSPACE [f(n)] \subseteq QN[f(n)^{2}/log(n)] \subseteq DSPACE[f(n)^{2}].$",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6251,An Analysis of the Total Least Squares Problem,"Totla least squares (TLS) is a method of fitting that is appropriate when  there are errors in both the observation vector $b (mxl)$ and in the data  matrix $A (mxn)$. The technique has been discussed by several authors and  amounts to fitting a ""best"" subspace to the points $(a^{T}_{i},b_{i}),  i=1,\ldots,m,$ where $a^{T}_{i}$ is the $i$-th row of $A$. In this paper a  singular value decomposition analysis of the TLS problem is presented. The  sensitivity of the TLS problem as well as its relationship to ordinary least  squares regression is explored. Aan algorithm for solving the TLS problem is  proposed that utilizes the singular value decomposition and which provides a  measure of the underlying problem's sensitivity.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6252,The Use of Negative Curvature in Minimization Algorithms,"IN this paper we examine existiing algorithms for minimizing a nonlinear  function of many variables which make use of negative curvature. These  algorithms can all be viewed as modified versions of Newton's method and their  merits and drawbacks are discussed to help identify new and more promising  methods. The algorithms considered include ones which compute and search along  nonascent directions of negative curvature and ones which search along  curvi-linear paths generated by these directions and descent directions.  Versions of the Goldfield-Quandt-Trotter method, or equivalently, methods  based upon a trust region strategy, and gradient path methods are also  considered. When combined with the numerically stable Bunch-Parlett  factorization of a symmetric indefinite matrix the latter two approaches give  rise to new, and what appears to be, efficient and robust minimization methods  which can take advantage of negative curvature when it is encountered. Several  suggestions are made for further research in this area.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6253,Languages Simultaneously Complete for One-Way and Two-Way Log-Tape Automata,"In this paper we study languages accepted by nondeterministic $\log n$-tape  automata which scan their input only once and relate their computational  power to two-way, $\log n$-tape automata. We show that for the one-way,  $\log n$-tape automata the nondeterministic model (1-NL) is computationally  much more powerful than the deterministic model (1-L); that under one-way,  $\log n$-tape reductions there exist natural complete languages for these  automata and that the complete languages cannot be sparse. Furthermore, we  show that any language complete for nondeterministic one-way $\log n$-tape  automata (under 1-L reductions) is also complete for the computationally more  powerful nondeterministic two-way, $\log n$-tape reductions. Therefore, for  all bounds $T(n),T(n \geq \log n$, the deterministic and nondeterministic  $T(n)$-tape bounded computations collapse if the nondeterministic one-way  $\log n$-tape computations can be carried out by two-way deterministic  $\log n$-tape automata.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6254,"Educating the Programmer: Notation, Proofs, and the Development of Programs","The current state of affairs in programming is discussed. The opinion is  expressed that effective programming requires more ""mathematical maturity""  than most programmers have. Further, education in formal logicc, which is  used (often informally) to reason about programs and specifications, and in a  theory of programming could do much to increase the programmer's competence.  Such education could lead to programming becoming more of a science than just  an art. Examples are given throughout to support the opinions presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6255,Computing the Singular Value Decomposition on the Illiac IV,"In this paper, we study the computation of the singular value decomposition of  a matrix on the ILLIAC IV computer. We describe the architecture of the  machine and explain why the standard Golub-Reinsch algorithm is not  applicable to this problem. We then present a one-sided orthogonalization  method which makes very efficient use of the parallel computing abilities of  the ILLIAC machine. Our method is shown to be Jacobi-like and numerically  stable. Finally, a comparison of our method on the ILLIAC IV computer with the  Golub-Reinsch algorithm on a conventional machine demonstrates the great  potential of parallel computers in the important area of matrix computations.  Key Words and Phrases: ILLIAC IV computer, singular value decomposition,  Golub-Reinsch algorithm, Jacobi-like method, parallel matrix computations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6256,On Census Complexity and Sparseness of NP Complete Sets,In this note we show that if there are sparse NP complete sets with a  polynomial time computable census function then $P=NP$. We also derive related  results about the complexity of the census function for context-sensitive  languages and $\log n$-tape bounded languages.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6257,Sparse Complete Sets for NP: Solution of a Conjecture by Berman and Hartmanis,"In this paper we show that if NP has a sparse complete set under many-one  reductions, then P=NP. The result is extended to show that if NP is sparse  reducible, then P=NP. The main techniques of this paper generalize the NP  recognizer for the complement of a sparse complete set with census function to  the case where the census function is not known (c.f. [HM]), then a many-one  reduction of this language to the sparse set permits a polynomial time bounded  tree search as in [B], [F], or [MP]. Even without actual knowledge of the  census, the algorithm utilizes the properties of the true census to decide  membership in SAT in polynomial time.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6258,Effective Information Retrieval Using Term Accuracy,"The performance of information retrieval systems can be evaluated in a number  of different ways. Much of the published evaluation work is based on measuring  the retrieval performance of an average user query. Unfortunately, formal  proofs are difficult to construct for the average case. In the present study, retrieval evaluation is based on optimizing the  performance of a specific user query. The concept of query term accuracy is  introduced as the probability of occurrence of a query term in the documents  relevant to that query. By relating term accuracy to the frequency of  occurrence of the term in the documents of a collection it is possible to give  formal proofs of the effectiveness with respect to a given user query of a  number of automatic indexing systems that have been used successfully in  experimental situations. Among these are inverse document frequency weighting,  thesaurus construction, and phrase generation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6259,The Communality Problem for Stieltjes Matrices,"The Communality Problem in Factor Analysis is that of reducing the diagonal  elements of a correlation matrix so that the resulting matrix will be positive  semidefinite and of minimum rank. The problem is well studied but no effective  solution procedures have been devised. In this paper, we propose a variant  problem and give an algorithm for its solution. We prove that a solution to  this problem also solves the Communality Problem if the correlation matrix is  Stieltjes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6260,Specification and Verification of Communication in Parallel Systems,"This thesis develops a verification theory for systems of parallel processes  communicating with one another by sending messages. The goal is independent  specification of processes in a system, so that the system can be verified  from the specifications of its component processes.  A process is regarded as a generator of a formal language called its  communication language. A specification is written as a first order predicate  calculus formula about this formal language. Processes are verified by  including assertions in them and proving that the assertions hold, much as is  done for sequential programs.  An important aspect of the work is its treatment of non-determinism and its  effect on the termination, non-termination, and deadlock properties of systems  and processes. It is argued that non-determinism should be curtailed if  specifications are to accurately reflect the specifier's wishes.  Rules relating assertions and statements are similar to those used in  Floyd-Hoare logic. However, we deal here with both partial correctness,  sometimes called safety in the literature, and liveness, which is a concept  analgous to termination of sequential programs. Justification of liveness  assertions takes advantage of statements that occur both before and after the  assertion, introducing a new kind of proof rule which we prove is correct.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6261,"User's Guide to Release 2, PL/CS",NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6262,An Essay About Research on Sparse NP Complete Sets,The purpose of this paper is to review the origins and motivation for the  conjecture that sparse NP complete sets do not exist (unless P=NP) and to  describe the development of the ideas and techniques which led to the recent  solution of this conjecture.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6263,Programs As Types,Programs are interpreted as types in a constructive type theory. Rules for a  logic of programs can then be derived from rules for types. This approach is  the basis of nonelementary reasoning in the PL/CV3 (program) verification  system. This paper summarizes the type theory and shows how to develop higher  order logic and algorithmic (or programming or dynamic) logic in the theory.  The theory described here is an evolution from de Bruijn's AUTOMATH and  Martin-Lof's Intuitionistic Theory of Types.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6264,The Fundamental Theorem of Arithmetic in PL/CV2,"This document is a section of formal elementary number theory leading up to a  complete proof of the fundamental theorem of arithmetic. On the way to this  result a large number of simple facts about integer division, prime numbers,  greatest common divisors, and the product function, $\prod_{i=1}^{m}a(i)$, are  developed. The entire section is written in the formal logic of PL/CV2, and  the proof was checked by the PL/CV2 Proof Checker on an IBM 370/168.  Readers familiar with the syntax of a high level programming language, like  PL/I, and accustomed to highly symbolic mathematical proofs should be able to  read this document as a specimen of extremely formal and rigorous mathematics.  The following remarks about PL/CV2 notation will simplify reading.  1. The *PROCESS line indicates the beginning of PL/I executable text, the  *THEOREM line indicates the beginning of purely declarative text.  2. All proof text is written between PL/I comment delimiters of the form  /*/...*/ or /#...#/ depending on context.  3. For the built-in PL/I functions ABS, MOD, SIGN, MAX, MIN, EXP, DIVISION  (/) only the properties of the functions are listed, in Section 0 called  BUILT-IN FUNCTIONS. No proofs of these properties are supplied (because the  operations are provided by the system). Thus proved propositions appear  starting in Section 1 (at line 0036).  4. In the listing the negation sign is written ^, thus B ^= 0 reads ""B not  equal to zero"". The PL/I symbol for ""or"" is the vertical bar, thus line 0037  TRI : B less than 0|B=0|B greater than 0 is labeled by TRI (for trichotomy) and means B is less than  or equal to 0 or greater than 0. The justification... BY ARITH... indicates  that the conclusion follows from simple arithmetic reasoning, provided by the  system, from the list of hypotheses.  5. Every PL/CV2 procedure, such as LOG at line 0049, begins with an ASSUME  statement, telling what is assumed about the input, and with an ATTAIN  statement telling what will be proved about it. Also every procedure is proved  to terminate. In the case of recursive procedures, the termination proof  begins with the line ARBITRARY (integer variable) WHERE (conditon) (see line  0053). It is proved that this integer variable decreases on any recursive  call.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6265,Three Surveys on Operating System Topics,"Recently, we were asked by the Wiley Publishing Company to write survey  articles covering some of the important concepts in operating systems for  their forthcoming Handbook of Electrical and Computer Engineering. The three  brief articles that comprise this report are the results of those efforts. The  first was written by Schneider, the latter two by Andrews. We have collected  them here in the hope that some may find them of interest. The first article  discusses concurrent programming, which is an underlying concern in most  operating systems. The use of a kernel or nucleus in constructing an operating  system is described in the second article. Lastly, in the third article, the  notion of hierarchical organization is developed and some of the advantage of  this approach are presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6266,A Subexponential Algorithm for Trivalent Graph Isomorphism,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6267,A Constructive Alternative to Axiomatic Data Type Definitions,"Many computer scientists advocate using axiomatic methods (such as algebraic  specification) to specify a program data domain - the universe of abstract  data objects and operations manipulated by a program. Unfortunately, correct  axiomatizations are difficult to write and to understand. Furthermore, their  non-constructive nature precludes automatic implementation by a language  processor.  In this paper, we present a more disciplined, purely constructive alternative  to axiomatic data domain specification. Instead of axiomatizing the program  data domain, the programmer explicitly constructs it by using four type  construction mechanisms: constructor generation, union generation, subset  generation, and quotient generation. These mechanisms are rich enough to  define all of the abstract data objects that programmers commonly use:  integers, sequences, trees, sets, arrays, functions, etc. In contrast to  axiomatic definitions, constructive definitions are easy to write and to  understand. An unexpected advantage of the constructive approach is a limited  capacity to support non-deterministic operations. As an illustration, we  define a non-deterministic ""choose"" operation on sets.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6268,Permutations and the APL Grade Down Function,"The APL gradeup (gradedown) function (denoted by $\uparrow \{respectively  \downarrow \}$) aapplied to a vector $v \in R^{n}$ `grades' the elements of  $v$ in ascending (descending) order. (Among equal elements of $v$ the ranking  is determined by their position). For example, if  $v=(2.3,4.7,6.8,0.6,3.7,4.7)$ then $\uparrow v$ is (4,1,5,2,6,3) and  $\downarrow v$ is (3,2,6,5,1,4). An immediate consequence of the versatility  of this functional form is that the expression $v[\uparrow v] (v[\downarrow v])$ `sorts' the elements of $v$ in ascending (descending) order.  The question of characterizing all vectors $v \in R^{n}$ such that  $\uparrow v=v$ was answered in a paper by Cooper, Best and Kennedy [see  Cooper, et al.(1)]. The results there are essentially determined by  scrutinizing the selection property of $\uparrow v$; that is, if  $v=(x_{1}, x_{2},\ldots, x_{n})$ then $\uparrow v$ can be visualized as the  unique permutation $P \in S_{n}$ such that $x_{P(1)},x_{P(2),\ldots,x_{P(n)$  is a list of the elements f $v$ in ascending order. Two straightforward  consequences of this interpretation are: 1) if $P \in S_{n}$, then  $\uparrow P$ is the inverse of $P$ and 2) the `fixed' points of the mapping  $\uparrow$ are precisely the involutions of $S_{n}$.  IN this note we continue this investigation for the gradedown function and  also resolve the open questions posed in that paper.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6269,A Classroom Note on Topological Ordering,"A partially ordered set (poset) is a pair (S,R) where S is a nonempty set and  R is a reflexive, antisymmetric, transitive relation on S. (Equivalently, a  pair (S,R') where R' is an irreflexive, transitive relation on S.) Unless  otherwise stated the second definition will be the one used in this  discussion. (S,R) is a chain if R is a total order on S, that is, given any  pair a, b in S, either (a,b) or (b,a) is in R.  The notion of embedding a poset in a complete lattice is a well known lattice  theoretic result. [ see Foulis(1)] In this sequel we consider a special case  of that result; namely, the embedding of a poset in a chain. Although the  proof in the finite case suggests an intuitively obvious constructive  algorithm [see Kahn(2)] it was only recently that an `optimal' solution was  discovered which can be implemented in linear time. [see Knuth(3)]. The proof  in the infinite case first appeared in print in a paper by Szpilrajn. [see  Szpilrajn(4)]. In this presentation the proof in the infinite case is a  reasonably `clean' and straightforward application of Zorn's lemma which can  be readily understood by the average undergraduate.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6270,An Informal Description of Russell,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6271,The Russell Semantics: An Exercise in Abstract Data Types,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6272,First Order Expressibility as a New Complexity Measure,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6273,Real Time Queue Operations in Pure LISP,Several methods of implementing a queue in Pure LISP are presented. A  technique to distribute the reversal of a list over a number of operations  leads to a real-time queue implementation.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6274,Two-Dimensional Turing Machines With Uninitialized Workspaces,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6275,Proof Rules for Communicating Sequential Processes,"This thesis presents proof rules for an extension of Hoare's Communicating  Sequential Processes (CSP). CSP is a notation for describing processes that  interact through communication, which provides the sole means of synchronizing  and passing information between processes. A sending process is delayed until  some process is ready to receive the message; a receiving process is delayed  until there is a message to be received. It is this delay that provides  synchronization.  A proof of a program is with respect to pre- and postconditions. A proof of  weak correctness shows that execution of the program beginning in a state  satisfying the precondition terminates in a state satisfying the  postcondition, provided deadlock does not occur. A proof of strong  correctness, in addition, shows that deadlock cannot occur.  A proof of weak correctness has three stages: a sequential proof, a  satisfaction proof, and a non-interference proof. A sequential proof reflects  the effects of a process running in isolation. A satisfaction proof combines  sequential proofs of processes, reflecting the message passing and  synchronization aspects of communication. A non-interference proof shows that  no process affects the validity of the proof of another process.  The introduction of the satisfaction proof and our symmetric treatment of send  and receive are important aspects of this thesis. By treating send and receive  on an equal basis, we simplify our rules and allow the inclusion of send in  guards.  A sufficient condition for freedom from deadlock is given that depends on the  proof of weak correctness; this is used to prove strong correctness. In  general, freedom from deadlock can be very hard to check. Therefore, we derive  special cases in which we can reduce the work needed to verify that a program  is free from deadlock.  We also present an algorithm for globally synchronizing processes; that is,  each process can recognize that all processes are simultaneously in a given  state. It works by recognizing a special class of deadlock. Having this  algorithm allows us to modify programs that deadlock when the postcondition is  established, so that they terminate normally.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6276,Floating-Point Arithmetic and Program Correctness Proofs,"This thesis develops tight upper and lower bounds on the relative error in  various schemes for performing floating-point arithmetic, proposes axioms for  characterizing the significant properties embodied by these schemes, and gives  examples to illustrate how these axioms may be used to reason about the  correctness of floating-point programs.  Three addition schemes are considered: (1) chopped addition, (2) addition with  both pre and post-adjustment rounding, and (3) addition with pre-adjustment  chopping and post-adjustment rounding. Schemes for performing both rounded and  chopped multiplication and division are also considered.  Our tight bounds are consistent with the commonly held opinion that a binary  base minimizes the maximum relative errors in floating-point arithmetic.  Also, these bounds show that one guard digit is optimal for minimizing the  maximum relative errors in chopped addition. The bounds derived for each of  the addition schemes considered are as tight as possible.  One guard digit and two guard bits are shown to be sufficient to round the  result of an exact addition to the nearest floating-point number. We show how  this scheme can be implemented using a single post-adjustment shift, no  rounding overflow, and (for certain implementations) requiring no more time  than an addition that chops instead of rounds.  Two approaches are considered for axiomatizing floating-point arithmetic. In  one approach, a set of floating-point numbers is associated with each  floating-point expression, and the assignment statement is modeled as a  nondeterministic selector of one of the members in the set. In the alternative  approach, the floating-point operations are modeled in terms of two cropping  functions whose significant properties are characterized by a small set of  axioms. In both cases, the axioms characterizing floating-point arithmetic are  used with Dijkstra's weakest pre-condition calculus to provide an axiomatic  framework for reasoning about floating-point programs.  Finally, the commom practice of modelling the floating-point operations by a  single function that chops or rounds the result of the corresponding exact  operation is shown to be invalid for many implementations of floating-point  arithmetic.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6277,The CORE User Interface,"The distinctive characteristic of the CORE program development environment is  its ttolerant user interface. This paper describes that interface. In addition  to its unusual response to incomplete and incorrect constructions entered by  the user, the interface is ""mode-free"", unusually frugal in the size of the  command set, and unusually consistent in its treatment of statements,  immediate statements and commands.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6278,A Generalized Broyden's Method for Solving Simultaneous Linear Equations,We present a generalized Broyden's method for solving rectangular systems of  linear equations. We show that the method computes a least squares solution  to the given simultaneous equations and that it posseses a remarkable finite  termination property in exact arithmetic.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6279,Parallel Computations in Information Retrieval,"Conventional information retrieval processes are largely based on data  movement, pointer manipulations and integer arithmetic; more refined retrieval  algorithms may in addition benefit from substantial computational power. In the present study a number of parallel processing methods are described  that serve to enhance retrieval services. In conventional retrieval  environments parallel list processing and parallel search facilities are of  greatest interest. In more advanced systems, the use of array processors also  proves beneficial. Various information retrieval processes are examined and  evidence is given to demonstrate the usefulness of parallel processing and  fast computational facilities in information retrieval.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6280,Broadcasts: A Paradigm for Distributed Programs,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6281,The Ellipsoid Method: A Survey,"IN February 1979 a note by L.G. Khachiyan indicated how an ellipsoid method  for linear programming can be implemented in polynomial time. This result has  caused great excitement and stimulated a flood of technical papers. Ordinarily  there would be no need for a survey of work so recent. The current  circumstances are obviously exceptional. Word of Khachiyan's result has spread  extraordinarily fast, much faster than comprehension of its significance. A  variety of issues have in general not been well understood, including the  exact character of the ellipsoid method and of Khachiyan's result on  polynomiality, its practical significance in linear programming, its  implementation, its potential applicability to problems outside of the domain  of linear programming, and its relationship to earlier work. Our aim here is  to help clarify these important issues in the context of a survey of the  ellipsoid method, its historical antecedents, recent developments, and  current research.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6282,Polynomial-Time Algorithms for Permutation Groups,"A permutation group on n letters may always be represented by a small set of  generators, even though its size may be exponential in n. We show that it is  practical to use such a representation since many problems such as membership  testing, equality testing, and inclusion testing are decidable in polynomial  time. In addition, we demonstrate that the normal closure of a subgroup can be  computed in polynomial time, and that this procedure can be used to test a  group for solvability. We also describe an approach to computing the  intersection of two groups. The procedures and techniques have wide  applicability and have recently been used to improve many graph isomorphism  algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6283,On Edge Coloring Bipartite Graphs,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6284,A Computer System for Checking Proofs,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6285,Optimal Conditioning in the Convex Class of Rank Two Updates,"Davidson's new quasi-Newton optimization algorithm selects the new inverse  Hessian approximation H at each step to be the ""optimally conditioned"" member  of a certain one-parameter class of rank two updates to the last inverse  Hessian approximation H. In this paper, we show that virtually the same goals  of conditioning can be achieved while restricting H to the convex class of  updates. We therefore suggest that Davidson's algorithms using optimal   conditioning, restrict the choice of H to members of the convex class.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6286,Language Features for Process Interaction,"Language for parallel programming should meet four goals: expressiveness,  reliability, security, and verifiability. This paper presents a set of  language features for describing processes and process interaction, gives  examples of their use, and briefly discusses their relation to the goals. Two  constructs, resources and protected variables, are introduced as the  mechanisms for describing interaction. Resources are extensions of the monitor  concept of Hoare; protected variables are global variables which can only be  accessed by one process at a time. Two types of access control are introduced:  restrictions on scope rules for static access, and capabilities for dynamic  access. Examples include the interface to machine devices, files and virtual  devices, device scheduling, device reservation, and buffer allocation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6287,Information Retrieval in the Business Environment,"This paper outlines a possible approach to the use of advanced information  storage and retrieval techniques for business correspondence. The present  situation in the Office Automation field is surveyed, and the role of  information retrieval is an integrated office information system is discussed.  Business letter characteristics that might be useful for analysis and  retrieval are described. The idea of a generalized business thesaurus  containing standard phrases and locutions as well as synonyms and index  phrases is presented. A technical solution to the analysis, storage and  retrieval of business letters based on the concepts from the SMART-system is  outlined. A description of the experiments performed so far follows. These  include decomposition, analysis, storage, automatic classification and  utilization of inter-letter references. The results from the experiments show  that the use of automatic indexing and retrieval in the office is feasible and  provides a viable alternative to existing manual business files. In  conclusion, several future experiments are outlined.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6288,Reversal-Bounded Computations,"IN computations by abstract computing devices such as the Turing machine, head reversals are required for searching the input or retrieving intermediate  results. Hence the number of head reversals is a measure of the complexity of  a computation. This thesis is a study of reversal-bounded computation on three  models of abstract computing devices.  The first model is the 1-tape Turing machine with finite bounds on head  reversals. It is known that such machines recognize exactly the regular sets  so that for recognition purposes, reversals can be eliminated entirely. For  transduction purposes, that is, if an output is expected on the tape, a single  reversal suffices. Hence these machines are most appropriately called finite  automata. Clearly they are among the weakest possible computing devices, and  many decision problems about them are solvable. We use this fact and a very  simple input-output encoding scheme to obtain greatly simplified proofs of the  decidability of some weak mathematical theories, including the weak monadic  second-order theory of one successor and Presburger arithmetic. Similar  techniques yield linear size bounds as well as linear time complexity bounds  (on the multitape Turing machine model) for functions definable in Presburger  arithmetic. As corollaries, we find applications in linear diophantine systems  and linear integer programming.  The second model is the multicounter machine with general bounds on counter  reversals. By relating counter reversal to time and space, we show that  recursiveness of reversal bounds implies recursiveness of the sets accepted.  For bounds that are at least linear, counter reversal is polynomially  equivalent to Turing machine time in both the deterministic and the  nondeterministic cases. This result leads to a general deterministic reversal  hierarchy and a natural formulation fo the P=?NP question on the multicounter  machine model. It also suggests that on every reasonable universal computing  model, there is a ""natural"" complexity measure that is polynomially  equivalent to Turing machine time. For reversal bounds that grow more slowly  than $n^{1/2}$, we show that the nondeterministic 2-way reversal complexity  class is not closed under complementation and strictly includes the  corresponding deterministic class. In contrast, the analogous questions are  open for 2-way 2-tape Turing machines with logarithmic space bounds. Finally,  we consider finite bounds on counter reversals. For both the 1-way and the  2-way models, we obtain very sharp upper bounds on the Turing machine time and  space complexity of the languages accepted. In the 1-way case, we present a  unified account of the known results, interspersed with our contributions,  which include (1) equivalence to 1-way simple multihead finite automata, (2)  an easy technique for proving nonrecognizability, (3) an abstract  characterization of the power of finite reversal-bounded counters, and (4) an  application to the theory of program schemes.  Lastly, we consider finite reversal-bounded multitape finite automata. We show  that over a single-letter alphabet, the languages accepted are exactly the  unary encodings of Presburger relations. This result holds whether the model  is determinisitic or nondeterministic, and even if it is augmented with, for  example, finite reversal-bounded counters and an unrestricted pushdown store,  or if the reversals are restricted to rewinds, that is, instructions that  simultaneously position all heads at the beginnings of their respective tapes.  For both deterministic and nondeterministic rewind automata, we establish  exhaustive hierarchies based on the finite number of rewinds. When restricted  to a single-letter alphabet, the deterministic hierarchy stands but the  nondeterministic one collapses.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6289,Detecting Distributed Termination When Processors Can Fail,"A collection of protocols to facilitate detection of the termination of a  computation on a distributed system are developed. Communication is assumed to  be accomplished by use of asynchronous broadcasting. It is argued that this is  a reasonable assumption for a distributed system in light of advances in local  networking. The protocols presented are all robust with respect to processor failures.  They differ in their requirements - some make heavy use of the communications  network at the end of a computation, while others spread the communications  cost out through the computation. Problems of restarting failed processors are also addressed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6290,The Optimality of Induction as an Axiomatization of Arithmetic,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6291,Asymptotic Complexity of Iterative Computations,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6292,Swapping Sections,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6293,Optimal-Time Incremental Semantic Analysis for Syntax-Directed Editors,"Attribute grammars permit the specification of static semantics in an  applicative and modular fashion, and thus are a good basis for syntax-directed  editors. Such editors represent programs as as attributed trees, which are  modified by operations such as subtree pruning and grafting. After each  modification, a subset of attributes, AFFECTED, requires new values.  Membership in AFFECTED is not known a priori; this paper presents an algorithm  that identifies attributes in AFFECTED and recomputes their values. The  algorithm is time-optimal, its cost is proportional to the size of AFFECTED.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6294,Report on the Type Theory (V3) of the Programming Logic PL/CV3,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6295,A Logic for Correct Program Development,"Existing verification technology, though theoretically adequate, is not  directly applicable to the construction of large software systems. This thesis  explores the view that reasoning about code is not the proper paradigm for  correct program development. Instead, specifications should be the objects of  study and a logic should be formulated for constructively proving that  specifications have acceptable implementations; from these proofs code may be  extracted. Thus, constructive existence proofs become the programmer's main  concern, while executable text is seen as a valuable by-product of correct  reasoning which cannot be produced from incorrect reasoning.  The thesis captures this view of program development in a logic for the  formal refinement of specifications. Specifications are written in an  imperative notation of generalized assignment; they allow calculations in  integer arithmetic and finite set theory. Classical reasoning techniques are  shown inconsistent in this domain (where propositions may claim the  constructive existence of programs), hence an alternative logic is developed  based on intuitionistic reasoning. Proofs in this constructive refinement  logic are trees, stylistically similar to those of Gerhard Gentzen's sequent  calculus. It is argued that while linear proofs are appropriate when reasoning  is developed and presented on paper, hierarchical proofs are appropriate  when reasoning is developed and presented with machine aid. A mechanism is  described that extracts correct codes from valid proofs; its existence assures  the consistency of the logic. Finally, several code optimization techniques  are examined and applied to code extracted from sample proofs.  The thesis concludes with a discussion of the expounded view of correct  program development, suggestions for a program development system based on  this view, and a look at the numerous research problems remaining in this area.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6296,Simple Error Recovery Scheme for Optimized LR-Parsers,"A new, simple and effective method for syntactic error recovery in optimized  (reduced) LR-parsers is presented. This method, called the Simple Recovery and  Correction scheme, is phrase oriented and performs local and some form of  global contect correction. The error handling mechanism is driven by  information obtainable from an LR-parser decision table.  The formal basis for the method is the concept of synchronizing triple. A  theoretical characterization of synchronizing triples is given and algorithms  for direct extraction of recovery control information are presented.  As a part of the SRC scheme a simplified method for the organization of  LR-parser forward moves is introduced.  In the last part of the paper the performance of the SRC scheme is illustrated  in a specific case and implementation problems are discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6297,A Comparison of Search Term Weighting: Term Relevance vs. Inverse Document Frequency,"The term relevance weighting method has been shown to produce optimal  information retrieval queries under well-defined conditions. The parameters  needed to generate the term relevance factors cannot unfortunately be  estimated accurately in practice; furthermore, in realistic test situations,  it appears difficult to obtain improved retrieval results using the term  relevance weights over much simpler term weighting systems such as, for  example, the inverse document frequency weights.  It is shown in this study that the inverse document frequency weights and the  term relevance weights are closely related over a wide range of the frequency  spectrum. Methods are introduced for estimating the term relevance weights,  and experimental results are given comparing the inverse document frequency  with the estimated term relevance weights.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6298,Determining Logical Dependency in a Decision Procedure for Equality,"Several existing program verification and automated prooff systems make use of  similar decision procedures for equality ([Krafft 1978], [Nelson and Oppen  1977] and [Downey, Sethi and Tarjan 1980]). The general method used by these  algorithms has been named congruence closure. Given two expressions on  uninterpreted function symbols, a congruence closure algorithm determines  whether the expressions can be deduced to be equal from a set of previously  asserted equalities. The existing congruence closure algorithms do not provide  any indication of which previously asserted equalities were required in the  deduction.  In this paper, we describe an extension to one version of congruence closure.  When two expressions are equal, the new algorithm can provide a certificate of  their equality: a list of prevviously asserted equalities from which the  queried equality can be deduced. This list is minimal, in the sense that if  any equality iss removed from the list, the queried equality can no longer be  deduced. The running time to produce the certificate is almost-linear in the  size of the list.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6299,COPE: A Cooperative Programming Environment,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6300,Upson's Familiar Quotations - Second Edition 1974-1981,"This report is a compilation of several hundred examples of context-free  language and very irregular expressions. Contributions were submitted over the  last five years by numerous computer science graduate students who collected  these now immortal words in classes and seminars. We wish to express our  gratitude to the faculty, guest lecturers, and students who provided the bulk  of this work.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6301,"Cornell Local Network (CLONE): Interface Unit, Principles of Operation",This document describes the architecture and operation of a CLONE Interface  Unit. It is the defining document.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6302,Generalizing the LINPACK Condition Estimator,"Two generalizations of the Cline-Moler-Stewart-Wilkinson ""LINPACK"" condition  estimator are described. One generalization combines the LINPACK notion of  ""look-ahead"" with a new feature called ""look-behind"" that results in a more  flexibly chosen right-hand side. The other generalization is a  ""divide-and-conquer"" scheme that involves estimating the condition of certain  principal submatrices whose dimension repeatedly doubles. Both generalizations  require that maximization of simple objective functions. When seeking an  $L_{1}$ condition estimate, these functions are convex while inthe $L_{2}$  case they are quadratic. All the algorithms considered appear to be at least  as reliable as the LINPACK estimator and are equally efficient.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6303,Display Condensation of Program Text,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6304,The Type Theory of PL/CV3,"The programming logic PL/CV3 is based on the notion of a mathematical type. We  present the core of the type theory, from which the full theory for program  verification and specification can be derived. Whereas the full theory was  designed to be useable, the core theory was selected to be analyzable. This  presentation strives to be succinct yet thorough. The last section consists of  examples, but the  approach here is not tutorial.  Key Words and phrases: automated logic, program verification, program  specification, semantics of programming languages, type theory, foundations of  mathematics.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6305,On the Minres Method of Factor Analysis,"The minres method is an effective means for estimating factor loadings under  the condition that the sum of squares of the off-diagonal residuals be  minimized. This paper is addressed to the efficient implementation and the  convergence properties of the method.  Key words: minres method, factor analysis, communality.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6306,A Note on the Complexity of Goedel Numberings and Isomorphisms,"Some problems involved in looking at recursive function theory and thinking  about the complexity of computations are discussed. Complexity classes of  Goedel numberings are studied where a Goedel numbering is in a given  complexity class if every other Goedel numbering can be translated into it by  functions ina given complexity class. In particular, we look at the class of  numberings that can be trnslated into by polynomial time mappings (GNP) and  the class that can be translated into by linear bounded automation mappings  (GNLBA). It is shown that polynomial time isomorphisms and LBA computable  isomorphisms between two Goedel numberings relate the complexity of the  syntax of the numberings. Since the classes GNP and GNLBA contain Goedel  numberings with arbitrarily hard syntax, not all members of these classes are  isomorphic by polynomial time or LBA mappings. LBA computable isomorphisms can  be found between members of GNLBA whose syntax is LBA recognizable. A similar  result holds for polynomial time isomorphisms and GNP if P=NP.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6307,AVID: A system for the Interactive Development of Verifiably Correct Programs,"The AVID system is designed to Aid Verification through the techniques of  Interactive program Development. AVID continues the work in programming logics  begun at Cornell University in 1975. It provides a syntax-directed editing  environment for the development by stepwise refinement of programs and proofs  in the PL/CV2 programming logic. AVID is another step in the continuing effort  to provide methods and software tools for developing correct programs. AVID contains a number of important contributions to the area of program/proof  development. To allow the full power of the AVID verification facilities to be  applied to programs developed by stepwise refinement, we created a new program  construct, called an ATTAIN block, that formalizes the concept of a refinement  level. This construct allows the independent verification of different  refinement levels, and thus of partially developed programs. Using this  construct, AVID can guarantee that the refinement in a top-down development  actually implements its high-level specification. AVID is the first system to support the interactive display of logical  dependency in proofs. We have developed a new algorithm, built on the  congruence closure method for deciding the theory of equality, that  efficiently determines logical dependency within this theory. This algorithm  is independent of the AVID system, and has potential applications wherever the  congruence closure method is used. AVID also contains some significant contributions to the area of  syntax-directed editor design. AVID makes use of a standard, powerful, and  widely available screen-oriented editor as its user interface. The system  design gives a strategy for the incorporation of other powerful editors into  syntax-directed development systems. AVID is also the first system to make  extensive use of derived nonterminals to avoid redundant specification and to  guide the user in developing his proof. Perhaps AVID's most important contribution is its demonstration of the  feasibility of a system to support and enforce the development by stepwise  refinement of provably correct programs. For programs that must be correct,  this approach may be one of the most promising. One final contribution of the AVID project is the system itself as a base for  future research. The modular design of the AVID system and its facilities for  the high-level description of AVID language constructs make the system easy to  modify and to build on. There are already several projects planning to use  AVID in this fashion. AVID has been implemented on a DEC VAX 11/780 under the Berkeley UNIX  operating system. The current version of the system, which supports the  development and verification of the predicate calculus portion of PL/CV2,  consists of approximately 20,000 lines of C language source code. When running  on the VAX, the current system requires 230K bytes of memory. A version of the  system suitable for distribution is expected to be available by January 1982.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6308,The Design and Implementation of a Cooperative Program Development Environment,"COPE is a program development environment that provides a highly tolerant user  interface specifically designed for novice users. The design and  implementation of COPE has been the work of a group which includes the author,  Richard Conway, Andrew Shore, and Leonard Silver. In presenting the results of  the joint effort, attention has been given to balance the presentation of the  author's contribution and the overall context of the system. The author has  been involved in all of the development and design phases of the system. The  initial system design and architecture were developed jointly with Richard  Conway and the sections presenting design, architecture, and user interface  represent joint work. Later sections on particular issues (parsing, file  system, etc.) are individual contributions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6309,On the Use of Abstract Data Types to Specify the Modules of a System,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6310,Orthogonal Rotation to a Partially Specified Target,"This paper addresses the problem of finding an orthogonal transformation of an  arbitrary factor solution that would lead to a least squares fit of a  partially specified target matrix. An iterative computing procedure is  presented.  Key words: orthogonal rotations, factor analysis, least squares, partially  specified target, procrustes problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6311,Rendezvous Primitives for Operating System Design,"A well chosen, comprehensive set of kernel primitives is essential for the  construction of higher levels of a computer's operating system. In particular,  although many solutions to the classical operating system problems of  interprocess synchronization and communication have been proposed in the past,  difficulties with destination naming and language construct symmetry have  continued to mar most proposed solutions.  This thesis proposes a set of primitives, the Rendezvous primitives, that form  the kernel of an operating system. It is argued that the Rendezvous primitives  constitute a reasonable and practical set of operations on which to base an  operating system. The Rendezvous primitive itself is presented as a solution  to the interprocess synchronization and communication problems. A rendezvous  occurs when two processes synchronize and subsequently exchange messages.  Rendezvous is symmetric, in that processes that wish to communicate both use  the same primitive; and processes invoke Rendezvous with class designations,  not procedure names. Rendezvous is presented within the context of the other  primitives, which support the restriction of access to Rendezvous, process  creation and destruction, process scheduling, and stack resource management. A  comparison of Rendezvous and existing primitives and language constructs to  solve interprocess synchronization and communication is made.  The full syntax and semantics of the Rendezvous primitives are presented,  along with a discussion of their design rationale. The Crossbar Switch, a  generalized virtual device interconnection and reconfiguration scheme, is  presented as an example of the use to which the Rendezvous primitives might be  put. A high level program description of the Crossbar Switch is presented as  well.  The thesis concludes with a description of the implementation of the  Rendezvous kernel on a DEC PDP 11/60. The kernel code is given in an appendix.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6312,Merging on Parallel Models of Computation,"A variety of models have been proposed for the study of synchronous parallel  computation. We review these models and study further some prototype problems.  Within a spectrum of shared memory models, we show that $\log \log n$ is  asymtotically optimal for $n$ processors to merge two sorted lists containing  $n$ elements.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6313,Fast Compact Prime Number Sieves (Among Others),NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6314,Converting a Swap-Based System to do Paging in an Architecture Lacking Page-Referenced Bits,"This paper discusses the modifications made to the UNIX operating system for  the VAX-11/780 to convert it from a swap-based segmented system to a  paging-based virtual memory system. Of particular interest is that the host  machine architecture does not include page-referenced bits. We discuss  considerations in the design of page-replacement and load-control policies for  such an architecture, and outline current work in modeling the policies  employed by the system. We describe our experience with the chosen algorithms  based on benchmark-driven studies and production system use.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6315,Efficient Generation of Memory Reference Strings Based on the LRU Stack Model of Program Behaviour,"We consider the problem of generating memory reference strings that are to be  used instead of real program address traces with the generator based on the  Least-Recently-Used Stack Model (LRUSM) of program behaviour. A method to  transform the stack distance probability mass function that drives the  generator is proposed which results in memory reference strings that are a  fraction of theoriginal string length while preserving most of its essential  performance characteristics. The reduced string can be processed in much the  same way as the original string for virtual memory studies that deal with  memory sizes greater than $k$, the parameter of the transformation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6316,User Recovery and Reversal in Interactive Systems,"Interactive systems, such as editors and program development environments,  should be explicitly support recovery - facilities that permit a user to  reverse the effects of past actions and to restore an object to a prior state.  A model for interactive systems is presented that allows recovery to be  defined precisely and user and system responsibilities to be delineated.  Various implementation techniques for supporting recovery are described.  Application of a general recovery facility to support reverse execution is  discussed. A program development system (called COPE) with extensive recovery  facilities, including reverse execution, is described. Keywords: recovery, reverse execution, undo, checkpoint, editor, programming  environments.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6317,Routing in Networks,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6318,A Logic for Expressions with Side Effects,"This paper presents a simple programming logic LES, which is particularly well  suited for reasoning about so-called expression languages, i.e. languages that  incorporate imperative features into expressions rather than distinguishing  between expressions and statements. An axiomatization of a simple programming  language is presented using this formalism. It is shown that this  axiomatization is relatively complete, roughly in the sense of [Coo 76].",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6319,An Approach to Designing Fault-Tolerant Computing Systems,"A methodology that facilitates the design of fault-tolerant computing systems  is presented. It is based on the notion of a fail-stop processor. Such a  processor automatically halts in response to any internal failure and does so  before the effects of that failure become visible. The problem of implementing  processors that, with high probability, behave like fail-stop processors is  addressed. Axiomatic program verification techniques are described for use in  developing provably correct programs for fail-stop processors. The design of  a process control system illustrates the use of our methodology.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6320,Axiomatic Verification to Enhance Software Reliability,"Techniques that facilitate the design of reliable software are described. Two  distinct phenomena that can cause execution of a program to deviate from its  specifications are considered. The first is the failure of the computing  system on which the program is running. When this occurs, the system might not  be capable of following the instructions specified by the program. The second  phenomenon is that the program is written so that it will not execute  consistently with its specifications, even on a failure-free computing system.  A methodology is presented for designing programs that can cope with failures  in the underlying system. It is based on the notion of a fail-stop processor -  a processor with well-defined failure mode operating characteristics.  Axiomatic program verification techniques are extended for use in developing  provably correct programs for such processors. The problem of meeting  response time goals in light of failures is discussed. Lastly, the problem of  implementing processors that, with high probability, behave like fail-stop  processors is addressed. Programming logics have already been developed to reason about sequential  programs, and parallel programs that use shared memory or synchronous  message-passing. That work is extended to facilitate reasoning about programs  that use asynchronous message-passing. Two benefits accrue from this. The  obvious one is that partial correctness proofs can be written for concurrent  programs that use such primitives. This allows such programs to be understood  as predicate transformers, instead of by contemplating all possible execution  interleavings - often an intractible task. The other benefit is that these  proof rules and their derivation shed light onto how this interference can be  controlled. In particular, disciplines that make asynchronous message-passing  primitives simple and safe to use are explored. A partial correctness proof of the two-phase commit protocol illustrates the  application of the new techniques. This protocol, widely used in database  applications, ensures that a specified action is performed either at all sites  in a distributed system, or at no site, despite failures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6321,Oblique Procrustes Rotations in Factor Analysis,"This paper addresses the problem of rotating a factor matrix obliquely to a  least squares fit to a target matrix. The target may be fully or partially  specified. An iterative computing procedure is presented. Keywords: oblique rotations, procrustes problem, factor analysis, least  squares.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6322,Opening Night at Upson Hall (Scripts from Holiday Party Skits),"Every holiday season comes the time when the thoughts of graduate students at  Cornell turn to the fast-approaching A-exams. More precisely, they think,  ""We'd better get them before they get us."". Hence, these attempts at  theatrical productions. Although they are based on the quirks and  idiosyncracies of faculty members, they should not be taken as criticism. The  authors would prefer to think that everyone is laughing together, rather than  at anyone in particular. And with this word of caution, we present... 1977, 1978, 1979, 1980, 1981.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6323,A Quorum-Based Commit Protocol,"Herein, we propose a commit protocol and an associated recovery protocol that  is resilient to site failures, lost messages, and network partitioning. The  protocols do not require that a failure be correctly identified or even  detected. The only potential effect of undetected failures is a degradation in  performance. The protocols use a weighted voting scheme that supports an  arbitrary degree of data replication (including none) and allows unilaterally  aborts by any site. This last property facilitates the integration of these  protocols with concurrency control protocols. Both protocols are centralized  protocols with low message overhead.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6324,On the Structure of Feasible Computations,"This paper discusses the study of computational complexity of feasible  computations and surveys some recent insights and results about the structure  of NP complete languages and the attempts to separate the classic complexity  classes DLOGTAPE, NDLOGTAPE, PTIME, NPTIME,$\ldots,\Sigma^{P}_{k}, \ldots,$  PTAPE.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6325,On Goedel Speed-Up and Succinctness of Language Representation,In this note we discuss the similarities and differences between Goedel's  result about non-recursive shortening of proofs of formal systems by  additional axioms and the corresponding results about the succinctness of  different representations of languages.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6326,On the Movement of Robot Arms in Two Dimensional Bounded Regions,"The classical mover's problem is the following: can a rigid object in  3-dimensional space be moved from one given position to another while avoiding  obstacles? It is known that a more general version of this problem involving  objects with movable joints is PSPACE complete, even for a simple tree-like  structure moving in a 3-dimensional region. In this paper, we investigate a  2-dimensional mover's problem in which the object is a robot arm with an  arbitrary number of joints. In particular, we give a polynomial time algorithm  for moving an arm confined within a circle from one given configuration to  another. We also give a polynomial time algorithm for moving the arm from its  initial position to a position in which the end of the arm reaches a given  point within the circle. Keywords: robotics, manipulators, mechanical arms, algorithms, polynomial time.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6327,Fast Parallel Matrix and GCD Computations,We present parallel algorithms to compute the determinant and characteristic  polynomial of n x n-matrices and the gcd of polynomials of degree $\leq$n. The  algorithms use parallel time $O(\log^{2}n)$ and a polynomial number of  processors. We also give a fast parallel Monte Carlo algorithm for the rank of  matrices. All algorithms work over arbitrary fields.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6328,"A Method for Solving Certain Graph Recognition and Optimization Problems, with Applications to Perfect Graphs","A polynomial time membership test and solutions to the minimum coloring and  maximum weight clique and stable set problems are given for certain families  of graphs. In particular, it is shown that for any arbitrary hereditary family  of graphs, these problems can be solved quickly for the entire family whenever  they can be solved quickly for the clique cutset free members of the family.  If the graphs in the family are perfect, then a similar statement holds for  the mimimum weight clique and stable set problems. These results are obtained  by applying a polynomial time algorithm for determining whether a graph has a  clique cutset. Several questions of Gavril concerning ""clique separable""  perfect graphs are answered, and a polynomial time recognition algorithm for  Gallai's ""i-triangulated"" perfect graphs is given. Keywords: graph algorithms, cliques, stable sets, perfect graphs, clique  separable graphs, i-triangulated graphs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6329,A Comparison of Four Methods for Solving Systems of Nonlinear Equations,"In this thesis, Brent's method and the Brent-Gay version of Brown's method for  solving systems of nonlinear equations are studied. A comparison is then made  between these two methods, Powell's hybrid method and Brown's original method.  The numerical results show that the Brent-Gay version is an improvement of the  method and that in the average Brent's method is the best. Finally, listings  of the two studied algorithms and of the test functions are given in the  appendices.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6330,"The ""Hoare Logic"" of CSP, and All That","Generalized Hoare Logic is a formal logical system for deriving invariance  properties of programs. It provides a uniform way to describe a variety of  methods for reasoning about concurrent programs, including noninterference,  satisfaction, and cooperation proofs. We describe a simple meta-rule of the  Generalized Hoare-Logic - the Decomposition Principle - and show how all these  methods can be derived using it.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6331,Using Message Passing for Distributed Programming: Proof Rules and Disciplines,"Inference rules are derived for proving partial correctness of concurrent  programs that use message passing. These rules extend the notion of a  satisfaction proof, first proposed for proving correctness of programs that  use synchronous message-passing, to asynchronous message-passing, rendezvous,  and remote procedures. Two types of asynchronous message-passing are  considered: unreliable datagrams and reliable virtual circuits. The proof  rules show how interference can arise and be controlled.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6332,The Definition of $\mu$PRL,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6333,The 711 Problem,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6334,A Symplectic Method for Approximating All the Eigenvalues of a Hamiltonian Matrix,"A fast method for computing all the eigenvalues of a Hamiltonian matrix M is  given. The method relies on orthogonal symplectic similarity transformations  which preserve structure and have desirable numerical properties. The  algorithm is about four times faster than the standard Q-R algorithm. The  computed eigenvalues are shown to be the exact eigenvalues of a matrix M+E  where $\Vert E \Vert$ depends on the square root of the machine precision. The  accuracy of a computed eigenvalue depends on its condition and its magnitude,  larger eigenvalues typically being more accurate.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6335,Programming Language Constructs for Which it is Impossible to Obtain Good Hoare-Like Axioms,Programming Language Constructs for Which it is Impossible to Obtain Good Hoare-Like Axioms,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6336,Determining the Last Process to Fail,"A total failure occurs whenever all processes cooperatively executing a  distributed task fail before the task's completion. A frequent prerequisite  for recovery from a total failure is the identification of the last group  (LAST) of processes concurrently failing. Herein, we derive necessary and  sufficient conditions for computing LAST from the local failure data of  recovered processes. These conditions are easily translated into decision  procedures for LAST membership using either complete or incomplete failure  data. The choice of failure data itself is dictated by two requirements: (1)  it can be cheaply maintained, and (2) maximum fault-tolerance is afforded in  the sense that the expected number of recoveries required for identifying LAST  is minimized.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6337,A Classification of Certain Graphs with Minimal Imperfection Properties,"The family of $(\alpha \omega)$-graphs are of interest for several reasons.  For example, any minimal counter-example to Berge's Strong Perfect Graph  Conjecture belongs to this family. This paper accounts for all (4,3)-graphs.  One of these is not attainable by existing techniques for generating $(\alpha  +1,\omega)$-graphs from $(\alpha, \omega)$-graphs. Keywords: perfect graphs, minimal imperfect graphs, $(\alpha,\omega)$-graphs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6338,On the Role of Words and Phrases in Automatic Text Analysis,"One of the most crucial operations in automatic information retrieval is the  assignment to written texts and documents of appropriate identifiers,  capable of representing information content for search and retrieval purposes.  This operation known as automatic indexing normally consists in assigning to  the documents either single terms, or more specific entities such as phrases,  or more general entities such as term classes. A model, known as discrimination value analysis is introduced which assigns  an appropriate role in the indexing operation to the terms, term phrases, and  thesaurus classes. The model is used to determine effectiveness criteria for  the content identifiers and to generate useful indexing policies. Experimental  evidence is given to validate the theory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6339,Dual Variable Metric Algorithms for Constrained Optimization,"We present a class of algorithms for solving constrained optimization  problems. In the algorithm non-negatively constrained quadratic programming  subproblems are iteratively solved to obtain estimates of Lagrange multipliers  and with these estimates a sequence of points which converges to the solution  is generated. To achieve a superlinear rate of convergence the matrix  appearing in the subproblem is required to be an approximate inverse of the  Hessian of the Lagrangian. Some well-known variable metric updates such as the  BFGS update are employed to generate the matrix and the resulting algorithm  converges locally with a superlinear rate. When the penalty Lagrangian  developed by Hestenes, Powell and Rockafellar is incorporated in the  algorithm, it turns out to be closely related to the recently developed the  method of multipliers. Unlike the method of multipliers, our algorithm  possesses a superlinear rate of convergence even without requiring a penalty  parameter goint to infinity and therefore avoids the numerical instability so  caused.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6340,Polynomial Time Computations in Models of ET,We investigate formal notions of computations in nonstandard models of the  weak arithmetic theory ET - the theory of exponential time. It is shown that  ET is a sufficiently weak theory that many of the natural notions are not  preserved.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6341,A Survey of Some Recent Results on Computational Complexity in Weak Theories of Arithmetic,"In spite of the fact that a great deal of effort has been expended trying to  prove lower bounds for algorithms and trying to solve the P = NP question,  only limited progress has been made. Although most computer scientists remain  convinced that solutions will be found, others (Hartmanis and Hopcroft,  Fortune, Leivant and O'Donnell and Phillips) have questioned the adequacy of  Peano arithmetic for computer science. This uncertainty has only been  increased by the recent work of Paris and Harrington, showing that certain  simple, finistic, combinatorial statements are in fact independent of Peano  Arithmetic. In this paper we survey complexity theoretic statements that are  known to be independent of arithmetic theories. In addition, we survey recent  results analyzing the arithmetic quantifier structure of computational  problems. Keywords: Independence results, NP=?coNP, P=?NP, Peano arithmetic.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6342,Software for Estimating Sparse Jacobian Matrices,"In many nonlinear problems it is necessary to estimate the Jacobian matrix of  a nonlinear mapping $F$. In large scale problems the Jacobian of $F$ is  usually sparse, and then estimation by differences is attractive because the  number of differences can be small compared to the dimension of the problem.  For example, if the Jacobian matrix is banded then the number of differences  needed to estimate the Jacobian matrix is, at most, the width of the band. In  this paper we describe a set of subroutines whose purpose is to estimate the  Jacobian matrix of a mapping $F$ with the least possible number of function  evaluations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6343,The Efficient Implementation of Very-High-Level Programming Language Constructs,"An investigation is made into efficiently-implementable very-high-level  programming language constructs. In a manner analogous to ALGOL 60's  abstraction away from GOTO's, an abstract replacement for pointers (the path)  is proposed. The use of paths instead of pointers in unshared recursive data  structures greatly simplifies the process of reasoning about programs. The  existence of an efficient implementation of paths makes their use palatable as  well as desirable. Also investigated is the integration of paths with existing  very-high-level programming language implementation techniques, such as  hash-consing. Several real-time programs in Pure LISP are presented. Building on the  foundation of a real-time queue and a real-time double-ended queue, a  real-time implementation of paths is given. This leads to the surprising  negative result that the addition of paths does not increase the ""power"" of  Pure LISP.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6344,A Case Study of Number-Theoretic Computation: Searching for Primes in Arithmetic Progression,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6345,Finding Repeated Elements,"Two algorithms are presented for finding the values that occur more than  $n \div k$ times in array b[O:n-1]. The second algorithm requires time  $O(n \log(k))$ and extra space $O(k)$. We prove that $O(n \log(k))$ is a lower  bound on the time required for any algorithm based on comparing array  elements, so that the second algorithm is optimal. As special cases,  determining whether a value occurs more than $n \div 2$ times requires linear  time, but determining whether there are duplicates - the case $k=n$ - requires  time $O(n \log(n))$. The algorithms may be interesting from a standpoint of programming  methodology; each was developed as an extension of an algorithm for the simple  case $k=2$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6346,A Separator Theorem for Graphs of Bounded Genus,"Many divide-and-conquer algorithms on graphs are based on finding a small set  of vertices or edges whose removal divides the graph roughly in half. Most  graphs do not have the necessary small separators, but some useful classes do.  One such class is planar graphs: If we can draw an n-vertex graph on the  plane, then we can bisect it by removing $O(\sqrt{n})$ vertices [Lipt79b]. The main result of this paper is that if we can draw a graph on a surface of  genus g, then we can bisect it by removing $O(\sqrt{gn})$ vertices. This  bound is best possible to within a constant factor. We give an algorithm for  finding the separator that takes time linear in the number of edges in the  graph, given an embedding of the graph in its genus surface. We discuss some  extensions and applications of these results.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6347,Extensions of the Reduction Process in the Wong-Youssefi Strategy for Query Processing,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6348,On Sparse Sets in NP-P,"The main result of this note shows that there exist sparse sets in $NP$ that  are not in $P$ if and only if NEXPTIME differs from EXPTIME. Several other  results are derived about the complexity of very sparse sets in $NP-P$ and an  interpretation of the meaning of these results is given in terms of the  complexity of solving ""individual instances"" of problems in $NP-P$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6349,On the Local Convergence of a Quasi-Newton Method for the Nonlinear Programming Problem,In this paper we propose a new local quasi-Newton method to solve the equality  constrained non-linear programming problem. The pivotal feature of the  algorithm is that a projection of the Hessian of the Lagrangian is  approximated by a sequence of symmetric positive definitive matrices. The  matrix approximation is updated at every iteration by a projected version of  the DFP or BFGS formula. We establish that the method is locally convergent  and the sequence of x-values converges to the solution at a 2-step  Q-superlinear rate.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6350,A Note on the Computation of an Orthonormal Basis for the Null Space of a Matrix,"A highly regarded method to obtain an orthonormal basis, $Z$, for the null  space of a matrix $A^{T}$ is the $QR$ decomposition of $A$, where $Q$ is the  product of Householder matrices. In several optimization contexts $A(x)$  varies continuously with $x$ and it is desirable the $Z(x)$ vary continuously  also. In this note we demonstrate that the standard implementation of the $QR$  decomposition does not yield an orthonormal basis $Z(x)$ whose elements vary  continuously with $x$. We suggest three possible remedies.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6351,Extended Boolean Information Retrieval,"In conventional information retrieval Boolean combinations of index terms are  used to formulate the users' information requests. While any document is in  principle retrievable by a Boolean query, the amount of output obtainable by  Boolean processing is difficult to control, and the retrieved items are not  ranked in any presumed order of importance to the user population. In the  vector processing model of retrieval, the retrieved items are easily ranked in  decreasing order of the query-record similarity, but the queries themselves  are unstructured and expressed as simple sets of weighted index terms. A new, extended Boolean information retrieval system is introduced which is  intermediate between the Boolean system of query processing and the vector  processing model. The query structure inherent in the Boolean system is  preserved, while at the same time weighted terms may be incorporated into both  queries and stored documents; the retrieved output can also be ranked in  strict similarity order with the user queries. A conventional retrieval system  can be modified to make use of the extended system. Laboratory tests indicate  that the extended system produces better retrieval output than either the  Boolean or the vector processing systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6352,Hierarchical Replacement Decisions in Hierarchical Stores,"One of the primary motivations for implementing virtual memory is its ability  to automatically manage a hierarchy of storage systems with different  characteristics. The composite system behaves as if it were a single-level  system having the more desirable characteristics of each of its constituent  levels. In this paper, we extend the virtual memory concept to within each of  the levels of the hierarchy. Each level is thought of as containing two  additional levels within it. This hierarchy is not a physical one, but rather  an artificial one arising from the employment of two different replacement  algorithms. Given two replacement algorithms, one of which has good  performance but high implementation cost and the other poor performance but  low implementation cost, we propose and analyze schemes that result in an  overall algorithm having the performance characteristics of the former and  the cost characteristics of the latter. We discuss the suitability of such  schemes in the management of storage hierarchies that lack page reference  bits.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6353,Key Exchange Using Keyless Cryptography,"Protocols to generate and distribute secret keys in a computer network are  described. They are based on keyless cryptography, a new cryptographic  technique where information is hidden by keeping only the originator of a  message, and not its contents, secret.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6354,Generating Language-Based Environments,"This thesis concerns the design of interactive, language-based programming  environments that use knowledge of a programming language to provide functions  based on the structure and meaning of programs. The goal of the research is a  system-constructor to enable editors for different languages to be created  easily. The most challenging aspect of such a system is the design of the semantic  component, because a language-based editor performs static semantic analysis  when a program is altered in order to detect erroneous constructions or to  prevent illegal modifications. For efficiency, this should be performed  incrementally, re-using as much old information as possible; therefore, a  major focus of my research concerns a model of editing for which it is  possible to perform incremental semantic analysis efficiently. In this model, a program is represented as an attributed tree in which all  attributes have consistent values; programs are modified by tree operations  such as pruning, grafting, and deriving. After each modification, some of the  attributes require new values; incremental semantic analysis is performed by  updating attribute values to again make them all consistent. The thesis  presents several algorithms for this process that are asymptotically optimal  in time. The chief disadvantage of attribute grammars is that they use large amounts of  storage. The thesis discusses three aspects of utilizing storage efficiently  in such systems. One way to reduce the amount of storage used is to reduce the  number of atttribute values retained at any stage of attribute evaluation.  The thesis establishes two results concerning this idea: it presents one  algorithm for evaluating an n-attribute tree that never saves more than  $O(\sqrt{n}$ attribute values, and it presents a second algorithm that never  saves more than $O(\log n)$ attribute values. A second method for reducing  the amount of storage is to share the space used for storing attributes whose  values are complex data structures; the thesis presents a very general method  for such sharing that can be applied to attributes of many types. Finally, the  thesis describes how, by restricting the class of attribute grammars, it is  possible to reduce the amount of storage overhead required for updating trees  in optimal time.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6355,Movement Problems for 2-Dimensional Linkages,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6356,Determining Points of a Circular Region Reachable by Joints of a Robot Arm,"An ""arm"" is a sequence of links whose endpoints are connected consecutively  by movable joints. The location of the first endpoint is fixed. This report  gives a polynomial time algorithm for determining the regions that each joint  can reach when the arm is restricted to a circular region of the plane.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6357,Graph Rigidity,"The relationship between graph isomorphism and graph rigidity is studied.  Although in general it is not known if these problems are equivalent under  polynomial time Turing reductions, equivalence is shown for a subclass of  graphs with abelian automorphism groups.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6358,Upson's Familiar Quotations - Third Edition,"This report is a compilation of several hundred examples of context-free  language and very irregular expressions. Contributions were submitted over the  past several years by numerous computer science graduate students who  collected these now immortal words in classes and seminars. We wish to express  our gratitude to the faculty, guest lecturers, and students who provided the  bulk of this work.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6359,Concepts and Notations for Concurrent Programming,"Much has been learned in the last decade about concurrent programming. This  paper identifies the major concepts and describes some of the more important  language notations for writing concurrent programs. The roles of processes,  communication and syhchronization are discussed from both an operational and  an axiomatic viewpoint. Language notations for expressing concurrent execution  and for specifying process interaction are surveyed. Synchronization  primitives based on shared variables and on message passing are described.  Finally, three general classes of concurrent programming languages are  identified and compared.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6360,Computing the Cholesky Factorization Using a Systolic Architecture,This note concerns the computation of the Cholesky factorization of a  symmetric and positive definite matrix on a systolic array. We use the special  properties of the matrix to simplify the algorithm and the corresponding  architecture given by Kung and Leiserson.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6361,A Systolic Architecture for the Singular Value Decomposition,"We propose a systolic architecture for computing a singular value  decomposition of an m x n matrix, where $m \geq n$. Our algorithm is stable  and requires only $O(mn)$ time on a linear array of $O(n)$ processors.  Extensions to algorithms for two-dimensional arrays are also discussed. Key Words and Phrases: Systolic arrays, singular value decomposition, Hestenes  method, threshold Jacobi method, real-time computation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6362,A Separator Theorem for Chordal Graphs,"Chordal graphs are undirected graphs in which every cycle of length at least  four has a chord. They are sometimes called rigid circuit graphs or perfect  elimination graphs; the last name reflects their utility in modelling Gaussian  elimination on sparse matrices. The main result of this paper is that a  chordal graph with $n$ vertices and $m$ edges can be cut in half by removing  $O(\sqrt{m})$ vertices. A similar result holds if the vertices have  non-negative weights and we want to bisect the graph by weight, or even if we  want to bisect the graph simultaneously by several unrelated sets of weights.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6363,Automatic Query Formulations in Information Retrieval,"Modern information retrieval systems are designed to supply relevant  information in response to requests received from the user population. In most  retrieval environments the search requests consist of keywords, or index  terms, interrelated by appropriate Boolean operators. Since it is difficult  for untrained users to generate effective Boolean search requests, trained  search intermediaries are normally used to translate original statements of  user need into useful Boolean search formulations. Methods are introduced in this study which reduce the role of the search  intermediaries by making it possible to generate Boolean search formulations  completely automatically from natural language statements provided by the  system patrons. Frequency considerations are used automatically to generate  appropriate term combinations as well as Boolean connectives relating the  terms. Methods are covered to produce automatic query formulations both in a  standard Boolean logic system, as well as in an extended Boolean system in  which the strict interpretation of the connectives is relaxed. Experimental  results are supplied to evaluate the effectiveness of the automatic query  formulation process in practice.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6364,A Systolic Architecture for Almost Linear-Time Solution of the Symmetric Eigenvalue Problem,"An algorithm is presented for computing the eigenvalues and eigenvectors of an  n x n real symmetric matrix. The algorithm is essentially a Jacobi method  implemented on a two-dimensional systolic array of $O(n^{2})$ processors with  nearest-neighbor communication between processors. The speedup over the serial  Jacobi method is $\Theta(n^{2})$, so the algorithm converges to working  accuracy in time $O(nS))$, where $S$ is the number of sweeps (typically  $S \leq 10)$. Key Words and Phrases: Eigenvalue decomposition, real symmetric matrices,  Hermitian matrices, Jacobi method, linear-time computation, systolic arrays,  VLSI, real-time computation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6365,A Systolic Array for the Linear-Time Solution of Toeplitz Systems of Equations,"The solution of an (n+1)x(n+1) Toeplitz system of linear equations on a  one-dimensional systolic architecture is studied. Our implementation of an  algorithm due to Bareiss is shown to require only $O(n)$ time and $O(n)$  storage, i.e. constant storage per systolic processor. Key words and phrases: Systolic arrays, Toeplitz matrices, linear equations,  Bareiss algorithm, VLSI.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6366,Computing the Minimum Eigenvalue of a Symmetric Positive Definite Toeplitz Matrix,A method for computing the smallest eigenvalue of a symmetric positive  definite Toeplitz matrix is given. It relies solely upon the Levinson-Durbin  algorithm. The procedure involves a combination of bisection and Newton's  method. Good starting values are also shown to be obtainable from the  Levinson-Durbin algorithm.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6367,Computation of the Singular Value Decomposition Using Mesh-Connected Processors,A cyclic Jacobi method for computing the singular value decomposition of an  $mxn$ matrix $(m \geq n)$ using systolic arrays is proposed. The algorithm  requires $O(n^{2})$ processors and $O(m + n \log n)$ units of time.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6368,Using $\cal SEEK$ for Multi-Channel Pattern Recognition,"Our work on computerized analysis of the 2-channel, 24-hr electrocardiogram  has resulted in the development of multi-channel signal processing systems  that learn by observation. In this paper a new tool for implementing such  algorithms is described: the pattern recognition language $\cal SEEK$.  Programs written in $\cal SEEK$ build a knowledge base containing tree-like  data structures, each of which stores acquired information about a particular  multi-channel waveform. Input data is interpreted by performing an efficient  parallel evaluation of the structures in the knowledge base. Our work is  applicable to a wide variety of pattern recognition problems that arise in  medical signal processing. The approach is illustrated with examples drawn  from ECG analysis.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6369,Proofs as Programs,"The significant intellectual cost of programming is for problem solving and  explaining and not for coding. Yet, programming systems offer mechanical  assistance exclusively with the coding process. Here we describe an  implemented program development system, called PRL (""pearl""), that provides   automated assistance with the hard part. The program and its explanation are  seen as formal objects in a constructive logic of the data domains. These  formal explanations can be executed at various stages of completion. The most  incomplete explanations resemble applicative programs, the most complete are  formal proofs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6370,A Note on the Standard Strategy for Developing Loop Invariants and Loops,"The by-now-standard strategy for developing a loop invariant and loop was  developed in [1] and explained [2]. Nevertheless, its use still poses problems  for some. The purpose of this note is to provide further explanation. Two  problems are solved that, without this further explanation, seem difficult.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6371,Programs as Proofs,"Programs are like constructive proofs of their specifications. This analogy is  a precise equivalence for certain classes of programs. The connection between  formal logic and programs is a foundation for programming methodology superior  to that usually adopted. Moreover, this equivalence suggests programming  languages which are far richer than all others currently in use. These claims  are established in this paper introducing parts of the PL/CV programming  logics as a source of precision and examples. Key Words and Phrases: Algorithmic logic, automated logic, axiomatic  semantics, constructive mathematics, program correctness, PL/CV, programming  logic, programming methodology, realizability, while rule.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6373,Making Variables Abstract: An Equational Theory for Russell,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6374,Estimation of Sparse Hessian Matrices and Graph Coloring Problems,"Large scale optimization problems often require an approximation to the  Hessian matrix. If the Hessian matrix is sparse then estimation by  differences of gradients is attractive because the number of required  differences is usually small compared to the dimension of the problem. The  problem of estimating Hessian matrices by diferences can be phrased as  follows: Given the sparsity structure of a symmetric matrix $A$, obtain  vectors $d_{1},d_{2},\ldots,d_{p}$ such that $Ad_{1},Ad_{2},\ldots,Ad_{p}$  determine $A$ uniquely with $p$ as small as possible. We approach this problem  from a graph theoretic point of view and show that both direct and indirect  approaches to this problem have a natural graph coloring interpretation. The  complexity of the problem is analyzed and efficient practical heuristic  procedures are developed. Numerical results illustrate the differences between  the various approaches.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6375,COFE: A Prototype Memo and Mail System for Non-Programmers,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6376,The Inherent Cost of Nonblocking Commitment,"A commitment protocol orchestrates the execution of a distributed transaction,  allowing each participant to ""vote"" on the transaction and then applying a  pre-specified rule to decide the outcome (commit or abort). A nonblocking is  able to correctly terminate a transaction at all operational participants in  the presence of any number of benign processor failures. Herein, we derive  strong lower bounds for both non-blocking protocols and their less  fault-tolerant blocking counterparts. Results on message complexity are both  surprising and encouraging: the message complexities of the two classes of  protocols are identical. Results on time complexity were less encouraging:  nonblocking protocols are approximately 50% more expensive. However, we show  how to overlap non-blocking executions of interfering transactions and thereby  reduce their extra cost.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6377,Fault-Tolerant Broadcasts,"A distributed program is presented that ensures delivery of a message to the  functioning processors in a computer network, despite the fact that processors  may fail at any time. All processor failures are assumedd to be detected and  to result in halting the offending processor. A reliable communications  network is assumed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6378,"Bounds on Oblivious, Conservative Matrix Transposition Networks",A matrix transposition network of depth $k$ is shown to require  $\theta (kn^{1+1/k})$ edges.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6379,Boolean Query Formulation with Relevance Feedback,The well-known relevance feedback process uses information extracted from  previously retrieved relevant documents to generate improved search  formulations for subsequent search iterations. Methods are outlined in this  study for the automatic generation of Boolean search statements based on the  natural language texts of initially available search requests and of  previously retrieved document excerpts identified as relevant by the user  population. The search requests are generated both in a conventional Boolean  system and in an extended system in which the normal interpretation of the  Boolean connectives is relaxed. Experimental output is included which shows  that substantial improvements in retrieval effectiveness are obtainable using  the automatic relevance feedback methods.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6380,A Data Abstraction Language for Concurrent Programming,No Abstract Supplied,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6381,Some Linear-Time Algorithms for Systolic Arrays,"We survey some recent results on linear-time and almost linear-time algorithms  for one and two-dimensional systolic arrays. In particular, we show how the  greatest common divisor (GCD) of two polynomials of degree $n$ over a finite  field can be computed in time $O(n)$ on a linear systolic array of $O(n)$  cells; similarly for the GCD of two $n$-bit binary numbers. Assuming that the  systolic cells can perform floating-point arithmetic, we show how $n$ by $n$  Toeplitz systems of linear equations can be solved in time $O(n)$ on a linear  array of $O(n)$ cells, each of which has constant memory size (independent of  $n$). Finally, we outline how a two-dimensional array of $O(n)$ by $O(n)$  cells with nearest-neighbor interconnections can be used to solve (to working  accuracy) the eigenvalue problem for a symmetric real $n$ by $n$ matrix in  time $O(nS(n))$. Here $S(n)$ is a slowly-growing function of $n$; for  practical purposes $S(n)$ can be regarded as a constant. In addition to their  theoretical interest, these results can be implemented relatively easily and  have potential applications in the areas of error-correcting codes, symbolic  and algebraic computation, signal processing and image processing. For  example, systolic GCD arrays for error correction have been implemented with  the microprogrammable ""PSC"" chip.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6382,Some Negative Results Concerning Prime Number Generators,"Programs due to Wirth and Misra for generating the prime numbers up to a  specified limit are investigated. It is shown that Wirth's program is  incorrect according to three increasingly weak criteria, and a composite  number is exhibited that the program accepts as prime. This is the smallest  known counter-example, and could not have been found by the usual method of  program testing - the program would run for trillions of years on the fastest  computer before reaching it! Closely related counter-examples are given to a  conjecture of Misra concerning his program.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6383,A Generalized Term Dependence Model in Information Retrieval,"The tree dependence model has been used successfully to incorporate  dependencies between certain term pairs on the information retrieval process,  while the Bahadur Lazarsfeld Expansion (BLE) which specifies dependencies  between all subsets of terms has been used to identify productive clusters of  items in a clustered data base environment. The successes of these models are  unlikely to be accidental; it is of interest therefore to examine the  similarities between the two models. The disadvantage of the BLE model is the exponential number of terms  appearings in the full expression, while a truncated BLE system may produce  negative probability values. The disadvantage of the tree dependence model is  the restriction to dependencies between certain term pairs only and the  exclusion of higher-order dependencies. A generalized term dependence model is  introduced in this study which does not carry the disadvantages of either the  tree dependence or the BLE models. Sample evaluation results are included to  demonstrate the usefulness of the generalized system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6384,Sparse Sets in NP-P: EXPTIME Versus NEXPTIME,"This paper investigates the structural properties of sets in NP-P and shows  that the computational difficulty of lower density sets in NP depends  explicitly on the relations between higher deterministic and nondeterministic  time-bounded complexity classes. The paper exploits the recently discovered  upward sparation method, which shows for example that there exist sparse sets  in NP-P if and only if EXPTIME $\neq$ NEXPTIME. In addition, the paper uses  relativization techniques to determine logical possibilities, limitations of  these proof techniques, and, for the first time, to exhibit structural  differences between relativized NP and CoNP.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6385,Graph Coloring Using Eigenvalue Decomposition,"Determining whether the vertices of a graph can be colored using $k$ different  colors so that no two adjacent vertices receive the same color is a well-known  NP-complete problem. Graph coloring is also of practical interest (for  example, in estimating sparse Jacobians and in scheduling), and many heuristic  algorithms have been developed. We present a heuristic algorithm based on the  eigenvalue decomposition of the adjacency matrix of a graph. Eigenvectors  point out ""bipartite-looking"" subgraphs that are used to refine the coloring  to a valid coloring. The algorithm optimally colors complete $k$-partite  graphs and certain other classes of graphs with regular structure.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6386,On the Optimum Checkpoint Selection Problem,"We consider a model of computation consisting of a sequence of $n$ tasks. In  the absence of failures, each task $i$ has a known completion time $t_{i}$.  Checkpoints can be placed between any two consecutive tasks. At a checkpoint,  the state of the computation is saved on a reliable storage medium.  Establishing a checkpoint immediately before task $i$ is known to cost  $s_{i}$. This is the time spent in saving the state of the computation. When a  failure is detected, the computation is restarted at the most recent  checkpoint. Restarting the computation at checkpoint $i$ requires restoring  the state to the previously saved value. The time necessary for this action is  given by $r_{i}$. We derive an $O(n^{3})$ algorithm to select out of the $n-i$  potential checkpoint locations those that result in the smallest expected  time to complete all the tasks. An $O(n^{2})$ algorithm is described for the  reasonable case where $s_{i} greater than s_{j}$ implies $r_{i} greater than r_{j}$. These  algorithms are applied to two models of failure. In the first one, each task  $i$ has a given probability $p_{i}$ of completing without a failure, i.e., in  time $t_{i}$. Furthermore, failures occur independently and are detected at  the end of the task during which they occur. The second model admits a  continuous time failure mode where the failure intervals are independent and  identically distributed random variables drawn from any given distribution. In  this model, failures are detected immediately. In both models, the algorithm  also gives the expected value of the overall completion time and we show how  to derive all the other moments.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6387,Merging Partitioned Databases,"Partitioning of a distributed data base requires either that update activity  be restricted or that a strategy for conflict resolution and partition  merging be used once communication is restored. The graph-theoretic approach  used by Davidson follows the latter approach and can be used to show that  finding an optimum solution to the general problem is NP-complete. We give  several methods of reducing the size of the graphs involved. Two open  subproblems are shown to be NP-complete, while an extension of a known  polynomial-time subproblem is given. Simulation results are used to study both  the amount of compression achieved by the graph reduction techniques and their  effects on heuristics for the problem. In addition, some modifications are  made to existing heuristics to improve their performance. A probabilistic  model is presented and compared with the simulations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6388,Computation Times of NP Sets of Different Densities,"In this paper, we study the computational complexity of sets of different  densities in NP. We show that the deterministic computation time for sets in  NP can depend on their density if and only if there is a collapse or partial  collapse of the corresponding higher nondeterministic and deterministic time  bonded complexity classes. We show also that for NP sets of different  densities there exist complete sets of the corresponding density under  polynomial time Turing reductions. Finally, we show that these results can be  interpreted as results about the complexity of theorem proving and proof  presentation in axiomatized mathematical systems. This interpretation relates  fundamental questions about the complexity of our intellectual tools to basic  structural problems about P, NP, CoNP, and PSPACE, discussed in this paper.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6389,Partial Functions in Constructive Formal Theories,"Partial functions abound in modern computing theory, and so any system which  purports to naturally formalize it must treat them. Surprisingly, the most  common treatments do not work well for constructive formal systems, i.e., for  those with computational content. Since constructive formal systems are  significant in computer science, it is important to give an account of partial  functions in them. This paper does that by construing a partial function  $\phi :N \rightarrow N$ as a total function $f:D_{f}\rightarrow N$ for $D_{f}$  an inductively defined set generated simultaneously with $f$. This idea has  appeared in other guises, at least in the author's previous work, but here it  is presented in a pure form. It is compared to Scott's method of using total  functions on domains. A formal system of arithmetic is defined to illustrate  the ideas. The system is shown consistent relative to constructive type  theory; from this result important corollaries are drawn about using the  theory as a programming language. KEY WORDS AND PHRASES: automated logic, Heyting arithmetic, constructivity,  intuitionistic predicate calculus, partial functions, recursive functions,  programming logics, program verification, type theory, type checking.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6390,Current Ideas on Programming Methodology,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6391,The Nearly Ultimate Pearl,"The PRL (""pearl"") system is an environment providing computer assistance in  the construction of formal proofs and programs in a particular formal theory,  called the object theory. Certain proofs can in fact be considered as  programs. The system embodies knowledge about programs in the form of rules of  inference and in the form of facts stored in its library. Ultimately PRL may  be regarded as an intelligent system for formal constructive problem solving  in a large domain of mathematics. The PRL system is evolving in stages. Since our report ""The Definition of  Micro-PRL"" in October 1981, we have had the experience of designing, building  and using a complete core version of the system (called $\lambda$PRL). We have  also studied more deeply the theoretical issues raised in that report. We are  now prepared to extend the core system closer to the ""ultimate"" PRL system  envisioned earlier. This document describes the mathematical theory of types  which is the object theory of that extension (called $\lambda$PRL) and it is  more or less self-contained. The type theory is defined in stages, starting  from a constructive theory of integers and lists (""PRL). The development is a  main feature of the paper.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6392,An Unconstrained Optimization Algorithm Which Uses Function and Gradient Values,A new method for unconstrained optimization is presented. It consists of a  modification of Powell's 1970 dogleg strategy with the approximate Hessian  given by Davidson's 1975 updating scheme which uses the projections of  $\triangle x$ and $\triangle g$ in updating H and G and optimizes the  condition number of $H^{-1}H_{+}$. This new algorithm performs well without  Powell's special iterations and singularity safeguards. Only symmetric and  positive definite updates to the Hessian are used.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6393,Axiomatic Proof Techniques for Parallel Programs,"This thesis presents an axiomatic method for proving certain correctness  properties of parallel programs. Axioms and inference rules for partial  correctness are given for two parallel programming languages: The General  Parallel Language and the Restricted Parallel Language. The General Language  is flexible enough to represent most standard synchronizers (e.g. semaphores,  events), so that programs using these synchronizers may be verified using the  GPL deductive system. However, proofs for GPL programs are in general quite  complex. The Restricted Language reduces this complexity by requiring shared  variables to be protected by critical sections, so that only one process at a  time has access to them. This discipline does not significantly reduce the  power of the language, and it greatly simplifies the process of program  verification. Although the axioms and inference rules are primarily intended for proofs of  partial correctness, there are a number of other important properties of  parallel programs. We give some practical techniques which use information  obtained from a partial correctness proof to derive other correctness  properties, including program termination, mutual exclusion, and freedom from  deadlock. A number of examples of such proofs are given. Finally, the axioms and inference rules are shown to be consistent and  complete (in a special sense) with respect to an interpretive model of  parallel execution. Thus the deductive system gives an accurate description of  program execution and is powerful enough to yield a proof of any true partial  correctness formula.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6394,Constructive Mathematics as a Programming Logic I: Some Principles of Theory,"The design of a programming system is guided by certain beliefs, principles,  and practical constraints. These considerations are not always manifest from  the rules defining the system. In this paper, the author discusses some of the  principles which have guided the design of the programming logics built at  Cornell in the last decade. Most of the necessarily brief discussion concerns  type theory with stress on the concepts of function space and quotient types. Key Words and Phrases: automated logic, combinators, Edinburgh LCF, partial  recursive functions, programming languages and logics, PL/CV, PRL,  propositions-as-types, quotient types, strong intensionality, type theory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6395,Exposure to Deadlock for Communicating Processes is Hard to Detect,"It is shown that the applicability of global state analysis as a tool for  proving correctness of communication protocols is rather limited. Brand, et  al. showed that reachability of global deadlock states for protocols with  unbounded FIFO channels is undecidable. It is shown, that the same is true  for unbounded non-FIFO channels. For bounded FIFO channels the problem is  shown to be PSPACE-hard. Protocols with bounded non-FIFO channels are shown to  be analyzable in polynomial time.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6396,A Distributed Path Algorithm and Its Correctness Proof,"A distributed program is developed to allow a process in a network to  determine a path from itself to any other process, assuming that the topology  of the entire network is not known to any process and that each process knows  only the names of the processes to which it is directly connected. The  solution, written in CSP, is proved correct and deadlock-free.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6397,On the Conditioning of DFP ad BFGS Updates for Unconstrained Optimization,A necessary and sufficient condition on when the conditioning of DFP updates  is given and a line search strategy which ensures that the DFP is better  conditioned than the BFGS is given.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6398,A Distributed Algorithm for Generalized Deadlock Detection,"An efficient distributed algorithm to detect deadlocks in distributed and  dynamically changing systems is presented. In our model, processes can request  any $N$ available resources from a pool of size $M$. This is a generalization  of the well-known AND-OR request model. The algorithm is incrementally derived  and proven correct. Its communication, computational, and space complexity  compares favorably to those of previously known distributed AND-OR deadlock  detection algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6399,Asynchronous Consensus and Byzantine Protocols in Faulty Environments,"A consensus protocol enables a system of $n$ aynchronous processes, some of  which are faulty, to reach agreement. There are two kinds of faulty processes:  fail-stop processes can only die, malicious processes can also send false  messages. We investigate consensus protocols that terminate within finite time  with probability 1 under certain assumptions on the behavior of the system.  With fail-stop processes, we show that $\lceil (n + 1)/2 \rceil$ correct  processes are necessary and sufficient to reach agreement. In the malicious  case, we show that $\lceil (2n + 1)/3 \rceil$ correct processes are necessary  and sufficient to reach agreement. This is contrasted with a recent result  that there is no consensus protocol for the fail-stop case that always  terminates within a bounded number of steps, even if only one process can  fail. We also investigate the possibility of reliable broadcast (Byzantine  Agreement) in an asynchronous system. We define the notion of Asynchronous  Byzantine Agreement, and show that $\lceil (2n + 1)/3 \rceil$ correct  processes are necessary and sufficient to reach Asynchronous Byzantine  Agreement.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6400,Some Considerations for Implementing the SMART Information Retrieval System Under UNIX,"Since the early 1960's the SMART project has tested out new ideas in  information science aimed at fully automatic document retrieval. Beginning in  1980 development of an enhanced and generalized version of SMART has  progresses at Cornell. The current implementation is in the C language and  runs under the UNIX operating system on a VAX 11/780 computer. The history of SMART is outlined. Considerations that led to the current  design are described. Since SMART now allows multiple concept types to be  manipulated in connection with an extended vector representation, storage and  processing issues are discussed, including use of INGRES relations. Clustering  algorithms are presented and run parameters are given for document clustering  and subsequent clustered searching. SMART experiments (e.g. with p-norm  queries, or probabilistic methods) can be compared using the evaluation  package. The S statistical package can be applied to performing other special  analysis and descriptive tasks. Finally, to illustrate the usefulness of these  facilities, an outline is given of current SMART activities and of future  plans.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6401,Characterization of Two New Experimental Collections in Computer and Information Science Containing Textual and Bibliographic Concepts,"Two new collections are described which are particularly useful for  investigating the interaction between textual and bibliographic data in the  automatic indexing and retrieval of documents. An extension to the vector  space model has been proposed whereby various types of concepts are included  in the representation of such documents. Experiments using an enhanced version  of the SMART system have shown such an extended model to perform better than  simpler schemes. The CACM and ISI collections developed for this research  should be of value for future related studies. The ISI collection has author, title/abstract, and co-citation data for the  1460 most highly cited articles and manuscripts in information science in the  1969-1977 period. The CACM collection contains 7 types of concepts for the  3204 articles published in the Communication of the ACM up through 1979.  These collections have 76 and 52 queries, respectively, along with relevance  judgments.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6402,The Solution of Singular-Value and Symmetric Eigenvalue Problems on Multiprocessor Arrays,"Parallel Jacobi-like algorithms are presented for computing a singular-value  decomposition of an $mxn$ matrix $(m \geq n)$ and an eigenvalue decomposition  of an $n x n$ symmetric matrix. A linear array of $O(n)$ processors is  proposed for the singular-value problem and the associated algorithm requires  time $O(mnS)$, where $S$ is the number of sweeps (typically $S \leq 10)$. A  square array of $O(n^{2})$ processors with nearest-neighbor communication is  proposed for the eigenvalue problem; the associated algorithm requires time  $O(nS)$. Key Words And Phrases: Multiprocessor arrays, systolic arrays, singular-value  decomposition, eigenvalue decomposition, real symmetric matrices, Hestenes  method, Jacobi method, VLSI, real-time computation, parallel algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6403,omputation of the Generalized Singular Value Decomposition Using Mesh-Connected Processors,This paper concerns the systolic array computation of the generalized singular  value decomposition. Numerical algorithms for both one and two-dimensional  systolic architectures are discussed.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6404,A Comparison of Two Methods for Boolean Query Relevance Feedback,"The relevance feedback process uses information derived from an initially  retrieved set of documents to improve subsequent search formulations and  retrieval output. In a Boolean query environment this implies that new query  terms must be identified and Boolean operators must be chosen automatically to  connect the various query terms. In this study, two recently proposed  automatic methods for relevance feedback of Boolean queries are evaluated and  conclusions are drawn concerning the use of effective feedback methods in a  Boolean query environment.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6405,Mathematics as Programming,"In a sufficiently rich programming language it is possible to express a very  substantial amount of mathematics in a natural way. I don't mean only that one  can write down functions or solve equations, I mean that one can write  theorems and proofs. Moreover, expressing mathematics in this way reveals its  computational content and makes it available for use with digital computers.  This point is illustrated with reference to a programming language which is  sufficiently rich in the above sense. I develop parts of Basic Recursive  Function Theory and logic to illustrate the way in which doing some rather  abstract mathematics is like programming. I chose BRFT in order to make  certain points about the programming language by reflecting part of it inside  itself. For example, while Church's Thesis can be false inside the language,  it is true outside, reflecting in some sense the fact that while we may  believe it, we do not expect to prove it. I chose a bit of logic to illustrate  that the virtues of model theory (a certain abstractness and notation  independence) are sometimes possible without sacrificing computational meaning.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6406,An Assertional Proof of a Byzantine Agreement Protocol,An assertional proof of a Byzantine Agreement protocol is given. This provides  a formal argument for the correctness of the protocol.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6407,A Linear Sieve Algorithm for Finding Prime Numbers,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6408,On the Duality of Intersections and Closest Points,"We call the common intersection of $k$ objects a $k$-intersection. We address  questions of the form: Given $n$ objects in the plane, ""Does there exist a  $k$-intersection?"", ""How many such $k$-intersections exist?"" and ""What is  the maximum value of $k$ for which there exists a $k$-intersection?"". In  answering such questions we utilize a duality that exists between  $k$-intersections and and $k$-closest points (the $k$ points with the smallest  enclosing circle), in that as long as $k$ points are close enough to be  enclosed by a circle of radius $r$, the common intersection of $k$ circles of  radius $r$ centered at each of those $k$ points (i.e. their $k$-intersection)  is non-null. A technique, dubbed ""rotation sorting"" is then developed to  provide efficient solutions to dual questions of the form: Given $n$ points in  the plane, ""Does there exist a set of $k$ points which can be covered by a  circle of radius $r$?"", ""How many such sets of $k$ points exist?"", and  ""What are the maximum number of points that can be enclosed by a circle of  radius $r$?"". A similar duality between the intersection of a line with circles and the  proximity of this line to the centers of the circles is exploited to obtain  efficient algorithms for the transversals of circles in the plane. Extensions  of the above questions to three and higher dimensions are also addressed,  along with problems concerning unequal sized objects. Further certain  generalizations of $k$-intersections and of the number of points enclosed by  $k$ objects in two dimensions and higher are shown to be NP-complete and  $D^{p}$-complete.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6409,Byzantine Generals In Action: Implementing Fail-Stop Processors,"A fail-stop processor halts instead of performing an erroneous state  transformation that might be visible to other processors, can detect whether  another fail-stop processor has halted (due to a failure), and has a  predefined portion of its storage that is unaffected by failures and  accessible to any other fail-stop processor. Fail-stop processors can simplify  construction of fault-tolerant computing systems. In this paper, the problem  of approximating fail-stop processors is compared with the state machine  approach, another general paradigm for constructing fault-tolerant systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6410,Advanced Feedback Methods in Information Retrieval,"Automatic feedback methods may be used in on-line information retrieval to  generate improved query statements based on information contained in  previously retrieved documents. In this study automatic relevance feedback  techniques are applied to Boolean query statements. The feedback operations  are carried out using both the conventional Boolean logic, as well as an  extended logic producing improved retrieval effectiveness. Experimental  output is included to evaluate the automatic feedback operations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6411,The Case for PL/I as the Language for Instruction in Programming,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6412,Managing Distributed Databases in Partitioned Networks,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6413,Generalized Kolmogorov Complexity and the Structure of Feasible Computations,"In this paper we define a generalized, two-parameter, Kolmogorov complexity of  finite strings which measures how much and how fast a string can be compressed  and we show that this string complexity measure is an efficient tool for the  study of computational complexity. The advantage of this approach is that it  not only classifies strings as random or not random, but measures the amount  of randomness detectable in a given time. This permits the study how  computations change the amount of randomness of finite strings and thus  establish a direct link between computational complexity and generalized  Kolmogorov complexity of strings. This approach  gives a new viewpoint for  computational complexity theory, yields natural formulations of new problems  and yields new results about the structure of feasible computations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6414,The Seven-Eleven Problem,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6415,A Study of the Structure of NP,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6416,On Non-Isomorphic NP Complete Sets,"In this note we show that if the satisfiability of Boolean formulas of low  Kolmogorov complexity can be determined in polynomial-time then there exist  NP complete sets that are not polynomial-time isomorphic. Keywords: NP complete sets, isomorphism, Kolmogorov complexity.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6417,The Ultimate Planar Convex Hull Algorithm ?,"We present a new planar convex hull algorithm with worst case time complexity  $O(n \log H)$ where $n$ is the size of the input set and $H$ is the size of  the output set, i.e. the number of vertices found to be on the hull. We also  show that this algorithm is asymptotically worst case optimal on a rather  realistic model of computation even if the complexity of the problem is  measured in terms of input as well as output size. The algorithm relies on a  variation of the divide-and-conquer paradigm which we call the  ""marriage-before-conquest"" principle and which appears to be interesting in  its own right.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6418,Predicting Fill for Sparse Orthogonal Factorization,"In solving large sparse linear least squares problems $Ax \cong b$, several  different numeric methods involve computing the same upper triangular factor  $R$ of $A$. It is of interest to be able to compute the nonzero structure of  $R$, given only the structure of $A$. The solution to this problem comes from  the theory of matchings in bipartite graphs. The structure of $A$ is modeled  with a bipartite graph and it is shown how the rows and columns of $A$ can be  rearranged into a structure from which the structure of its upper triangular  factor can be correctly computed. Also, a new method for solving sparse least  squares problems, called block back-substitution, is presented. This method  assures that no unnecessary space is allocated for fill, and that no space is  needed for intermediate fill.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6419,String-Matching Cannot be Done by a Two-Head One-Way Deterministic Finite Automaton,"We show that string-matching cannot be performed by a two-head one-way  deterministic finite automaton (or even by a Turing machine with two one-way  input heads and o(n) storage space). Thus we answer the special case $k=2$ of  the open question, due to Galil and Seiferas [GS], whether a $k$-head one-way  deterministic finite automaton can perform string-matching.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6420,"Long Arithmetic Progressions of Primes: Some Old, Some New",NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6421,Increasing Availability in Partitioned Database Systems,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6422,Howard Aiken's Children: The Harvard Computation Laboratory and its Students,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6423,Documentation for the CHIP Computer System (Version 1.1),"CHIP (Cornell Hypothetical Instructional Processor) is a computer system that  was designed as an educational tool for teaching undergraduate courses in  operating systems and machine architecture. This document constitutes the sole  reference manual for the CHIP computer system. A simulator for this  hypothetical system exists under the UNIX operating system. The CHIP  architecture includes dynamic memory mapping suitable for implementing virtual  memory, eight interrupt priority levels, memory-mapped input/output and two  modes of processor operation. The central processor of CHIP is compatible  with the PDP-11 at the user-mode instruction level. Therefore, any  non-privileged code written for the PDP-11 can be executed on CHIP. Several  new user and kernel-mode instructions have been added to CHIP for increased  efficiency. The CHIP simulator also supports input/output devices such as  terminals, drums, disks and printers. All interactions with CHIP take place  through an operator's console being simulated on a terminal. Users can  examine/alter memory locations, set breakpoints, detect the referencing of  specified memory locations, start/stop execution, etc. through a console  command language. Program global variables and functions can be referred to by  symbolic name with the mapping to absolute addresses being performed  automatically by the system. The software support environment for CHIP  includes a C compiler, assembler and loader.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6424,The HOCA Operating System Specifications,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6425,Derivation of a Distributed Algorithm for Finding Paths in Directed Networks,"A distributed algorithm is developed that can be used to compute the topology  of a network, given that each site starts with information about sites it is  adjacent to, the network is strongly connected, and communication channels are  uni-directional. The program is derived and proved correct using assertional  reasoning.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6426,Randomized Asynchronous Byzantine Agreements,"A randomized protocol for reaching Byzantine Agreement in asynchronous systems  with $n$ processes was recently proposed in [Rabi83]. This protocol tolerates  up to $\lfloor (n-1)/10 \rfloor$ faulty processes, and agreement is reached  within an expected number of phases that is a small constant independent of  $n$ and the number of faulty processes $t$. In this paper, using the same  computation model as in [Rabi83], it is shown that no Byzantine Agreement  protocol can overcome more than $\lfloor (n-1)/3 \rfloor$ faulty processes in  an asynchronous system, and we describe a protocol that achieves this upper  bound. Agreement is also reached within an expected number of phases that is a  small constant independent of $n$ and $t$, but the communication complexity is  higher than in [Rabi83}.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6427,Bounds on Fundamental Problems in Parallel and Distributed Computation,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6428,The Use of Extended Boolean Logic in Information Retrieval,"An extended Boolean retrieval strategy has previously been introduced in  which the individual Boolean operators can be treated more or less strictly,  depending on the perceived strength of association of the query terms. The  extended Boolean system is illustrated by examples and evaluation output is  used to demonstrate the effectiveness of the operations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6429,Design and Analysis of Multi-User Benchmarks for Database Systems,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6430,An Asynchronous [(n-1)/3]-Resilient Consensus Protocols,"A consensus protocol enables a system of $n$ asynchronous processes, some of  them malicious, to reach agreement. No assumptions are made on the behaviour  of the processes and the message system; both are capable of colluding to  prevent the correct processes from reaching decision. A protocol is  $t$-resilient if in the presence of up to $t$ malicious processes it reaches  agreement with probability 1. In a recent paper, $t$-resilient consensus  protocols were presented for $t less than n / 5$. We improve this to $t less than n / 3$,  thus matching the lower bound on the number of correct processes necessary  for consensus. The protocol restricts the behaviour of the malicious  processes to that of merely fail-stop processes, which makes it interesting  in other contexts.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6431,On One Tape Versus Two Stacks,"We develop a simple method which enables us to prove three new lower bounds  (for both worst and average cases) for on-line computations, answering two  open problems summarized in [DGPR]. We give a language that requires $\Omega (n^{2})$ time for any 1-tape  deterministic on-line machine, but it can be accepted by a 2-stack 1-reversal  bounded deterministic on-line machine in real time. This provides a tight  lower bound, closing the gap between $\Omega ( n(logn)^{1/2})$ lower bound by  [P2] and the trivial $O(n^{2})$ upper bound. We also prove that 1-tape nondeterministic real time is much stronger than  its deterministic version. For 1-tape on-line machines, we give language  L (L"") which is in nondeterministic linear (real) time but requires  $\Omega(n^{2})(\Omega (n^{1.5}))$ deterministic time. Finally we give a language which can be accepted by a 2-stack 1-reversal  bounded deterministic machine in real time, but it requires  $\Omega(n^{1+1/2})$ time for any one tape nondeterministic online machine.  This sharply improves an $nlogn$ lower bound in [DGPR].",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6432,A Method for Proving Lower Bounds for Certain Geometric Problems,We prove lower bounds for a number of geometric problems. Our results show  that certain types of additional input information cannot possibly permit  faster solutions for these problems. The main idea in all our lower bound  proofs is the use of the index of a point as an additional coordinate.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6433,A Logic for the Russell Programming Language,"We consider a programming language with a number of characteristics  detrimental to conventional axiomatic descriptions. These include arbitrary  side effects in expressions, aliasing among variables, very general recursive  function declarations, and the ability to pass functions as parameters and  return them as results. We give an axiomatic definition of this language  based on a novel formalism. We prove the axiomatization sound and relatively  complete with respect to a (somewhat nonstandard) denotational semantics. In  spite of the nonstandard formalism, most conventional techniques for  developing and reasoning about programs can be carried over. (ABRIDGED)",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6434,Implementing Fault-Tolerant Distributed Objects,"This paper describes a technique for implementing $k$-resilient objects -  distributed objects that remain available, and whose operations are  guaranteed to progress to completion, despite up to $k$ site failures. The  implementation is derived from the object specification automatically, and  does not require any information beyond what would be required for a  non-resilient, non-distributed implementation. It is therefore unnecessary  for an appplications programmer to have knowledge of the complex protocols  normally employed to implement fault-tolerant objects. Our technique is used  in ISIS, a system being developed at Cornell to support resilient objects.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6435,Randomized Byzantine Agreement,"A randomized model of distributed computation was presented in [Rabin83].  This model admits a solution to the Byzantine Agreement Problem for systems  of $n$ asynchronous processes where no more than $t$ are faulty. The  algorithm described in [Rabin83] produces agreement in an expected number of  rounds whish is a small constant independent of $n$ and $t$. Using the same  model, we present an algorithm of similar complexity which is able to  tolerate a greater proportion of malicious processes. The algorithm is also  applicable, with minor changes, to systems of synchronous processes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6436,"A User's Guide to The Factory Modelling System, A Planning and Design Tool for Manufacturing Engineering",ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6437,Automatic Construction of CSP Programs from Sequential Non-Deterministic Programs,"In this paper we describe a systematic method for transforming a sequential  program, written in a guarded command language, into a distributed program,  written in CSP. The variables of the sequential program are first partitioned  into $n$ disjoint sets, and then the program is transformed into a CSP  program of $n$ communicating processes. The two versions of the program are  shown to be strongly equivalent, in the sense that they exhibit the  properties of reaching the same final states and of either aborting,  terminating, or running forever. We also discuss the conditions under which,  when compared to the execution of the original sequential program, a speed-up  in the execution of the resulting distributed program can be achieved.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6438,The Sparse Null Space Basis Problem,"The sparse null space basis problem is the following: $A t \times n$ matrix  $A (t less than n)$ is given. Find a matrix $N$, with the fewest nonzero entries in  it, whose columns span the null space of $A$. This problem arises in the  design of practical algorithms for large-scale numerical optimization  problems.  Surprisingly, this problem can be formulated as a combinatorial optimization  problem under a non-degeneracy assumption on $A$. THe theory of matchings in  bipartite graphs - marriage theorems - can then be used to obtain the nonzero  positions in $N$. Numerically stable matrix factorizations are used in the  next phase to compute $N$. We use conformal decompositions to characterize the columns of a sparsest  null basis. Matroid theory is used to prove that a greedy algorithm  constructs a sparsest null basis. We prove that finding a sparsest null basis  is NP-hard by showing that associated matroidal and graph-theoretic problems  are NP-complete. We propose two approximation algorithms to construct sparse  null bases. Both of them make use of the Dulmage-Mendelsohn decomposition of  rectangular matrices. One algorithm is a sparsity exploiting variant of the  variable-reduction technique. The second is a locally greedy algorithm that  constructs a null basis with an upper triangular submatrix. These results are  extended to computing sparse orthogonal null bases. We discuss how this  ""two-phase"" approach can construct sparser null bases than a purely  numerical approach; it is also potentially faster than the latter. Finally,  we classify all known methods for constructing null bases, and show some  unexpected equivalences between some of them.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6439,A User's Guide to The COPE Programming Environment,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6440,Buffer Management as Inventory Control,"We consider computer subsystems that use buffering as a mechanism to enhance  communication performance between two or more components exhibiting a  short-term speed mismatch. Often, a fixed size buffer is inserted in such a  communication path since it can improve performance by dampening speed  variations. We formalize this buffer management problem within the framework  of inventory control theory. We show that among all admissible policies for  controlling such communications, the structure of the optimal one is  analogous to the reorder point/order up to level policy that arises in the  single commodity, continuous review, inventory control problem. This confirms  the appropriateness of the intuitive and often-used high water mark/low water  mark policy for buffer management. Given this policy structure, we derive  expressions for the optimal parameter values. We discuss extensions of these  results whereby policy parameters are dynamically estimated based on current  observations of the communication characteristics. An algorithm to generate  the optimal ordering decisions (and resulting costs) when communication  patterns are known a priori is developed as a useful benchmark for evaluating  the goodness of on-line policies.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6441,A Taxonomy of Parallel Sorting,"In this paper, we propose a taxonomy of parallel sorting that includes a  broad range of array and file sorting algorithms. We analyze the evolution of  research on parallel sorting, from the earliest sorting networks to the  shared memory algorithms and the VLSI sorters. In the context of sorting  networks, we describe two fundamental parallel merging schemes - the odd-even  and the bitonic merge. Sorting algorithms have been derived from these  merging algorithms for parallel computers where processors communicate  through interconnection networks such as the perfect shuffle, the mesh and a  number of other sparse networks. After describing the network sorting  algorithms, we show that, with a shared memory model of parallel computation,  faster algorithms have been derived from parallel enumeration sorting  schemes, where keys are first ranked and then rearranged according to their  rank. Parallel sorting algorithms are evaluated according to a number of criteria,  related not only to their time complexity, but also to their feasibility from  a computer architecture point of view. We show that in addition to their  attractive communication schemes, network sorting algorithms have  non-adaptive schedules that make them suitable for implementation. In  particular, they are easily generalized to block-sorting algorithms, that  utilize limited parallelism to solve large sorting problems. We also address  the problem of sorting large mass-storage files in parallel, using modified  disk devices or intelligent bubble memories. Finally, the newer area of VLSI  sorting is mentioned as an active and promising direction of research on  parallel sorting.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6442,On the Motion of Objects in Contact,"There is an increasing use of computers in the design, manufacture and  manipulation of physical objects. An important aspect of reasoning about such  actions concerns the motion of objects in contact. The study of problems of  this nature requires not only the ability to represent physical objects but  the development of a framework or theory in which to reason about them. In  this paper such a development is investigated and a fundamental theorem  concerning the motion of objects in contact is proved. The simplest form of  this theorem states that if two objects in contact can be moved to another  configuration in which they are in contact, then there is a way to move them  from the first configuration to the second configuration such that the  objects remain in contact throughout the motion. This result is proved when  translation and rotation of objects are allowed. The problem dealing with  more generalized types of motion is also discussed. This study has obvious  applications in compliant motion and in motion planning.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6443,Analysis of Some Matrix Problems Using the CS Decomposition,"The gist of the CS decomposition is that the blocks of a partitioned  orthogonal matrix have related singular value decompositions. In this paper  we develop a perturbation theory for the CS decomposition and use it to  analyze (a) the total least squares problem, (b) the Golub-Klema-Stewart  subset selection algorithm, (c) the algebraic Riccati equation, and (d) the  generalized singular value decomposition.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6444,On the Method of Weighting for Equality Constrained Least Squares Problems,The generalized singular value decomposition is used to analyze the problem  of minimizing $||Ax - b||_{2}$ subject to the constraint Bx = d. A byproduct  of the analysis is a new iterative procedure that can be used to improve an  approximate solution obtained via the method of weights. All that is required  to implement the procedure is a single QR factorization. These developments  turn out to be of interest when A and B are sparse and for the case when  systolic architectures are used to carry out the computations.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6445,A User's Guide to PMT - A computer System Performance Modeling Tool,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6446,Independence Results about Context-Free Languages and Lower Bounds,"We show that for any axiomatizable, sound formal system F there exist  instances of natural problems about context-free languages, lower bounds of  computations and P versus NP that are not provable in F for any recursive  representqation of these problems. Most previous independence results in  computer science have been proven for specific representations of the  problems, by exploiting the ""opaqueness"" of Turing machine names. Our  results rely on the complexity of the logical structure of the problem and  yield independence results which do not depend on the representations of  problems. We show, for example, that there exists a non-regular context-free  language $L_{o}$ such that for no cf-grammar $G, L(G) = L_{o}$, it is  provable in F that ""L(G) is not regular"". We also show, among other results  P and NP, that there exists a recursive oracle A such that  $NP^{A} \neq P^{A}$, and that this fact is not provable in F for any  recursive representation of A. The difference of what is and is not provable in F is well illustrated by  questions about polynomial time isomorphisms (p-isomorphisms) of NP complete  sets. We show that for every NP complete set, L, there is a representation of  L by a non-deterministic polynomial time machine for which we can prove that  L is NP complete. Furthermore if L is p-isomorphic to SAT then this is also  provable in F for some representation of L. On the other hand, if there exist  NP complete sets not p-isomorphic to SAT then there exists an NP complete set  L for which, independent of its representation, there is no proof in F that L  is or is not p-isomorphic to SAT.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6447,Reducibility among Geometric Location-Allocation Optimization Problems,"Three different classes of multiple points location-allocation problems in  the Euclidean plane are considered under a discrete optimization criterion  which minimizes the maximum cost based on certain interpoint distances. Each  of these classes of geometric optimization problems is studied with three  different distance metrics (Euclidean, Rectilinear, Infinity) as well as for  feasible solution sets in the plane which are both discrete and infinite. All  of these problems are shown to be polynomial-time reducible to each other and  furthermore D^{p} complete.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6448,Automatic Assignment of Soft Boolean Operators,"The conventional bibliographic retrieval systems are based on Boolean query  formulations and inverted file implementations. Such systems provide rapid  responses in answer to search queries but they are not easy to use by  uninitiated patrons. An extended Boolean retrieval strategy has been devised  in which the Boolean operators are treated more or less strictly, depending  on the setting of a special parameter, known as the p-value. The extended  system is much more forgiving than the conventional system, and provides  better retrieval effectiveness. In this study various problems associated  with the determination of appropriate p-values are discussed, and suggestions  are made for an automatic assignment of p-values. Evaluation output is  included to illustrate the operations of the suggested procedures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6449,Some Notions about Information Retrieval in Automated Office Environments,"A substantial portion of the work required in office environments involves  the processing of natural language texts. This note contains some ideas  relating to the structure of natural language texts in office environments.  Certain approaches are also outlined concerning the analysis, storage,  search, and retrieval of such items. Attention is paid in particular to the  processing of items with mixed representations and the handling of complex  information specifications.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6450,Distributed Agreement in the Presence of Processor and Communication Faults,"A model of distributed computation is proposed in which processes may fail by  not sending or receiving the messages specified by a protocol. The solution  to the Byzantine Generals Problem for this model is presented. Our algorithm  exhibits early-stopping under conditions of less than maximum failure and is  as efficient as the algorithms developed for the more restrictive crash-fault  model in terms of time, message, and bit complexity. We show extant models to  under-estimate resiliency when faults in the communication medium are  considered; the model of this paper is more accurate in this regard.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6451,Patterns of Communication in Consensus Protocols,"This paper presents a taxonomy of consensus problems, based on their safeness  and liveness properties, and then explores the relationships among the  different problems in the taxonomy. Each problem is characterized by the  communication patterns of protocols solving it. This then becomes the basis  for a new notion of reducibility between problems. Formally, problem $P_{1}$  reduces to problem $P_{2}$ whenever each set of communication patterns of a  protocol for $P_{2}$ is the set of comunication patterns of a protocol for  $P_{1}$. This means intuitively that any protocol for $P_{2}$ can solve  $P_{1}$ by relabeling local states and padding messages. Consequently, the  message complexity (measured in number of messages) of $P_{1}$ is not greater  than the message complexity of $P_{2}$. Our method of characterizing and  comparing problems is the principal contribution of this paper.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6452,A Jacobi-like Algorithm for Computing the QR-Decomposition,A parallel Jacobi-like method for computing the QR-decomposition of an  $n \times n$ matrix is proposed. It requires $O(n^{2})$ processors and  $O(n)$ units of time. The method can be extended to handle an $m \times n$  matrix $(m \geq n)$. The requirements become $O(n^{2})$ processors and  $O(m)$ time.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6453,Computing the CS and the Generalized Singular Value Decompositions,"If the columns of a matrix are orthonormal and it is partitioned into a  2-by-1 block matrix, then the singular value decompositions of the blocks are  related. This is the essence of the ""CS decomposition"". The computation of  these related SVD's requires some care. Stewart has given an algorithm that  uses the LIN-PACK SVD algorithm together with a Jacobi-type ""clean-up""  operation on a cross-product matrix. Our technique is equally stable and fast  but avoids the cross-product matrix. The simplicity of our technique makes it  more amenable to parallel computation on systolic-type computer  architectures. These developments are of interest because the best way to  compute the generalized singular value decomposition of a matrix pair (A,B)  is to compute the CS decomposition of a certain orthogonal column matrix  related to A and B.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6454,Thrifty Execution of Task Pipelines,"A sequence of tasks that must be performed on a sequential database can be  scheduled in various ways. Schedules will differ with respect to the number  of accesses made to peripheral storage devices and the amount of memory space  consumed by buffers. Buffer requirements are discussed for task schedules  that avoid accesses to peripherals storing the sequential database. The  relationship between certain thrifty scheduling policies and loop jamming, a  standard code optimization technique, is also identified. Application to UNIX  pipelines and to file processing is discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6455,Reducing Multiple Object Motion Planning To Graph Searching,"In this paper we study the motion planning problem for multiple objects where  an object is a 2-dimensional body whose faces are line segments parallel to  the axes of $R^{2}$ and translations are the only motions allowed. Towards  this end we analyze the structure of configuration space, the space of points  that correspond to positions of the objects. In particular, we consider  CONNECTED, the set of all points in configuration space that correspond to  configurations of the objects where the objects form one connected component.  We show that CONNECTED consists of faces of various dimensions such that if  there is a path in CONNECTED between two 0-dimensional faces (vertices) of  CONNECTED then there is a path between them along 1-dimensional faces (edges)  of CONNECTED. It is known that if there is a motion between the  configurations. Thus by the result of this paper the existence of a motion  between two vertices of CONNECTED implies a motion corresponding to a path  along edges of CONNECTED. Hence we have reduced the motion planning problem  from a search of a high dimensional space to a graph searching problem. Searching the graph of vertices and edges of CONNECTED for a path has a  prohibitive worse-case complexity because of the large number of vertices and  edges. However, if the search generates edges and vertices only as they are  needed, a practical and efficient algorithm may be possible using some  effective heuristic. From this result it is shown that motion planning for rectangles in a  rectangular boundary is in PSPACE. Since it is known that the problem is  PSPACE-hard we conclude it is a PSPACE-complete problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6456,Consistency in a Partitioned Network: A Survey,"Recently, several strategies for transaction processing in partitioned  distributed database systems with replicated data have been proposed. We  survey these strategies in light of the goal of maintaining reliability.  Extensions and combinations are then discussed, and guidelines for the  selection of a strategy for a particular application are presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6457,Algebraic Specification of a Communication Scheduler,"A distributed programming language normally incorporates one mechanism by  which processes communicate with each other. This mechanism can be used to  transfer information or to synchronize the flow of control in the program.  Different communication mechanisms have been proposed for different languages.  In this paper, we provide a common framework in which these mechanisms can be  examined independently of the languages in which they may be embedded.  Operationally, this framework is a communication scheduler: formally, it is  specified algebraically as a data type. A number of different communication  mechanisms, such as synchronous and asynchronous message passing, broadcasts  and remote procedure calls, are modelled and, as an illustration of how  global properties can be analysed, we consider the problem of deadlock  detection.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6458,The Complexity of the Quaternion Product,"Let X and Y be two quaternions over an arbitrary ring. Eight multiplications  are necessary and sufficient for computing the product XY. If the ring is  assumed to be commutative, at least seven multiplications are still necessary  and eight are sufficient.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6459,An Authenticated Byzantine Generals Algorithm with Early Stopping,A protocol that solves the authenticated Byzantine General's Problem is  presented. It is proved correct and shown to exhibit early stopping under the  condition that fewer than half the processes are faulty.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6460,Simple and Efficient Byzantine General Algorithms with Early Stopping,"We describe a Byzantine Agreement algorithm, with early stopping, for systems  with arbitrary process failures. The algorithm presented is simpler and more  efficient than those previously known. It was derived using a broadcast  primitive that provides properties of message authentication and thus  restricts the disruptive behavior of faulty processes. This primitive is a  general tool for deriving fault-tolerant algorithms in the presence of  arbitrary failures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6461,Concurrency Control in Resilient Objects,"Resilient objects are instances of distributed abstract data types that are  tolerant to failures. Due to the distributed nature of resilient objects and  the use of replicated data, the potential for a high degree of concurrency  exists within them. This paper introduces a new concurrency control algorithm  which achieves higher concurrency than conventional methods like two-phase  locking. Objects are specified in a high level language. The algorithm uses  the specification taking advantage of the structure of resilient objects and  exploiting semantic information about operations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6462,Simulating Authenticated Broadcasts to Derive Simple Fault-Tolerant Algorithms,"Fault-tolerant algorithms for distributed systems are simpler to develop and  prove correct if messages can be authenticated. However, using digital  signatures for message authentication usually incurs substantial overhead in  communication and computation. To exploit the simplicity provided by  authentication without this overhead, we present a broadcast primitive that  simulates properties of authenticated broadcasts. This gives a methodology for  deriving non-authenticated algorithm. We have applied this approach to various  problems and in each case obtained simpler and more efficient solutions than  those previously known.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6463,Distributed Snapshots In Spite of Failures,"An extension of the Chandy-Lamport algorithm ([Chan84]) to find global states  of distributed systems is presented where benign failures of processes and  channels are permitted. The scope of the algorithm in detecting stable  properties in distributed systems is discussed. As an application, an  algorithm to detect deadlocks in failure-prone distributed systems is  presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6464,A Triangular Processor Array for Computing the Singular Value Decomposition,A triangular processor array for computing a singular value decomposition  (SVD) of an $m \times n (m \geq n)$ matrix is proposed. A Jacobi-type  algorithm is used to first triangularize the given matrix and then diagonalize  the resultant triangular form. The requirements are $O(m)$ time and  $1/4 n^{2} + O(n)$ processors.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6465,The Solution of Singular Value Problems Using Systolic Arrays,This paper contains the computation of the singular value decomposition using  systolic arrays. Two different linear time algorithms are presented.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6466,"Disambiguation, Correctness and Flow-Analysis Issues for Trace Scheduling Compilers","Trace scheduling is a global compaction technique for transforming sequential  programs into parallel code. When this investigation began, trace scheduling  was unimplemented and many serious questions of appropriateness and  effectiveness needed to be solved. This paper addresses questions of its  applicability to ordinary programming for Very Long Instruction Word  machines. We developed practical methods of exploiting this parallelism  (e.g. memory anti-aliasing). To justify and better understand the dynamic  interaction between trace scheduling and anti-aliasing, we designed a more  formal model in which we proved the correctness of trace scheduling and  showed that it terminates. This in turn allowed us to analyze our flow  information requirements. Finally we addressed the problem of ambiguous  memory references which cannot be resolved at compile time.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6467,Intersection Graph Algorithms,"An intersection graph for a set of sets $C$ is a graph $G$ together with a  bijection from the vertices of $G$ to $C$ such that distinct vertices in $G$  are adjacent if and only if their images under this bijection intersect. Of  particular interest have been the classes of chordal graphs, the intersection  graphs of sets of subtrees of a tree, and interval graphs, the intersection  graphs of sets of intervals of the real line. I examine another class of intersection graphs, the class of directed path  graphs: intersection graphs of sets of paths in a directed tree. This class  properly contains the class of interval graphs, and is properly contained by  the class of chordal graphs. I give a linear time algorithm for recognizing  directed path graphs and for constructing intersection representations, and a  polynomial time algorithm for deciding directed path graph isomorphism. Both algorithms use a data structure called a partial path tree, which is a  kind of skeletal representation of the clique hypergraph of a directed path  graph. I present linear time algorithms for finding partial path trees with  specific roots and for finding partial path trees with arbitrary roots. I  prove that partial path trees with identical roots are identical. Using this  fact I develop a polynomial time algorithm for directed path graph isomorphism.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6468,Geometric Optimization and Computational Complexity,"Our purpose here is to study problems involving geometric optimization,  namely, questions of the type: Is there at least a minimum or at most a  maximum number of certain geometric figures, that are within certain distances  of other figures (objects). We are also concerned with the optimization of the  size of these geometric figures. These problems arise as geometric reductions  from various classes of location-allocation optimization problems and are  inherently not pure combinatorial. Our primary aim, then, is to discover  techniques of dealing with such geometric optimization problems, while  adapting to these problems the older combinatorial design and analysis methods. The task of classifying problems accurately in the polynomial hierarchy is one  of increasing importance. To solve an optimization problem deterministically  it seems that one must solve both an $NP$ and a $Co-NP$ problem. The  significance of the classes $NP$ and $Co-NP$ are that none of the problems  they include is known to have a polynomial time solution. We show that if  $NP \neq Co-NP$ then there are interesting natural geometric optimization  problems (location-allocation problems under minsum) in $\Delta^{P}_{2}$ that  are in neither $NP$ nor $Co-NP$. Hence, all these problems are shown to belong  properly to $\Delta^{P}_{2}$, the second level of the polynomial hierarchy.  We also show that if $NP \neq Co-NP$ then there are again some interesting  geometric optimization problems (location-allocation problems under minmaz)  properly in $\Delta^{P}_{2}$ and furthermore they are complete for a class  $D^{P}$ (which is contained in $\Delta^{P}_{2}$ and contains  $NP \bigcup Co-NP$). Also considered are the above geometric  location-allocation optimization problems for the case when the allocation is  predetermined. Both efficient algorithms and worst-case lower bounds are  derived. Necessary conditions for the existence of mazima and minima in optimization  problems are generally tied to the question of solvability of an equation or  a system of equations. In calculus these equations are algebraic. By  generating the minimal polynomial whose root over the field of rational  numbers is the solution of the geometric optimization problem on the real  (Euclidean) plane, we are able to prove the non-solvability of certain  geometric optimization problems by radicals. The algebraic degree of the  optimizing solution, which is the degree of the irreducible minimal polynomial  for the problem, correlates with the inherent difficulty of constructing the  solution and provides an algebraic complexity measure for these geometric  optimization problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6469,Sublinear-Space Evaluation Algorithms for Attribute Grammars,"The chief hindrance to the widespread adoption of attribute-grammar-based  systems has been that they are profligate consumers of storage. This paper  concerns new storage management techniques that reduce the amount of storage  used by reducing the number of attribute values retained at any stage of  attribute evaluation; it presents one algorithm for evaluating an  $n$-attribute tree that never retains more than $O(\sqrt{n})$ attribute  values, and it presents a second algorithm that never retains more than  $O(\log n)$ attribute values.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6470,"An O(lg n) Expected Rounds Probabilistic Byzantine Generals Algorithm (The Bigger They Are, The Harder They Fall)",Byzantine Generals algorithms enable processes to reliably broadcast messages  in a system of $n$ processes where up to $t$ of the processes may be faulty.  The algorithms are conducted in synchronous rounds of message exchange. For a  system where $n = (3 + \delta)t$ we prove the existence of a randomized  algorithm whose expected number of rounds is $O(lg n)$. This is an improvement  on the lower bound of $t + 1$ rounds required for deterministic algorithms and  on the previous result of $t/lg n$ expected number of rounds for randomized  algorithms.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6471,Formal Model of MOS Clocking Disciples,"This paper presents a formalization of clocking disciplines used to prevent  race conditions in VLSI circuits. A signal-labeling scheme for the two-phase clocking discipline informally  described in Mead and Conway [MC] is presented. Rules are given for checking  the correct labeling of a circuit consisting of combinatorial logic and  memory elements. The signal-labeling conventions are based in part on those of  Noice, Mathews, and Newkirk [NMN]. A formal basis is presented for constructing signal-labeling schemes for  multi-phase clocks (both overlapping and non-overlapping) from a definition of  the master timing signals. The two-phase scheme is shown to be a special case  of this general method. The method is also illustrated for four-phase  overlapping clocks.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6472,A Note About Information Science Research,This note deals with the relationship between information science research and  practice. The impression that the field is moribund and that the research  output is uniformly inferior is not supported by an examination of the  information retrieval literature.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6473,The Incompleteness of Misra and Chandy's Proof Systems,"In this paper we show that Misra and Chandy's proof systems for networks of  communicating processes ([1, 2]) are incomplete.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6474,Constraints: A Uniform Approach to Aliasing and Typing,No abstract supplied.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6475,Lower Bounds on String-Matching,"New techniques for obtaining lower bounds on string-matching problems are  developed and we prove the following new results. String-matching cannot be performed by a three-head one-way deterministic  finite automaton. This answers the $k=3$ case of the open question, due to  Galil and Seiferas [GS], whether a $k$-head one-way deterministic finite  automaton can perform string-matching. String-matching by a k-head two-way DFA with k-1 heads blind (can only see two  end symbols) is studied, tight upper and lower bounds are provided. Probabilistically moving a string on one tape (requiring $n^{2}$ time) is  harder than probabilistically matching two strings on 1 tape. Notice that this  is not true for deterministic or even nondeterministic TMs. This is the first  result showing that checking is easier than generating.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6476,Finding Minimal Perfect Hash Functions,"A heuristic is given for finding minimal perfect hash functions without  extensive searching. The procedure is to construct a set of graph (or  hypergraph) models for the dictionary, then choose one of the models for use  in constructing the minimal perfect hashing function. The construction of this  function relies on a backtracking algorithm for numbering the vertices of the  graph. Careful selection of the graph model limits the time spent searching.  Good results have been obtained for dictionaries of up to 181 words. Using the  same techniques, non-minimal perfect hash functions have been found for sets  of up to 667 words.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6477,Derivation of a Maximally Parallel Algorithm for Balancing Binary Search Trees,A recent trend in program methodologies is to derive efficient parallel  programs from sequential programs. This paper explores the question of  transforming a sequential algorithm into an efficient parallel algorithm by  considering the problem of balancing binary search trees. The derivation of  the parallel algorithm makes use of stepwise refinement. We first derive a new  iterative balancing algorithm that exploits the similarity of pointer  restructuring required at all the nodes at the same level. From this we derive  a parallel algorithm that has time complexity O(1) on an $N$-processor  configuration. This achieves the theoretical limit of speed-up possible in a  multi-processor configuration.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6478,Presburger's Article on Integer Arithmetic: Remarks and Translation,No abstract supplied.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6479,Universally Closed Classes of Total Computable Functions,"One of the most important characteristics of universal programming languages  is that they can express their own semantics, that is universal partial  functions, say interpreters, can be defined in the language. A fundamental  result of computability theory is that no class of total functions can contain  its own universal function. In practical terms this is disappointing, one  must give up the advantages of universality to gain those of totality. In this  paper the fundamental negative result is circumvented for programming  languages with a sufficiently rich type structure. A new method is given for  building a universally closed class of total computable functions starting  with any class of such functions. These results have direct practical  application in programming logics, and they raise new questions for  computability theory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6480,General Correctness: A Unification of Partial and Total Correctness,"General correctness, which subsumes partial and total correctness, is defined  for both weakest preconditions and strongest postconditions. Healthiness  properties for general-correctness predicate transformers are more uniform and  complete than those for partial-and-total-correctness systems. In fact, the  healthiness properties for partial and total correctness are simple  restrictions of those for general correctness. General correctness allows  simple formulations of the connections between weakest and strongest  postconditions and between the notions of weakest precondition under the  ""demonic"" and ""angelic"" interpretations of nondeterminism. A problem that  plagues $sp - sp(P, C)$ is undefined if execution of $C$ begun in some state  of $P$ may not terminate - disappears with the generalization. This paper is a study of some simple theory underlying predicate transformer  semantics, and as yet has little bearing on current programming practices. The  theory uses a relational model of programs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6481,An Overview of the Isis Project,"The goal of the ISIS projest is to provide a high-level support for  fault-tolerant distributed computing by automatically replicating data and  code. The extent to which information is replicated and the physical location  of information are not specified directly by the programmer, but are instead  inferred from a specification, which looks much like a conventional program in  an object-oriented language. This novel approach to fault-tolerant software  construction requires much less sophistication from programmers than current  alternatives. Moreover, optimization techniques that would be too complex for  implementation in general purpose applications can be supported by the ISIS  system. This overview discusses the goals of the project, its current status,  and some of the implications of our work.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6482,Proof Rules for Fault-Tolerant Distributed Programs,"Proving properties of fault tolerant distributed programs is a complex task as  such proofs must take into account failures at all possible points in the  execution of individual processes. The difficulty in accomplishing this is  compounded by the need also to cater for simultaneous failures of two or more  processes. In this paper, we consider programs written in a version of Hoare's  CSP and define a set of axioms and inference rules by which proofs can be  constructed in three steps: proving the properties of each process when its  communicants are prone to failure, establishing the effects of failure of each  process, and combining these proofs to determine the fault tolerant properties  of the whole program.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6483,Low Cost Management of Replicated Data in Fault-Tolerant Distributed Systems,"Many distributed systems replicate data for fault tolerance or availability.  In such systems, a logical update on a data item results in a physical update  on a number of copies. The synchronization and communication required to  ensure that the copies of replicated data are kept consistent introduces a  delay when operations are performed. In this paper, we describe a technique  that relaxes the usual degree of synchronization, permitting copies of  replicated data to be updated concurrently with other operations, while at the  same time ensuring that correctness is not violated. The additional  concurrency thus obtained results in better response time when performing  operations on replicated data. We also discuss how this technique performs in  conjunction with roll-back and roll-forward failure recovery mechanisms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6484,Writing Programs that Construct Proofs,"When we learn mathematics, we learn more than definitions and theorems. We  learn techniques of proof. In this paper, we describe a particular way to  express these techniques and incorporate them into formal theories and into  computer systems used to build such theories. We illustrate the methods as  they were applied in the $\lambda$-PRL system, essentially using the ML  programming language from Edinburgh LCF [23] as the formalised metalanguage.  We report our experience with such an approach emphasizing the ideas that go  beyond the LCF work, such as transformation tactics, refinement tactics, and  special purpose reasoners. We also show how the validity of tactics can be  guaranteed. The introduction places the work in historical context and the  conclusion briefly describes plans to carry the methods further. The majority  of the paper presents the $\lambda$-PRL approach in detail.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6485,The Cyclic Coloring Problem and Estimation of Sparse Hessian Matrices,"Numerical optimization algorithms often require the (symmetric) matrix of  second derivatives, $\nabla^{2} f (x)$, of some problem function  $f: R^{n} \rightarrow R^{1}$. If the Hessian matrix is large and sparse then  estimation by finite differences can be quite attractive since several schemes  allow for estimation in $\ll n$ gradient evaluations. The purpose of this paper is to analyze, from a combinatorial point of view, a  class of methods known as substitution methods. We present a concise  characterization of such methods in graph-theoretic terms. Using this  characterization, we develop a complexity analysis of the general problem and  derive a roundoff error bound on the Hessian approximation. Moreover, the  graph model immediately reveals procedures to effect the substitution process  optimally (ie. using fewest possible substitutions given the differencing  directions) in space proportional to the number of nonzeroes in the Hessian  matrix.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6486,On Computing the CS Decomposition with Systolic Arrays,"The computation of the CS decomposition is the key to the stable computation  of the Generalized Singular Value Decomposition, and is also important in  other applications. This paper describes our implementation of a technique to  compute the CS decomposition, and investigates the transfer of this technique  to systolic computer architectures with parallel computation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6487,Signal Processing Computations Using the Genralized Singular Value Decomposition,"The ordinary Singular Value Decomposition (SVD) is widely used in statistical  and signal processing computation, both for the insight it provides into the  structure of a linear operator, and as a technique for reducing the  computational word length required for least-squares solutions and certain  Hermitian eigensystem decompositions by roughly a factor of two, via computing  directly on a data matrix, rather than on the corresponding estimated  correlation or covariance matrix. Although the SVD has long been utilized as a  method of off-line or non-real-time computation, parallel computing  architectures for its implementation in near real time have begun to emerge.  The Generalized Singular Value Decomposition (GSVD) bears the same  relationship to the computation of certain Hermitian generalized eigensystem  decompositions that the ordinary SVD bears to the corresponding ordinary  eigensystem decompositions. This paper discusses methods for computing the GSVD via a sequence of more  familiar computations and indicates the relation of the GSVD to the MUSIC  algorithm of R. Schmidt.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6488,How Near is a Stable Matrix to an Unstable Matrix?,"In this paper we explore how close a given stable matrix A is to being  unstable. As a measure of ""how stable"" a stable matrix is, the spectral  abscissa is shown to be flawed. A better measure of stability is the Frobenius  norm of the smallest perturbation that shifts one of A's eigenvalues to the  imaginary axis. This leads to a singular value minimization problem that can  be approximately solved by heuristic means. However, the minimum destabilizing  perturbation may be complex even when A is real. This suggests that in the  real case we look for the smallest real perturbation that shifts one of the  eigenvalues to the imaginary axis. Unfortunately, a difficult constrained  minimization problem ensues and no practical estimation technique could be  devised.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6489,A Model and Temporal Proof System for Networks of Processes,"A model and a sound and complete proof system for networks of processes in  which component processes communicate exclusively through messages is given.  The model, an extension of the trace model, can desribe both synchronous and  asynchronous networks. The proof system uses temporal-logic assertions on  sequences of observations - a generalization of traces. The use of  observations (traces) makes the proof system simple, compositional and  modular, since internal details can be hidden. The expressive power of  temporal logic makes it possible to prove temporal properties (safety,  liveness, precedence, etc.) in the system. The proof system is  language-independent and works for both synchronous and asynchronous networks.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6490,Resilient Communication Structures for Local Area Networks,"Reliable communication is crucial to the correct functioning of distributed  systems. We propose a multi-ring communication structure and a reconfiguration  algorithm that tolerate multiple link failures before the network divides into  more than one partition. In case of partitioning, each partition is  reconfigured to allow communication among the sites within the partition. The  algorithm handles recovery of links and merges partitions once links become  operational again. The algorithm itself is fault-tolerant, and it is fully  distributed and does not require global knowledge about the status of the  network at any one site.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6491,Quotient Tree Partitioning of Undirected Graphs,"The partitioning of the vertices of an undirected graph, in a way that makes  its quotient graph a tree, mirrors a way of permuting a square symmetric  matrix to allow its factoring with little fil-in. We analyze the complexity of  finding the best partitioning and show that it is NP-complete. We also give a  new and simpler implementation of an algorithm that finds a maximal quotient  tree.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6492,An Approach to the Functional Description of an Information Retrieval System Based on a Generalized Model,"In this paper, the authors present a high level, functional approach to the  description of a generalized information retrieval system. The description is  based on the top-down decomposition of the system into modules and processes  and on an appropriate data abstraction. The purpose of this paper is to describe the behavior of the system in terms  of the component processes and the interactions of these processes in terms of  inputs, outputs, and the associated transformations. It allows one to view the  system as a collection of abstract processes, each of which is concisely  defined via a notation that describes what is accomplished but not how such a  process is to be implemented. Semantically irrelevant details are removed,  thereby producing a nonprocedural description which not only elucidates  system behavior but serves as a basis for subsequent formal specification.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6493,Optimal Clock Synchronization,"We present a simple, efficient and unified solution to the problems of  synchronizing, initializing, and integrating clocks, for systems with  different types of failures: crash, omission, and arbitrary failures with and  without message authentication. This is the first known solution that achieves  optimal accuracy, i.e., the accuracy of synchronized clocks (with respect to  real time) is as good as that specified for the underlying hardware clocks.  The solution is also optimal with respect to the number of faulty processes  that can be tolerated to achieve this accuracy.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6494,Streets of Byzantium: Network Architecture for Fast Reliable Broadcasts,"A site broadcasting its local value to all other sites in a fault-prone  environment is a fundamental paradigm in constructing reliable distributed  systems. Time complexity lower bounds and network connectivity requirements  for reliable broadcast protocols in point-to-point communication networks are  well known. In this paper we consider the reliable broadcast problem in  distributed systems with broadcast networks (for example, Ethernets) as the  basic communication architecture. We show how properties of such network  architectures can be used to effectively restrict the externally visible  behavior of faulty processors. We use these techniques to derive simple  protocols that implement reliable broadcast in only two rounds, independent  of the failure upper bounds.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6495,Defining Liveness,"A formal definition for liveness properties is proposed. It is argued that  this definition captures the intuition that liveness properties stipulate that  ""something good"" eventually happens during execution. A topological  characterization of safety and liveness is given. Every property is shown to  be the intersection of a safety property and a liveness property.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6496,State Machines and Assertions (An Integrated Approach to Modelingand Verification of Distributed Systems,"This paper describes a methodology for modeling and verifying protocols for  asynchronous message passing systems. It combines the techniques of finite  state analysis and axiomatic verification. It overcomes the problem of state  explosion by using variables and logical assertions where the finite state  approach would require a large number of states. By explicitly including  states where interactions between processes occur, the complexity of  assertional proofs is significantly reduced. Properties like freedom from  deadlock, freedom from unspecified message receptions, boundedness of channel  size, and partial correctness can be proved. Properties of channels like  losing or garbling messages can be modeled, as can premature and non-premature  timeouts. The technique is illustrated by proving a sliding window flow  control protocol and an alternating bit protocol that is correct only if  timeouts are non-premature.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6497,Randomized Agreement Protocols and Distributed Deadlock Detection Algorithm,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6498,The Cluster Hypothesis Revisited,"A new means of evaluating the cluster hypothesis is introduced and the  results of such an evaluation are presented for four collections. The results  of retrieval experiments comparing a sequential search, a cluster-based  search, and a search of the clustered collection in which individual  documents are scored against the query are also presented. These results  indicate that while the absolute performance of a search on a particular  collection is dependent on the pairwise similarity of the relevant documents,  the relative  effectiveness of clustered retrieval versus sequential  retrieval is independent of this factor. However, retrieval of entire  clusters in response to a query usually results in a poorer performance than  retrieval of individual documents from clusters.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6499,Recursive Definitions in Type Theory,"The type theories we consider are adequate for the foundations of mathematics  and computer science. Recursive type definitions are important practical ways  to organize data, and they express powerful axioms about the termination of  procedures. In the theory examined here, the demands of practicality arising  from our implemented system, Nuprl, suggest an approach to recursive types  that significantly increases the proof theoretic power of the theory and  leads to insights into computational semantics. We offer a new account of recursive definitions for both types and partial  functions. The computational requirements of the theory restrict recursive  type definitions involving the total function-space constructor  ($\rightarrow$) to those with only positive occurrences of the defined type.  But we show that arbitrary recursive definitions with respect to the partial  function-space constructor are sensible. The partial function-space  constructor allows us to express reflexive types of Scott's domain theory  (as needed to model the lambda calculus) and thereby reconcile parts of  domain theory with constructive type theory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6500,Software For Estimating Sparse Hessian Matrices,"The solution of a nonlinear optimization problem often requires an estimate  of the Hessian matrix for a function $f$. In large scale problems the Hessian  matrix is usually sparse, and then estimation by differences of gradients is  attractive because the number of differences can be small compared to the  dimension of the problem. In this paper we describe a set of subroutines  whose purpose is to estimate the Hessian matrix with the least possible  number of gradient evaluations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6501,Automatic Surface Generation in Computer Aided Design,No abstract available,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6502,Early Stopping Protocols for Fault-Tolerant Distributed Agreement,No abstract available,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6503,Lower bounds in Computational Complexity,No abstract available,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6504,Representing Constructive Theories in High-Level Programming Languages,No abstract available,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6505,Design by Example: An Application of Armstrong Relations,"Example relations, and especially Armstrong relations, can be used as  user-friendly representations of dependency sets. In this paper we analyze  the use of Armstrong relations in database design with functional  dependencies, and show how they and the usual representation of dependencies  can be used together. Special attention is given to the size of Armstrong  relations. We derive new bounds for the size of minimal Armstrong relations  for normalized schemes. New algorithms are also given for generating  Armstrong relations and for inferring the functional dependencies holding in  a relation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6506,Lower Bounds by Kolmogorov-Complexity,"Using Kolmogorov-complexity, we obtain the following new lower bounds. For on-line nondeterministic Turing machines, (1) simulating 2 pushdown stores by 1 tape requires $\Omega(n^{1.5} / logn)$  time; together with a newly proved $O( n^{1.5}\sqrt{logn})$ upper bound [L3],  this basically settled the open problem 1 in [DGPR] for 1 tape vs. 2 pushdown  case (the case of 1 tape vs. 2 tapes was basically settled by [M]);  (2) simulating 1 queue by 1 tape requires $\Omega(n^{4/3} / logn)$ time; this  brings us closer to a newly proved $O( n^{1.5}\sqrt{logn})$ upper bound [L3];   (3) simulating 2 tapes by 1 tape requires $\Omega(n^{2} / lognloglogn)$ time;  this is a minor improvement of [M]'s $\Omega(n^{2} / log^{2}nloglogn)$ lower  bound; it is also claimed (full proof contained in [L3]) that the actual  languages used in [M] (also here) and [F] do not yield $\Omega(n^{2})$ lower  bound. To cope with an open question of [GS] of whether a $k$-head 1-way DFA  ($k$-DFA) can do string matching, we develop a set of techniques and show  that 3-DFA cannot do string matching, settling the case $k = 3$. Some other  related lower bounds are also presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6507,Simulating Two Pushdown Stores by One Tape in $O(n^{1.5}\sqrt{logn}$) Time. (Preliminary Version),"Based on two graph separator theorems, one old (the Lipton-Tarjan planar  separator theorem) and one new, we present two unexpected upper bounds and  resolve several open problems for on-line computations: (1) 1 tape nondeterministic machines can simulate 2 pushdown stores in time  $O(n^{1.5} \sqrt{logn})$ (true for both on-line and off-line machines).  Together with the $\Omega (n^{1.5} \sqrt{logn})$ lower bound by the author  [L1], this solved the open problem 1 in [DGPR] for the 1 tape vs. 2 pushdown  case. It also disproves the commonly conjectured $\Omega (n^{2})$ lower  bound. (Note, the $\Omega (n^{2})$ lower bound has been proved for the  deterministic case [M, L, V].)   (2) the languages defined by [M] and [F], aimed to obtain optimal lower bound  for 1 tape nondeterministic machines, can be accepted in $O(n^{2}loglogn /  \sqrt{logn})$ and $O(n^{1.5}\sqrt{logn})$ time by a 1 tape TM, respectively. (3) 3 pushdown stores are better than 2 pushdown stores. This answers open  problem 3 of [DG]. (An $\Omega(n^{4/3} / log^{e} n)$ lower bound is also  obtained.) (4) 1 tape can nondeterministically simulate 1 queue in  $O(n^{1.5} \sqrt{logn})$ time. (The lower bounds were: $\Omega(n^{2})$ for  deterministic case [V] and $\Omega(n^{4/3} / logn)$ [L1] for nondeterministic  case.)",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6508,Replication and Fault-Tolerance in the ISIS System,"The ISIS system transforms abstract type specifications into fault-tolerant  distributed implementations while insulating users from the mechanisms used  to achieve fault-tolerance. This paper discusses techniques for obtaining a  fault-tolerant implementation from a non-distributed specification and for  achieving improved performance by concurrently updating replicated data. The  system itself is based on a small set of communication primitives, which are  interesting because they achieve high levels of concurrency while respecting  higher level ordering requirements. The performance of distributed  fault-tolerant services running on this initial version of ISIS is found to  be nearly as good as that of non-distributed, fault-intolerant ones.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6509,Voronoi Diagrams and Arrangements,We propose a uniform and general framework for defining and dealing with  Voronoi Diagrams. In this framework a Voronoi Diagram is a partition of a  domain $D$ induced by a finite number of real valued functions on $D$.  Valuable insight can be gained when one considers how these real valued  functions partition $D \times R$. With this view it turns out that the  standard Euclidean Voronoi Diagram of point sets in $R^{d}$ along with its  order-$k$ generalizations are intimately related to certain arrangements of  hyperplanes. This fact can be used to obtain new Voronoi Diagram algorithms.  We also discuss how the formalism of arrangements can be used to solve  certain intersection and union problems.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6510,On Complete Problems for NP$\cap$CoNP,"It is not known whether complete languages exist for $NP\cap CoNP$, and  Sipser has shown that there are relativizations so that $NP\cap CoNP$ has no  $\leq ^{P}_{m}$-complete languages. In this paper we show that $NP\cap CoNP$  has $\leq ^{P}_{m}$-complete languages if and only if it has  $\leq ^{P}_{T}$-complete languages. Furthermore, we show that if a complete  language $L_{0}$ exists for $NP\cap CoNP$ and $NP\cap CoNP \neq NP$ then the  reduction of $L(N_{i}) \in NP\cap CoNP$ cannot be effectively computed from  $N_{i}$. We extend the relativization results by exhibiting an oracle $E$  such that $P^{E} \neq NP^{E} \cap CoNP^{E} \neq NP^{E}$ and for which there  exist complete languages in the intersection. For this oracle the reduction  to a complete language can be effectively computed from complementary pairs  of machines $(N_{i}, N_{j})$ such that $L(N_{i})= \overline{L(N_{j})}$. On  the other hand, there also exist oracles $F$ such that $P^{F} \neq NP^{F}  \cap CoNP^{F} \neq NP^{F}$ for which the intersection has complete languages,  but the reductions to the complete language cannot be effectively computable  from the complementary pairs of machines. In this case, the reductions can be  computed from $(N_{i}, N_{j}$, Proof that $L(N_{i})= \overline{L(N_{j})}).$",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6511,A Better Tool for Query Optimization,"When evaluating the performance of a query strategy, one must often estimate  the number of distinct values of an attribute in a randomly selected subset  of a relation. Most query optimizers compute this estimate based on the  assumption that prior to the selection, the attribute values are uniformly  distributed in the relation. In this paper we depart from this assumption and  instead consider Zipf distributions that are known to accurately model text  and name distributions. Given a relation of cardinality $n$ where a non-key  attribute $A$ has a Zipf distribution, we derive both an exact formula and an  approximate non-iterative formula for the expected number of distinct  $A$-values contained in a sample of $k$ randomly selected tuples. The  approximation is accurate, and it is very easy to compute. Thus it provides a  practical tool to deal with non-uniform distributions in query optimization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6512,The Homogenous Capture of Random Strings,"It is well known that a set of strings that are random in the Kolmogorov  sense is immune to all computable enumerations. In this paper, we discuss the  generalization of this property to the computational resource hierarchies. We  then introduce the notion of homogeneous capture of sets and show that sets  of random strings are not homogeneously captured by any computable  enumeration. Again, we discuss the extension of this property to the resource  hierarchies. Finally, we discuss the relationship between the notion of  homogeneous capture and the traditional concept of randomness.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6513,Wide Quotient Trees for Finite Element Problems,"In solving the system of linear equations $Ax = b$ where $A$ is an  $n \times n$ large sparse symmetric positive definite matrix, one important  objective is to minimize fill. One approach is to partition the matrix so  that its corresponding quotient graph is a tree and then use block  factorization techniques to solve the system. We examine several methods for  generating valid quotient tree partitionings of grid graphs and find that  those producing short wide quotient trees are superior for large enough  graphs. We then give an algorithm for generating wide quotient tree  partitionings of a more general class of graphs. Bounds on its storage and  computational requirements are provided and compared to those of a  generalized nested dissection algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6514,Quadratic Blending Surfaces,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6515,Aspects of the Implementation of Type Theory,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6516,Sparse Null Bases and Marriage Theorems,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6517,Symmetry and Similarity in Distributed Systems,"Similarity is introduced as a model-independent characterization of symmetry.  It can be used to decide when a concurrent system has a solution to the  selection problem. It can also be used to compare different models of  parallel computation, including differences in scheduling policy and  instruction set, and the consequences of using randomization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6518,Percolation Scheduling: A Parallel Compilation Technique,"Percolation Scheduling (PS) is a new technique for compiling programs into  parallel code. It attempts to overcome problems that limit the effectiveness  and applicability of currently available techniques. PS globally rearranges code past basic block boundaries. Its core is a small  set of simple, primitive program transformations defined in terms of adjacent  nodes in a program graph. These transformations constitute the lowest level  in a system of transformations and guidance rules. Higher levels of this  hierarchy control and enhance the applicability of the core transformations  and enable us to exploit both fine grained and coarse parallelism. Unlike other, more ad hoc approaches, PS is based on rigorous definitions of  the computational model and of the core transformations. The correctness and  termination of the transformations is proven here. The completeness of the  transformations is also discussed. As a result our implementation, which is  now underway, can proceed on a sound basis. In particular, PS enjoys greater  adaptability and independence between the levels than would be possible  otherwise. This paper describes PS in detail. The correctness aspects as well as  illustrations of the effectiveness of our techniques are presented.  Architectures which may benefit from the use of PS are also discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6519,Multilevel Data Structures Models and Performance,"We advocate a stepwise method of deriving high performance implementation of  a set of operations. This method is based on the ability to organize the data  into a multilevel data structure so as to provide an efficient implementation  of all the operations. Typically, for such data organization the performance  may deteriorate over a period of time and that can be corrected by  reorganizing the data. This data reorganization is done by the introduction  of maintenance processes. For a particular example we consider the multilevel data organization and the  different models of maintenance processes possible. We sketch a correctness  proof for the implementation we develop. Performance behaviour for the  different models are derived and we also present some simulation studies of  the performance.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6520,The Block Jacobi Method for Computing the Singular Value Decomposition,"Jacobi techniques for computing the symmetric eigenvalue and singular value  decompositions have achieved recent prominence because of interest in  parallel computation. They are ideally suited for certain multiprocessor  systems having processors that are connected in nearest neighbor fashion. If  the processors are reasonably powerful and have significant local memory,  then block Jacobi procedures are attractive because they render a more  favorable computation to communication ratio. This paper examines some of the  practical details associated with two block Jacobi methods for the singular  value decomposition. The methods differ in how the 2-by-2 subproblems are  solved.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6521,The WY Representation for Products of Householder Matrices,A new way to represent products of Householder matrices is given that makes a  typical Householder matrix algorithm rich in matrix-matrix multiplication.  This is very desirable in that matrix-matrix multiplication is the operation  of choice for an increasing number of important high performance computers.  We tested the new representation by using it to compute the QR factorization  on the FPS-164/MAX. Preliminary results indicate that it is a very efficient  way to organize Householder computations.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6522,Characterizations for Acyclic Database Schemes,"Acyclic database schemes have attracted much interest because of the nice  properties enjoyed by such schemes. Recently some new acyclicity conditions  that are strictly stronger than the normal $\alpha$-acyclicity have been  introduced by Fagin. Because of increased requirements, the database schemes  in the new classes have some further useful properties that are not shared by  $\alpha$-acyclic schemes. Therefore the new classes have practical relevance. A database designer may work in terms of attribute sets and data  dependencies, and not only in terms of database schemes. Thus it is important  to have a characterization for the acyclic schemes of various degree in terms  of data dependencies. For $\alpha$-acyclic schemes such a characterization  exists, but for the new classes the question has been open. In this paper we  provide characterizations for $\beta$-, $\gamma$- and Berge-acyclic database  schemes. The characterizations can be stated in a simple form: thus they  should be useful for the database designer.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6523,"Inexact Agreement: Accuracy, Precision, and Graceful Degradation","An Inexact Agreement protocol alows processors that each have a value  approximating $\hat{\nu}$ to compute new values that are closer to each other  and close to $\hat{\nu}$. Two fault-tolerant protocols for Inexact Agreement  are described. As long as fewer than 1/3 of the processors are faulty, the  protocols give the required convergence; they also permit iteration and thus  convergence to any desired precision. When between 1/3 and 2/3 of the  processors are faulty, the protocols may not converge. However, then  processors either detect that too many faults have occurred or the new values  computed by processors remain close to each other and to $\hat{\nu}$. In this  case, the divergence is bounded. Use of the protocols for clock  synchronization in a distributed system is explained.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6524,The Semantics of Evidence,The usual meaning of a sentence in the predicate calculus is its truth value.  In this paper we show that there is associated with every statement a set of  elements comprising evidence for it. A statement is true in a model exactly  when there is evidence for it. Proofs can be regarded as expressions which  denote evidence. A statement is constructively true when the evidence can be  computed from its proofs. Proofs are useful in practical computations when  evidence for statements is needed. They are especially valuable in relating  computations to the problems they solve.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6525,FRESH: A Higher-Order Language with Unification and Multiple Results,"This paper presents Fresh, a language that integrates logic programming  features into higher-order functional programming. The language incorporates  unification, multiple results and a collection construct. Many examples  illustrate that these extensions of functional programming are useful. We  define an operational semantics along the lines of Plotkin's structural  approach. The semantics is of intrinsic interest since it covers backtracking  and the collection construct. To illustrate the conceptual similarities and  differences between functional and logic programming, we begin with a purely  functional core language and add first unification and then backtracking.  With each addition we discuss the enhanced eloquence of the language and the  concomitant modifications to the semantics.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6526,Implementation of the SMART Information Retrieval System,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6527,Time-Communication Tradeoffs for Reliable Broadcast Protocols,"In the Reliable Broadcast Problem, a processor disseminates a value to all  other processors in a distributed system where both processors and  communication components are subject to failures. Solutions to this Reliable  Broadcast problem are at the heart of most fault-tolerant applications. We  characterize the execution of Reliable Broadcast protocols as a function of  the properties of the underlying communication network. The class of networks  considered includes familiar communication structures constructed out of  fully-connected point-to-point graphs, linear chains, rings, broadcast  networks (such as Ethernet) and buses. We derive a protocol that implements  Reliable Broadcast for any member within this class. The execution time of  the protocol is a linear function of the two parameters that characterize  each network instance. The hardware-software tradeoffs that are revealed  between performance, resiliency and network cost offer many new alternatives  previously not considered in designing fault-tolerant systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6528,Graph Minimal Uncolorability is $D_{p}$-Complete,"In their excellent paper, C.H. Papadimitriou and M. Yannakakis [PY] asked  whether the minimal-3-uncolorability problem is, among other Critical  Problems, $D_{p}$-complete. This paper gives an affirmative answer to the  above question. We show that minimal-$k$-uncolorability is $D_{p}$-complete,  for all fixed $k \geq 3$. Furthermore, for $k$ = 3, the reduction can be  modified by using ""sensitive"" gadgets to resolve the planar case, bounded  vertex degree case and their combination.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6529,On The Schur Decomposition of a Matrix for Parallel Computation,"An algorithm to solve the eigenproblem for non-symmetric matrices on an  $N \times N$ array of mesh connected processors, isomorphic to the  architecture described by Brent and Luk for symmetric matrices, is presented.  This algorithm is a generalization of the classical Jacobi method, which  holds promise for parallel architectures. The rotational parameters for the  non-symmetric case are carefully analyzed; many examples of a working  program, simulating the parallel architecture, are given.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6530,A Model and Temporal proof system for Networks of Processes,"An approach is presented for modeling networks of processes that communicate  exclusively through message passing. A process (or a network) is defined by  its set of possible behaviors, where each behavior is an abstraction of an  infinite execution sequence of the process. The resulting model is simple and  modular and facilitates information hiding. It can describe both synchronous  and asynchronous networks. It supports recursively-defined networks and can  characterize liveness properties such as progress of inputs and outputs,  termination, and deadlock. A sound and complete temporal proof system based on the model is presented.  It is compositional - a specification of a network is formed naturally from  specifications of its components.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6531,A Theory of Processes,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6532,Design-By-Example: A Design Tool for Relational Databases,"In recent years, research in relational design theory and in query  optimization has established a firm ground for designing well-structured  logical and physical database schemes. However, the design process prequires  mastering a considerable amount of theoretical results. Furthermore, even for  the initiated database designer, many of the known algorithms for logical  design do not provide constructive guidelines for generating a database  scheme that would prevent update anomalies and data inconsistencies. Nor do  the algorithms and evaluation methods for file structures and query  processing provide constructive physical design rules. We propose an expert tool that would make knowledge in relational design  theory and query optimization automatically and transparently available to  the database designer. This tool is a system with an interactive, graphical  interface that uses examples to guide the designer through several phases of  logical and physical database design. Logical design is based on example  relations, and physical design on example queries. The example relations are  automatically generated by the system. They contain sample data and satisfy  the data dependencies that the designer specifies with the assistance of the  expert tool. The example queries and their expected frequency are specified  by the designer, using graphically displayed skeleton queries. The system  generates a physical design scheme that optimizes the mix of queries expected  by the designer, and computes a performance forecast. Both example relations  and example queries can be modified by the designer, until the expert tool  generates a satisfactory design.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6533,Analysis of Hard Real-Time Systems,"In this paper we study hard real-time systems: systems where strict time  deadlines have to be met. We analyze a special case as well as a general  model for hard real-time systems and study pre-emptive, static, scheduling  policies for a single processor. The analysis is exact and can handle any  arbitrary choice of strict deadlines. For any specification of a hard  real-time system, a feasible priority assignment is one where all deadlines  are met. An optimal scheduling algorithm is an algorithm that always produces  a feasibile priority assignment if one exists. For both the special and  general model we present an optimal scheduling algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6534,Reliable Communication in the Presence of Failures,"We report on the design and correctness of a communication facility for a  distributed computer system. The facility provides support for fault tolerant  process groups in the form of a family of reliable multicast protocols that  can be used both in local and wide-area networks. These protocols attain high  levels of concurrency while respecting application-specific delivery ordering  constraints, and have varying cost and performance that depends on the degree  of ordering desired. In particular, a protocol that enforces causal delivery  orderings is introduced, and shown to be a valuable alternative to  conventional asynchronous communication protocols. The facility also ensures  that the processes belonging to a fault tolerant process group will observe  consistent orderings of events affecting the group as a whole, including  process failures, recoveries, migration, and dynamic changes to group  properties like member rankings. A review of several uses for the protocols  in the ISIS system, which supports fault-tolerant resilient objects and  bulletin boards, illustrates the significant simplification of higher-level  algorithms; made possible by our approach.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6535,Combinatorial Problems in Matrix Computation,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6536,Generating Language-Based Editors: A Relationally-Attributed Approach,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6537,The Cornell Robot System Design Report,This report describes a robot control system under development at Cornell  University. The goal of the system is to demonstrate automatic generation of  robot programs for mechanical assemblies that are specified by exploded  diagrams. The structure and current capabilities of the system are discussed.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6538,The GENERIC Programming Language Manual,"GENERIC is a programming language for the description and manipulation of  integrated circuits. GENERIC works on the layout level with the designer in  complete control of the layout process. To design an integrated circuit, a  program is written which hierarchically describes the chip. The dynamic  calling structure of the program determines the integrated circuit's  hierarchical cell structure. These cells are created by special procedures  called generators. Generators are capable of producing completely custom  structures-they do not consist of predefined layout. In addition to the specification, GENERIC provides operators for the  manipulation of integrated circuit layouts, thus enabling existing geometry  to be modified. These modifications can be geometrical, topological or circuit. GENERIC is a very high level language. The language is general purpose-the  VLSI aspects of the language are layered on top of the basic language as a  run-time library. Since the library itself is written in GENERIC, the  language is completely extensible.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6539,The Potential Method for Blending Surfaces and Corners,"We survey the potential method for blending implicit algebraic surfaces,  summarizing and extending work previously reported. The method is capable of  deriving blends for pairs of algebraic surfaces, and is guaranteed to produce  blending surfaces of lowest possible degree for two quadrics in general  position. We give two paradigms by which to understand the method. The first paradigm  views the blends as surfaces swept out by a family of space curves. The  second, more general paradigm considers the surfaces as result of deformation  of a parameter space effected by substitution. The method has a general  formulation based on projective parameter spaces, but is also the image under  projective transformation of the simpler, affine formulation. The deformation by substitution paradigm is extended to blend blending  surfaces at solid vertices without a degree penalty, under the assumption  that the vertex valence has been reduced to three. It may also lead to a  general solution for blending patches of algebraic surfaces that meet  tangentially. A special case of this problem is solved and illustrated.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6540,Some Comments on Functional Self-Reducibility and the NP Hierarchy,"In Valiant [11] and Schnorr [9], concepts of ""functional self-reducibility""  are introduced and investigated. We concentrate on the class NP and on the NP  hierarchy of Meyer and Stockmeyer [7] to further investigate these ideas.  Assuming that the NP hierarchy exists (specifically, assuming that  $P \stackrel{\subset}{+} NP = \sum^{P}_{1} \stackrel{\subset}{+} \sum^{P}_{2}$  we show that, while every complete set in $\sum^{P}_{2}$ is functionally  self-reducible, there exist sets in $\sum^{P}_{2}$ which are not functionally  self-reducible.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6541,Investigations of Type Theory in Programming Logics and Intelligent Systems,"Type theory has become central to computer science because it deals with  fundamental issues in programming languages, in programming methodology and  specification languages, in automatic theorem proving and programming logic,  in natural language semantics and in the foundations of intelligent systems.  At Cornell we have been studying a logical theory of types which has  influenced the design of programming languages and has become the basis of an  implemented program development system. This theory answers many basic  questions about data types. Here we discuss three general questions about this theory: how logical types  relate to domains, how they relate to sets, how they organize programming  logics and the intelligent systems built around them. These issues are each  of independent value, but they also arise naturally as part of a program to  provide a computationally meaningful foundation to computing theory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6542,The Complexity of Facets Resolved,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6543,In-situ Inversion of a Cyclic Permutation,"An algorithm is developed for the in-situ inversion of a cyclic permutation  represented in an array. The emphasis is on the quo modo rather than the  quod; we are interested in finding concepts and notations for dealing more  effectively with formal developments and proofs of such algorithms, rather  than in this particular algorithm itself.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6544,Upson's Familiar Quotations. Fourth Edition. (1984 - 1985),"This report is a compilation of several hundred examples of context-free  language and very irregular expressions. Contributions were submitted over  the past several years by numerous computer science graduate students who  collected these now immortal words in classes and seminars. We wish to  express our gratitude to the faculty, guest lecturers, and students who  provided the bulk of this work.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6545,The Effectiveness and Efficiency of Agglomerative Hierarchic Clustering in Document Retrieval,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6546,Checkpointing and Rollback-Recovery for Distributed Systems,"We consider the problem of bringing a distributed system to a consistent  state after transient failures. We address the two components of this problem  by describing a distributed algorithm to create consistent checkpoints, as  well as a rollback-recovery algorithm to recover the system to a consistent  state. In contrast to previous algorithms, they tolerate failures that occur  during their executions. Furthermore, when a process takes a checkpoint, a  minimal number of additional processes are forced to take checkpoints.  Similarly, when a process rolls back and restarts after a failure, a minimal  number of additional processes are forced to roll back with it. Our  algorithms require each process to store at most two checkpoints in stable  storage. This storage requirement is shown to be minimal under general  assumptions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6547,On Sparse Oracles Separating Feasible Complexity Classes,"This note clarifies which oracles separate NP from P and which do not. In  essence, we are changing our research paradigm from the study of which  problems can be relativized in two conflicting ways to the study and  characterization of the class of oracles achieving a specified  relativization. Results of this type have the potential to yield deeper  insights into the nature of relativization problems and focus our attention  on new and interesting classes of languages. A complete and transparent characterization of oracles that separate NP from  P would resolve the long-standing P =? NP question. In this note, we settle a  central case. We fully characterize the sparse oracles separating NP from P  in worlds where P = NP. We display related results about coNP, E, NE, coNE,  and PSPACE.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6548,Safety Without Stuttering,"A new formalization of safety properties is given. The formalization agrees  with the informal definition - that a safety property stipulates that some  ""bad thing"" doesn't happen during execution - for properties that are not  invariant under stuttering, as well as for properties that are.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6549,Loop Quantization: Unwinding for Fine-Grain Parallelism Exploitation,"Loop unwinding is a well known technique for reducing loop overhead, exposing  parallelism and increasing the efficiency of pipelining. Traditional loop  unwinding is limited to the innermost loop in a group of nested loops and the  amount of unwinding is either fixed or has to be specified by the user, on a  case by case basis. In this paper we present a general technique for  automatically unwinding multply nested loops, explain its advantages over  other transformation techniques and illustrates its practical effectiveness.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6550,Microflow: A Fine-Grain Parallel Processing Approach,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6551,Developing Two of Arsac's Funny Algorithms,"In Some Funny Program (Ecole Normale Superieure, Paris, June 1985) J. Arsac  discusses several algorithms, but not from the standpoint of their  development. Here, we develop the algorithms given their specification using  the methods espoused in The Science of Programming.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6552,Low Cost Management of Replicated Data,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6553,Another Look at Automatic Text Retrieval Systems,"The characteristics of automatic text retrieval systems are briefly  described, and the available experimental evidence comparing manual with  automatic retrieval is reviewed. Several automatic text analysis and indexing  models are then examined, and a basic automatic indexing process is proposed.  There is no evidence that an intellectual content analysis performed by human  subject experts produces better retrieval results than comparable automatic  text processing systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6554,Type Theory and Concurrency,"The burgeoning interest in concurrent computation has sparked an increased  interest in theoretical models of concurrency. While standard sequential  programming has a well-understood semantics and proof theory, the  nondeterministic nature of concurrency has made a similar understanding of  concurrent programming extremely difficult. Much interesting work in the  field has been done, and much remains yet to be done; it is our intention in  this paper to present a different kind of model of concurrency, a  type-theoretic one, which we hope will shed light on reasoning about  concurrency. We encode the synchronization tree model of Milner's CCS as a type in the  Nuprl Type Theory. This is a constructive type theory equipped with a rich  collection of inference rules for reasoning about types. We relate the  equality in the type of synchronization trees with various behavioral  equivalences. We also discuss the relation between the logic induced by our  models and various modal logics for reasoning about concurrency.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6555,"With Probability One, a Random Oracle Separates PSPACE from the Polynomial-Time Hierarchy","We consider how much error a fixed depth Boolean circuit has to make for  computing the parity function. We show that with an exponential bound of the  form $exp(n^{\lambda})$ on the size of the circuits, they make asymptotically  50% error on all possible input, uniformly. As a consequence, we show that  with a random oracle set $A,Pr.(PSPACE^{A} \supseteq  PH^{A} = 1$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6556,Categorical Type Theory,"This paper examines the connections between intuitionistic type theory and  category theory. A version of type theory is developed in a category  theoretic framework by interpreting types as objects and type connectives as  constructions in categories. This yields a theory that uniformly models type  inhabitation, proof theory, type universes, syntactic forms, equality and  computation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6557,Semantics of Digital Networks Containing Indeterminate Modules,"We discuss a formal model based upon dataflow, usable for high-level digital  hardware design, among other things. One of our goals is to give a  denotational semantics for this model, which includes indeterminate modules.  While it is well known that denotational semantics for networks containing  only determinate modules can be simply expressed as a composition of stream  functions, this aproach has previously been shown unacceptable for networks  with indeterminate modules. Our approach is to devise composition rules based  on modelling a network by the set of its possible behaviors, i.e., sequences  of computational events, where each event is the appearance or consumption of  a token on a data path. A sequence of such events is called a history and a  set of such histories is called an archive. We give composition rules that  allow us to derive an archive for a network from the archive of its  constituents. We show how causal and operational constraints on network  behavior can be inferred from the specification of archives. We also present  a construction which allows us to obtain the the denotation of networks  containing loops by a process of successive approximations. This construction  is carried out using a construction resembling the category-theoretic notion  of limit, which differs from that of more traditional domain theory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6558,A General Framework for Computing Block Accesses,"A physical database system design should take account of skewed block access  distributions, nonuniformly distributed attribute domains, and dependent  attributes. In this paper we derive general formulas for the number of blocks  accessed under these assumptions by considering a class of related occupancy  problems. We then proceed to develop robust and accurate approximations for  these formulas. We investigate three clases of approximation methods,  respectively based on generating functions, Taylor series expansions, and  majorization. These approximations are as simple to use and far more accurate  than the cost estimate formulas generated by making independence and  uniformity assumptions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6559,The Complexity of Optimization Problems,"Many important problems in computer science, such as CLIQUE, COLORING, and  TRAVELLING SALESPERSON, arise naturally as optimization problems. Typically  one considers these problems as decision procedures, which are often in NP,  and one shows intractibility by showing them NP-complete. We generalize the  notion of an NP problem, in a manner analogous to Valiant's class #P, by  considering the optimization version of the problem itself, and we show that  this idea yields a natural class of problems that we call OptP. This class  allows us to make finer distinctions on the complexity of optimization  problems than is possible in NP. For example, assuming P $\neq$ NP, we can  show that TRAVELLING SALESPERSON is strictly harder than CLIQUE and CLIQUE is  strictly harder than BIN PACKING. We then relate OptP to the class of  functions computable in polynomial time with an oracle for NP, by showing  that every $P^{SAT}$  function decomposes into an OptP function followed by a  polynomial-time computation. This allows us to clear up a misconception on  the role of uniqueness for the problem of UNIQUELY OPTIMAL TRAVELLING  SALESPERSON as considered by Papadimitriou is the 1982 FOCS conference.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6560,Reliable Broadcasts Through Partial Broadcasts,"In the Reliable Broadcast Problem, a processor disseminates a value to all  other processors in a distributed system where both processors and  communication components are subject to failures. We prove lower bounds for  the execution time of any reliable broadcast protocol in distributed systems  with arbitrary communication networks. Our results apply to common  distributed system architectures consisting of multiple broadcast  network-based clusters of processors. In light of these lower bounds, our  earlier protocols are shown to be optimal with respect to execution time.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6561,"Relations Between Diagonalization, Proof Systems, and Complexity Gaps","In this paper we study diagonal processes over time-bounded computations of  one-tape Turing machines by diagonalizing only over those machines for which  there exist formal proofs that they operate in the given time bound. This  replaces the traditional ""clock"" in resource bounded diagonalization by  formal proofs about running times and establishes close relations between  properties of proof systems and existence of sharp time bounds for one-tape  Turing machine complexity classses. These diagonalization methods also show  that the Gap Theorem for resource bounded computations can hold only for those  complexity classes which differ from the corresponding provable complexity  classes. Furthermore, we show that there exist recursive time bounds $T(n)$  such that the class of languages for which we can formally prove the existence  of Turing machines which accept them in time $T(n)$ differs form the class of  languages accepted by Turing machines for which we can prove formally that  they run in time $T(n)$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6562,A Development Environment for Scientific Parallel Programs,"This paper describes a development environment for parallel scientific code.  The environment uses Percolation Scheduling, a transformational system for  parallelism extraction, and an interactive profiling system to give the user  control over the parallelization process while reducing the burdensome  details of architecture, correctness-preservation and synchronization.  Through a graphical interface the user suggests what should be done in  parallel, while the system performs the actual changes using  semantics-preserving transformations. If a request cannot be satisfied, the  system reports the problem causing the failure. The user may then help  eliminate the problem by supplying guidance or information not explicit in  the code.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6563,Some Ideas on Data Types in High Level Languages,"WE explore some new and old ideas concerning data types; what a data type is,  overloading operators, when and how implicit conversions between programmer  data types should be allowed and so forth. The current notion that a data  type is a set of values together with basic operations in that set leads us to  conclude that formal parameter types need not be so explicitly stated. Given a  formal parameter X with operations $o_{1},\ldots o_{n}$ being performed on X  within a procedure, one should be able to supply, as actual parameter in call,  a variable of any type which has operations $o_{1},\ldots o_{n}$ defined on  it. We introduce a notation for this, using PASCAL as a basic language,  illustrate the added flexibility it gives us, and show briefly how to  implement the idea efficiently.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6564,The Boolean Hierarchy: Hardware over NP,"In this paper, we study the complexity of sets formed by boolean operations  $(\bigcup, \bigcap,$ and complementation) on NP sets. These are the sets  accepted by trees of hardware with NP predicates as leaves, and together form  the boolean hierarchy. We present many results about the boolean hierarchy: separation and immunity  results, complete languages, upward separations, connections to sparse  oracles for NP, and structural asymmetries between complementary classes.  Some results present new ideas and techniques. Others put previous results  about NP and $D^{P}$ in a richer perspective. Throughout, we emphasize the  structure of the boolean hierarchy and its relations with more common classes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6565,Geometric Ambiguities in Boundary Representations,"Boundary representations are usually separated into two components, a  topological component and a geometric component. The conditions necessary to  insure that the topological component is unambiguous are well understood.  However, in algebriac modeling systems (as opposed to polyhedral modeling  systems), an unambiguous topological structure can have noncongruent  geometric interpretations with identical vertex coordinates, face equations  and edge descriptions using the usual representation of edges as the  intersection of faces along with tangent vectors at vertices. This means that  the conversion of a CSG tree that unambiguously describes a solid can lead to  an ambiguous boundary representations unless additional information is  retained in the boundary representation. This paper examines the source of  these ambiguities and presents one method for their elimination.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6566,On Estimating the Condition of Eigenvalues and Eigenvectors,"A method is developed for estimating the accuracy of computed eigenvalues and  eigenvectors that are obtained via certain EISPACK subroutines. It does this  at a cost of $O(n^{2})$ flops per eigenpair assuming that the eigenpair is  known and assuming that the original matrix has been reduced to Hessenberg  form. The heart of the technique involves estimating the smallest singular  value of a certain nearly triangular submatrix. This is accomplished by some  standard ""zero-chasing"" with Hivens transformations and with a 2-norm  version of the LINPACK condition estimator. An EISPACK compatible code has  been developed and its performance is discussed. Suggestions for extending  the current work to general invariant subspaces and to the generalized  eigenvalue problem are given.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6567,Recognizing Safety and Liveness,Formal characterizations for safety properties and liveness properties are  given in terms of the structure of the Buchi automaton that specifies the  property. The characterizations permit a property to be decomposed into a  safety property and a liveness property whose conjunction is the original. The characterizations also give insight into techniques required to prove a  large class of safety and liveness properties.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6568,Enhancement of Text Representations Using Related Document Titles,"Various attempts have been made over the years to construct enhanced document  representations by using thesauruses of related terms, term association maps,  or knowledge frameworks that can be used to extract appropriate terms and  concepts. None of the proposed methods for the improvement of document  representation has proved to be generally useful when applied to a variety of  different retrieval environments. Some recent work by Kwok suggests that  document indexing may be enhanced by using title words taken from  bibliographically related items. An evaluation of the process shows that many  useful content words can be extracted from related document titles, as well  as many terms of doubtful value. Overall, the procedure is not sufficiently  reliable to warrant incorporation into operational automatic retrieval systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6569,McLaren's Masterpiece,Abstract not available,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6570,Computing a Sparse Basis for the Null Space,"We present algorithms for computing a sparse basis for the null space of a  sparse underdetermined matrix. We describe several possible computational  strategies, both combinatorial and noncombinatorial in nature, and we compare their effectiveness for several test problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6571,Performance Evaluation of Main Memory Database Systems,"In this paper we present the results of a comprehensive benchmark of the  relational Main Memory Database System (MMDBS), that is the foundation of the  interactive office system. Office-By-Example (OBE). Based on this case study,  we identify issues that must be considered in the design and implementation  of MMDBS's. We determine relevant performance metrics and describe techniques  for benchmarking MMDBS's.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6572,Proving Temporal Properties of Concurrent Programs: A Non-Temporal Approach,This thesis develops a new method for proving properties of concurrent  programs and gives formal definitions for safety and liveness. A property is specified by a property recognizer - a finite-state machine  that accepts the sequences of program states in the property it specifies. A  property recognizer can be constructed for any temporal logic formula.  (ABRIDGED ABSTRACT),,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6573,A Parallel Algorithm for Large Sparse Cholesky Factorization on a Multiprocessor,"We develop an algorithm for computing the symbolic and numeric Cholesky  factorization of a large sparse symmetric positive definite matrix. The  algorithm is intended for a message-passing multiprocessor system, such as  the hypercube, and is based on the concept of elimination forests. In  addition, we provide an algorithm for computing these forests along with a  discussion of the algorithm's complexity and a proof of its correctness. We also examine the related issue of load balancing.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6574,The Complexity of Fine Motion Planning,"We study the complexity of fine motion planning for robots with position  measurement and damping. A reduction from fine motion planning with position  measurement only to the ""classical piano mover's problem"" is developed,  thereby showing it to be feasible in polynomial time. We then show that  deciding the existence of fine motion plans for robots with damping in three  dimensional scenes is PSPACE-hard and, with a view to finding the cause for  the jump in the complexity, we identify a restricted subclass of the  PSPACE-hard problem that is PSPACE-complete. Finally, we show how to restrict  this subclass to permit polynomial time algorithms for the problems in it.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6575,A Paradigm for Reliable Clock Synchronization,"Existing fault-tolerant clock synchronization protocols are shown to result  from refining a single clock synchronization paradigm. In that paradigm, a  reliable time source periodically issues messages that cause processors to  resynchronize their clocks. The reliable time source is approximated by  reading all clocks in the system and using a convergence function to compute  a fault-tolerant average of the values read. The performance of a clock  synchronization algorithm based on the paradigm can be quantified in terms of  the two parameters that characterize the behavior of the convergence function  used: accuracy and precision.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6576,Monadic Spectra and Regular Sets,Abstract not available.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6577,A Note on the Transaction Backout Problem,"The transaction backout problem arises in the area of distributed databases.  Suppose failures partition a data-redundant distributed database, and each  partition continues to function as if it were the entire database. When the  database is reconnected, the transactions executed by different partitions  may not be serializable, and hence it may be necessary to back out some of  the transactions. The transaction backout problem is to remove the smallest  set of transactions that will leave the remaining ones serializable. The  general problem is NP-complete, and in this paper we show that the special  case of a fixed-size database can be solved in polynomial time by dynamic  programming.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6578,On the Reliability of Fault-Tolerant Distributed Computing Systems,"The designer of a fault-tolerant distributed system faces numerous  alternatives. Using a stochastic model of processor failure times, we  investigate design choices such as replication level, protocol running time,  randomized versus deterministic protocols, fault detection and  authentication. We use the probability with which a system produces the  correct output as our evaluation criterion. This contrasts with previous  fault-tolerance results that guarantee correctness only if the percentage of  faulty processors in the system can be bounded. Our results reveal some  subtle and counterintuitive interactions between the design parameters and  system reliability.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6579,Designing Fault-Tolerant Algorithms for Distributed Systems Using Communication Primitives,"Fault-tolerance is an important requirement in distributed computing systems.  However, designing applications for distributed systems is a difficult task,  particularly when components of the system can fail. The difficulty of this  task increases with the severity of failures encountered. Arbitrary process  failures are generally much harder to overcome than failures that are  restricted, e.g. where processes only fail by halting. Thus, techniques that  restrict the disruptive behavior of faulty processes can greatly simplify the  design of fault-tolerant algorithms. Such techniques effectively provide  reduction mechanisms from one class of failures to a more benign class. Message authentication is an example of a technique that imposes restrictions  on the bahavior of fault processes. This technique has been used to derive  simple solutions to many problems of fault-tolerance for systems with  arbitrary failures. To exploit the simplicity provided by authentication we  present communication primitives that provide properties of authentication  without using digital signatures. These primitives can also be extended to  provide properties beyond those of authentication, thereby further  restricting the types of faults that have to be overcome. (ABRIDGED ABSTRACT)",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6580,A Parallel Ordering for the Block Jacobi Method on a Hypercube Architecture,Jacobi methods for computing the singular value decomposition are ideally  suited for multiprocessor environments since they contain a great deal of  inherent parallelism. We give a parallel ordering for the block Jacobi Method  that allows us to take full advantage of the nearest-neighbor topology of the  hypercube. It is based on recursively embedding smaller rings into the  hypercube using a Gray code labelling of processor nodes. This scheme is  optimal in that it entails the lowest communication overhead possible.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6581,Sorting Large Files on a Backend Multiprocessor,"A fundamental measure of processing power in a database management system is  the performance of the sort utility it provides. When sorting a large data  file on a serial computer, performance is limited by factors involving  processor speed, memory capacity and I/O bandwidth. In this paper, we  investigate the feasibility and efficiency of a parallel sort-merge algorithm  through implementation on the JASMIN prototype, a backend multiprocessor  built around a fast packet bus. We describe the design and implementation of  a parallel sort utility that may become a building block for query processing  in a database system that runs on JASMIN. We present and analyze the results  of measurements corresponding to a range of file sizes and processor  configurations. Our results show that using current, off-the-shelf technology  coupled with a streamlined distributed operating system, three and five  microprocessor configurations provide a very cost-effective sort of large  files. The three processor configuration sorts a 100 megabyte file in one  hour, which compares well with commercial sort packages available on  high-performance mainframes. In additional experiments, we investigate a  model to tune our sort software, and scale our results to higher processor  and network capabilities.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6582,Formalized Metareasoning in Type Theory,"In this paper we present two practical methods of formalizing the metatheory  of constructive type theory and demonstrate how they would be used to improve  the reasoning capabilities of formal problem solving systems such as Nuprl.  One method depends upon the design of a family of languages, and we sketch  that construction. The second approach depends on a particular metatheorem  that justifies partial reflection, and we outline this proof. We also  illustrate the construction of simple metatheoretic functions, tactics, in  Nuprl.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6583,Infinite Objects in Type Theory,In this paper we show how infinite objects can be defined in a constructive  type theory. The type theory that we use is a variant of Martin-Lof's  Intuitionistic Type Theory. We show how one can express the intuition that  infinite objects are understood through a limiting process without having to  introduce partial objects in the theory. This means that we can adhere to the  propositions-as-types principle. The type of infinite objects thus contains  only total elements. The approximation is expressed through a sequence of  types that approximate the type of infinite objects. We give two semantic  accounts of types of infinite objects. The first is lattice theoretic and  shows how these types can be understood as fixed points. The second is  category theoretic and shows the duality between types of infinite objects  and the ordinary recursive type definitions.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6584,ISIS: A System for Fault-Tolerant Distributed Computing,"The ISIS system transforms abstract type specifications into fault-tolerant  distributed implementations, while insulating users from the mechanisms  whereby fault-tolerance is achieved. This paper discusses the transformations  that are used within ISIS, methods for achieving improved performance by  concurrently updating replicated data, and user-level issues that arise when  ISIS is employed to solve a fault-tolerant distributed problem. We describe a  small set of communication primitives upon which the system is based. These  achieve high levels of concurrency while respecting ordering requirements  imposed by the caller. Finally, the performance of a prototype is reported  for a variety of system loads and configurations. In particular, we  demonstrate that performance of a replicated object in ISIS can equal or  exceed that of a nonreplicated object.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6585,Abstractions for Fault Tolerance in Distributed Systems,"Abstractions useful in fault-tolerant and distributed systems are described.  The abstractions are specified as properties of protocols, hence they have a  different flavor from abstractions prevalent in sequential and concurrent  programming. Among the abstractions discussed are agreement, order, failure  detection, and stable storage.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6586,Complexity Classes Without Machines: On Complete Languages for UP,"This paper develops techniques for studying complexity classes that are not  covered by known recursive enumerations of machines. Often, counting classes,  probabilistic classes, and intersection classes lack such enumerations.  Concentrating on the counting class UP, we show that there are  relativizations for which $UP^{A}$ has no complete languages and other  relativizations for which $P^{B} \neq UP^{B} \neq NP^{B}$ and $UP^{B}$ has  complete languages. Among other results we show that $P \neq UP$ if and only  if there exists a set $S$ in $P$ of Boolean formulas with at most one  satisfying assignment such that $S \bigcap SAT$ is not in $P$. $P \neq UP  \bigcap coUP$ if and only if there exists a set $S$ in $P$ of uniquely  satisfiable Boolean formulas such that no polynomial-time machine can compute  the solutions for the formulas in $S$. If $UP$ has complete languages then  there exists a set $R$ in $P$ of Boolean formulas with at most one satisfying  assignment so that $SAT \bigcap R$ is complete for $UP$. Finally, we indicate  the wide applicability of our techniques to counting and probabilistic  classes by using them to examine the probabilistic class $BPP$. There is a  relativized world where $BPP^{A}$ has no complete languages. If $BPP$ has  complete languages then it has a complete language of the form $B \bigcap  MAJORITY$, where $B \in P$ and $MAJORITY = \{f | f$ is true for at least half  of all assignments\} is the canonical $PP$-complete set.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6587,The Null Space Problem II: Algorithms,"The Null Space Problem is that of finding a sparsest basis for the null space  (null basis) of a $t \times n$ matrix of rank $t$. This problem was shown to  be NP-hard in Coleman and Pothen (1985). In this paper we develop heuristic  algorithms to find sparse null bases. These algorithms have two phases: In  the first combinatorial phase, a minimal dependent set of columns is  identified by finding a matching in the bipartite graph of the matrix. In the  second numerical phase, a null vector is computed from this dependent set. We describe an implementation of our algorithms and provide computational  results on several large sparse constraint matrices from linear programs. One  of our algorithms compares favorably with previously reported algorithms in  sparsity of computed null bases and in running times. Unlike the latter, our  algorithm does not require any intermediate dense matrix storage. This  advantage should make our algorithm an attractive candidate for large sparse  null basis computations. A matching based algorithm is designed to find orthogonal null bases, but we  present some theoretical evidence that such bases are unlikely to be sparse.  Finally, we show how sparsest orthogonal null bases may be found for an  $n$-vector and a $t \times n$ dense matric by a divide and conquer strategy.  The algorithm for a dense matrix is suited for implementation on a parallel  machine architecture.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6588,Impact of Communciation Networks on Fault-Tolerant Distributed Computing,"When the desired reliability of a computing system exceeds that of its  individual hardware components the need for fault-tolerant systems arise.  While distributed systems have the potential to achieve highly reliable  computing, programming them is a challenging task. Several paradigms have  been identified that can simplify the conceptual design of fault-tolerant  distributed systems. Properties of a distributed system have profound implications on the  solvability and efficiency of implementations of these paradigms. In this  thesis we study the effect that different communication models have on the  efficiency of fault-tolerant computing. As an instance of a fundamental  operation we examine protocols for reliable broadcast in distributed systems.  Our main contribution is the characterization of the time complexity of  reliable broadcast with respect to communication models. A practical  consequence of our results is the development of efficient reliable broadcast  protocols with respect to communication models. A variety of common networks  are shown to support this style of communication. In fact, by parameterizing  the minimum multicast size and diameter of these networks, we are able to  characterize all known network architectures. Distributed systems where processors perceive the same approximate time makes  programming them much easier. Clock synchronization protocols implement this  abstraction given only clocks that have bounded drift rates with respect to  real time. We show how a primitive which is normally used only for  communication in a distributed system can also be used for synchronizing  clocks. If this primitive occurs naturally with a sufficient frequency, clock  synchronization can be achieved at no additional message cost. Our results reveal hardware/software tradeoffs between performance,  resiliency and network cost. Thus, they offer many new alternatives  previously not considered in designing fault-tolerant systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6589,Implementation Issues In Clock Synchronization,"We present some results from an experimental implementation of a recent  clocks synchronization algorithm. This algorithm was designed to overcome  arbitrary processor failures, and to achieve optimal accuracy, i.e., the  accuracy of synchronized clocks (with respect to real time) is as good as  that specified for the underlying hardware clocks. Our system was implemented  on a set of workstations on a local area braodcast network. Initial results  indicate that this algorithm can form the basis of an accurate, reliable, and  practical distributed time service.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6590,Predicting Structure in Sparse Matrix Computations,We describe the results of an experiment in which the Nuprl proof development  system was used in conjunction with a collection of simple proof-assisting  programs to constructively prove a substantial theorem of number theory. We  believe that these results indicate the promise of an approach to reasoning  about computationally meaningful mathematics by which proof construction and  the results of formal reasoning are mathematically comprehensible.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6591,The Efficiency of Inverted Index and Cluster Searches,"The processing time and disk space requirements of an inverted index and  top-down cluster search are compared. The cluster search is shown to use both  more time and more disk space, mostly due to the large number of cluster  centroids needed by the search. When shorter centroids are used, the  efficiency of the cluster search improves, but the inverted index search  remains more efficient.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6592,Implementing Number Theory: An Experiment with Nuprl,We describe the results of an experiment in which the Nuprl proof development  system was used in conjunction with a collection of simple proof-assisting  programs to constructively prove a substantial theorem of number theory. We  believe that these results indicate the promise of an approach to reasoning  about computationally meaningful mathematics by which both proof construction  and the results of formal reasoning are mathematically comprehensible.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6593,Communication Support for Reliable Distributed Computing,"We describe a collection of communication primitives integrated with a  mechanism for handling process failure and recovery. These primitives  facilitate the implementation of fault-tolerant process groups, which can be  used to provide distributed services in an environment subject to  non-malicious crash failures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6594,Reliable Broadcast Protocols and Network Architecture: Tradeoffs and Lower Bounds,"Reliable Broadcast is a mechanism by which a processor in a distributed  system disseminates a value to all other processors in the presence of both  communication and processor failures. Protocols to achieve Reliable Broadcast  are at the heart of most fault-tolerant applications. We characterize the  execution time of Reliable Broadcast protocols as a function of the  properties of the underlying communication network. The class of networks  considered includes familiar communication structures such as fully-connected  point-to-point graphs, linear chains, rings, broadcast networks (such as  Ethernet) and buses. We derive a protocol that implements Reliable Broadcast  for any member within this class. We present a novel proof technique to  obtain lower bound results for Reliable Broadcast in this environment. This  proof technique is based on graph mappings. The hardware-software tradeoffs  that are revealed between performance, resiliency and network cost offer many  new alternatives previously not considered in designing fault-tolerant systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6595,Engineering Fault-Tolerant Distributed Computing Systems,"We view the design of fault-tolerant computing systems as an engineering  endeavor. As such, this activity requires understanding the theoretical  limitations and the scope of the feasible designs. We survey the impact that  various environment characteristics and design choices have on the resultant  system properties. We propose a single metric - the system reliability - as  an appropriate measure for exploring tradeoffs among a potentially-large  design space.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6596,Stopping Times of Distributed Consensus Protocols: A Probabilistic Analysis,"Given a model where each processor remains correct for an exponentially  distributed random time and then fails independently of the others, we  characterize system executions that permit the processors to reach consensus.  We show that with non-zero probability, a protocol can achieve consensus even  during executions where the number of actual processors to fail exceeds its  resiliency.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6597,Extracting Efficient Code From Constructive Proofs,"Extraction is a technique for producing verified programs. A proof of  $\forall chi : T \ldot \exists y : T' \ldot F$ corresponds to a function $f$  of type $T \rightarrow T'$ that maps every $\chi$ of type $T$ to a $y$ of  type $T'$ such that $F$ is true. If the proof is constructive, then $f$ is  recursive. The semantics of extracted code involves the manipulation of  justifications, which are pieces of evidence for the truth of formulas. The  raw extracted code for the formula above is actually a function $\gamma$ that  maps $\chi$ to a pair $(y, \gamma')$, where $\gamma'$ is a justification that  provides evidence for the truth of $F$. This thesis presents various ways to improve the efficiency of extracted  programs. The first way uses traditional code optimizations. Though very  helpful, they are no panacea. The second way involves small changes to its  underlying semantics. Certain formulas, called singleton formulas, have no  interesting justifications; if $F$ is such a formula, no justification for it  needs to be built, which simplifies the extracted code. The third way to improve extracted code is to add call-by-reference  parameters to it. As originally defined, extracted code passes arguments by  value, which leads to inefficient code for mutable objects like arrays:  passing an array by value requires making a copy of it. Adding call-by-reference parameters entails adding a state to the semantics  of extracted code, which in turn leads to various semantic and syntactic  design issues, like aliasing and side-effects. To account for these changes,  the constructive logic used to build proofs is modified. A proof of quicksort  illustrates the functional, assignment-free, side-effect-free style of proof  promoted by the new logic. To relieve the user of some of the mental overhead involved in using the new  logic, an array inferencing algorithm is presented. The algorithm allows  users to get code that uses arrays from proofs that reason about and  manipulate lists in restricted ways. In this way, users can view the use of  arrays as an optimization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6598,The Geometry of Projective Blending Surfaces,"Blending surfaces smoothly join two or more primary surfaces that otherwise  would intersect in edges. We outline the potential method for deriving  blending surfaces, and explain why the method needs to be considered in  projective parameter space, concentrating on the case of blending quadrics.  Let $W$ be the quadratic polynomial substituted for the homogenizing variable  of parameter space. We show that a blending surface derived in projective  parameter space is the projective image of a different blending surface  derived in affine parameter space, provided that $W = U^{2}$ for some linear  $U$. All blending surfaces may therefore be classified on basis of the  projective classification of $W$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6599,Discussion of Parallel Algorithms,"In recent years we have witnessed a tremendous surge in the availability of  very fast and inexpensive hardware. However, our ability to design fast and  cheap hardware far outstrips our ability to utilize them effectively in  solving large problems fast. Hence there is a continuing interest in the  study and development of parallel algorithms. In this paper we present a  survey of deterministic parallel algorithms for a class of computational  problems. Both graph-theoretic and non graph-theoretic problems are  considered and the parallel algorithms presented are motivated by identifying  some common paradigms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6600,Impredicative Strong Existential Equivalent to Type:Type,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6601,Exact Counting is as Easy as Approximate Counting,"We show that exact counting and approximate counting are polynomially  equivalent. That is $P^{#P} = P^{Approx#P}$, where #$P$ is a function that  computes the number of solutions to a given Boolean formula $f$ (denoted by  $|| f ||$), and Approx#P computes a short list that contains $|| f ||$. It  follows that if there is a good polynomial time approximator for #$P$ (i.e.,  one where the list has at most $O(|f|^{1-\epsilon})$ elements), then  $P = NP = P^{#P}$ and probabilistic polynomial time equals polynomial time.  Thus we have strong evidence that #$P$ cannot be easily approximated.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6602,A Chordal Preconditioner for Large Scale Optimization,"We propose an automatic preconditioning scheme for large sparse numerical  optimization. The strategy is based on an examination of the sparsity pattern  of the Hessian matrix: using a graph-theoretic heuristic, a block diagonal  approximation to the Hessian matrix is induced. The blocks are submatrices of  the Hessian matrix; furthermore, each block is chordal. That is, under a  positive definiteness assumption, each block can be Cholesky factored without  creating new nonzeroes (fill). Therefore the preconditioner is space  efficient. We conduct a number of numerical experiments to determine the  effectiveness of the preconditioner in the context of a linear conjugate  gradient algorithm for optimization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6603,Computation of Aliases and Support Sets,"When programs are intended for parallel execution it becomes critical to  determine whether the evaluations of two expressions can be carried out  independently. We provide a scheme for making such determinations in a  language with higher order constructs and imperative features. The heart of  our scheme is a mechanism for computing the support of an expression, i.e.  the set of global variables involved in its evaluation. This computation  requires knowledge of all the aliases of an expression. The inference schemes  are presented as abstract semantic interpretations. We prove the soundness of  our estimates by establishing a correspondence between the abstract semantics  and the standard semantics of the programming language.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6604,First- and Second-Order Lambda Calculi with Recursive Types,Recursive types are added to the first- and second-order lambda calculi and  the resulting typed terms are shown to be strongly normalizable. A necessary  and sufficient condition for strong normalizability is given for unrestricted  definitions of recursive types.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6605,Implementing Agglomerative Hierarchic Clustering Algorithms for Use in Document Retrieval,"Searching hierarchically clustered document collections can be effective, but  creating the cluster hierarchies is expensive since there are both many  documents and many terms. However, the information in the document-term  matrix is sparse: documents are usually indexed by relatively few terms. This  paper describes the implementations of three agglomerative hierarchic  clustering algorithms that exploit this sparsity so that collections much  larger than the algorithms' worst case running times would suggest can be  clustered. The implementations described in the paper have been used to  cluster a collection of 12,000 documents.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6606,Completeness and Incompleteness of Trace-Based Network Proof Systems,"Most trace-based proof systems for networks of processes are known to be  incomplete. Extensions to achieve completeness are generally complicated and  cumbersome. In this paper, a simple trace logic is defined and two examples  are presented to show its inherent incompleteness. Surprisingly, both  examples consist of only one process, indicating that network composition is  not a cause of incompleteness. Axioms necessary and sufficient for the  relative completeness of a trace logic are then presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6607,Some Nested Dissection Order is Nearly Optimal,"The minimum fill problem is to reorder the rows and columns of a given sparse  symmetric matrix so that its triangular factor is as sparse as possible.  Equivalently, it is to find the smallest set of edges whose addition makes a  given undirected graph chordal. The problem is known to be NP-complete, and  no polynomial-time approximation algorithms are known that provide any  nontrivial guarantee for arbitrary graphs (matrices), although some  heuristics perform well in practice. Nested dissection is one such heuristic.  In this note we prove that every graph with a fixed bound on vertex degree  has a nested dissection order that achieves fill within a factor of  $O(\logn)$ of minimum. This does not lead to a polynomial-time approximation  algorithm, however, because the proof does not give an efficient method for  finding the separators required by nested dissection.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6608,The PRL Mathematics Environment: A Knowledge Based Medium,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6609,Adaptive Bitonic Sorting: An Optimal Parallel Algorithm for Shared Memory Machines,"We propose a parallel algorithm, called adaptive bitonic sorting, which runs  on a PRAC, a shared-memory multiprocessor where fetch and store conflicts are  disallowed. On a $P$ processors PRAC, our algorithm achieves optimal  performance $TP = O(N \log N)$, for any computation time $T$ in the range  $\Omega (\log^{2} N) \leq T \leq O(N \log N)$. Adaptive bitonic sorting has  also a small constant factor, since it performs less than $2N \log N$  comparisons, and only a handful of operations per comparison.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6610,On Algebraic Surfaces Meeting with Geometric Continuity,"An increasingly prominent area of computer science is Computer Aided  Geometric Design or CAGD. The main task of CAGD is to automate, to the  greatest extent possible, the process of designing physical objects. A  designer typically models an object as a collection of surfaces. For many  objects, design specifications indicate only a few critical surfaces, with  the remaining surfaces to be chosen so as to make the surface of the  resulting object smooth. Smoothness is important because, in many mechanical  objects, sharp edges are undesirable for functional or aesthetic reasons. For  example, sharp edges on the interior surface of a gate valve retard fluid  flow. Automatically calculating these remaining surfaces, called blending  surfaces is an important task in any CAGD system. Therefore, an understanding  of the mathematics of surfaces that meet smoothly is fundamental to CAGD. Specifically, this thesis investigates the following problem: given a surface  V and a point or curve W on that surface, construct surfaces that meet with V  with a specified degree of smoothness along W. Working from a measure of  smoothness known as geometric continuity, the first half of this thesis  establishes that the space of all surfaces meeting V with the k-th order  geometric continuity along W is directly related to certain algebraic  structures called ideals. For example, let Z(M) (the set of point for which a  polynomial M is zero) be an irreducible surface that intersects another  surface Z(N) transversally (nontangentially) in an irreducible curve  Z(M) $\frown$ Z(N). It is shown that a surface Z(F) meets Z(M) with order k  geometric continuity along Z(M) $\frown$ Z(N) if and only if F is a  polynomial of the form $AM = BN^{k+1}$ where A and B are free polynomials and  A is nonzero on Z(M) $\frown$ Z(N). The second half of this work applies these results to the problem of  generating blending surfaces. Using the geometric properties of blending  surfaces, it is shown that any surface Z(F) that smooths the intersection of  two surfaces Z(M) and Z(N) must have certain algebraic properties. In  particular, the degree of F must be greater than or equal to the maximum of  the degrees of $M^{2}$ and $N^{2}$. Finally, existing methods for  constructing blending surfaces are shown to be consistent within the above  algebraic framework. In fact, we demonstrate that these distinct methods are  instances of a single general method for generating blending surfaces.  Moreover, this general method is shown to generate blending surfaces of the  lowest possible degree.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6611,Deterministic Polynomial Time O(log n) Queries,"$P^{NP[\log n]}$ is the class of languages recognizable by determining  polynomial time machines that make $O(\log n)$ queries to an oracle for NP.  Many of the languages related to optimal solution sizes of NP optimization  problems are members of this class. We relate $P^{NP[\log n]}$ to the study  of sparse oracles for NP by showing that if NP has a sparse  $\leq^{P}_{T}$-complete set, then the polynomial time hierarchy collapses to  $P^{NP[\log n]}$. We also discuss complete problems and show that UOCSAT, the  set of CNF formulas with the property that every assignment that satisfies  the maximum number of clauses satisfies the same set of clauses, is  $\leq^{P}_{m}$-complete for $P^{NP[\log n]}$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6612,Programming with Shared Bulletin Boards in Asynchronus Distributed Systems,"We consider loosely coupled distributed computing systems in which processes  interact through shared resources, which are modeled as bulletin boards. The  first part of the paper formalizes the notion of consistent behavior when  unreliable processes concurrently access a bulletin board. This model is  interesting both as a tool for showing the correctness of a board  implementation and also because it provides a mechanism for reasoning about  consistency in distributed systems, which was previously lacking. The  remainder of the paper discusses software techniques for implementing  consistent bulletin boards in a network of processors lacking shared memory.  Applications for our approach range from asynchronous interprocess  communication to mechanisms for achieving mutual exclusion, deadlock  detection and for building distributed database systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6613,Polynomial Decomposition Algorithms,"In a recent paper [BZ], Barton and Zippel examine the question of when a  polynomial $f(x)$ over a field of characteristic 0 has a nontrivial  decomposition $f(x)=g(h(x))$. They give two exponential-time algorithms, both  of which require polynomial factorization. We present an $O(s^{2}r\logr)$  algorithm, where $r$=deg $g$ and $s$ =deg $h$. The algorithm does not use  polynomial factorization. We also show that the problem is in $NC$. In  addition, we give a new structure theorem for testing decomposibility over  any field. We apply this theorem to obtain an $NC$ algorithm for decomposing  irreducible polynomials over finite fields and a subexponential algorithm for  decomposing irreducible polynomials over any field.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6614,The Automated Design of Parts Orienters,This paper concerns the design of parts orienters - the dual to the motion  planning problem. Three particular paradigms are considered and their  abstractions to the computational domain lead to interesting problems in  graph pebbling and function composition on finite sets. Polynomial time  algorithms are developed for the abstracted problems.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6615,On Moving and Orienting Objects,"Many problems arising in the area of robotics are directly or indirectly  related. In order to analyze such problems, it is necessary to incorporate  the dynamics with the geometry in the mathematical formulation. With this in  view, this thesis deals with two such problems - motion planning in the  presence of uncertainty and the automated design of parts orienters. Motion planning for robots with errors in position measurement, velocity and  time is considered and shown to be decidable in polynomial time for a large  class of inputs. The robot model is then extended to include damping - a  limited form of force sensing. Motion planning for point objects in  three-dimensional scenes and robots with damping is shown to be PSPACE-hard.  A simplified version of the same problem is shown to be PSPACE-complete. The problem of the automated design of parts orienters is rather closely  related to motion planning. But the dynamics of the problem is so dominant  that similar general formulations seem impossible. In this thesis, the  alternative pursued is paradigm-by-paradigm analysis. Three paradigms are  presented and analyzed - the ""belt"", for orienting convex polygons that are  infinite in the third dimension, the ""pan handler"", for flat polygonal  objects and the vibratory track for flat, convex polygons. Polynomial time  algorithms are developed for the automated design of orienters in each of the  paradigms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6616,"Resource Bounded Kolmogorov Complexity, A Link Between Computational Complexity and Information Theory","The resource bounded Kolmogorov complexity classes identify finite strings  (and by extension infinite strings) according to how much we can compress and  then recover the strings in a space or time bounded environment. We view the resource bounded Kolmogorov complexity classes as a link between  computational complexity and information theory. Firstly, we study these classes with respect to information theory (or  unbounded Kolmogorov complexity classes). Most of what we know about  information theory can also be shown in a space bounded environment. Whether  it also stands in a time bounded environment is an interesting problem and  parallels open questions about the power of nondeterminism. Then, we investigate the structure of the classes and show the analogies and  differences with the structure of computational complexity classes. For  example, we build hierarchies paralleling the time and space hierarchies. We  show that the exponential hierarchy collapses if and only if our parallel  hierarchy collapses. Lastly, we analyse the statistical properties of random strings. Martin-Lof  has shown that all strings with no short description possess all the  computable statistical properties of random strings. We show that this result  carries over to the space bounded Kolmogorov random strings, which pass all  statistical tests using less space than the space bound. Also, allowing a  little more space, we can design a test to detect all those strings. These results are further applied to the theory of pseudo-random number  generators. Among other consequences, it is shown that there are some  properties that no space bounded random number generator can possess. The  notion of statistical tests is compared to the notion of a good pseudo-random  number generator, as defined by Andrew Yao.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6617,The Sky is Falling: The Strong Exponential Hierarchy Collapses,"This paper investigates the complexity of the high levels of the exponential  hierarchy [HY84,HIS85]: Are they hard, and if so why are they hard? We show that $P^{NE} = NP^{NE}$. From this we conclude that the strong exponential hierarchy collapses:  $P^{NE} = NP^{NE} \bigcup NP^{NP^{NE}} \bigcup NP^{NP^{NP^{NE}}} \bigcup  \cdots,$ where NE is nondeterministic exponential time. This suprising result, a  nontrivial hierarchy collapse, is based on $P^{NE}$ overmastering the  $NP^{NE}$ computation tree by computing better and better partial census  information. We note why the combinatorics involved prevents us from  similarly proving that the polynomial hierarchy collapses. Next we look at the exponential hierarchy, which is NE given a rich database:   $NE \bigcup NE^{NP} \bigcup NE^{NP^{NP}} \bigcup \cdots$. We show that if the exponential hierarchy's $\Delta_{i}$ and $\Sigma_{i}$  levels do separate, this is due not to the power of the database but to the  extravagant number of queries NE makes to the database. Thus the high levels  of the strong exponential hierarchy are no harder than the low levels. The  high levels of the exponential hierarchy separate completely only if NE  floods its database with queries. Extending our techniques, we derive  sufficient conditions for collapsing complexity classes, and use them to  generate strong new quantitative relativization results.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6618,On Some Most Probable Separations of Complexity Classes,"This thesis is a study of separations of some complexity classes which take  place in almost all relativized worlds. We achieve probability one  separations of PSPACE from the Polynomial-time Hierarchy PH. Also we separate  with probability one all levels of the Boolean Hierarchy BH. The study on the Boolean Hierarchy is a continuation of the work by Bennet  and Gill in [BG81] and the joint work in [CH86], where we introduced the  ""sawing"" argument. This ""sawing"" technique is adapted here to yield  probability one separation. The study on PSPACE versus the Polynomial-time Hierarchy is more intriguing.  Several novel techniques are employed here. The connection with Boolean  circuit is exploited to reduce the problem to a Boolean circuit computation  problem. The fixed depth unbounded fan-in Boolean circuit model is considered in  connection with the parity function. We show that with an exponential bound  of the form $exp(n^{\lambda}$ on the size of the circuits, they make  asymptomatically 50% error on all possible inputs, uniformly. Certain  probabilistic and game theoretic methods are applied extensively to conclude  the result.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6619,Constructive Automata Theory Implemented with the Nuprl Proof Development System,The Nuprl proof development system was designed for the computer-assisted  problem solving in mathematics and programming. In particular it can be used  for the development of mathematical proofs and of programs which are  guaranteed to meet their specifications. The implementation of the theory of  finite automata gave lots of insights into its strengths and weaknesses and  shows that Nuprl is indeed powerful enough now to obtain nontrivial results  within reasonable amounts of time. Its success shall encourage people to  actually use the system and build theories within it. This report describes the techniques and the user-defined extensions to the  Nuprl object language which were necessary to formulate and prove theorems  from the theory of finite automata. It also describes the experiences which  came from actually working with the current Nuprl system and gave some useful  insights into its strenghts and weaknesses. A complete Nuprl-proof of the  pumping lemma and its computational evaluation are presented and an outline  for future development is given.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6620,Developing a Linear Algorithm for Cubing a Cyclic Permutation,"A linear algorithm is developed for cubing a cyclic permutation stored as a  function in an array. This continues work discussed in [0] and [1] on  searching for disciplined methods for developing and describing algorithms  that deal with complicated data structures such as linked lists. Here, a  different representation of a cyclic permutation reveals a simple algorithm;  then, an equally simple coordinate transformation is used to yield the final  algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6621,Efficient Concurrency Control for Libraries of Typed Objects,"Concurrency control algorithms use a conflict detection strategy to determine  operations that have to be delayed to provide a correct serialization order.  To keep the cost of detecting conflicts feasible, most algorithms employ  rather crude strategy that sometimes delays operations when in reality they  could proceed concurrently. In an object oriented system where calls to  objects can be nested this problem is exacerbated by the fact that a  concurrency control decision is made at each level in the calling hierarchy. In this dissertation we address concurrency control issues in object oriented  systems. We develop a model of execution for operations on objects, drawing  on similar models developed for database systems. We propose a new  serialization algorithm that keeps a partial history of operations at each  site, and exploits semantic knowledge of operations to achieve a finer  granularity of conflict detection. Conflict detection is based on user  supplied conflict predicates, thus giving the user the option of fine grained  concurrency control and the responsibility for the level of cost of the  conflict detection strategy. We then show how to implement the algorithm in a  distributed system where sites can fail and recover independently. Finally,  we explore techniques to reduce the message overhead and latency for the  algorithm in a distributed system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6622,A Proof System for Dataflow Networks with Indeterminate Modules,In this paper we discuss a model for dataflow networks containing  indeterminate operators and the associated proof system. The model is  denotational and associates with each network the set of possible behaviors.  The possible behaviors are represented by traces. The novel feature of our  proof system is that we give an inductive proof rule for recursively defined  networks based on a fixed point construction given by Keller and Panangaden.  We show soundness and relative completeness of our proof system.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6623,Sparse Partial Pivoting in Time Proportional to Arithmetic Operations,"Existing sparse partial pivoting algorithms can spend asymptomatically more  time manipulating data structures than doing arithmetic, although they are  tuned to be efficient on many large problems. We present an algorithm to  factor sparse matrices by Gaussian elimination with partial privoting in time  proportional to the number of arithmetic operations. Implementing this algorithm requires only simple data structures and gives a  code that is competitive with, and often faster than, existing sparse codes.  The key idea is a new triangular solver that uses depth-first search and  topological ordering to take advantage of sparsity in the right-hand side.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6624,Output-Size Sensitive Algorithms for Constructive Problems in Computational Geometry,"In computer science the efficiency of algorithms is usually measured in terms  of the size of the input. The output size, on the other hand, has been used  for this purpose rather infrequently, except in certain enumerative query  problems. This thesis deals with several constructive (in constrast to query) problems  in computational geometry and presents algorithms whose running time depends  non-trivially on the output size. We present an algorithm that finds the convex hull on $n$ points in the plane  in worst case time $O(n \log H)$, where $H$ is the number of points that turn  out to be vertices of the convex hull. we examine the $d$-dimensional maximal vector problem and show that as long  as $V$, the number of maximal vectors in a set, is not too large, these  maximal vectors can be found in $O(n \log V)$. We present an algorithm for solving the planar convex subdivision overlay  problem in time proportional to the combined input and output size. Finally we show that, after some preprocessing in the form of linear  programs, $d$-dimensional convex hulls can be constructed at logarithmic cost  per face.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6625,A Development Environment for Horizontal Microcode,"This paper describes a development environment for horizontal microcode. The  environment used Percolation Scheduling - a transformational system for  parallelism extraction - and an interactive profiling system that gives the  user control over the microcode compaction process while reducing the  burdensome details of architecture, correctness-preservation, and  synchronization. Through a graphical interface the user suggests what can be  executed in parallel, while the sytem performs the actual changes using  semantics-preserving transformations. If a request cannot be satisfied, the  system reports the problem causing the failure. The user may then help  eliminate the problem by supplying guidance or information not explicit in  the code. Index terms - microcode, compaction, Percolation Scheduling, environment,  transformation, parallelization, compiler.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6626,Generating a Random Cyclic Permutation,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6627,A Parallel Triangular Solver for a Hypercube Multiprocessor,"We consider solving triangular systems of linear equations on a hypercube  multiprocessor. Specifically, we propose a fast parallel algorithm,  applicable when the triangular matrix is distributed around the cube by  column in a wrap fashion. Numerical experiments indicate that the new  algorithm is very efficient. A theoretical analysis confirms that the total running time varies linearly,  with respect to the matrix order, up to a threshold value of the matrix  order, after which the dependence is quadratic. Moreover, we show that total  message traffic is essentially the minimum possible. Finally, we describe an analogous row-oriented algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6628,Finitary Choice Cannot Express Fairness: A Metric Space Technique,,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6629,A Parallel Algorithm for Finding Fill in a Sparse Symmetric Matrix,"We describe a parallel algorithm for finding the fill that occurs when a  sparse symmetric positive definite matrix A is factored into its Cholesky  factor L. The algorithm is in two steps: First we determine the elimination  forest F for A. Then from F and A we compute the fill. The algorithm takes  $O(\log^{2} n)$ time, using $m + n$ processors to find the elimination forest  and $m^{*}+ n$ processors to find the fill.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6630,Substituting for Real Time and Common Knowledge in Distributed Systems,"We study time and knowledge in synchronous and asynchronous reliable  distributed systems. For both types of systems, we describe clocks that can  be used as if they were perfectly synchronized real-time clocks in the  solution of a large class of problems that we formally characterize. For this  same class of problems, we also propose a broadcast primitive that can be  used as if it achieves common knowledge. Our clocks and broadcast primitive  are tools that considerably simplify the task of designing and proving  correct distributed algorithms: the designer can assume that processors have  access to real-time clocks and the ability to achieve common knowledge. The  latter can be used to implement the abstraction of shared memory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6631,(Almost) No Cost Clock Synchronization,"We show how synchronized clocks can be realized in a distributed system as a  byproduct of a common communication paradigm where processors periodically  perform broadcasts. Our approach decouples the precision concern-limiting how  much correct clocks can differ from each other-and the accuracy  concern-limiting how much any correct clock can differ from real time-of  clock synchronization. Given a system that guarantees only precision, we  develop a protocol whereby high accuracy can be achieved on demand. In this  manner, the ""lazy"" protocol we obtain incurs the cost of high accuracy only  when needed while keeping the basic synchronization procedure extremely  simple and cheap.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6632,A Fine-Grain Parallelizing Compiler,"Percolation Scheduling (PS) is a new technique for compiling programs into  parallel code. It attempts to overcome problems that limit the effectiveness  and applicability of currently available techniques. PS globally rearranges code past basic block boundaries. Its core is a small  set of simple, primitive program transformations defined in terms of adjacent  nodes in a program graph. These transformations constitute the lowest level  in a system of transformations and guidance rules. Higher levels of this  hierarchy control and enhance the applicability of the core transformations  and enable us to exploit both fine grained and coarse parallelism. Unlike other, more ad hoc approaches, PS is based on rigorous definitions of  the computational model and of the core transformations. The correctness and  termination of the transformations is proven here. The completeness of the  transformations is also discussed. As a result our system implementation can  proceed on a sound basis. In particular, PS enjoys greater adaptability and  independence between the levels than would be possible otherwise. This has  greatly facilitated the implementation of the first prototype version of our  compiler, which is now complete. This paper describes PS in detail. The correctness aspects as well as  illustrations of the effectiveness of our techniques are presented.  Architectures which may benefit from the use of PS are also discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6633,A Category Theoretic Analysis of Predicative Type Theory,ABSTRACT NOT AVAILABLE,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6634,On Ranking,"This paper structurally characterizes the complexity of ranking. A set is  P-rankable if there is a polynomial time computable function $f$ so that for  all $x, f(x)$ computes the number of elements of $A$ that are  lexicographically $\leq x$, i.e., the rank of $x$ with respect to $A$. We'll  say a class $C$ is P-rankable if all sets in $C$ are P-rankable. Our main  results show that with the same certainty with which we believe counting to  be complex, and thus with at least the certainty with which we believe  P $\neq$  NP, we may believe that P has no ranking functions of any type -  uniform, strong, weak, or approximate. We show that: P and NP are equally likely to be P-rankable. P is P-rankable if and only if $P = P^{#P}$. This extends important work of  Blum and Sipser [Sip85]. Even weak variations of P-ranking are hard if $P \neq P^{#P}$. PSPACE is P-rankable if and only if P = PSPACE. If P has small ranking circuits, then it has small ranking circuits of  relatively low complexity. If P has small ranking circuits then the power of counting falls into the  polynomial hierarchy (i.e., $P^{#P} \subseteq \(\sum_{2}^{p})\ = PH$). P/poly, the class of sets with small circuits is not P-rankable. P/poly has small ranking circuits if and only if $P^{#P}$/poly =  $P^{#P/poly}$ = P/poly. If P is rankable, then P/poly has small ranking circuits. This links the  ranking complexity of uniform and nonuniform classes. The ranks of some strings in easy sets are of high relative time-bounded  Kolmogorov complexity unless P = $P^{#P}$. It follows that even approximate  ranking is hard unless P = $P^{#P}$. This partially resolves a question posed  by Sipser [Sip85, pp. 447-448].",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6635,Can P and NP Manufacture Randomness?,"This paper studies how Kolmogorov complexity dictates the structure of  standard deterministic and nondeterministic classes. We completely  characterize, in Kolmogorov terms, when $P^{NP[\log]}= P^{NP}$, where [log]  indicates that $O(\log n)$ oracle calls are made. We give a Kolmogorov  characterization of P=NP that links the work of Adleman and Krentel. Briefly stated, complexity classes collapse unless they can manufacture  randomness.  A $\Delta^{p}_{2}$ machine is a P machine with an NP oracle. The series of  replies the NP oracle makes is called the pronouncement. We show that $P^{NP[\log]}= P^{NP}$ if and only if each $\Delta^{p}_{2}$ language is  accepted by some $\Delta^{p}_{2}$ machine with Kolmogorov simple  pronouncements. (i.e., $(\forall P_{i}) (\exists c) (\forall x) [Pronouncements_{P_{i}}$ SAT  $(x) \in K[c \log n, n^{c} | x]])$. Turning to functions, we show that: $P^{NP[\log]}F = P^{NP}F$ if and only if all $\Delta^{p}_{2}$ machines have  Kolmogorov simple pronouncements.  Since $P^{NP[\log]}F = P^{NP}F \Longleftrightarrow$ P=NP (Krentel), the above  gives an alternate Kolmogorov characterization of the P=NP question, which  complements Adleman's classic characterization. Our key technique is an oracle-based divide and conquer over a tree of  potential pronouncements. The results generalize to many other classes,  including truth-table classes and counting classes. Thus, Kolmogorov complexity dictates the structure of the classes that are at  the center of our understanding of feasible computation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6636,"One-Way Functions, Robustness, and the Non-Isomorphism of NP-Complete Sets","This paper  1. gives a relativized counterexample to the conjectured connection between  the existence of one-way functions and the existence of non-isomorphic  NP-complete sets. 2. establishes that in relativized worlds there are NP-complete sets that  are non-isomorphic in a strong sense. 3. proves that robust machines squander their powerful nondeterministic  oracle access in all relativizations. (1) resolves an open question. (2) extends our knowledge about non-isomorphic  NP-complete sets. (3) sharing the proof techniques of (1) and (2), enriches  the nascent theory of robustness and presents a consequence of the limited  combinatorial control of machines.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6637,A Block or Factorization Scheme for Loosely Coupled Systems of Array Processors,"A statically scheduled parallel block QR factorization procedure is  described. It is based on ""block"" Givens rotations and is modeled after the  Gentleman-Kung systolic QR procedure. Independent tasks are associated with  each block column. ""Tallest possible"" subproblems are always solved. The  method has been implemented on the IBM Kingston LCAP-1 system which consists  of ten FPS-164/MAX array processors that can communicate through a large  shared bulk memory. The implementation revealed much about the tradeoff  between block size and load balancing. Large blocks make load balancing more  difficult but give better 164/MAX performance and less shared memory traffic.  The results obtained indicate that our approach to parallelizing the QR  factorization is competitive for very large problems, e.g. of the order  5000-by-1000.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6638,Proving Properties of Parallel Programs: An Axiomatic Approach,"This paper presents an axiomatic technique for proving a number of properties  of parallel programs. Hoare has given a set of axioms for partial correctness  of parallel programs, but they are not strong enough in most cases. Here we  define a deductive system which is in some sense complete for partial  correctness. The information in a partial correctness proof is then used to  prove such properties as mutual exclusion, blocking and termination.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6639,"NC Algorithms for Comparability Graphs, Interval Graphs, and Unique Perfect Matchings","Laszlo Lovasz recently posed the following problem: ""Is there an NC  algorithm for testing if a given graph has a unique perfect matching?"" We  present such an algorithm for bipartite graphs. We also give NC algorithms  for obtaining a transitive orientation of a comparability graph, and an  interval representation of an interval graph. These enable us to obtain an NC  algorithm for finding a maximum matching in an incomparability graph.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6640,The State Machine Approach: A Tutorial,The state machine approach is a general method for achieving fault tolerance  and implementing decentralized control in distributed systems. This paper  reviews the approach and identifies abstractions needed for coordinating  ensembles of state machines. Implementations of these abstractions for two  different failure models -Byzantine and fail-stop-are discussed. The state  machine approach is illustrated by programming several examples. Optimization  and system reconfiguration techniques are explained.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6641,Representing Generic Solid Models by Constraints,"A generic solid is a representation of a class of similar solid objects. This  report introduces microCOSM, a constraint language for specifying generic  solids. MicroCOSM allows relationships between parts of an object to be  expressed as constraints between those parts. As a result, microCOSM can  express many more such relationships than current languages for building  generic solids. An editor for building and modifying two-dimensional generic  solids in microCOSM has been written. This report describes the microCOSM  language, the user interface, and implementation of the editor, and concludes  with a discussion of some improvements that should be made to the editor.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6643,A Parallel Graph Partitioning Algorithm for a Message-Passing Multiprocessor,"We develop a parallel algorithm for partitioning the vertices of a graph  into $p \geq 2$ sets in such a way that few edges connect vertices in  different sets. The algorithm is intended for a message-passing  multiprocessor system, such as the hypercube, and is based on the  Kernighan-Lin algorithm for finding small edge separators on a single  processor. We use this parallel partitioning algorithm to find orderings for  factoring large sparse symettric positive definite matrices. These orderings  not only reduce fill, but also result in good processor utilization and low  communication overhead during the factorization. We provide a complexity  analysis of the algorithm, as well as some numerical results from an Intel  hypercube and a hypercube simulator.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6644,Integration Constraints in Parametric Design of Physical Objects,"Design by constraint is a powerful approach to improve CAD systems and  designer productivity. This paper addresses the topic of incorporating  integration constraints concerning object mass and inertia in a CAD system. Two classes of generic objects are discussed that contain affine and  conformal images of a given solid, usually derived from the initial design  solution. Domain-derivatives are partial derivatives needed to solve the  existence problem of an object instance satisfying all constraints and,  eventually, to find an optimal design solution. In the paper, it is shown  that these derivatives are closely linked to the topology of the solid. They are symbolically expressable as integrals over domains having a lower  geometrical dimension than the original solid.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6645,Size-Time Complexity of Boolean Networks for Prefix Computations,"The prefix problem consists of computing all the products $x_{0}x_{1}\ldots  x_{j} (j=0,\ldots,N-1)$, given a sequence $X = (x_{0},x_{1},\ldots,x_{N-1})$   of elements in a semigroup. In this paper we completely characterize the  size-time complexity of computing prefixes with boolean networks, which are  synchronized interconnections of boolean gates and one-bit storage devices.  This complexity crucially depends upon a property of the underlying  semigroup, which we call cycle-freedom (no cycle of length greater than one  in the Cayley graph of the semigroup). Denoting by $S$ and $T$ size and  computation time, respectively, we have $S = \Theta((N/T) \log(N/T))$, for  non-cycle-free semigroups, and $S = \Theta((N/T)$, for cycle-free semigroups. In both cases, $T \in [\Omega(\logN),O(N)]$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6646,Low-level programming for a massively parallel fine-grain computer: the Microflow approach,"A new programming language $MFL^{3}$ is described, which, while low level,  combines both message passing and shared memory models. We examine both the  programming style and implementation issues of such a language. The programming style splits the computation into a computation thread (one  process per processor) and several server threads. The computation thread  (which performs the bulk of the computation) is deterministic, while all of  the non-deterministic code is in the server threads. Also described are several ways of making programming in message passing  languages less tedious and more modular, in terms of compilation techniques,  runtime structures and a new programming structure.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6647,Epochs,"To date, the implementation of message passing languages have required the  communications variables (sometimes called ports) either to be limited to the  number of physical communications registers in the machine, or to be mapped  to memory. Neither solution is satisfactory. Limiting the number of variables  decreases modularity and efficiency of parallel programs. Mapping variables  to memory increases the cost of communications and the granularity of  parallelism. We present here a new programming language construct called  epochs. Epochs are a scoping mechanism within which the programmer can declare  communications variables, which are live only during the scope of that epoch.  To limit the range of time a register has to be allocated for a  communications variable, the compiler ensures that all processors enter an  epoch simultaneously. The programming style engendered fits somewhere between  the SIMD data parallel and MIMD process spawning models. We describe an implementation for epochs including an efficient  synchronization mechanism, means of statically binding registers to  communications variables and a method of fusing epochs to reduce  synchronization overhead.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6648,A New Language - Independent Prettyprinting Algorithm,"An algorithm for prettyprinting using word wrapping is described that is  independent of the language being formatted and is substantially simpler than  other published algorithms. The algorithm makes use of a simple model with a  small set of primitives to direct the prettyprinting of text. For an input  string of length $n$, and an output device $m$ characters wide the algorithm  runs in $O(n)$ time and requires $O(m)$ space. The algorithm can be restarted  from an intermediate point and is therefore well suited for incremental  prettyprinting of text. This algorithm is now being used in the Cornell  Synthesizer Generator [2]. The algorithm is compared with and contrasted to  the previously published algorithm by Oppen [1].",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6649,Dense Patch-oriented Matrix Factorization on a Hypercube Multiprocessor,"We develop algorithms for Cholesky factorization and the solution of  triangular systems of linear equations on a hypercube multiprocessor. Specifically, we describe algorithms that apply when the matrix is  distributed around the hypercube by submatrices, or patches. We show that  these algorithms use asymptomatically less internode communication than more  common row- and column- oriented algorithms. Empirical results accompany the  analysis and show that patch-oriented algorithms are competitive with, but  not demonstrably superior to, the other algorithms for hypercubes of low  dimension. Implementations in C appear in an appendix.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6650,I-Structures: Data Structures for Parallel Computing,"It is difficult simulteneously to achieve elegance, efficiency and  parallelism in functional programs that manipulate large data structures. We demonstrate this through careful analysis of program examples using three  common functional data-structuring approaches - lists using Cons and arrays  using Update (both fine-grained operators), and arrays using make-array (a  ""bulk"" operator). We then present I-structures as an alternative, defining  precisely the parallel operational semantics of Id, a language with  I-structures. We show elegant, efficient and parallel solutions for the  program examples in Id. I-structures make the language non-functional, but do  not raise determinancy issues. Finally, we show that even in the context of  purely functional languages, I-structures are invaluable for implementing  functional data abstractions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6651,Exploiting Virtual Synchrony in Distributed Systems,"We describe applications of a new software abstraction called the virtually  synchronous process group. Such a group consists of a set of processes that  cooperate to implement some distributed behavior in an environment where  events like broadcasts to the group as an entity, process failures, and  process recoveries appear to occur synchronously. The utility of this  approach is illustrated by solving a number of classical problems using our  methods. Many are problems that are quite difficult in the absence of some  sort of support, and all are easily solved in the context of the mechanisms  we propose here. We then describe a new version of the ISIS system, which is  based on this abstraction. $ISIS_{2}$ provides a number of high level  mechanisms that facilitate the use of process groups in application software  design, including addressing support for atomic communication with the  members of a single or several groups (even when their membership is  changing), group RPC constructs, a package of distributed programming tools,  a fault-tolerant asynchronous bulletin board mechanism, and resilient objects.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6652,A New Method for Solving Triangular Systems on Distributed Memory Message-Passing Multiprocessors,"Efficient triangular solvers for use on message passing multiprocessors are  required, in several contexts, under the assumption that the matrix is  distributed by columns (or rows) in a wrap fashion. In this paper we describe  a new efficient parallel triangular solver for this problem. This new  algorithm is based on the previous method of Li and Coleman [1986] but is  considerably more efficient when $\frac{n}{p}$ is relatively modest, where  $p$ is the number of processors and $n$ is the problem dimension. A useful  theoretical analysis is provided as well as extensive numerical results  obtained on an Intel iPSC with $p \leq 128$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6653,"A Graphical, Language-Based Editor for Generic Solid Models Represented by Constraints.","A solid model is a representation of the space occupied by a rigid object. A generic solid (or ""generic"") expresses the solid models for a class of  similar objects, or equivalently, a non-rigid object. Automated manufacturing  systems require solid models of the objects with which they work. For  example, solid models are needed to discover collision-free paths for robot  arms. Previously, generics have been created using clumsy textual languages, and  solid models have usually been created using graphical editors. This thesis describes a technique for editing generics graphically, thus  decreasing the labor required to create both generics and solid models. This thesis introduces microCOSM, a language for specifying solid models and  generics in which a solid or generic is represented by its parts along with  constraints that the parts must satisfy. Relationships between parts of an  object are expressed as constraints between those parts. As a result,  microCOSM can express more such relationships than current generic solid  languages. A graphical editor for two-dimensional generics in microCOSM has  been written. The microCOSM language and the user interface and  implementation of the editor are described, and some improvements that should  be made to the editor are discussed. The microCOSM editor, like any constraint-based editor, must have a  constraint solver, a module that forces any object displayed by the editor to  satisfy its constraints. This thesis shows why the usual techniques for  solving constraints do not work well with microCOSM and show that the  constraints in microCOSM are best solved as a related minimization problem. The minimization problem is chosen to achieve a harmonious compromise between  the numerical complexity of the problem and the principle of least  astonishment. Most bugs in microCOSM generic definitions involve having too many or too few  constraints on some part of the solid. Algorithms are presented that detect  under and overconstraint, under some reasonable assumptions about the  constraints. These algorithms are dynamic; it is possible to determine if a  modification induces an error without rerunning the entire computation. Error messages can be updated interactively, easing identification of the  erroneous constraints.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6654,Optimal Trie Compaction is NP-Complete,NOT AVAILABLE,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6655,"A Counter-example for ""A Simpler Construction for Showing the Intrinsically Exponential Complexity of the Circularity Problem for Attribute Grammars""","Jazayeri proposes a simpler construction for use in the proof by Jazayeri,  Ogden, and Rounds that the circularity problem for attribute grammars has  inherent exponential complexity. The simplification introduces a flaw that  invalidates the proof. Correcting the flaw leaves the new construction only  slightly simpler than the old.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6656,Merging and Sorting Networks with the Topology of the Omega Network,"We consider a class of comparator networks obtained from the omega  permutation network by replacing each switch with a comparator exchanger of  arbitrary direction. These networks are all isomorphic to each other, have  merging capabilities, and can be used as building blocks of sorting networks  in ways different from the standard merge-sort scheme. It is shown that the  bitonic merger and the balanced merger are members of the class. These two  networks were not previously known to be isomorphic.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6657,Some Observations About NP Complete Sets,In this paper we summarize and extend some recent results about the  properties of NP complete sets and related results about the structure of  feasible computations.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6658,Definability with Bounded Number of Bound Variables,"A theory satisfies the $k$-variable-property if every first-order formula is  equivalent to a formula with at most $k$ bound variables (possibly reused).  Gabbay has shown that a fixed time structure satisfies the $k$-variable  property for some $k$ if and only if there exists a finite basis for the  temporal connectives over that structure. We give a model-theoretic method  for establishing the $k$-variable property, involving a restricted  Ehrenfeucht-Fraisse game in which each player has only $k$ pebbles. We use  the method to unify and simplify results in the literature for linear orders.  We also establish new $k$-variable properties for various theories of  bounded-degree trees, and in each case obtain tight upper and lower bounds on  $k$. This gives the first finite basis theorems for branching-time models.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6659,Proving Boolean Combinations of Deterministic Properties,"This paper gives a method for providing that a program satisfies a temporal  property that has been specified in terms of Buchi automata. The method  permits extraction of proof obligations for a property formulated as the  Boolean combination of properties, each of which is specified by a  deterministic Buchi automaton, directly from the indiviudal automata. The  proof obligations can be formulated as Hoare triples. The method is proved  sound and relatively complete. A simple example illustrates application of  the method.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6660,The Computational Behaviour of Girard's Paradox,"In their paper ""Type"" Is Not a Type, Meyer and Reinhold argued that serious  pathologies can result when a type of all types is added to a programing  language with dependent types. Central to their argument is the claim that by  following the proof of Girard's paradox it is possible to construct in their  calculus $\lambda^{\tau \tau}$ a term having a fixed-point property. Because  of the tremendous amount of formal detail involved, they were unable to  establish this claim. We have made use of the Nuprl proof development system  in constructing a formal proof of Girard's paradox and analysing the  resulting term. We can show that the term does not have the desired  fixed-point property, but does have a weaker form of it that is sufficient to  establish some of the results of Meyer and Reinhold. We believe that the  method used here is in itself of some interest, representing a new kind of  application of a computer to a problem in symbolic logic.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6661,Loop Quantization: an Analysis and Algorithm,"Loop unwinding is a well-known technique for reducing loop overhead, exposing  parallelism, and increasing the efficiency of pipelining. Traditional loop  unwinding is limited to the innermost loop of a set of nested loops and the  amount of unwinding is either fixed or must be specified by the user. In this  paper we present a general technique, loop quantization, for unwinding  multiple nested loops, explain its advantages over other transformations, and  illustrate its practical effectiveness. An abstraction of nested loops is  presented which leads to results about the complexity of computing  quantizations and an algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6662,Partial Objects in Constructive Type Theory,"Constructive type theories generally treat only total functions; partial  functions present serious difficulties. In this paper, a theory of partial  objects is given which puts partial functions in a general context. Semantic  foundations for the theory are given in terms of a theory of inductive  relations. The domain of convergence of a partial function is exactly  characterized by a predicate within the theory, allowing for abstract  reasoning about termination. Induction principles are given for reasoning  about these functions, and comparisons are made to the domain theoretic  account of LCF. Finally, an undecidability result is presented to suggest  connections to a subset of recursive function theory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6663,Effects of Message Loss on Distributed Termination,"We study the problem of termination in distributed systems with faulty  communication channels. We show that for asynchronous systems, protocols that  guarantee knowledge gain via message transfers cannot be guaranteed to  terminate even if we assume that only transient communication failures can  occur, and want to achieve only a weak kind of termination. The same result  holds for synchronous systems as well.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6664,Load Balanced FFT Implementations on the Intel iPSC,"Two implementations of both the Cooley-Tukey and Gentelman-Sande radix-two  FFT algorithms are described where the distribution of computational work  among the processors is balanced, i.e. every processor does the same number  of complex multiplications and additions. One method requires no extra  storage space for the buffering of the complex data that is to be exchanged  between processors therefore allowing ""in-place"" computation. The second  implementation is useful for doing FFT's of symmetric sequences and an  example of its use in the sine transform is presented. We also show how to  simulate the second implementation in terms of the first to gain ""in-place""  computation without the need for buffering and intra-processor swapping.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6665,A Sine Transform Algorithm for the Hypercube,"A new sine transform algorithm is presented where the pre-and post-processing  steps are amenable to implementation on the hypercube parallel computer. Interprocessor communication is minimized at the expense of some redundant  computations resulting in an algorithm with almost linear speedup against the  conventional sequential algorithm. The transforms for both naturally ordered  input and bit-reversed input can be processed, thereby avoiding the  communication overhead needed to either run an autosort algorithm or to  unscramble the results by performing a bit-reversed permutation about $O(d)$  parallel transmissions on hypercubes of dimension $d$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6666,Polynomial Decomposition Algorithms For Multivariate Polynomials,ABSTRACT NOT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6667,Historical Note: The Past Thirty Years in Information Retrieval,"The documentation literature of the nineteen fifties is reviewed briefly, and  some early text processing endeavors are discussed. Various predictions made  in 1960 by Mooers about the creative role of computers in information  retrieval are then considered, and an attempt is made to explain why some of  the more exciting predictions have not been fulfilled. Conclusions are drawn  concerning the limits of computer power in text retrieval applications.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6668,Parallel Text Search Methods,"An evaluation of recently proposed parallel text search methods does not  support the notion that the parallel methods provide large-scale gains in  either retrieval effectiveness or efficiency, compared with alternative  available search strategies using serial processing machines.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6669,Adaptive Locking,Adaptive locking is a new concurrency control scheme for relational database  systems. An adaptive locking scheduler automatically issues to each  transaction appropriate locks on its read and write sets. The read and write  sets of transactions are exactly the parts of the shared database that it is  necessary and sufficient to lock in order to prevent all state and view  inconsistencies. This paper shows how to compute logical expressions  representing the read and write sets of access statements and describes an  efficient algorithm to check whether the locks issued to different  transactions cause them to conflict. The algorithm is based on extended  tableaux capable of representing all conjunctive queries. The paper discusses  how to use adaptive locking with complex queries and compares the new scheme to conventional locking. A prototype database system demonstrating how an  adaptive locking scheduler reasons about conflict is presented.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6670,On the Operationality/Generality Trade-Off in Explanation-Based Learning,"In this paper we examine the operationality/generality trade-off and how it  affects performance of explanation-based learning systems. Experience with  the ARMS learning apprentice system, presented in the form of an empirical  performance analysis, illustrates both sides of the trade-off.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6671,Efficient Concatenable Ordered Lists,"A new approach for providing an efficient implementation of concatenable  ordered lists is discussed. The structures described have an equivalence to  search trees. In balanced search trees the tree is continually modified to  maintain certain balance properties; with our structure the tree is  guaranteed to be structured randomly and with very high probability is relatively balanced. We thus avoid the overhead associated with explicitly  maintaining the balance. Because of this property, the structures described  are referred to as guaranteed-random trees.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6672,A Non-Type-Theoretic Definition of Martin-Lof's Types,"It is possible to make a natural non-type-theoretic reinterpretation of  Martin-Lof's type theory. This paper presents an inductive definition of the  types explicitly defined in Martin-Lof's paper, Constructive Mathematics and  Computer Programming. The definition is set-theoretically valid, and probably  will be convincing to intuitionists as well. When this definition is used  with methods set out in the author's thesis, the inference rules presented in Martin-Lof's paper can be shown to be valid under the non-type-theoretic  interpretation. This interpretation is non-trivial, that is, there are both  inhabited types and empty types, and so, validity entails simple consistency.  Finally, Michael Beeson has defined some recursive realizability models which  we shall compare with the term model presented here, and we shall compare the  methods of definition.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6673,Trace-Based Network Proof Systems: Expressiveness and Completeness,"Most trace-based proof systems for networks of processes are known to be  incomplete. Extensions to achieve completeness are generally complicated and  cumbersome. In this thesis, we isolate the componenets of a trace-based  network proof system that are necessary and sufficient to achieve relative  completeness.  We then consider the expressiveness required of any trace  logic that encodes these componenets.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6674,The Complexity of Optimization Problems,"We study computational complexity theory and define a class of optimization  problems called OptP (Optimization Polynomial Time), and we show that  TRAVELLING SALESPERSON, KNAPSACK and 0-1 INTEGER LINEAR PROGRAMMING are  complete for OptP. OptP is a natural generalization of NP (Nondeterministic  Polynomial Time), but while NP only considers problems at the level of their  yes/no question, the value of an OptP function is the optimal value of the  problem. This approach enables us to show a deeper level of structure in  these problems than is possible in NP.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6675,ALEX - an Alexical Programming Language,"ALEX is an experimental language for high-level parallel programming. It is a  testbed for exploring various non-traditional ways of expressing algorithmic  ideas, making extensive use of high-resolution color graphics. The language  itself is not a programming language in the traditional sense, since there is  no lexical syntax. This paper discusses the basic design of the ALEX user  interface.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6676,Incremental Graph Evaluation,"There are many computer applications that can be made incremental. After a  small perturbation to the computation at hand, intermediate values of a  previous evaluation can be used to obtain the result of the new computation.  This requires less time than reevaluating the entire computation.  We propose the use of a directed graph to represent computations that we wish  to make incremental. This graph, called a dependency graph, represents an  intermediate computation at each vertex. Edges between vertices represent the  dependence of intermediate computations on other intermediate computations.  A change to the computation can be represented as a change in the dependency  graph.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6677,Type-Theoretic Models of Concurrency,"Sequential computation has well-understood correctness criteria and proof  techniques for verifying programs, but the novelty and complexity of  concurrent computation complicates a similar analysis of concurrenct  programs. This thesis examines the use of a system for developing formal  mathematics, the Nuprl proof development system, as a tool for reasoning  about concurrency and ameliorating somewhat the complex chore of analyzing  concurrent programs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6678,Attribute Grammars in Constraint-based Graphics Systems,"A constraint-based graphics system provides a flexible, intuitive framework  for describing relationships among graphical objects in applications such as  document preparation, font design, and solid modelling. This paper describes  two constraint-based graphics systems, micro-COSM and the IDEAL Synthesizer,  and their implementation in terms of attribute grammars. The implementation  of these two systems is noteworthy since they represent the first interactive  constraint-based graphics systems that are implemented using attribute  grammars. Our experiences with attribute grammars suggest that they provide a  powerful framework for representing constraints and extracting important  semantic information such as the equations to be solved by the constraint  solver. We discuss the advantages of using attribute grammars in  constraint-based graphics and from our experiences make several observations  about the way attribute grammars should be used.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6679,Structural Complexity Column for the Bulletin of the European Association for Theoretical Computer Science,Abstract not Available,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6680,Counting in Structural Complexity Theory,"Structural complexity theory is the study of the form and meaning of  computational complexity classes. Complexity classes - P, NP, Probabilistic  P, PSPACE, etc. - are formalizations of computational powers - deterministic,  nondeterministic, probabilistic, etc. By examining the structure of and the  relationships between these classes, we seek to understand the relative  strengths of their underlying computational paradigms. This thesis studies counting in structural complexity theory. We are  interested in complexity classes defined by counting and in the use of  counting to explore the structure of these and other classes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6681,The Sorting of Points Along an Algebraic Curve,"The area of geometric modeling is concerned with the creation of  computationally efficient models of solid physical objects to facilitate  their design, assembly, and analysis. In a geometric modeling system, a solid such as a robot hand or a coffee cup is modeled by a collection of points,  curves, and surfaces. The sorting of points along an algebraic curve is an  operation that arises frequently during the creation and manipulation of  geometric models. This thesis presents a thorough investigation of sorting,  including an evaluation of the two conventional methods of sorting and the  presentation of a new and superior method.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6682,Is One NP Question as Powerful as Two?,"For any integer $k$, $P^{SAT[k]}$ is the class of languages accepted by  deterministic polynomial time oracle machines that make at most $k$ queries  to an oracle for SAT. It is easy to see that $P^{SAT[1]} \subseteq D^{P}  \subseteq P^{SAT[2]}$. We use a technique called oracle replacement to show  that if $D^{P}$ = co-$D^{P}$, then there is a sparse set $S$ such that  $\overline{SAT} \in NP^{S}$ , there exist ""small"" NP machines that  recognize initial segments of $\overline{SAT}$, and the polynomial time  hierarchy (PH) is contained in $\Delta^{3}_{P}$. Thus for deterministic  polynomial time oracle machines, if one NP question is as powerful as two,  then the PH collapses to $\Delta^{3}_{P}$. As another application of oracle  replacement, we show that if there exists a sparse set $S \in NP^{SAT}$ such  that $\overline{SAT} \in NP^{S}$, then $PH \subseteq \Delta^{3}_{P}$. We also  discuss how oracle replacement is a unifying principle for many of the  results concerning sparse oracles for NP.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6683,The Polynomial Time Hierarchy Collapses if the Boolean Hierarchy Collapses,"The structure of the Boolean hierarchy (BH) is related to the polynomial time  hierarchy (PH) by showing that if the BH collapses, then $PH \subseteq   \Delta^{P}_{3}$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6684,On Teaching Left-Handed Children to Write,"It is argued that the handwriting method commonly taught to left-handed  children is incorrect and harmful. The disadvantages of this method are  noted, and a new method alleviating these disadvantages is proposed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6685,Colormap: A Color Image Quantizer,"This paper is a preliminary report on color image quantization and the  background, design and implementation of the colormap program. The purpose of  colormap is to quantize 24-bit per pixel color images down to only 8 or 9  bits per pixel with minimal perceived image degradation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6686,An Environment for Formal Systems,"This report describes the Environment for Formal Systems, EFS, that allows a  user to interactively define the syntax and inference rules of a formal  system and to construct proofs in the defined system. The EFS supports two  AUTOMATH-like formalisms for encoding logics: the Edinburgh Logical Framework  and the Calculus of Constructions. Facilities are provided for the definition  of notational abbreviations and the construction of goal-directed proofs. New  goal-directed rules can be interactively defined and checked for validity.  The EFS was implemented with the Cornell Synthesizer Generator.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6687,Computing a Trust Region Step for a Penalty Function,"We consider the problem of minimizing a quadratic function subject to an  ellipsoidal constraint when the matrix involved is the Hessian of a quadratic  penalty function (i.e., a function of the form $p(x) = f(x) + \frac{1}{2\mu}  c(x)^{T} c(x))$. Most applications of penalty functions require $p(x)$ to be  minimized for values of $\mu$ decreasing to zero. In general, as $\mu$ tends  to zero the nature of finite precision arithmetic causes a considerable loss  of information about the null space of the constraint gradients when  $\nabla^{2}p(x)$ is formed. This loss of information renders ordinary trust  region Newton's methods unstable and degrades the accuracy of the solution to  the trust region problem. The algorithm of More and Sorenson [1983] is  modified so as to be more stable and less sensitive to the nature of finite  precision arithmetic in this situation. Numerical experiments clearly  demonstrate the stability of the proposed algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6688,Verifying Temporal Properties without using Temporal Logic,"An approach to proving temporal properties of concurrent programs that does  not use temporal logic as an inference system is presented. The approach is  based on using Buchi automata to specify properties. To show that a program  satisfies a given property, proof obligations are derived from the Buchi  automaton for that property. These obligations are discharged by devising  suitable invariant assertions and variant functions for the program. The  approach is shown to be sound and relatively complete. A mutual exclusion  protocol illustrates its application.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6689,ISIS DOCUMENTATION: RELEASE 1,ABSTRACT NOT AVAILABLE,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6690,Comparison of Two-Dimensional FFT Methods on the Hypercube : The Choice Between Strips and Patches,"Complex two-dimensional FFT's up to size 256 X 256 points were implemented on  the Intel iPSC/System 286 hypercube with emphasis on comparing the effects of  data mapping, data transposition, and distributed FFT's. Comparison is based on partitioning the data into either strips or patches and three distinct  methods are discussed. Of the two strips methods, the Transpose-Split  implementation involves local independent FFT computations in both directions  with an intervening transpose, while the Local-Distributed method performs  local FFT's in one direction followed by distributed FFT's in the other. The  patch or Block method partitions the matrix in submatrices and maps the  ($i,j$)th block into node $i \hat j$ ($\hat$ denoting concatenation of binary  numbers). Both the row-wise FFT's and the column-wise FFT's require  inter-node communication for the distributed butterfly computations. Timing  results show that on the Intel iPSC/System 286, there is hardly a difference  between the three methods. This is due primarily to the inadequacies of Intel  communication handling and its inability to overlap communication and  computation as well as a lack of vector boards. A model follows where several  important factors such as vectorization and communication complexity are  considered. While timing results show that on a vectorized hypercube with  ideal synchronization of communication and computation the Block method is  asymptomatically the fastest. The conclusion is that this problem is highly  system dependent and therefore no sweeping recommendations can be made.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6691,Functional Decomposition of Polynomials,ABSTRACT NOT AVAILABLE,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6692,On Parity and Near-Testability: $P^{A} \neq NT^{A}$ With Probability 1,"The class of near-testable sets, NT, was defined by Goldsmith, Joseph, and  Young. They noted that $P \subseteq NT \subseteq PSPACE$, and asked whether P=NT. This note shows that NT shares the same $m$-degree as the  parity-based complexity class $\bigoplus P$ (i.e., $NT\equiv^{p}_{m}  \oplus P$) and uses this to prove that relative to a random oracle $A,  P^{A} \neq NT^{A}$ with probability one. Indeed, with probability one,  $NT^{A} - (NP^{A} \bigcup coNP^{A}) \neq 0$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6693,A Paradigm for Concurrency Control Protocols for Distributed Databases,"In this thesis, we present a paradigm for concurrency control protocols for  distributed replicated databases. This paradigm presents a framework for both  developing and analyzing concurrency control protocols, especially those that  are designed to handle partitioning failures. Any concurrency control  protocol that is an instance of the paradigm must be correct. We show that  several known protocols are instances of this paradigm. Consequently, these  seemingly unrelated protocols can now be compared and their understanding is  simplified. We also present two new concurrency control protocols: the  virtual partitions protocol and the accessibility thresholds protocol. Both  protocols allow the reading and writing of data in spite of site and  communication failures, even when these failures lead to network  partitioning. In neither protocol is it ever necessary for a read operation  to physically access more than one copy, which makes these protocols  desirable for applications where efficient read operations are necessary. The  accessibility thresholds protocol provides the database designer with much  flexibility in trading off the cost of executing operations and the  availability of data objects. Unlike previous protocols, the cost of executing operations on an object is  separated from the read and write availability of that object.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6694,Partial Implementations in Program Derivation,"A partial implementation of an abstract notation provides an implementation  for some of the notations operations on some of the values in the notation. A  collection of partial implementations of a fixed notation -differing in the  selection of values and operations implemented- caters to different patterns  of usage of the notation in individual programs. Partial implementations of a  general mathematical notation are more appropriate to the formal development of programs than the more familiar paradigm of abstract data types with  complete implementations. Furthermore, partial implementations provide the  only realistic account of the implementation of finite machinery of many  familiar mathematical notations. From a practical point of view, partial  implementations of a fixed notation exhibit great reusability and provide a convenient approach to early prototyping in program development. The incorporation of mathematical notations into a programming system is  studied, with particular regard to the formal development of programs in the  style of Dijkstra and Gries. A new notion of encapsulation is presented to  define partial implementations and a predicate-transformer characterization  of implementation correctness is defined. The implementation correctness  criterion simplifies and extends the original data-type implementation  criterion of Hoare, generalizes implementation criterion for algebraic  abstract data types, and accommodates the implementation of non-deterministic  operations. Different variables of the same type may have different  representations and implementations of operations within the same program.  Not all implementations are adequate in a given program, so syntactic and  semantic conditions are given to ensure that a proposed implementation of a  variable is adequate.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6695,Symmetry in Distributed Systems,"A distributed computing system can be considered to be symmetric because of  its topology or because of its behavior. Unfortunately, these different  definitions can categorize the same system differently. The choice of  definition becomes important when one is trying to prove that certain  problems, such as the Dining Philosophers problem, cannot be solved on  symmetric distributed computing systems. Since the behavioral definitions are  based on the possible patterns of computation, it is much easier to use them  for these proofs. However, behavioral definitions admit straightforward  decision procedures. This thesis presents a new definition for symmetry, called similarity, that,  while based on behavior of processes, is decidable given the initial  configuration of the system. The decision procedure for similarity depends  partly on the model of computation being used, but a way to discover these  decision procedures is given and is used to find decision procedures for a  wide range of models of distributed computation. Distributed versions of  these decision procedures form the basis of solutions to the problem of  selecting a process as the leader. The thesis also shows how to use  similarity to compare the relative power of different models of computation,  including models with shared variables with and without locking, models using  synchronous and asynchronous message-passing, models making different  assumptions about fairness, and models based on probabilistic techniques.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6696,Sparse Cholesky Factorization on a Multiprocessor,"Systems of linear equations of the form $Ax = b,$ where $A$ is a large sparse  symmetric positive definite matrix, arise frequently in science and  engineering. The sequential computation of the solution vector $x$ is well  understood and many algorithms for this problem employ the following steps. First, try to reorder the rows and columns of $A$ so that its Cholesky factor  $L$ is sparse. Next, determine the structure of $L$ by symbolically factoring  $A$ and allocate storage for $L$. Finally, numerically factor $A$ and then  compute $x$ by solving the triangular systems $Ly=b$ and $L^{T}x=y$. In this thesis, we present parallel algorithms for the different steps of  this computation. We design our algorithms for message-passing multiprocessors. The algorithms limit communication overhead and can solve problems that are  too large to reside in the memory of any single processor. We provide  numerical results based upon an implementation on an Intel hypercube. We begin by presenting a parallel column-oriented sparse numeric Cholesky  factorization algorithm. Then, viewing $A$ as a graph, we develop a parallel  graph partitioning algorithm that we use to order the columns of $A$ and  partition them among the processors. In addition to producing a sparse $L$, the resulting ordering and partitioning allows for parallelism and reduces  communication overhead during the remaining phases of the computation. The  parallel graph partitioning algorithm is based on the sequential  Kernighan-Lin algorithm for finding small edge separators. Since the computation of a particular column of $L$ may depend on columns stored on several processors, the processors cannot operate independently.  The elimination forest of $A$ captures these dependencies and allows for  efficient numeric factorization. We provide a parallel algorithm for  computing the forest and prove its correctness. We also develop a parallel  row-oriented symbolic factorization algorithm that uses the elimination forest. Finally, we describe fast parallel forward and backward triangular solve algorithms. These algorithms solve for the components of $x$ requiring  information from other processors by using a variant of Li and Coleman's  dense triangular solve algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6697,Maintaining Availability in Partitioned Replicated Databases,"In a replicated database, a data item may have copies residing on several  sites. A replica control protocol is necessary to ensure that data items with several copies behave as if they consist of a single copy, as far as users  can tell. We describe a new replica control protocol that allows the  accessing of data in spite of site failures and network partitioning. This  protocol provides the database designer with a large degree of flexibility in  deciding the degree of data availability, as well as the cost of accessing  data.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6698,Techniques for Simplifying the Programming of Distributed Systems,"It is difficult to design and verify distributed programs that execute  correctly despite transient processor failures, or despite variable and  unpredictable processor speeds and message transmission times. In this  thesis, we describe a checkpointing/rollback mechanism that allows  programmers to write distributed programs with the simplifying assumption that processors do not fail, and then run these programs correctly on systems with  transient processor failures. We also describe a translation mechanism that  can be used to write programs with the simplifying assumptions that  processors execute in synchronized steps and messages take exactly one step  to arrive, and then run these programs correctly on systems that violate  these assumptions. Both mechanisms are transparent to the programmer, and  they can be applied to solve a large class of problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6699,Understanding Protocols for Byzantine Clock Synchronization,"All published fault-tolerant clock synchronization protocols are shown to result from refining a single paradigm. This allows the different clock  synchronization protocols to be compared and permits presentation of a single  correctness analysis that holds for all. The paradigm is based on a reliable  time source that periodically causes events; detection of such an event  causes a processor to reset its clock. In a distributed system, the reliable  time source can be approximated by combining the values of processor clocks  using a generalization of a ""fault-tolerant average"", called a convergence  function. The performance of a clock synchronization protocol based on our  paradigm can be quantified in terms of the two parameters that characterize  the behavior of the convergence function used: accuracy and precision.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6700,"NC Algorithms for Computing the Number of Perfect Matchings in $K_{3,3}$-free Graphs and Related Problems","We show that the problem of computing the number of perfect matchings in  $K_{3,3}$-free graphs is in $NC$. This stands in striking contrast with the  #P-completeness of counting the number of perfect matchings in arbitrary  graphs. As corollaries we obtain $NC$ algorithms for checking if a given  $K_{3,3}$-free graph has a perfect matching and if it has an EXACT MATCHING.  Our result also opens up the possibility of obtaining an $NC$ algorithm for  finding a perfect matching in $K_{3,3}$-free graphs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6701,The Collapsing Hierarchies,No Abstract Available,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6702,A Unitary Method for the ESPRIT Direction-of-Arrival Estimation Algorithm,ESPRIT is an interesting new method for solving the Direction-of-Arrival  estimation problem. It involves some rather tricky matrix manipulations. We  show how these calculations can be carried out using only unitary  transformations of the data. No inverses or cross-products are required  making the new method extremely robust.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6703,Matrix Computations and Signal Processing,"The interactions between the signal processing and matrix computation areas  is explored by examining some subspace dimension estimation problems that  arise in a pair of direction-of-arrival algorithms: MUSIC and ESPRIT. We show  that the intelligent handling of these numerical problems requires a  successful intermingling of perturbation theory, sensible problem  formulation, and reliance upon unitary matrix methods.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6704,A Storage Efficient WY Representation for Products of Householder Transformations,"A product $Q = P_{1} \cdots P_{r}$ of m-by-m Householder matrices can be  written in the form $Q = I + WY^{T}$ where W and Y are each m-by-r. This is  called the WY representation of Q. It is of interest when implementing  Householder techniques in high-performance computing environments that  ""like"" matrix-matrix multiplication. In this note we describe a storage  efficient way to implement the WY representation. In particular, we show how  the matrix Q can be expressed in the form $Q = I + YTY^{T}$ where  $Y \epsilon R^{mxr}$ and $T \epsilon R^{rxr}$ with T upper triangular. Usually r less than less than m and so this ""compact"" WY representation requires less storage. When compared with the recent block-reflector strategy proposed by Schreiber  and Parlett the new technique still has a storage advantage and involves a  comparable amount of work.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6705,"Complete, Trace-based, Network Proof Systems: An Advisor's Perspective",NO ABSTRACT AVAILABLE,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6706,A Non-Type-Theoretic Semantics For Type-Theoretic Language,"Since 1970 several methods have been proposed for using formal systems of  constructive logic as programming languages. One prominent approach is based  upon systems of computationally significant terms which either bear or are  assigned types; these systems are essentially lambda calculi or combinatory  logics in which either the terms are explicitly typed or else types are  assigned to untyped terms in the manner of Curry. This thesis concerns two  such systems, namely, Martin-Lof's intuitionistic type theory of 1979, and a  variation of that theory upon which Nuprl is based. Nuprl is a system  implemented at Cornell for developing functional programs and constructive  proofs. The expressive machinery of these theories can be given a rather natural  non-type-theoretic semantics that is not inherently constructive and yet  closely follows the semantical explanation of type theory. The principal  content of this thesis is a careful development of such a semantic reinterpretation with the intention of making the bulk of type-theoretic practice, of the kind arising from the use of Nuprl and formalizations of  Martin-Lof's theory, independent of its original type-theoretic and  constructive basis. The reinterpretation opens the type-theoretic methodology  of programming to nonconstructivists and others who may not subscribe to the  intuitionistic theory of types, preserving the features of type-theoretic  language that make it a suitable language for programming. Moreover, the  natural structural similarity between the type-theoretic concepts and their  reinterpretations yields an analytic tool which may serve type-theorists  as well. The body of this thesis has two phases. In the first, the semantic concepts  of Martin-Lof's theory, including expressions, types, judgements of  functionality, and universes, are reinterpreted. This phase culminates in a  non-type-theoretic definition of the types explicitly defined in Martin-Lof's  paper of 1979. The remainder of the thesis treats various topics of semantic  significance, including the representation of propositions as types, the  anticipation of new terms and types, certain ""type-free"" forms of inference, and a sort of ""universe polymorphism."" Finally, we shall reinterpret the  semantics of Nuprl's judgements of functionality which differs radically from that of Martin-Lof's judgements in the use of assumptions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6707,Expressiveness Bounds for Completeness in Trace-Based Network Proof Systems,"Network proof systems based on first-order specifications over channel traces are incomplete unless reasoning over the interleaving of communication events is permitted. Relatively complete trace-based proof systems using temporal logic have been described, but full temporal logic is more powerful than necessary. Using the interleaving approach, we isolate the expressiveness required of a relatively complete trace logic.  A hierarchy of temporal logic subsets is then defined; a certain subset is shown to have necessary and sufficient expressive power for relative completeness.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6708,Experiments in Automatic Phrase Indexing For Document Retrieval:A Comparison of Syntactic and Non-Syntactic Methods,"In order for an automatic information retrieval system to effectively  retrieve documents related to a given subject area, the content of each  document in the system's database must be represented accurately. This study  examines the hypothesis that better representations of document content can  be constructed if the content analysis method takes into consideration the  syntactic structure of document and query texts. Two methods of automatically  generating phrases for use as content indicators have been implemented and  tested experimentally. The non-syntactic (or statistical) method is based on  simple text characteristics such as word frequency and the proximity of words  in text. The syntactic method uses augmented phrase structure rules  (production rules) to selectively extract phrases from parse trees generated  by an automatic syntactic analyzer. Experimental results show that the effect of non-syntactic phrase indexing is  inconsistent. For the five collections tested, increases in average precision  ranged from 22.7% to 2.2% over simple, single term indexing. The syntactic  phrase indexing method was tested on two collections. Precision figures  averaged over all test queries indicate that non-syntactic phrase indexing  performs significantly better than syntactic phrase indexing for one  collection, but that the difference is insignificant for the other  collection. More detailed analysis of individual queries, however, indicates   that the performance of both methods is highly variable, and that there is  evidence that syntax-based indexing has certain benefits not available with the non-syntactic approach. Possible improvements of both methods of phrase indexing are considered. It  is concluded that the prospects for improving the syntax-based approach to  document indexing are better than for the non-syntactic approach. The PLNLP system was used for syntactic analysis of document and query texts,  and for implementing the syntax-based phrase construction rules. The SMART  information retrieval system was used for retrieval experimentation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6709,Computing the Singular Value Decomposition on a Distributed System of Vector Processors,"Jacobi methods for computing the singular value decomposition (SVD) of a  matrix are ideally suited for multiprocessor environments due to their  inherent parallelism. In this paper we show how a block version of the  two-sided Jacobi method can be used to compute the SVD efficiently on a  distributed architecture. We compare two variants of this method that differ  mainly in the degree to which they diagonalize a given subproblem. The first  method is a true block generalization of the scalar scheme in that each  off-diagonal block is completely annihilated. The second method is a scalar  Jacobi algorithm reorganized in such a manner that it conforms to the block  decomposition of the problem. We have performed experiments on the Loosely  Coupled Array Processor (LCAP) system at IBM Kingston which for the purposes  of this article can be viewed as a ring of up to ten FPS-164/MAX array  processors. These experiments show that the block Jacobi algorithm performs  well on a distributed system, especially when the processors have vector  processing hardware. As an example, we were able to achieve a sustained performance of 159 MFlops on a 960-by-720 SVD problem using eight processors.  A surprising outcome of these experiments is that the determining factor for  the performance of the algorithm on a high-performance architecture is the  subproblem solver, not the communication overhead of the algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6710,Inductive Definition in Type Theory,"Type theories can provide a foundational account of constructive mathematics, and for the computer scientist, they can also  serve the dual roles of  specification and programming languages. In the search for natural and expressive extensions to the  NuPrl type theory, we are lead to consider forms of inductive and co-inductive definition. We realize these notions through the addition of two new type constructors,  denoted $\mu and \nu$. This represents a step towards a more expressive theory, without adopting a completely impredicative notion of type. With these constructors we can define all the common inductive data types, from natural numbers to infinite trees. Through the propositions-as-types  principle, these type constructors yield inductively defined propositions. The induction principle associated with the $\mu$ types lets us define well-founded recursive functions, and dual principle for the $\nu$ types lets us inductively define their ""infinite"" elements. We present another induction principle for the $\mu$ types which takes advantage of the  information hiding properties of the $\{ __ | __ \}$ type, and can be used to  define an unbounded search operator, or more generally, to compute not with  elements of the $\mu$ type, but under the assumption of its inhabitation. After presenting the proof rules for these new type constructors we give a semantic account, from which intuitionistic consistency is a consequence. First, we consider the the question of inductive types in the simpler setting of the second-order lambda calculus, where we prove a strong normalization property. We also consider typing terms in the presence of type constraints, and present a condition  on the constraints (of polynomial complexity in the size of the constraints) for determining if the terms will be strongly normalizable or there will be a diverging typed term. Second, we develop a semantic account of the basic type theory, then relativize it to account for the impredicativity inherent in the definition of the new type constructors. We  also show how this model can justify other impredicative type  constructors, such as an impredicative type abstraction operation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6711,"On the Semantics of ""Data Type""","This paper considers the general problem of specifying the meaning of  programming languages which include ""data type definition facilities"". The  fundamental question posed in attempting to define such languages is: ""what  meaning should be given to a data type definition,"" or more simply, ""what does  data type mean?"". In this paper we describe a new approach to defining the  meaning of data types and give its application to the definition of a typed  lambda calculus extension. We also prove a theorem stating that our language  is ""strongly typed"".",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6712,What Programmers Don't and Should Know,ABSTRACT UNAVAILABLE,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6713,Perfect Pipelining: A New Loop Parallelization Technique,"Parallelizing compilers do not handle loops in a satisfactory  manner.  Fine-grain transformations  capture irregular parallelism inside a loop body not amenable to coarser approaches but have limited ability to exploit parallelism across iterations. Coarser methods sacrifice irregular forms of  parallelism in favor of pipelining (overlapping) iterations. In this paper we  present a new transformation, Perfect Pipelining, that bridges the gap between these fine-and coarse-grain transformations while retaining the  desirable features of both. This is accomplished even in the presence of  conditional branches and resource constraints. For loops typically  encountered in practice, Perfect Pipelining achieves the effect of full loop  unrolling coupled with fine-grain parallelization. To make our claims  rigorous, we develop a formalism for parallelization. The formalism can also  be used to compare transformations across computational models. As an illustration, we show that Doacross, a transformation intended for  synchronous and asynchronous multiprocessors, can be expressed as a  restriction of Perfect Pipelining.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6714,Decomposing Properties into Safety and Liveness,A new proof is given that every property can be expressed as a conjunction of  safety and liveness properties. The proof is in terms of first-order  predicate logic.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6715,Robust Set Operations on Polyhedral Solids,"We describe an algorithm for performing regularized set operations on  polyhedral solids. Robustness of this algorithm is achieved by adding  symbolic reasoning as a supplemental step that compensates for possible  numerical uncertainty. The algorithm has been implemented, and our experience  with the implementation is discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6716,Inorder Traversal of a Binary Tree and its Inversion,ABSTRACT NOT AVAILABLE,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6717,Lazy Evaluation and the Logic Variable,"Functional languages can be enriched with logic variables to provide new  computational features such as incremental construction of data structures.  In this paper, we present a novel application for logic variables that  highlights their importance: we argue that they are essential for efficient  implementations of pure functional languages. This point is made by  demonstrating that logic variables are required for explicating the process  of demand propagation in lazy evaluation of functional programs. There are  two applications of this result. For dataflow researchers, it offers a simple  and efficient implementation of laziness on dataflow machines. For  researchers investigating lazy graph reduction, it suggests new strictness  analysis algorithms in which logic variables play an important role.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6718,Towards Task Level Robot Programming,"This paper summarizes our research efforts in robotics. The primary goal is  to bring robotics science closer to its goal of task-level planning. We  approach this goal through blend of theory, implementation, and  experimentation. We have identified several key problem areas on which to  concentrate, and are undertaking research on generating assembly strategies from task-level descriptions. Our projects focus on: Algorithmic techniques for modelling geometric constraints, and the planning  of robot motions using these constraints. The synthesis of compliant motion programs using the geometric constraints  imposed by the task. The explicit modelling of uncertainty and error in sensing, control, and the  shape of the manipulated parts. The development of a precise theory of Error Diagnosis and Recovery, and a  method for generating sensor-based plans with built-in error detection and  recovery. The heart of this research lies in a geometrical planning theory, for  reasoning about and manipulating physical systems. We will develop this  underlying theory, implement and test the theory in simulation, and conduct  robotics laboratory experiments.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6719,Simplified Voronoi Diagrams,"We are interested in Voronoi diagrams as a tool in robot path planning, where  the search for a path in an $r$ dimensional space may be simplified to a  search on an $r-1$ dimensional Voronoi diagram. We define a Voronoi diagram  $V$ based on a measure of distance which is not a true metric. This formulation has lower algebraic complexity than the usual definition, which is a  considerable advantage in motion planning problems with many degrees of  freedom. In its simplest form, the measure of distance between a point and a  polytope is the maximum of the distances of the point from the half-spaces  which pass through faces of the polytope. More generally, the measure is  defined in configuration spaces which represent rotation. The Voronoi diagram  defined using this distance measure is no longer a strong deformation retract  of free space, but it has the following useful property: any path through  free space which starts and ends on the diagram can be continuously deformed so that it lies entirely on the diagram. Thus it is still complete for motion  planning, but it has lower algebraic complexity than a diagram based on the  euclidean metric.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6720,Planning Multi-Step Error Detection and Recovery Strategies,"Robots must plan and execute tasks in the presence of uncertainty.  Uncertainty arises from sensing errors, control errors, and uncertainty in the geometry of the environment. By employing a combined strategy of force  and position control, a robot programmer can often guarantee reaching the  desired final configuration from all the likely initial configurations. Such  motion strategies permit robots to carry out tasks in the presence of  significant uncertainty. However, compliant motion strategies are very  difficult for humans to specify-for this reason we have been working on the  automatic synthesis of motion strategies for robots. In previous work [D], we  presented a framework for computing one-step motion strategies that are  guaranteed to succeed in the presence of all three kinds of uncertainty. The  motion strategies comprise sensor-based gross motions, compliant motions, and  simple pushing motions. However, it is not always possible to find plans that are guaranteed to succeed. For example, if tolerancing errors render an assembly infeasible, the plan executor should stop and signal failure. In such cases the  insistence on guaranteed success is too restrictive. For this reason we investigate Error Detection and Recovery (EDR) strategies. EDR plans will  succeed or fail recognizably: in these more general strategies, there is no  possibility that the plan will fail without the executor realizing it. The  EDR framework fills a gap when guaranteed plans cannot be found or do not  exist: it provides a technology for constructing plans that might work, but  fail in a ""reasonable"" way when they cannot. We describe techniques for planning multi-step EDR strategies in the presence  of uncertainty. Multi-step strategies are considerably more difficult to  generate, and we introduce three approaches for their synthesis: these are  the Push-forward Algorithm, Failure Mode Analysis, and the Weak EDR Theory.  We have implemented the theory in the form of a planner, called LIMITED, in  the domain of planar assemblies.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6721,Term Weighting Approaches in Automatic Text Retrieval,"The experimental evidence accumulated over the past 20 years indicates that  textindexing systems based on the assignment of appropriately weighted single  terms produce retrieval results that are superior to those obtainable with  other more elaborate text representations. These results depend crucially on  the choice of effective term weighting systems. This paper summarizes the  insights gained in automatic term weighting, and provides baseline single  term indexing models with which other more elaborate content analysis  procedures can be compared.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6722,The Fast Fourier Transform on Hypercube Parallel Computers,"The Fast Fourier Transform appears frequently in scientific computing.  Therefore it is desirable to implement it efficiently on parallel computers.  In this thesis, we investigate several different aspects of parallel Fast  Fourier Transform implementation techniques for distributed-memory  message-passing systems such as hypercube multiprocessors. We describe  various Fast Fourier Transform algorithms using a matrix notation. An error  analysis is presented that considers the effect of different methods used in  the computation of the Fourier Transform coefficients as well as accumulated  roundoff. New implementations of one and two-dimensional Fast Fourier  Transforms are presented along with comparisons with existing methods. New  algorithms for symmetric transforms are also developed and the results show excellent speedup when implemented on the Intel iPSC hypercube.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6723,"Computations, Residuals, and the Power of Indeterminacy","We investigate the power of Kahn-style dataflow networks, with processes that  may exhibit indeterminate behavior. Our main result is a theorem about  networks of ""monotone"" processes, which shows: (1) that the input/output  relation of such a network is a total and monotone relation; and (2) every  relation that is total, monotone, and continuous in a certain sense, is the  input/output relation of such a network. Now, the class of monotone networks  includes networks that compute arbitrary continuous input/output functions,  an ""angelic merge"" network, and an ""infinity-fair merge"" network that  exhibits countably indeterminate branching. Since the ""fair merge"" relation  is neither monotone nor continuous, a corollary of our main result is the  impossibility of implementing fair merge in terms of continuous functions,  angelic merge, and infinity-fair merge. Our results are established by  applying the powerful technique of ""residuals"" to the computations of a  network. Residuals, which have previously been used to investigate optimal reduction strategies for the $\lambda$-calculus, have recently been demonstrated by one of the authors (Stark) also to be of use in reasoning  about concurrent systems. Here, we define the general notion of a ""residual  operation"" on an automaton, and show how residual operations defined on the  components of a network induce a certain preorder $\extend$ on the set of  computations of the network. For networks of ""monotone port automata,"" we  show that the ""fair"" computations coincide with $\extend$-maximal computations. Our results follow from this extremely convenient property.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6724,An Environment for Automated Reasoning About Partial Functions,We report on a new environment developed and implemented inside the Nuprl  type theory that facilitates proving theorems about partial functions. It is  the first such automated type-theoretic account of partiality. We demonstrate  that such an environment can be used effectively for proving theorems about  computability and for developing partial programs with correctness proofs. This extends the well-known proofs as programs paradigm to partial functions.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6725,ROPE: A New Twist in Computer Architectures,"Supercomputer architectures are not as fast as logic technology allows  because memories are slow than the CPU, conditional jumps limit the  usefulness of pipelining and prefetching mechanisms, and functional-unit parallelism is limited by the speed of hardware scheduling. We propose a  supercomputer architecture called Ring Of Prefetch Elements (ROPE) that  attempts to solve the problems of memory latency and conditional jumps  without hardware scheduling. ROPE consists of a pipelined CPU or  very-large-instruction-word data path with a new instruction prefetching  mechanism that supports general multi-way conditional jumps. To get  high-performance without scheduling hardware, ROPE relies on an optimizing  compiler based on a global code transformation technique (Percolation  Scheduling). This paper describes both the promise and the limitations of ROPE.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6726,"Pfaffian Orientations, 0/1 Permanents, and Even Cycles in Directed Graphs","The following issues in computational complexity remain imprecisely  understood: the striking difference in the complexities of computing the  permanent and determinant of a matrix despite their similar looking formulae,  the complexity of checking if a directed graph contains an even length cycle,  and the complexity of computing the number of perfect matchings in a graph  using Pfaffian orientations. Via polynomial time equivalences, we show  inter-relationships among these issues.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6727,Solving Systems of Nonlinear Equations on a Message-Passing Multiprocessor,"We develop parallel algorithms for the solution of dense systems of nonlinear  equations on a message-passing multiprocessor computer. Specifically, we  propose a distributed finite-difference Newton method, a multiple secant  method, and a rank-1 secant method. Experimental results, obtained on an  Intel hypercube, indicate that our methods exhibit good parallelism.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6728,Supplying High Availability with a Standard Network File System,"This paper describes the design of a network file service that is tolerant to fail-stop failures and can be run on top of a standard network file service. The fault-tolerance is completely transparent, so the resulting file system can support the same set of heterogeneous workstations and applications as the chosen standard supports. To demonstrate that our design  can provide the benefit of highly available files at a reasonable cost to the  user, we implemented a prototype based on the Sun NFS protocol. Our approach  is not limited to being used with NFS, however. The methodology we used  should apply to any network file service built along the client-server model.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6729,The Complexity of Planar Compliant Motion Planning Under Uncertainty,"We consider the computational complexity of planning compliant motions in the  plane, given geometric bounds on the uncertainty in sensing and control. We  can give efficient algorithms for generating and verifying compliant motion strategies that are guaranteed to succeed as long as the sensing and control  uncertainties lie within the specified bounds. We also consider the case  where a compliant motion plan is required to succeed over some parametric  family of geometries. While these problems are known to be intractable in 3D,  we identify tractable subclasses in the plane.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6730,On Planning: What is to be Done?,"In this paper, we suggest research directions in domain-independent planning,  addressing several open problems. In particular, we present: A modal truth criterion for the planning of overlapping actions with multiple  agents. A ""reduction"" of planning in time to classical planning and a discussion of  the relative power of the two methods. A formal framework towards describing planners with partial deductive closure  (derived side effects). A discussion of failure analysis, error diagnosis, and recovery in  domain-independent planning. An exploration of mathematical models of time (and space) proposed in naive  physics. A discussion of the relative difficulty of classical planning, versus  planning with a dense model of time.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6731,On the Expressive Power of Indeterminate Network Primitives,"It is well known that a fair merge primitive leads to unbounded  indeterminacy. In this paper we show that unbounded indeterminacy cannot express a fair merge in the setting of Kahn-style dataflow networks. Intuitively, unbounded indeterminacy can be used to program a fair merge when  it is guaranteed that data will always be available. But such schemes rely on  predictive scheduling and they may fail if one of the inputs to the merge is  a finite stream. It is reasonable to expect that if one were to add a  primitive which ""knows how to avoid bottom"" (so called ""angelic merge"")  then one could use this in conjunction with unbounded choice in order to  produce a fair merge. Somewhat surprisingly, this expectation is incorrect as  we show in this paper. The method we use to prove this is to identify a  property which generalises monotonicity to indeterminate networks and then  show that this property is possessed by determinate networks and by unbounded  choice and by angelic merge but not by fair merge. It appears that there is a  hierarchy of inequivalent indeterminate primitives all of which feature some  form of unbounded indeterminacy.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6732,Metamathematical Extensibility in Type Theory,"An automated theorem prover is said to be metamathematically extensible if a  metalanguage can be employed by the user to soundly extend the reasoning  capabilities of the system. In this thesis, we present a framework for  metamathematical extensibility for a system based upon a type-theoretic  logic, the Nuprl system. Using this framework, the user can construct  programs called proof tactics that may be used to provide new reasoning  capabilities for the logic. These proof tactics can encode reasoning methods as simple asd a derived rule of inference or as ambitious as a theorem prover. The design of the framework ensures that all proof tactics are correct. A  formal metalanguage called Metaprl is defined that represents the proof  theory of Nuprl in a natural and computationally-oriented fashion. The logic  of Metaprl is an extension of the constructive type theory of Nuprl. Type  theories like Nuprl and Metaprl are distinguished by the uniform treatment  of computations (programs) and logical propositions and by rich languages for expressing computations. In Metaprl, formal specifications for tactics  may be written and formally correct tactics extracted from the proofs of the  specification. Three classes of tactics are defined: complete tactics, partial tactics, and  search tactics. Complete tactics are analogous to derived axioms for the  Nuprl logic. Partial tactics are analogous to derived rules of inference.  Search tactics are analogous to the procedural tactics of LCF and the current  Nuprl system. Examples from each class of tactics are presented. There are a number of advantages to using a formal logic as a metalanguage  for metamathematical extensibility. System-implemented reflection principles  guarantee that the framework is a conservative extension of Nuprl. The  expressiveness of the Metaprl logic allows the validity of tactics to be  ensured. Often it is not even necessary to execute tactics since they have been proved correct and all that is required is that a proof exists; the exact  form for the proof is not needed. This can result in substantial  computational savings. Finally, the construction of a metalanguage for  metamathematical extensibility for Nuprl is generalized to a hierarchy of metalanguages, each logic providing for metamathematical extensibility of the  preceeding logic.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6733,Parallel Cholesky Factorization of Sparse Matrices,"We describe a parallel algorithm for finding the Cholesky factorization of a  sparse symmetric positive definite matrix A. The algorithm runs in  $O(h \log n)$ time with $m\*$ processors, where $h$ is the height of A's  elimination tree. We then show how to speed up that algorithm, so that it  runs in $O(\log n \log^{2}h)$ time with increased number of processors. Also, we present corresponding parallel algorithms for forward solve and back  solve with the same time bounds and similar processor bounds.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6734,An Assertional Characterization of Serializability and Locking,"The problem of synchronizing transactions in a database system so that  concurrent execution transforms the system from one consistent state to  another is called the Concurrency Control Problem. Over the past 20 years, a  property of concurrent execution called serializability has evolved as a  universal paradign for colving the Concurrency Control Problem. Up until now,  most work on serializability has been characterized by an emphasis on  sequences of operations. Researchers studying programming logics and  methodologies have developed a different approach to characterizing the  semantics of concurrent programs. This approach is called assertional  reasoning, and emphasizes the system state instead of sequences of  operations. This dissertation describes the extension of the formalisms and  tools of assertional reasoning to the Concurrency Control Problem. Proposed is a definition of serializability that generalizes previous  definitions in many respects. Two methods are described by which this  definition of serializability can be specified in an assertional programming  logic using formulas called proof outlines. As a consequence of specifying  serializability with proof outlines, it becomes possible to formally verify  serializability. The use of an assertional programming logic eliminates the  need to explicitly consider transaction interleavings, simplifying  verfication. Another consequence of specifying serializability with proof  outlines is the ability to derive synchronization protocols for  serializability. This possibility is realized in the form of a method for  deriving locking protocols from assertional specifications. The method is  based on a novel view of locking, in which locks held by transactions reflect  properties of the system state. Using this method, semantic information  available during the derivation process can be used to obtain locking  protocols permiting greater concurrency among transactions than locking  protocols obtained by more traditional methods. Examples are given throughout  the dissertation to illustrate the methods described.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6735,A Geometric Approach to Error Detection and Recovery for Robot Motion Planning With Uncertainty,"Robots must plan and execute tasks in the presence of uncertainty.  Uncertainty arises from sensing errors, control errors, and uncertainty in  the geometric models of the environment and of the robot. The last, which we  will call model uncertainty, has received little previous attention. In this  paper we present a formal framework for computing motion strategies which are  guaranteed to succeed in the presence of all three kinds of uncertainty. We  show that it is effectively computable for some simple cases. The motion strategies we consider include sensor-based gross motions, compliant motions,  and simple pushing motions. We show that model uncertainty can be represented by position uncertainty in  a generalized configuration space. We describe the structure of this space,  and how motion strategies may be planned in it.  It is not always possible to find plans that are guaranteed to succeed. In  the presence of model error, such plans may not even exist. For this reason  we investigate Error Detection and Recovery (EDR) strategies. We characterize  what such strategies are, and propose a formal framework for constructing  them. Our theory represents what is perhaps the first systematic attack on  the problem of error detection and recovery based on geometric and physical reasoning.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6736,Static Analysis of Aliases and Side Effects in Higher-Order Languages,"In recent years, there has been substantial interest in the development of  programming languages for new parallel architectures. A basic design conflict  arises because languages with simple semantics tend to use storage  inefficiently, whereas languages allowing the programmer to access storage explicitly are difficult to analyze. We present a compile-time estimation  scheme for determining whether an expression in an imperative language either  uses or updates the store. We also determine the aliasing behavior of  expressions and in general, we can tell whether the evaluation of two  expressions interfere.  Current interprocedural dataflow techniques for  aliasing and side effect inference are valid for first-order languages. Our  inference schemes provide information about aliasing and side effects in a  higher-order expression language with call-by-value semantics. The higher  order character of the language represents only a partial obstacle. On the  other hand, the presence of l-valued expressions has the consequence that  aliasing information must be computed for all expressions, and cannot be represented as a relation among identifiers. Furthermore, the introduction of pointers make aliasing and side effects flow-dependent properties. Abstract interpretation techniques allow us to define compositional static  inference schemes for aliasing and side effects, which can be proved sound  with respect to the standard semantics by structural induction. The abstract  interpretation functions are easy to modify, in case a different type of  information is requested. We also discuss how different language features may  affect the static analyses, simplifying them or making them untractable. The abstract interpretation functions implicitly define static inference  algorithms, which can easily be implemented by an attribute grammar, or any  other tool capable of performing computations on the abstract syntax tree. The accuracy of these algorithms is better than for the dataflow ones,  because we make use of control flow information. Our algorithms also compare  favorably in complexity, but the dataflow approach is probably cheaper in  most practical settings. In addition, our schemes can give information even  in the presence of dynamically allocated data structures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6737,The 1986-1987 Taulbee Survey Report: The Computing Research Board's Survey on the Production and Employment of Ph.D.'s and Faculty in Computer Science and Engineering,ABSTRACT NOT AVAILABLE,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6738,Improving Retrieval Performance by Relevance Feedback,"Relevance feedback is an automatic process, introduced over 20 years ago,  designed to produce query formulations following an initial retrieval  operation. The principal relevance feedback methods described over the years  are examined briefly, and evaluation data are included to demonstrate the  effectiveness of the various methods. Prescriptions are given for conducting text retrieval operations iteratively using relevance feedback.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6739,Computational Metatheory in Nuprl,"This paper describes an implementation within Nuprl of mechanisms that  support the use of Nuprl's type theory as a language for constructing  theorem-provind procedures. The main componenet of the implementation is a  large library of definitions, theorems and proofs. This library may be  regarded as the beginning of a book of formal mathematics; it contains the  formal development and explanation of a useful subset of Nuprl's metatheory,  and of a mechanism for translating results established about this embedded  metatheory to the object level. Nuprl's rich type theory, besides permitting  the internal development of this partial reflection mechanism, allows us to  make abstractions that drastically reduce the burden of establishing the  correctness of new theorem-proving procedures. Our library includes a  formally verified term-rewriting system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6740,Restricted Turing Reducibilities and the Structure of the Polynomial Time Hierarchy,"The polynomialtime many-one and Turing reducibilities, Karp and Cook  reducibilities respectively, play an major role in computational complexity  theory, particularly in the study of such classes as P, NP, the polynomial  time hierarchy (PH), and PSPACE. In this thesis, we consider polynomial time  Turing reducibilities with various restricted oracle access mechanisms such  as restrictions on the number of queries allowed or requiring that all  queries be made at once, in parallel. Such restrictions are related to  polynomial time truth-table and bounded truth-table reducibilities. We focus mostly on classes of languages reducible to NP sets via these reducibilities. For any integer $k, P^{NP[k]}$ is the class of languages recognizable in polynomial time with $k$ queries to an oracle from NP. The  query hierarchy, QH, is $\bigcup_{k} P^{NP[k]}$. The class $P^{NP[\log n]}$  is the set of languages recognizable with $O(\log n)$ queries. Two related  hierarchies are the Boolean hierarchy Boolean hierarchy (BH) and the parallel query hierarchy $(\rm QH_{||})$. The BH, QH, and $\rm QH_{||}$ intertwine to  form a rich structure within $P^{NP}$: NP $\cup$ co-NP $\subseteq P^{NP[1]} \subseteq P^{NP[2]} \subseteq \cdots  \subseteq QH = QH_{||} = BH \subseteq P^{NP[\log n]} \subseteq P^{NP}.$        We show that the structure of these classes is closely tied to the existence  of nonuniform algorithms for NP and co-NP languages and to the structure of  the PH as a whole. We improve Mahaney's result for sparse Turing-complete sets for NP by showing  that if there exists a sparse set $S \in NP$ such that co-NP $\subseteq  NP^{S}$, then PH $\subseteq P^{NP[\log n]}$. We show that there are relativized worlds where this collapse is optimal, and thus we provide a clear  distinction between the effects of a sparse many-one-complete set and a  sparse Turing-complete set for NP. We prove that if the BH, QH, or $QH_{||}$ collapses, for instance, if $D^{P}  =$co-$D^{P}$ or if $P^{NP[k]} = P^{NP[k+1]}$, then there exists a sparse set $S$ such that co-NP $\subseteq $NP^{S}$, and therefore the PH collapses to $P^{NP^{NP}[\log n]}$, a subclass of the $\Delta^{P}_{3}$ level of the PH. Hence the structure of unsatisfiable Boolean formulas, co-NP, and the whole PH  are all closely related to the structure of the BH and to the issue of how deterministic polynomial time algorithms can access the information from NP oracles.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6741,A Formal Account of Notational Definition,"In the course of developing a mathematical theory or proof it is a common  practice to introduce new notation to represent notation that is previously  understood. This paper presents a formal account that is intended to model  the practice of introducing  and using notational (abbreviative) definitions. The aim of this work is a pragmatic one: to provide a framework useful in the  design and implementation of secure proof system interfaces which accommodate, as much as possible, conventional mathematical practice. A typed  $\lambda$-calculus is used to represent expressions of a given object language. A new type of equation, called a $\Delta$-equation, is introduced to model  conventional definitional equations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6742,"Extending Planar Graph Algorithms to $K_{3}$,$_{3}$-free Graphs","For several problems, restricting attention to special classes of graphs has  yielded better algorithms. In particular, restricting to planar graphs yields  efficient parallel algorithms for several graph problems. In this paper we  extend these algorithms to $K_{3}$,$_{3}$-free graphs, showing that the  restriction of planarity is not important. The three problems dealt with are:  graph coloring, depth first search and maximal independent sets. As a corollary we show that $K_{3}$,$_{3}$-free graphs are five colorable  (this bound is tight).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6743,Presenting an Algorithm to Find the Minimum Edit Distance,ABSTRACT UNAVAILABLE,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6744,Computational Foundations of Basic Recursive Function Theory,"The theory of computability, or basic recursive function theory as it is  often called, is usually motivated and developed using Church's Thesis. Here we show that there is an alternative computability theory in which some  of the basic results on unsolvability become more absolute, results on  completeness become simpler, and many of the central concepts become more  abstract. In this approach computations are viewed as mathematical objects,  and the major theorems in recursion theory may be classified according to  which axioms about computation are needed to prove them. The theory is a typed theory of functions over the natural numbers, and there  are unsolvable problems in this setting independent of the existence of  indexings. The unsolvability results are interpreted to show that the partial  function concept, so important in computer science, serves to distinguish  between classical and constructive type theories (in a different way than  does the decidability concept as expressed in the law of excluded middle).   The implications of these ideas for the logical foundations of computer  science are discussed, particularly in the context of recent interest in  using constructive type theory in programming.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6745,Optimal Loop Parallelization,"Parallelizing compilers promise to exploit the parallelism available in a given program, particularly parallelism that is too low-level or irregular to be  expressed by hand in an algorithm. However, existing parallelization  techniques do not handle loops in a satisfactory manner. Fine-grain  (instruction level) parallelization, or compaction, captures irregular  parallelism inside a loop body but does not exploit parallelism across loop  iterations. Coarser methods, such as doacross [9], sacrifice irregular forms  of parallelism in favor of pipelining iterations (software pipelining). Both  of these approaches often yield suboptimal speedups even under the best  conditions-when resources are plentiful and processors are synchronous. In this paper we present a new technique bridging the gap between fine-and  coarse-grain loop parallelization, allowing the exploitation of parallelism  inside and across loop iterations. Furthermore, we show that, given a loop  and a set of dependencies between its statements, the execution schedule obtained by our transformation is time optimal: no transformation of the loop  based on the given data-dependencies can yield a shorter running time for  that loop.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6746,"The Hopcroft-Tarjan Planarity Algorithm, Presentation and Improvements","We give a rigorous, yet, we hope, readable, presentation of the  Hopcroft-Tarjan linear algorithm for testing the planarity of a graph, using  more modern principles and techniques for developing and presenting  algorithms that have been developed in the past 10-12 years (their algorithm  appeared in the early 1970's). Our algorithm not only tests planarity but  also constructs a planar embedding, and in a fairly straightforward manner.  The paper concludes with a short discussion of the advantages of our approach.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6747,On the Use of Spreading Activation Methods in Automatic Information Retrieval,"Spreading activation methods have been recommended in information retrieval  to expand the search vocabulary and to complement the retrieved document  sets. The spreading activation strategy is reminiscent of earlier associative  indexing and retrieval systems. Some spreading activation procedures are  briefly described, and evaluation output is given, reflecting the  effectiveness of one of the proposed procedures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6748,New Developments in Structural Complexity Theory,"This paper discusses the scope and goals of structural complexity theory,  describes some working hypothesis of this field and summarizes (some) recent development.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6749,Parallel Algorithms for $K_{5}$-minor Free Graphs,"For several problems, restricting attention to special classes of graphs has  yielded better algorithms. In particular, restricting to planar graphs yields  efficient parallel algorithms for several graph problems. In this paper, we  extend these algorithms to $K_{5}$-minor free graphs, showing that the  restriction of planarity is not important. The two problems dealt with are:  graph coloring and maximal independent sets. We also show that $K_{5}$-minor  free graphs are four colorable (this bound is tight). We also give an NC  algorithms to recognize $K_{5}$-minor free graphs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6750,An Incremental Planning Algorithm for Ordering Equations in a Multilinear System of Constraints,"Constraint equations are increasingly being used in interactive applications  such as graphics, logical programming, and simulation that demand immediate  feedback. To handle the performance requirements imposed by such systems  constraint evaluators must use incremental satisfaction techniques. In this  paper, we apply these techniques to noncircular, multilinear systems of  equations. The constraint satisfaction process is divided into two phases--a  planning phase that imposes a topological order on the equations and an  execution phase that evaluates the equations. A planning algorithm is  presented that incrementally updates this order each time the constraint  system changes. This technique achieves significant performance improvements  in large constraint systems since modifications generally perturb only a small portion of the topological order.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6751,Characterization of Associative Operations with Prefix Circuits of Constant Depth and Linear Size,"The prefix problem consists of computing all the products $x_{0}x_{1} \ldots  x_{j} (j = 0, \ldots,N - 1)$, given a sequence $x =(x_{0},x_{1},\ldots, x_{N-1})$ of elements in a semigroup. It is shown that there are unbounded  fan-in and fan-out boolean circuits for the prefix problem with constant  depth and linear size if and only if the Cayley graph of the semigroup does  not contain a special type of cycle called monoidal cycle.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6752,Structural Complexity Column: Some Observations About Relativization of Space Bounded Computations,NO ABSTRACT AVAILABLE,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6753,McCarthy's Amb Cannot Implement Fair Merge,"In this paper, we establish that fair merge is a powerful non-deterministic  primitive that cannot be implemented in terms of other well-known primitives.  It is well known that fair merge embodies countable non-determinism. It is  also been known that McCarthy's amb embodies countable non-determinism. It  had not been known, however, whether amb could implement a fair merge. We  show that countable non-determinism together with angelic non-determinism  cannot implement fair merge even in dynamic dataflow networks. This settles a  question posed by Abramsky over four years ago. Earlier work had suggested  this result by showing that for static dataflow networks, one cannot  implement fair merge using angelic merge.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6754,Critical (of) Issues in Real-Time Systems: A Position Paper,NO ABSTRACT AVAILABLE,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6755,On Time Versus Space,"It is shown that every deterministic multitape Turing machine of time  complexity t(n)/log t(n). Consequently, for tape constructable t(n), the  class of languages recognizable by multitape Turing machines of time  complexity t(n) is strictly contained in the class of languages recognized by  Turing machines of tape complexity t(n). In particular, the context sensitive  languages can not be recognized in linear time by deterministic multitape  Turing machines. Keywords and phrases: Turing machines, time complexity, tape complexity.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6756,A Round-Robin Parallel Partitioning Algorithm,"We develop parallel heuristic algorithms for partitioning the vertices of a graph into many groups of roughly equal size so that few edges connect vertices in different groups. The algorithms are intended for a message passing multiprocessor such as a hypercube, but only require the processors to be connected as a ring. They are based on the Kernighan-Lin algorithm, which finds a small edge separator that divides a graph into two pieces of equal size. Each of the algorithms features a parameter that allows for a trade-off between the potentially conflicting goals of reducing the number of edges between different groups and keeping the sizes of the groups roughly the same. These algorithms are applied to the problem of parallel block oriented Cholesky factorization. For an efficient factorization, we need a graph partition in which few pairs of vertex groups are interconnected; that is, we desire the quotient graph induced by the partition to be sparse. We discuss how standard partitioning heuristics may fail to give sparse quotient graphs and how they can be modified to correct this.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6757,Exploiting Replication,NO ABSTRACT AVAILABLE,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6758,Reliable Broadcast Protocols,NO ABSTRACT AVAILABLE,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6759,A Temporal-Logic Based Compositional Proof System for Real-Time Message Passing,"We consider a model of real-time network computation in which synchronous communication events occur during (possibly overlapping) intervals along a dense time scale. A specification language for processes and networks based on real-time temporal logic is defined. We give a simple proof system for network specifications when specifications for component processes are given. The proof system is then extended for a version of real-time CSP, under the  assumption that all communications take some fixed length of time. Finally, it is shown that this proof system can be modified to allow varying communication lengths. All versions of the proof system are compositional, sound, and relatively complete.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6760,A Practical Attribute Grammar Circularity Test,Efficient implementations for two optimisations to Knuth's attribute grammar  circularity test are described. A new method for eliminating useless visits  to productions is introduced. This improves upon a somewhat weaker mechanism  introduced previously by Deransart et. al. Data structures and algorithms for  graph covering and elimination of redundant unions are discussed and proven  correct.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6761,On Computing Graph Closures,"Given a graph $G$, the closure of $G$ is the graph obtained from $G$ by  recursively joining pairs of non-adjacent vertices whose degree sum is at  least $n$ until no such pair remains. We give an efficient algorithm to  compute the closure using F-heaps. We also define the general closure of a  graph and show that computing the general closure is $P$-complete with  respect to log space transformations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6762,Compaction-Based Parallelization,"We present a transformational system for extracting parallelism from programs. Our transformations generate code for synchronous parallel computers, such as  Very Long Instruction Word and pipelined machines. The transformational  system, which is based on percolation scheduling,is simple and uniform. There are four primitive transformations-three that perform code motion plus  loop unrolling-from which all parallelizing algorithms are constructed. Our transformations are studied as a formal system. We define a formal  measure of program improvement, and show that our transformations improve  programs with respect to the measure. This formal approach allows a number of  results on the expressive power of our transformations. Most importantly, we  show that it is possible to compute limits of infinite sequences of the  primitive transformations. This leads to a number of new algorithms for  software pipelining, including: an algorithm that generates optimal code for  loops without tests, an algorithm for software pipelining of multiple nested  loops, and a general solution to the problem of software pipelining in the  presence of tests.  Using the four primitives and the limit-taking transformation, it is possible  to express the classical parallelization techniques for vector,  multiprocessor, and VLIW machines, such as doacross, the wavefront method,  loop interchange, trace scheduling, and a simple form of vectorization. Thus,  our transformational system can be viewed as a formal foundation for the area  of parallelization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6763,Solution of Nonlinear Least-Square Problems on a Multiprocessor,"In this paper we describe algorithms for solving nonlinear least-squares problems on a message-passing multiprocessor. We demonstrate new parallel  algorithms, including an efficient parallel algorithm for determining the Levenberg-Marquardt parameter and a new row-oriented QR factorization  algorithm. Experimental results obtained on an Intel iPSC hypercube are  presented and compared with sequential MINPACK code executed on a single  processor. These experimental results show that essentially full efficiency  is obtained for problems where the row size is sufficiently larger than the  number of processors. These algorithms have the advantage of involving only  simple data movements and consequently are not constrained to the hypercube architecture.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6764,Recursive Data Structures and Parallelism Detection,Interference estimation is a key aspect of automatic parallelization of programs. In this paper we study the problem of estimating interference in a language with dynamic data-structures. We focus on the case of binary trees to illustrate the approach. We develop a structural flow-analysis technique that allows us to estimate whether two statements influence disjoint sub-trees of a forest of dynamically-allocated binary trees. The method uses a regular-expression-like representation of the relationships between the nodes of the trees and is based on the algebraic properties of such expressions. We have implemented our analysis in Standard ML and have obtained some promising experimental results.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6765,Automating Reasoning in an Implementation of Constructive Type Theory,"The starting point for this thesis is the Nuprl proof development system. Nuprl is an environment for the development of formal computational mathematics and has a rich constructive type theory as a logical basis. It provides sophisticated editors and an integrated tactic mechanism that allows the programming of guaranteed-sound extensions to the inference system. The work presented in this thesis concerns the automation of reasoning in Nuprl, and consists of three parts. The first is a collection of general-purpose tactics. These tactics are simple enough that their function can be readily understood, yet powerful enough to support development of substantial formal mathematics. The second part is the use of Nuprl to solve an open problem in the theory of programming languages. The set of basic tactics together with various tools provided by Nuprl play a crucial role in the solution, and it seems that this problem is not tractable without computer assistance. The third part is an implementation within Nuprl of mechanisms that support the use of Nuprl's type theory as a language for constructing theorem-proving procedures. The main component of the implementation is a large library of definitions, theorems and proofs. This library may be regarded as the beginning of a book of formal mathematics; it contains a complete formal development and explanation of a useful subset of Nuprl's metatheory, and of a mechanism for translating results established about this embedded metatheory to the object level. The type theory, besides permitting the internal development of this partial reflection mechanism, allows us to make abstractions that drastically reduce the burden of establishing the correctness of new theorem-proving procedures. Our library includes a formally verified term-rewriting system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6766,A Direct Active Set Algorithm for Large Sparse Quadratic Programs withSimple Bounds,"We show how a direct active set method for solving definite and indefinite  quadratic programs with simple bounds can be efficiently implemented for  large sparse problems. All of the necessary factorizations can be carried out  in a static data structure that is set up before the numeric computation  begins. The space required for these factorizations is no larger than that  required for a single sparse Cholesky factorization of a matrix with the same  sparsity structure as the Hessian of the quadratic. We propose several  improvements to this basic algorithm: a new way to find a search direction  in the indefinite case that allows us to free more than one variable at a  time and a new heuristic method for finding a starting point. These ideas are  motivated by the two-norm trust region problem. Additionally, we also show  how projection techniques can be used to add several constraints to the  active set at each iteration. Our experimental results show that an algorithm  with these improvements runs much faster than the basic algorithm for  positive definite problems and finds local minima with lower function values  for indefinite problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6767,Parallel Algorithms For Maximum Matching And Other Problems On Interval Graphs,"In this paper, we consider parallel algorithms on interval graphs. An  interval graph is a graph having a one-to-one correspondence with a sequence  of intervals on the real line, such that each vertex maps to an interval in  the sequence and an edge exists between two vertices if and only if the  corresponding intervals overlap. Throughout the paper we use the CREW PRAM  model. Our main result is an $O(\log^{2} n)$ time, $O(n^{6}/\log n)$  processor algorithm for maximum matching on interval graphs. We give PT-optimal algorithms for maximum weighted clique, maximum independent set, minimum  clique cover, and minimum dominating set for representations of interval  graphs; and Hamiltonian circuit for representations of proper interval  graphs. We also give an improved algorithm for minimum bandwidth on  representations of proper interval graphs. In addition, we present  $O (\log n)$ time, $O (n^{2}/\log n)$ processor algorithms for depth-first  search on representations of interval graphs and maximum matching on  representations of proper interval graphs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6768,The Use of Efficient Broadcast Protocols in Asynchronous Distributed Systems,"Reliable broadcast protocols are important tools in distributed and  fault-tolerant programming. They are useful for sharing information and for  maintaining replicated data in a distributed system. However, a wide range of  such protocols has been proposed. These protocols differ in their fault  tolerance and delivery ordering characteristics. There is a tradeoff between  the cost of a broadcast protocol and how much ordering it provides. It is,  therefore, desirable to employ protocols that support only a low degree of  ordering whenever possible. This dissertation presents techniques for  deciding how strongly ordered a protocol is necessary to solve a given  application problem. We show that there are two distinct classes of application problems: problems  that can be solved with efficient, asynchronous protocols, and problems that  require global ordering. We introduce the concept of a linearization function  that maps partially ordered sets of events to totally ordered histories. We  show how to construct an asynchronous implementation that solves a given  problem if a linearization function for it can be found. We prove that in general the question of whether a problem has an  asynchronous solution is undecidable. Hence there exists no general algorithm  that would automatically construct a suitable linearization function for a  given problem. Therefore, we consider an important subclass of problems that  have certain commutativity properties. We present techniques for constructing  asynchronous implementations for this class. These techniques are useful for  constructing efficient asynchronous implementations for a broad range of  practical problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6769,On the Complexity of Kinodynamic Planning,"In robotics, kinodynamic planning attempts to solve a motion problem subject  to simultaneous kinematic and dynamic constraints. We consider the following  problem: given a robot system, find a minimal-time trajectory from a start  position and velocity to a goal position and velocity, while avoiding  obstacles and respecting dynamic constraints on velocity and acceleration. We  consider the simplified case of a point mass under Newtonian mechanics,  together with velocity and acceleration bounds. The point must be flown from  a start to a goal, amidst polyhedral obstacles in 2D or 3D. While exact  solutions to this problem are not known, we provide the first provably good  approximation algorithm, and show that it runs in polynomial time.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6770,On Characterizations of Superlinear Convergence for Constrained Optimization,"We show how the Dennis-More characterization of superlinear convergence for  unconstrained optimization can be applied, and usefully restricted for use in  the constrained setting.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6771,Partitioned Quasi-Newton Methods for Nonlinear Equality Constrained Optimization,"We derive new quasi-Newton updates for the (nonlinear) equality constrained  minimization problem. The new updates satisfy a quasi-Newton equation,  maintain positive definiteness on the null space of the active constraint  matrix and satisfy a minimum change condition. The application of the updates  is not restricted to a small neighbourhood of the solution. In addition to  derivation and motivational remarks, we discuss various numerical subtleties  and provide results of numerical experiments.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6772,Building Theories in Nuprl,"This paper provides an account of how mathematical knowledge is represented,  reasoned about, and used computationally in a mechanized constructive theorem  proving environment. We accomplish this by presenting a particular theory  developed in the Nuprl proof development system: finite set theory  culminating in Ramsey's theorem. We believe that this development is  interesting as a case study in the relationship between constructive  mathematics and computer science. Moreover, the aspects we emphasize-the  high-level development of definitions and lemmas, the use of tactics to  automate reasoning, and the use of type theory as a programming logic-are not  restricted in relevance to this particular theory, and indicate the promise of  our approach for other branches of constructive mathematics.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6773,Techniques for Simplifying the Design of Distributed Systems,"Distributed computing systems offer a number of advantages over centralized  systems, such as the replication of data and functionality, which may result  in increased performance and fault-tolerance. The design of protocols for  distributed systems is more complex than for centralized systems because  coordination and cooperation between the different processors can be  difficult to achieve. Among the factors complicating this design are the  following: lack of processor synchronization, lack of common knowledge, and  processor failures. This thesis presents techniques for simplifying the  design of distributed systems by addressing these three complicating factors. Processor synchronization is provided by using logical clocks as if they are  real-time (and hence, perfectly synchronized) clocks. This can be done in  solutions to a large class of problems. Common knowledge is simulated by timestamped common knowledge, which is  identical to true common knowledge in systems with perfectly synchronized  clocks. A communication primitive, called publication, is defined which  achieves timestamped common knowledge, and an implementation of publications  is given that uses logical clocks. When solving problems in the class  characterized earlier, publications can be used as if they achieve true  common knowledge. The design of fault-tolerant protocols is simplified through methods that  automatically translate protocols tolerant of benign failures into ones  tolerant of more severe failures. The design task is reduced to that of  designing simpler protocols.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6774,Fine-Grain Compilation for Pipelined Machines,"Computer architecture design requires careful attention to the balance  between the complexity of code scheduling problems and the cost and  feasibility of building a machine. In this paper, we show that recently  developed software pipelining algorithms produce optimal or near-optimal code  for a large class of loops when the target architecture is a clean pipelined  parallel machine. The important feature of these machines is the absence of  structural hazards. We argue that the robustness of the scheduling algorithms  and relatively simple hardware make these machines realistic and  cost-effective. To illustrate the delicate balance between architecture and  scheduling complexity, we show that scheduling with structural hazards is  NP-hard, and that there are machines with simple structural hazards for which  vectorization and the software pipelining techniques generate poor code.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6775,Process Decomposition Through Locality of Reference,"In the context of sequential computers, it is common practice to exploit  temporal locality of reference through devices such as caches and virtual  memory. In the context of multiprocessors, we believe that it is equally  important to exploit spatial locality of reference. We are developing a  system which, given a sequential program and its domain decomposition,  performs process decomposition so as to enhance spatial locality of  reference. We describe an application of this method - generating code from  shared-memory programs for the (distributed memory) Intel iPSC/2.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6776,Incremental Computation and the Incremental Evaluation of Functional Programs,"Incremental computation is generally thought of as the technique of  efficiently updating the result of a computation when the input is changed.  This idea is used in doing semantic checking in programming environments,  document formatting in WYSIWYG editors and other applications. More  generally, incremental computation is the technique of efficiently applying a  function to a series of similar inputs. Much of the previous work on incremental computation has centered on  incremental attribute grammar and incremental dependency graph evaluation  schemes, but these techniques are only suitable for certain applications.  This thesis examines an alternative method for providing incremental  computation. Our results provide practical methods that can be used for  applications such as theorem provers for which attribute grammars are  unusable. Even for those problems for which attribute grammars are best  suited, our methods perform almost as well as attribute grammars. We describe an incremental evaluator for functional programs that makes use  of function caching. Function caching, or memoising, allows reuse of  solutions to problems that were solved previously. We examine how function  caching can be effectively used when solving problems that are similar to  problems that were solved previously. In order for function caching to provide incremental evaluation, two similar  problems must be solved by decomposing them into sub-problems in such a way  that they share many common sub-problems. We formalize and quantify this idea  with the notion of a stable decomposition, and we present data structures for  representing sets and sequences that have stable decompositions. We solve several problems related to the efficient implementation of function  caching. To perform function caching efficiently, one must be able to  determine if two values are equal in constant time and perform updates  applicatively. The data structures we present for sets and sequences support  these features. This was previously an open problem for representations that  also supported efficient updates. We also examine how to calculate hash keys  and perform fast equality tests for S-expressions and how to determine what  to purge from a function cache when it is full. We report benchmarks that  show our function caching implementation produces significant speed-ups in  complex programs such as incremental theorem provers.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6777,Notational Definition and Top-Down Refinement for Interactive Proof Development Systems,"This thesis is concerned with issues related to the design and implementation  of systems that support interactive proof development. The goal is to provide  logic-independent frameworks that can be used in the design and  implementation of component parts for such systems. In particular, this  thesis will focus on two frameworks: a language-independent account of  notational definition and a logic-independent account of a structure-oriented  approach to the interactive construction of goal-directed proofs. These  particular concerns were inspired and motivated by the Nuprl proof  development system. However, the results presented in this thesis are meant  to be applicable to a wide class of logics. The formal account of notational definition begins with the presentation of a  simply typed $\lambda$-calculus together with a method of representing  expressions in a given language $\cal L$ as $\lambda$-expressions. The  $\lambda$-calculus has a very simple abbreviative mechanism that allows a new  constant, introduced by means of a $\delta$-equation, to represent a closed  expression. A new construct, called a $\Delta$-equation, is introduced. It  provides a higher-level means of introducing new notations that is close to  the conventional style of definition. A $\Delta$-equation is given meaning by  a translation into a simple $\delta$-equation. The implementation of  mechanisms that support notational definitions in interactive proof  development systems as well as applications to Nuprl are discussed. The second part of the thesis presents a logic-independent framework for  top-down proof development called abstract refinement. Rather than  presenting, as is done for Nuprl, refinement and refinement rules as  primitive notions that are extended by grafting on tactics, tactics are  instead viewed as the basic notion from which refinement trees arise as  tree-structured representations of the iterated composition of tactics. This  is accomplished with the definition of a new construct called a tactic tree  that extends the LCF tactics framework in a natural way. Several examples of  proof development using tactic trees are presented. One example demonstrates  that the refinement rules and the extraction mechanism of Nuprl can be  modeled in this framework.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6778,Partial Objects in Type Theory,"Intuitionistic type theories, originally developed by Martin-Lof, provide a  foundation for intuitionistic mathematics, much as set theory provides a  foundation for mathematics. They are of interest to computer scientists  because the objects typed are computations, making type theory an appropriate  setting for reasoning about computation. Type theories such as Nuprl or the  theories of Martin-Lof have types for objects that always terminate, but  objects which may diverge are not directly typable. If type theory is to be a  full-fledged theory for reasoning about computations, we need to be able to  reason about potentially diverging objects. In this thesis we show how potentially diverging computations, which we call  partial objects, may be typed by extending type theory to partial object type  theory. New partial types are added to type partial objects. These types are  usable:  partial objects written in natural program notation can easily be  shown to lie in the types. In addition to being able to express partial  objects, it is also important to be able to reason about them; for this  purpose general principles are given for proving facts about partial objects  via induction. The resulting theory serves as a foundation for computational as well as  mathematical reasoning. It also gives insights into abstract recursion  theory, leads to a new method for constructive reasoning, and sheds light on  inductive methods for reasoning about recursive computation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6779,QR Factorization Algorithms for Coarse-Grained Distributed Systems,"We present the techniques of adaptive blocking and incremental condition  estimation which we believe to be useful for the computation of common matrix  decompositions in high-performance environments. We apply these new  techniques to algorithms for computing the Householder QR factorization with  and without pivoting on a coarse-grained distributed system. For reasons of  portability, we use a pipelined scheme on a ring of processors as the basis  of our algorithms. To take advantage of possible floating point hardware on each node we develop  a blocked version of the pipelined Householder QR algorithm that employs the  compact WY representation for products of Householder matrices. While a  strategy involving blocks of fixed width leads to increased floating point  utilization per node, it also leads to increased load imbalance. To reconcile  this tradeoff we introduce a variable width block strategy based on a model  of the critical path of the algorithm. The resulting adaptive blocking  strategy provides for good floating point performance per node while  maintaining overall load balance. Experimental results on the Intel iPSC  hypercube show that the adaptive blocking strategy performs indeed better  than any fixed width blocking strategy. In the second part of our thesis we develop methods for introducing pivoting  into the distributed QR factorization algorithm. Incorporating the  traditional column pivoting strategy in a straightforward manner introduces a  global synchronization constraint which results in increased communication  overhead. A strictly local pivoting scheme avoids the resulting loss in  efficiency, but has to be monitored for reliability. To this end, we  introduce an incremental condition estimator which allows us to update the  estimate of the smallest singular value of an upper triangular matrix $R$ as  new columns are added to $R$. The update requires only $O(n)$ flops an the  storage of $O(n)$ words between successive steps. Experiments indicate that  the incremental condition estimator is reliable despite its small  computational cost. Using the incremental condition estimator we are then  able to guard against the selection of troublesome pivot columns in our local  pivoting scheme at little extra cost. Simulation results show that the  resulting algorithm is about as reliable as the traditional QR factorization  algorithm with column pivoting.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6780,Parallel Sparse Cholesky Factorization,"As sequential computers seem to be approaching their limits in CPU speed  there is increasing interest in parallel computers. This development calls  for parallel algorithms for problems that may already have efficient  sequential algorithms. The problem of solving a linear system of equations arises in many areas of  science and engineering. Quite often each equation only involves a small  number of the variables. In that case the linear systems is sparse. If we can  take advantage of the sparsity we can solve much larger systems. Consider the linear system $Ax = b$, where $A$ is a sparse symmetric positive  define matrix. A common approach to solving this system is to use Cholesky  factorization. Algorithms that solve sparse linear systems using the Cholesky  factorization usually consist of the following steps. First the matrix $A$ is permuted in order to get a sparse Cholesky factor  $L$. Then there is the symbolic factorization of $A$ to determine the nonzero  structure of $L$. Finally the value of $L$ is calculated in the numeric  factorization phase and $x$ is computed by solving the triangular systems  $Ly = b$ and $L^{T}x = y$. In this thesis we present parallel algorithms for all the above steps except  for the permutation step. Before the symbolic factorization we compute the elimination tree of $A$.  Elimination trees have many applications in sparse matrix computations.  Therefore our parallel algorithm to find elimination trees is important in  its own right. The algorithm we present for symbolic factorization then uses  the elimination tree to compute the nonzero structure of $L$. We next present a parallel algorithm to compute the numeric factorization of  $A$. It runs in time proportional to the height of $A$'s elimination tree  times a log factor. We also show how that algorithm can be converted into an  NC algorithm (i.d., an algorithm that runs in polygarithmic time) by use of  fast algorithms for dense matrices. Finally we demonstrate a parallel algorithm to solve sparse triangular  systems of equations. There again we show a version that runs in time related  to the height of the elimination tree and a version that is an NC algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6781,Incremental Constraint Satisfaction and its Application to Graphical Interfaces,"Software that emphasizes pictures, rather than text, has become increasingly  popular since the introduction of the Macintosh computer. Creating this  software is a time-consuming task that can take months or years. Researchers  have attempted to speed up this process by developing constraint-based tools  that automate portions of the software development cycle. However, these  tools are often limited in the types of applications they can generate, since  1) they lack powerful editing models that can manipulate complex data  structures, such as lists, trees, and sets; and 2) in large applications,  they cannot perform constraint satisfaction quickly enough to provide  instantaneous feedback to the user. We present tools for overcoming each of these difficulties. First, we  describe a new model, called constraint grammars, that integrates aspects of  both attribute grammars and constraint-based, object systems to produce a  powerful specification language for graphical interfaces. Constraint grammars  integrate important concepts such as the part-whole hierarchy,  almost-hierarchical structures, and multidirectional constraints. These  features are augmented with a pattern-matching editing model that permits a  designer to manipulate complex data structures. We then present techniques for incrementally resatisfying multidirectional,  noncircular sets of constraints. It is shown that minimizing the number of  re-solved constraints is NP-complete. We therefore describe an approach that  attempts to minimize the amount of time spent updating the constraint  solution. This technique divides constraint solving into two phases-a planning  phase that linearly orders the constraints and an evaluation phase that  solves the constraints using this linear order. Previous approaches have  thrown away the linear order whenever the constraint system changes. However,  this is unnecessary since only a local portion of the linear order is  typically modified. We exploit this fact to develop an algorithm that  incrementally updates this order. We the augment this algorithm with a  heuristic that attempts to choose a linear order that minimizes the number of  equations that the evaluation stage must solve. We present benchmarks that  show that these algorithms can significantly reduce the number of equations  examined by the planning phase and the number of equations solved by the  evaluation phase.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6782,Fast Polar Decomposition of an Arbitrary Matrix,"The polar decomposition of an $m x n$ matrix $A$ of full rank, where  $m \geq n$, can be computed using a quadratically convergent algorithm of  Higham [SIAM J. Sci. Stat. Comput., 7 (1986), pp.1160-1174]. The algorithm is  based on a Newton iteration involving a matrix inverse. We show how with the  use of a preliminary complete orthogonal decomposition the algorithm can be  extended to arbitrary $A$. We also describe how to use the algorithm to  compute the positive semi-definite square root of a Hermitian positive  semi-definite matrix. We formulate a hybrid algorithm which adaptively  switches from the matrix inversion based iteration to a matrix multiplication  based iteration due to Kovarik, and to Bjorck and Bowie. The decision when to  switch is made using a condition estimator. This ""matrix multiplication  rich"" algorithm is shown to be more efficient on machines for which matrix  multiplication can be executed 1.5 times faster than matrix inversion.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6783,Generic Singularities of Robot Manipulators,"The singularities of the differential kinematic map, i.e., of the manipulator  Jacobian, are considered. We first examine the notion of a ""generic""  kinematic map, whose singularities form smooth manifolds of prescribed  dimension in the joint space of the manipulator. For 3-joint robots, an  equivalent condition for genericity using determinants is derived. The  condition lends itself to symbolic computation and is sufficient for the  study of decoupled manipulators, i.e., manipulators which can be separated  into a 3-joint translating part and a 3-joint orienting part. The results are  illustrated by analyzing the singularities of two classes of 3-joint  positioning robots.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6784,On the Structure of Bounded Queries to Arbitrary NP Sets,"In [Kad87b], Kadin showed that if the Polynomial Hierarchy (PH) has  infinitely many levels, then for all $k$, $P^{SAT[k]} \subseteq  P^{SAT[k+1]}$. In this paper, we extend Kadin's technique to show that a proper query  hierarchy is not an exclusive property of SAT. In fact, for any  $A \in  NP - \overbrace{low_{3}}$, if PH is infinite, then $P^{A[k]} \subseteq  P^{A[k+1]}$. Moreover, for the case of parallel queries, we show that $P^{A||[k+1]}$ is  not contained in $P^{SAT||[k]}$. We claim that having a proper query  hierarchy is a consequence of the oracle access mechanism and not a result of  the ""hardness"" of a set. To support this claim, we show that assuming PH is  infinite, one can construct an intermediate set $B \in NP$ so that $P^{B[k+1]} \subseteq  P^{SAT[k]}$. That is, the query hierarchy for $B$ grows as ""tall"" as the query hierarchy  for SAT. In addition, $B$ is intermediate, so it is not ""hard"" in any  sense (e.g., not NP hard under many-one, Turing, or strong nondeterministic  reductions). Using these same techniques, we explore some other questions  about query hierarchies. For example, we show that is there exists any $A$  such that $P^{A[2]} = P^{SAT[1]}$ then PH collapses to $\Delta^{P}_{3}$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6785,Providing Design Abstractions in Distributed Systems,"The design of protocols for distributed systems is more complex than for  centralized systems because coordination and cooperation between processors  are difficult to achieve. Among the factors complicating this design are the  failure of processors and the lack of processor synchronization. In this  paper, we show how to simplify the design of fault-tolerant protocols using  methods that automatically translate protocols tolerant of benign failures  into ones tolerant of more severe failures. Such methods provide the  abstraction of restricted faulty behavior. We also show how to circumvent the  lack of processor synchronization by using logical clocks, which provide the  abstraction of perfectly synchronized clocks in solutions to a large class of  problems, both in asynchronous and partially synchronized systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6786,Finding a Minimal Cover for Binary Images: An Optimal Parallel Algorithm,"Given a black and white image, represented by an array of $\surd n x \surd n$  binary valued pixels, we wish to cover the black pixels with a minimal set of  (possibly overlapping) maximal squares. It was recently shown that obtaining  a minimum cover with squares for a polygonal binary image having holes is  NP-hard. We derive an optimal parallel algorithm for the minimal square cover  problem, which for any desired computation time T in [log n, n] runs on an  EREW-PRAM with (n/T) processors. The cornerstone of our algorithm is a novel  data structure, the cover graph, which compactly represents the covering  relationships between the maximal squares of the image. The size of the cover  graph is linear in the number of pixels. This algorithm has applications to  problems in VLSI mask generation, incremental update of raster displays, and  image compression.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6787,A Provably Good Approximation Algorithm for Optimal-Time Trajectory Planning,"We consider the following problem: given a robot system, find a minimal-time  trajectory from a start position and velocity to a goal position and  velocity, while avoiding obstacles and respecting dynamic constraints on  velocity and acceleration. Based on the theoretical results of [CDRX], we  have developed and implemented a new, provably good approximation algorithm  for the minimum-time trajectory problem. Our algorithm differs from previous  work in three ways. First, it is possible to bound the goodness of the  approximation by an error term $\epsilon$. Second, we can polynomially bound  the running time (complexity) of our algorithm. Third, we can express the  complexity as a polynomial function of the error term. Hence, one supplies  the algorithm with the geometric obstacles, dynamics bounds, and the error  term $\epsilon$. The algorithm returns a solution that is $\epsilon$-close to  optimal, and promises to spend only a polynomial (in $(\frac{1}{\epsilon})$)  amount to time computing the answer. In this paper, we describe the algorithm  and explain the results in simple terms. We show how it can be applied to  robotics, and report on an implementation and experiments.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6788,Quantifier Elimination in the First-Order Theory of Algebraically Closed Fields,"We consider the problem of deciding whether a set of multivariate polynomials  with coefficients in any field $F$ have a common algebraic solution. In this  paper we develop a fast parallel algorithm for solving this decision problem.  Since the proposed algorithm is algebraic, it easily yields a procedure for  quantifier elimination in the theory of an arbitrary algebraically closed  field. More precisely, we show how to decide whether $m$ polynomials in $n$  variables, each of degree at most $d$, with coefficients in an arbitrary  field $F$ have a common zero in the algebraic closure of $F$, using  sequential time $m^{n + O(1)} d^{n^{2} + O(n)}$, or parallel time  $O(n^{3} \log^{3} d \log m)$ with $m^{n + O(1)} d^{n^{2} + O(n)}$ processors,  in the operations of the coefficient field $F$. Using randomization, this may  be improved to $m^{O(1)} d^{O(n)}$ time. In addition, the construction is  used give a direct EXSPACE algorithm for quantifier elimination in the theory  of an algebraically-closed field, which runs in PSPACE or parallel polynomial  time when restricted to formulas with a fixed number of alternations of  quantifiers.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6789,Causally Consistent Recovery of Partially Replicated Logs,"An algorithm is presented for the consistent recovery of replicated data in a  client-server system. The algorithm is based on logging and is similar to the  optimistic techniques that are well known in the literature. However, unlike  in existing optimistic techniques, explicit dependency information is not  maintained. Instead, dependency information is estimated from the ordering of  messages found in servers' logs. These dependency estimates can, in general,  be expensive to compute. It is therefore shown how inexpensive estimates can  be applied when a system is well structured.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6790,Conditions Unique Graph Embeddings,"The graph embedding problem is that of computing the relative locations of a  set of vertices placed in Euclidean space relying only upon some set of  inter-vertex distance measurements. This paper is concerned with the closely  related problem of determining whether or not a graph has a unique embedding.  Both these problems are NP-hard, but the proofs rely upon special  combinations of edge lengths. If we assume the edge lengths are unrelated  then the uniqueness question can be approached from a purely graph theoretic  framework that ignores edge lenghts. This paper identifies three necessary  graph theoretic conditions for a graph to have a unique embedding in any  dimension.  Efficient sequential and NC algorithms are presented for each  condition, although these algorithms have very different flavors in different  dimensions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6791,Deterministic Simulations of PRAMs on Bounded Degree Networks,"The problem of simulating a PRAM with $n$ processors and memory size  $m \geq n$ on an $n$-node bounded degree network is considered. A scheme is  presented which simulates an arbitrary PRAM step in  $O ((\log n \log m)/\log \log n)$ time in the worst case on an expander-based  network. By extending a previously established lower bound, it is shown that  the proposed simulation is optimal whenever $\Omega (n^{1 + \epsilon}) \leq  m \leq O(2^{(\log n)\alpha})$ for some $\epsilon greater than O$ and some $\alpha > O$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6792,Accumulators: New Logic Variable Abstractions for Functional Languages,"Much attention has been focused by the declarative languages community on  combining the functional and logic programming paradigms. In particular,  there are many efforts to incorporate logic variables into functional  languages.  We propose a generalization of logic variables called  accumulators which are eminently suited for incorporation into functional  languages. We demonstrate the utility of accumulators by presenting examples  which show that accumulators can be used profitably in many scientific  applications to enhance storage efficiency and parallelism.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6793,Bounding the Error in Gaussian Elimination for Tridiagonal Systems,"If $\hat{x}$ is the computed solution to a tridiagonal system $Ax = b$  obtained by Gaussian elimination, what is the ""best"" bound available for  the error $x - \hat{x}$ and how can it be computed efficiently? This question  is answered using backward error analysis, perturbation theory, and  properties of the $LU$ factorization of $A$. For three practically important  classes of tridiagonal matrix, those that are symmetric positive definite,  totally nonnegative, or are $M$-matrices, it is shown that  $(A + E)\hat{x} = b$ where the backward error matrix $E$ is small  componentwise relative to $A$. For these classes of matrix the appropriate  forward error bound involves Skeel's condition number cond$(A, x)$, which we  show can be computed exactly in $O(n)$ operations. For diagonally dominant  tridiagonal $A$ the same type of backward error result holds and we obtain a  useful upper bound for cond$(A, x)$ which can be computed in $O(n)$  operations. We also discuss error bounds and their computation for general  tridiagonal matrices.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6794,On the Application of Syntactic Methodologies in Automatic Text Analysis,"This study summarizes various linguistic approaches proposed for document  analysis in information retrieval environments. Included are standard  syntactic methods to generate complex content identifiers, and the use of  semantic know-how obtained from machine-readable dictionaries and from  specially constructed knowledge bases. A particular syntactic analysis  methodology is also outlined and its usefulness for the automatic  construction of book indexes is examined.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6795,Computing Polynomial Composition Factors and Inverses of Automorphisms in Polynomial Time,"The problem of determining when an endomorphism on a polynomial ring is an  automorphism and, when it is, the problem of computing its inverse are long  standing problems which have received much attention both recently and in the  past [BCW], [N], [NS], [SS]. There has also been much attention given  recently to various problems relating to the functional decomposition of  polynomials [AT], [BZ], [D], [G1], [G2], [GKL], [KL]. In this paper, we present the first polynomial time algorithm for computing  the left composition factor of a multivariate polynomial decomposition and we  use that result in the first polynomial time algorithm for computing the  inverse of an automorphism on a polynomial ring. Finally, we show how these  algorithms can be used to determine when an endomorphism is an automorphism.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6796,The Computational Structure and Characterization of Nonlinear Discrete Chebyshev Problems,We present the generalisation of some concepts in linear Chebyshev theory to  the nonlinear case. We feel these generalisations capture the inherent  structure and characteristics of the best Chebyshev approximation and that  they can be usefully exploited in the computation of a solution to the  discrete Chebyshev problem.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6797,A Category-Theoretic Semantics for Unbounded Indeterminacy,"In this paper we give a category-theoretic semantics for a simple imperative  language featuring unbounded indeterminacy. This semantics satisfies the  categorical analogues of continuity and has the meaning of while loops  defined as co-limits of $\omega$-diagrams. Furthermore, it collapses via an  abstraction function to a semantics that is fully abstract, and coincides  with the operational semantics. The abstraction function is the only  discontinuous function appearing in our semantics.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6798,L-domains and Lossless Powerdomains,"The category of L-domains was discovered by Achim Jung [5] while solving the  problem of finding maximal cartesian closed categories of algebraic CPO's and  continuous functions. In this note we analyse the properties of the lossless  powerdomain construction, that is closed on the algebraic-L-Domains. The  powerdomain is shown to be isomorphic to a collection of subsets of the  domain on which the construction was done. The proof motivates a certain  finiteness condition on the inconsistency relations of elements. It is shown  that all algebraic CPO's $D$ whose basis $B(D)$ has property $M$ satisfy the  condition. In particular, the coherent L-domains [3] satisfy the condition.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6799,Random Polynomial Time is Equal to Semi-Random Polynomial Time,We prove that any one-sided error random polynomial time (RP) algorithm can  be simulated with a semi-random source at no more than polynomial factor loss  in efficiency. i.e. RP=SRP. This contrasts with the fact that a semi-random  source is too weak to simulate fair coin flips [SV].,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6800,The Two-Processor Scheduling Problem is in Random NC,An efficient parallel algorithm $(RNC^{2})$ for the two-processor scheduling  problem is presented. An interesting feature of this algorithm is that it  finds a highest level first schedule: such a schedule defines a  lexicographically first solution to this problem in a natural way. A key  ingredient of the algorithm is a generalization of a theorem of Tutte which  establishes a one-to-one correspondence between the bases of the Tutte matrix  of a graph and the sets of matches nodes in maximum matchings in the graph.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6801,The Role of Order in Distributed Programs,"We discuss the role of order in building distributed systems. It is our  belief that a ""principle of event ordering"" underlies the wide range of  operating systems mechanisms that have been put forward for building robust  distributed software. Stated concisely, this principle is that one achieves  correct distributed behavior by ordering classes of distributed events that  conflict with one another. By focusing on order, one can obtain simplified  descriptions and convincingly correct solutions to problems that might  otherwise have looked extremely complex. Moreover, we observe that there are  a limited number of ways to obtain order, and that the choice made impacts  greatly on performance.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6802,Space Bounded Computations: Review And New Separation Results,"In this paper, we review the key results about space bounded complexity  classes, discuss the central open problems and outline the relevant proof  techniques. We show that, for a slightly modified Turing machine model, the  low level deterministic and nondeterministic space bounded complexity classes  are different. Furthermore, for this computation model, we show that Savitch  and Immerman-Szelepcsenyi theorems do not hold in the range lg lg $n$ to lg  $n$. We also discuss some other computation models to bring out and clarify  the importance of space constructability and establish some results about  these models. We conclude by enumerating a few open problems which arise out  of the discussion.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6803,Hypercube Algorithms on the Polymorphic Torus,"The Polymorphic Torus architecture is a reconfigurable, massively parallel  finegrained system, which in its two-dimensional $(N^{2})$ case has a lower  wiring complexity than, say, hypercubes. However, due to the dynamic  connection features at run-time, it allows several parallel structures such  as trees, rings, and hypercubes to be emulated efficiently. In this paper, we consider algorithms that are especially well-suited for  hypercubes, i.e. algorithms that take advantage of the relatively high  connectivity of the hypercube topology, and show how these algorithms attain  comparable bounds on a 2-D Polymorphic Torus. In particular, algorithms for  dense matrix vector multiplication (including using 2 orthogonal trees for  the matrix-vector case), sparse matrix-vector multiplication, and the FFT are  discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6804,Computational Complexity of Motion and Stability of Polygons,"The ability to model physical objects and procedures accurately enough to  predict their behavior without performing physical experimentation is a  fundamental goal of robotics. This facility is prerequisite to offline  modeling of assembly tasks, high level robotics languages, and automated  assembly planning. This thesis defines and gives algorithms for two classes of physical modeling  problems: Mobility problems and Stability problems. The Mobility problem for polygons is that of determining whether, in a  configuration of non-intersecting polygons, one or more polygons can be  moved (relative to some other polygon in the configuration) without causing  intersection. Mobility is shown to be NP-hard. An upper bound for the  mobility problem remains an open problem. Translational mobility is the problem of determining whether any polygons can  be simultaneously moved by translations without causing intersection.  Translational mobility is shown to be NP-complete. Infinitesimal mobility is the problem of determining whether there is a set  of velocities for the polygons of the configuration such that no point of a  polygon $P_{i}$ that is in contact with another polygon $P_{j}$ has a  velocity directed towards the interior of $P_{j}$. Infinitesimal mobility can  be viewed as an approximation to the mobility problem in that any  configuration that is mobile is also infinitesimally mobile. Infinitesimal  mobility is shown to be NP-complete. The Stability problem for polygons with mass is the problem of determining  whether a configuration of polygons is at a static equilibrium point. The  stability problem is considered for configurations of polygons with and  without friction, and is shown to be NP-hard for both cases. An algorithm is  given that distinguishes between configurations that are stable, unstable,  and indeterminate. The ability to distinguish indeterminate configurations  is important because indeterminate configurations arise when the model of an  assembly is not accurate enough to determine whether the assembly is stable. Finally, a restricted class of configurations is developed, the determined  configurations, for which a conservative stability problem can be solved in  polynomial time. The determined configurations are a natural class in the  sense that they preclude a type of contact that ""seems unpredictable"". If  undetermined points are desired or unavoidable, the restricted stability  problem can be solved in time exponential in the number of undetermined  points in the configuration.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6805,Pretending Atomicity,"We present a theorem for deriving properties of a concurrent program by  reasoning about a simpler, coarser-grained version. The theorem generalizes a  result that Lipton proved for partial correctness and deadlock-freedom. Our  theorem applies to all safety properties.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6806,Language Features that Support Program Verification (illustrated in PL/C),"The author of a program can convince its readers (including himself) that it  computes as he intended by writing into the program text a precise description  of what it should do. This description can include a clear proof that the  program behaves as advertised. In the future, programming languages may offer  far more mechanical assistance in expressing, checking, and processing these  descriptions than they do now. However, some existing languages, such as PL/C,  provide features which help in these tasks considerably. Here we examine such  features applied to simple programs of the type traditionally taught in  beginning programming classes. We discuss various proposals for expanding  programming languages to provide more assistance of this type. Keywords and phrases: program correctness, automatic program verification,  Hoare axioms, Scott induction, recursive programs, least number operator,  bounded quantifiers, inductive assertion method, programming language design,  very high level programmng languages, PL/I, PL/C, macro facilities.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6807,On Encryption Systems Realized by Finite Transducers,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6808,The Boolean Hierarchy and the Polynomial Hierarchy: a Closer Connection,"We show that if the Boolean hierarchy collapses to its $k^{th}$ level, then  the polynomial hierarchy collapses to the $k^{th}$ level of the difference  hierarchy of $\Sigma^{P}_{2}$ languages.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6809,A Framework for Learning in Planning Domains with Uncertainty,"Attempts to apply classical planning techniques to realistic environments  have met with two major difficulties. The first is that of average-case  inadequacy. As one might expect, the (worst-case) computational  characteristics of planning problems are ugly at best; a system that is to  operate on problems of any reasonable size must rely on heuristics to reduce  the average-case complexity of the problem. The second difficulty is that of  uncertainty, or what to do when the real world doesn't work as expected. We have shown in earlier work that particular machine learning techniques are  a viable means of addressing the problem of average-case inadequacy [Segre88]  in domains without uncertainty. This paper describes a planner operating in a  realistic environment that is intended to support the same kind of learning.  We report some preliminary experimental results comparing our planner with  other approaches to planning in the presence of uncertainty.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6810,Not the Last Word on EBL Algorithms,This paper describes a new domain-independent explanation-based learning  (EBL) algorithm that is able to acquire useful new rules in situations where  previous EBL algorithms would fail. The new algorithm is complete in the  sense that every valid rule that can be extracted from an explanation can be  extracted by this algorithm. The new algorithm is described inside a  framework that provides insight into how the design of successful EBL systems  takes into account operationality and imperfect domain theory issues.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6811,Concurrent Common Knowledge: A New Definition of Agreement for Asynchronous Systems,"In this paper we discuss a new, knowledge-theoretic definition of agreement  appropriate to asynchronous systems. This definition has two important  features: first, it uses causality, rather than time, in its definition and,  second, this form of agreement is attainable. In analogy with common  knowledge, it is called concurrent common knowledge. In defining concurrent  common knowledge we give a logic with new model operators and a semantics,  both of which are based on causality and consequently capture only the  relevant structure of purely asynchronous systems. We give general conditions  by which protocols can attain concurrent common knowledge and prove that two  simple and efficient algorithms do so. We also present several applications  of our logic, including necessary and sufficient local preconditions for the  concurrent performance of distributed actions. In general, applications that  involve all processes reaching agreement about some property of a consistent  global state are protocols that use concurrent common knowledge.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6812,Time Lower Bounds for CREW-PRAM Computation of Monotone Functions,"It is shown that the time to compute a monotone boolean function depending  upon $n$ variables on a CREW-PRAM satisfies the lower bound  $T = \Omega$(log $l$ + (log $n$)/$l$), where $l$ is the size of the largest  prime implicant. It is also shown that the bound is existentially tight by  constructing a family of monotone functions that can be computed in  $T = O$(log $l$ + (log $n$)/$l$), even by an EREW-PRAM. The same results hold  if $l$ is replaced by $L$, the size of the largest prime clause. An intermediate result of independent interest is that $S (n,l)$, the size of  the largest minimal vertex cover minimized over all (reduced) hypergraphs of  $n$ vertices and maximum hyperedge size $l$, satisfies the bounds  $\Omega(n^{1/l}) \leq S (n,l) \leq O (ln^{1/l}).$",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6813,Efficient Parallel Algorithms for Covering Binary Images,"Given a black and white image, represented by an array of $\surd$ n x $\surd$  n binary valued pixels, we wish to cover the black pixels with a minimal set  of (possible overlapping) maximal squares. It was recently shown that  obtaining a minimum cover with squares for a polygonal binary image having  holes is NP-hard. We derive a processor-time-optional parallel algorithm for  the minimal square cover problem, which for any desired computation time T is  [log n, n] runs on an EREW-PRAM with (n/T) processors. We also outline an  implementation on a mesh architecture which runs in O ($\surd$ n ) time, and  is P-T-optimal. Finally, we also show how to obtain a speedup in the running  time of our algorithm when polymorphic communication primitives are available  on the mesh. The cornerstone of our algorithm is a novel data structure, the  cover graph, which compactly represents the covering relationships between  the maximal squares of the image. The size of the cover graph is linear in  the number of pixels. This algorithm has applications to problems in VLSI  mask generation, incremental update of raster displays, and image compression.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6814,How Robust Are Distributed Systems?,No abstract is available.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6815,Logarithmic Time Parallel Algorithms for Recognizing Comparability and Interval Graphs,"We give fast parallel algorithms for recognizing ad representing comparability  graphs that can be transitively oriented, and interval graphs, the  intersection graphs of intervals along the real line. Under the CRCW PRAM  model, both algorithms use $O(n^{3})$ processors in $O$(log $n$) time to  check if a graph belongs to the desired class, and if it does then a valid  representation of the graph can be produced. The algorithms gain their  efficiency by using fast algorithms for finding the modular decomposition of  a graph. Both problems were known to be in $NC$, but the known algorithms  require more time than ours does.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6816,Fast Parallel Algorithms for the Modular Decomposition,"A module in a graph is like a black box: all the vertices in the module look  the same to vertices not in the module. This paper gives the first $NC$  algorithm for finding the modular decomposition of a graph. The algorithm  runs in $O$(log $n$) time using $O(n^{3})$ processors on a CRCW PRAM. This  decomposition is used to obtain fast sequential and parallel algorithms for  solving graph problems on graphs of bounded module size, e.g. the class of  cographs where each module with more than one vertex is either disconnected  or its complement is disconnected. These graph problems include minimum  coloring, maximum clique, matching, Hamiltonian circuit, and maximum cut.  Many of these problems can be solved with $O(n^{3})$ processors in  $O$(log $n$) time. All of them can be solved in $NC$. Our modular  decomposition algorithm can be used to obtain more efficient algorithms for  recognizing and orienting comparability graphs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6817,Recursive and Iterative Functions for Generating Fibonacci Numbers,"As reference to the popular computing press will confirm, there is a great  deal of misunderstanding about the efficient calculation of Fibonacci  numbers. As the ""obvious"" iterative version is linear and the ""obvious""  recursive version is exponential, many assume that recursion is inherently  less efficient than iteration. Even in the technical press, the more  efficient logarithmic versions are given in an abstract way, which makes  their use rather inconvenient. This report gives complete functions, both  iterative and recursive, for the linear and logarithmic algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6818,Verification of Combinational Logic in Nuprl,"We present a case study of hardware specification and verification in the  Nuprl Proof Development System. Within Nuprl we have built a specialized  environment consisting of tactics, definitions, and theorems for specifying  and reasoning about hardware. Such reasoning typically consists of  term-rewriting, case-analysis, induction, and arithmetic reasoning. We have  built tools that provide high-level assistance for these tasks.  The hardware component that we have proven is the front end of a  floating-point adder/subtractor. This component, the MAEC (Mantissa Adjuster  and Exponent Calculator), has 5459 transistors and has been proven down to  the transistor level. As the circuit has 118 inputs and 107 outputs,  verification by traditional methods such as case analysis would have been a  practical impossibility.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6819,Reversing is Not Inherent in Lexicographical Permutation Generation,"In his comprehensive 1977 survey of permutation generation methods, Sedgewick  [4] stated that ""(reversing) seems to be inherent in lexicographical  (permutation) generation"". It is the purpose of this paper to give an  algorithm which does not use reversing and to show its relationship to the  classical reversing algorithm of Ord-Smith [3]. We also give a number of  related algorithms to illustrate the flexibility of the new algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6820,Equality of Terms Containing Associative-Commutative Functions and Commutative Binding Operators is Isomorphism Complete,We demonstrate that deciding if two terms containing uninterpreted  associative-commutative function symbols and commutative variable binding  operators are equal is polynomially equivalent to determining if two graphs  are isomorphic. The reductions we use provide insight into this result and  suggest polynomial time special cases.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6821,Nuprl as a General Logic,"Study of the architecture and design of proof development systems has become important lately as their use has spread and become closely tied to programming environments. One of the central issues is how to  provide a general framework for defining and using a variety of logics in such systems; in particular, whether it is better to staart with a  simple core system, such as the typed lambda-calculus with dependent  function types, or start with a very rich theory providing a formalized metatheory. The first approach is exemplified by the  Edinburgh LF. Here we illustrated the second approach by showing how  to use Nuprl as a framework for defining logics in the style of the LF. Central to the viability of the second apprroach is a method of showing that the encoding of user defined logics in Nuprl is faithful. This paper presents a new semantic method to solve the problem. The method is applicable to the LF as well, and seems simpler than the syntactic methods that previously were used and which seem to hinder the use of rich thoeries as logical frameworks.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6822,Full Abstraction for Nondeterministic Dataflow Networks,We discuss the problem of finding fully abstract semantic models for  nondeterministic dataflow networks. We present the result that there exist  nondeterministic networks using only bounded choice for which the input-output  relation is not compositional. We go on to show that the trace semantics is  fully abstract for all nondeterministic as well as deterministic networks.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6823,The Functional Decomposition of Polynomials,"Let $f(\vec{x}), h_{1}(\vec{x}),...,h_{d}(\vec{x})$ and $g(\vec{x})$ be  elements of the polynomial ring $K [\vec{x}]$ (or ""polynomials over $K$"").  If $f(\vec{x}) = g(h_{1}(\vec({x}),..., h_{d}(\vec{x})),$ then we call $g,  h_{1},..., h{d}$ a functional decomposition of $f$. Polynomial decomposition is an important and interesting problem with a  number of applications in computer scinece and computational algebra.  Problems related to the decomposition of polynomials have received much  attention in the past five years [AT85, BZ85, KL86, Dic87, vzGKL87, vzG87,  vzG88, Dic88, KL89] as well as in the less recent past [Rit22, Eng41, Lev41,  FM69, DW74]. In fact, the decomposition of polynomials is considered  important enough that most major computational algebra systems (SCRATCHPAD  II, MAPLE, MATHEMATICA) support polynomial decomposition for univariate  polynomials. In this thesis, we examine various problems related to the functional  decomposition of polynomials. We will give a brief history of polynomial  decomposition, and then give a number of new results, including the first  polynomial time algorithms for two important decomposition problems and a  proof of the NP-completeness of another interesting polynomial decomposition  problem. We will also discuss some ot the applications of polynomial  decomposition to problems such as polynomial factorization and computing the  inverse of an automorphism over a multivariate polynomial ring. For the  latter, we will give the first known polyomial time algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6824,How Accurate is Gaussian Elimination?,"J.H. Wilkinson put Gaussian elimination (GE) on a sound numerical footing in  the 1960's when he showed that with partial pivoting the method is stable in  the sense of yielding a small backward error. He also derived bounds  proportional to the condition number $\kappa(A)$ for the forward error  $\| x - \hat{x} \|$, where $\hat{x}$ is the computed solution to  $Ax = b$. More recent work has furthered our understanding of GE, largely  through the use of componentwise rather than normwise analysis. We survey  what is known about the accuracy of GE in both the forward and backward error  senses. Particular topics include: classes of matrix for which it is  advantageous not to pivot; how to estimate or compute the backward error;  iterative refinement in single precision; and how to compute efficiently a  bound on the forward error. Key Words: Gaussian elimination, partial pivoting, rounding error analysis,  backward error, forward error, condition number, iterative refinement in  single precision, growth factor, componentwise bounds, condition estimator.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6825,A Collection of Test Matrices in MATLAB,"We present a collection of forty-four parametrized test matrices. The  matrices are mostly square, dense, nonrandom, and of arbitrary dimension. The  collection includes matrices with known inverses or known eigenvalues;  ill-conditioned or rank deficient matrices; and symmetric, positive definite,  orthogonal, defective, involuntary, and totally positive matrices. For each  matrix we give a MATLAB M-file that generates it, and for small dimensions, a  printout of the matrix, pictures of it, and a plot of its field of values.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6826,A Global and Quadratic Affine Scaling Method for Linear $L_{1}$ Problems.,"Recently, various interior point algorithms - related to the Karmarkar  algorithm - have been developed for linear programming. In this paper, we  first show how this ""interior point"" philosophy can be adapted to the  linear $l_{1}$ problem (in which there are no feasibility constraints) to  yield a globally convergent algorithm. We then show that the linear algorithm  can be modified to provide a globally and ultimately quadratically convergent  algorithm. This modified algorithm is significantly more efficient in  practice: we present numerical results to support this claim.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6827,A Comparison Between Statistically and Sytactically Generated Term Phrases,It is customary to use single terms (words) or terms in context (phrases) as  indexing units for the representation of natural-language text content. There  is evidence that term phrases may provide some advantages over the use of  single terms for text content representation. This note presents an  evaluation of the expected usefulness of automatic term phrase generation  systems involving syntactic processing compared with methods based only on  the statistical co-occurance characteristics between individual text words.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6828,Super Edge-Connectivity of Dense Digraphs and Graphs,"Super-$\lambda$ is a more refined network reliability index than  edge-connectivity; $G$ is super-$\lambda$ if every minimum edge-cut set is  trivial (the set of edges incident at a node with the minimum degree  $\delta$). This paper clarifies the relations between diameter and  super-$\lambda$; enlarging the order (the number of nodes) $n$ under the  given maximum degree $\Delta$ and a diameter $D$ results in not only  maximizing edge-connectivity but also minimizing the number of minimum  edge-cut sets, thus attaining super-$\lambda$. The following sufficient  conditions for digraph and graph $G$ to be super-$\lambda$ are derived. Digraph $G$ is super-$\lambda$ if  $n greater than \delta  (\frac{\Delta^{D-1}-1}{\Delta -1} + 1) + \Delta^{D-1}$ Digraph $G$ is super-$\lambda$ if  $n greater than \delta  (\frac{(\Delta-1)^{D-1}-1}{\Delta -2} + 1) + (\Delta-1)^{D-1}$ These conditions are best possible. From these, de Bruijn digraph $B(d,D)$,  Kautz digraph $K(d,D)$, and most of the densest known graphs (listed in [3,9]  are shown to be super-$\lambda$. Also, the digraph $G^{\ast}_{B}(n,d)$  proposed in [24] as a maximally connected $d$-regular digraph with  quasiminimal diameter (at most one larger than the lower bound) is proved to  be super-$\lambda$ for any $d$ greater than 2 and any order $n$ greater than $d^{3}$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6829,Partitions and Principles for Secure Operating Systems,"As part of the general goal of providing secure computer systems, the design  of verifiably secure operating systems is one of the most important tasks.  This paper addresses the problem by defining security in terms of a model and  proposing a set of principles which we feel should be satisfied in a secure  operating system. Informally, an operating system is secure if its users  completely control the use of all information which they introduce. Four key  partitions are identified: user interface functions, user invoked services,  background services, and the security kernel. Principles are then defined to  insure that interface functions provide a safe initial environment for  executing user programs, user called services are confined, background  services have no access to user information, and the security kernel  adequately protects information storage.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6830,The Complexity of Quantifier Elimination in the Theory of an Algebraically Closed Field,"This thesis addresses several classic problems in algebraic and symbolic  computation related to the solvability of systems of polynomial equations. We  develop a parallel algebraic procedure for deciding when a set of  multivariate polynomial equations with coefficients in an arbitrary field $K$  have a common solution in an algebraic closure of this field. All computation  required by these algorithms takes place over $K$, the field of definition,  and hence does not require explicit construction or approximation of  solutions. The decision procedure is subsequently extended to yield an  algorithm for deciding when solutions exist for arbitrary Boolean  combinations of polynomial equations over an algebraically closed field.  Modifications are introduced to compute projections of algebraic and  semi-algebraic sets, producing an exponential-space algorithm for determining  the truth of sentences in the theory of an arbitrary algebraically closed  field. In addition, this algorithm can be executed in polynomial space  (PSPACE) when restricted to sentences with a bounded number of quantifier  alternations.  The algebraic nature of the construction also allows us to  develop naturally a quantifier elimination procedure for formulas in this  theory within similar time and space bounds. Finally, we show that these  results are nearly optimal in a common model of parallel arithmetic  computation. We also show how these methods can be used to compute the dimension of an  arbitrary algebraic set. A variety of other applications-including the  construction and approximation of solutions for systems of multivariate  polynomial equations and the isolation of real zones-are investigated.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6831,Message Classes: An Approach to Process Synchronization,"In multiprogramming systems, parallel processes compete for access to shared  resources and cooperate by exchanging information. Semaphores are a useful  means for controlling competition and synchronizing execution and  inter-process messages are useful for communication. Neither semaphores nor  inter-process message, however, are natural for solving both problems. This  paper introduces a new approach, message classes, which combines and extends  features of both semaphores and message passing. Using message classes,  numerous mutual exclusion, producer/consumer, process communication, and  resource allocation problems can be readily solved.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6832,Fault-Tolerant Computing Based on Mach,"We consider the problem of providing automatic and transparent fault  tolerance to arbitrary user computations based on the Mach operating system.   Among the several alternatives for structuring such a system, we pursue the  ""task-pair backup"" paradigm in detail and outline how it might be supported  by Mach.  Some of the new system calls and protocols that need to be  incorporated into the Mach kernel and server tasks are sketched.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6833,A Comparison of Book Indexing Methods,"Several book indexing methods are introduced based in part on statistical and in part on syntactic analysis methods to process the text of documents. These indexing methods are used to construct global indexes for two book chapters covering the areas of text compression and text encryption,  respectively. An attempt is made to evaluate the adequacy of the several  indexing products.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6834,Maintaining Tree Projections in Amortized $O$(log $n$) Time.,"The projection of a set of marked nodes in a tree can be represented by a  structure tree, that is, a subtree containing the marked nodes and the lowest common ancestors of all pairs of marked nodes. As an application modifies a forest of trees by linking and cutting trees and by marking and  unmarking nodes, the structure tree associated with each tree must be updated  in order to reflect the current set of marked nodes. Previous algorithms have  used $O(n)$ time per operation [Hoover 87] to maintain structure trees. This  algorithm makes use of self-adjusting binary trees [Sleator and Tarjan 85] and  reduces the running time to amortized $O$(log $n$) per operation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6835,A Theory of Alternating Paths and Blossoms for Proving Correctness of the $O(\sqrt{VE})$ General Graph Matching Algorithm,No abstract is available.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6836,Verifying Safety Properties Using Non-deterministic Infinite-state Automata,"A new class of infinite-state automata, called safety automata, is introduced. Any safety property can be specified by using such an automaton. Sound and  complete proof obligations for establishing that an implementation satisfies  the property specified by a safety automaton are given.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6837,Simpler Proofs for Concurrent Reading and Writing,Simplified proofs are given for Lamport's protocol to coordinate concurrent  reading and writing.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6838,Automatic Design of Relational Databases,"Advances in relational database technology have made available relational  database systems that support state of the art query languages and query  processing algorithms. However, because database systems do not include  adequate tools for database design, their use and accessibility is hampered by  major difficulties that users experience in the process of designing a  database. In this dissertation, we present methods and algorithms for  automating the design of relational databases and describe a prototype design  tool. Unlike researchers who have advocated the use of higher level data  models, we focus on the pure relational model, because of its sound  theoretical foundation and investigate issues in automatic design of  relational databases. We present a new graph representation for functional dependencies, which  simplifies and enhances several design algorithms, such as algorithms for  computing closures, keys, and projecting dependency sets. We define the basis  $B(F)$, a compact representation of $F^{+}$, which is used to find multiple  BCNF decompositions. The basis also provides a way to find the generator of  the $F$-closed sets, an essential component in the computation of Armstrong  relations, which are relations representing a set of functional dependencies. We study the inference of multivalued dependencies from an acyclic relational  scheme. These multivalued dependencies capture the relationship between the  relations in the database. For the inference of functional dependencies  within a relation, we optimize previously proposed algorithms. Queries can be used to rate candidate schemes according to how queries perform  against them. We present an algorithm for finding the exact query formulation  for a particular design, given a scheme independent definition of the query.  Multiple ways of accessing the data or no way of accessing the data  consistently can be a result indicating that the current design is not valid. Until now, there has been limited experience with feasibility and performance  aspects of automatic relational design. We describe a prototype design tool  and present a detailed performance study of the dependency inference  algorithms implemented in this prototype.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6839,An Assertional Characterization of Serializability,Serializability is usually defined operationally in terms of sequences of  operations. This paper gives another definition of serializability-in terms  of sequences of states. It also shows how this definition can be used to  prove correctness of solutions to the concurrency control problem.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6840,Designing Distributed Services Using Refinement Mappings,"The thesis addresses the design of multiple-server implementations for  services in distributed systems-a generalization of the replication  management problem. A frequently used correctness criteria for replication  management is that clients of a service not be able to distinguish a  single-server implementation from on that involves multiple servers. Our  approach formalizes this idea. It is based on viewing a single-server  implementation of a service as a specification of that service. A  multiple-server implementation is considered correct if it implements this  single-server based specification. We show how program proof outlines can be viewed as specifications and, using  refinement mappings, define what it means for one proof outline to implement  another. The notion of a structural refinement, which formalizes the  relationship between a program and the result of performing step-wise  refinement, is defined. When one proof outline is a structural refinement of  the other, simplified proof obligations can be used to show that the one  implements the other. Finally, a methodology for designing a multiple-server implementation of a  service is presented. The methodology is based on structural refinement and  on viewing proof outlines as specifications. A designer defines a refinement  mapping to express the relationship between the state space of a given  single-server implementation of a service and the state space of the desired  multiple-server implementation. Using this refinement mapping, a provably  correct multiple-server implementation is derived from the single server one.  Different refinement mappings as well as different single-server based  specifications result in different implementations. Examples illustrate the  concepts and the methodology.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6841,Some Proofs of Transforms,"Three simple examples of data refinement-replacement of an abstract program  fragment and its variables by a more concrete fragment and variables-are  presented in the Polya transform notation. Correctness of each transformation  is derived using the formulations of Prinz-Gries, Morris, and Chen/Udding,  which are formally equivalent but require different proof strategies. This  allows comparison of the three formulations based on ease of use.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6842,Deceit: A Flexible Distributed File System,"Deceit, a distributed file system being developed at Cornell, focuses on  flexible file semantics in relation to efficiency, scalability, and reliability. Deceit servers are interchangeable and collectively provide the  illusion of a single, large server machine to any clients of the Deceit  service. Non-volatile replicas of each file are stored on a subset of the  file servers. The user is able to set parameters on a file to achieve  different levels of availability, performance, and one-copy serializability.  Deceit also supports a file version control mechanism. In contrast with many  recent DFS efforts, Deceit can behave like a plain Sun Network File System  server and can be used by any NFS client without modifying any client software. The current Deceit prototype uses the ISIS Distributed Programming  Environment for all communication and process group management, an approach  that reduces system complexity and increases system robustness.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6843,"Second Order Kinematic Constraint Between Two Bodies Rolling, Twisting and Slipping Against Each Other While Maintaining Point Contact","The second order kinematic constraint (acceleration constraint) between two  rigid bodies that are rolling, twisting, and slipping against each other while  maintaining point contact, is derived by differentiation of the first order  constraint and by including the geometry of the surfaces at their contact.  This constraint is derived with a view to facilitate the simulation of such  motion with general purpose dynamics simulators, and more specifically for  the Newton dynamic simulator developed at Cornell University. The constraint  is first derived for planar motion and then generalized for motion in three  dimensions. Some simple, but representative, examples are presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6844,A Paradigm for Robust Geometric Algorithms,No abstract is available.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6845,The Complexity of Equivalence and Containment for Free Single Variable Program Schemes,"Non-containment for free single variable program schemes is shown to be  NP-complete. A polynomial time algorithm for deciding equivalence of two free  schemes, provided one of them has the predicates appearing in the same order  in all executions, is given. However, the ordering of a free scheme is shown  to lead to an exponential increase in size.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6846,On Oraclizable Networks and Kahn's Principle,"In this paper we investigate generalizations of Kahn's principle to nondeterministic dataflow networks. Specifically, we show that for the class  of ""oraclizable"" networks a semantic model in which networks are represented by certain sets of continuous functions is fully abstract and has  the fixed-point property. We go on to show that the oraclizable networks are  the largest class representable by this model, and are a proper superclass of  the networks implementable with the infinity fair merge primitive. Finally,  we use this characterization to show that infinity fair merge networks and  oraclizable networks are proper subclasses of the networks with Egli-Milner  monotone input-output relations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6847,Simple Programs on Strings and Their Decision Problems,Classes of simple programs operating on srings are considered. Their power as  acceptors and their power as generation devices are compared and consequences  on upper bounds and lower bounds for several decision problems are derived. It  is shown that even for such a small class of programs some problems are  undecidable.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6848,Cataloging Software Packages for Automatic Document Processing,"Considerable advances have been made in the last few years in the development  of hardware structures useful for the implementation of real-time document  processing systems and on-line information retrieval. At the same time,  relatively little is known about the software packages most appropriate for  the new technology. Following certain proposals for the creation of national  and international registries of software packages, a sample catalog of  software routines is developed for use in modern automatic documentation  systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6849,A Constructive Proof of Higman's Lemma,"Higman's Lemma is a special case of the more general Kruskal's tree embedding  theorem and the graph minor theorem. Prior to this work, only classical (and  impredicative) proofs of the Lemma were known. Recently, there has been much  interest in developing a constructive proof of the Lemma, primarily via  Friedman's A-translation. In this paper we present a direct constructive  proof. We achieve this by reducing the problem to a construction of certain  sets of sequential regular expressions. We then exhibit a well-founded order  on such sets, and the Lemma then follows by induction.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6850,From Control Flow to Dataflow,"Are imperative languages tied inseparably to the von Neumann model or can  they be implemented in some natural way on dataflow architectures? In this  paper, we show how imperative language programs can be translated into  dataflow graphs and executed on a dataflow machine like Monsoon. This  translation can exploit both fine-grain and coarse-grain parallelism in  imperative language programs. More importantly, we establish a close  connection between our work and current research in the imperative languages  community on data dependencies, control dependencies, program dependence  graphs, and static single assignment form. These results suggest that  dataflow graphs can serve as an executable intermediate representation in  parallelizing compilers.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6851,Improved Bounds for the Token Distribution Problem,The problem of packet routing on bounded degree networks is considered. An algorithm is presented that can route $n$ packets in $O$(log $n + K)$ time on a particular $n$-node expander-based network provided that no more than $K$ packets share the same source or destination.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6852,Completeness of a Temporal Logic for Asynchronous Systems,"In this paper, we define a variant of temporal logic that is designed to  capture the temporal and causal aspects of asynchronous distributed systems.  In these systems, the usual physical concept of time based upon the notion of  a global clock is relegated to a secondary role; causal dependency or  necessary temporal precedence is fundamental. Causal dependence is just  temporal order locally; globally it is based on communication. An instant of  time is replaced by a consistent cut. The semantics of most temporal logics have been based on computation  sequences, either linear or branching time. In these models, one views an  execution of a system as a single sequence of events. In such models, a  ""spurious"" linearization is introduced, effectively disregarding  concurrency. Recently, however, partially ordered models have been considered  because, it is argued, that they more accurately represent the system being  studied. The main technical contribution of this paper is to show that such a  logic is complete for the class of models defined by executions of  asynchronous systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6853,What Should a Roboticist do Next? A Progress Report From the Cornell Computer Science Robotics Laboratory,"The most important intellectual capital of a research laboratory is its  coherent vision of science, research and progress. In this progress report,  we identify key areas of research, describe the progress we have made in  attacking these areas, and discuss our plans for future work. Our primary goal is to bring robotics science closer to its goal of task-level  planning. We approach this goal through a blend of theory, implementation,  and experimentation. A major impediment to developing truly task-level  robotic systems has been the very hard algorithmic problems that arise in  task-level robot planning. We have identified several key areas on which to  concentrate in developing new algorithmic technologies to crack these  problems. Roughly speaking, these areas are: 1. Basic research in compliant motion planning under uncertainty. This  research will result in algorithms and systems that can assemble  mechanical parts using compliant motion strategies, despite uncertainty  and errors in sensing, control, and modeling. 2. Basic research in planning with full dynamics. It is vital that robots  execute tasks quickly, and take dynamics into account. Our research on  kinodynamic planning provides the first provably good approximation  algorithms for planning nearly time-optimal collision-avoiding paths that  respect dynamics bounds. 3. Basic research in design for assembly. The design of mechanical devices  and the planning to assemble them should not be independent activities. We  introduce a new, fully algorithmic, combinatorially precise approach to  designing devices so that they are easy to assemble and (optionally) hard  to disassemble. Our analysis can be used to validate good designs, and can  be iterated to generate improved designs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6854,Overloading and Bounded Polymorphism,We present an extension of the Hindley/Milner polymorphic type system that  deals with overloading. The system uses a kind of bounded polymorphic type to  describe the nonuniform polymorphism resulting from the use of overloaded  identifiers. We consider the type inference problem for our system and show that it is undecidable. Restrictions are proposed to cope with this limitation.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6855,Stabilitly and Sequentiality in Dataflow Networks,"The class of monotone input/output automata has been shown in the authors'  previous work to be a useful operational model for a dataflow-style networks  of communicating processes. An interesting class of problems arising from  this model are those that concern the relationship between the input/output  behavior of automata to the structure of their transition graphs. In this  paper, we restrict our attention to the subclass of determinate automata,  which compute continuous functions, and we characterize classes of  determinate automata that compute: (1) the class of functions that are stable  in the sense of Berry, and (2) the class of functions that are sequential in  the sense of Kahn and Plotkin.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6856,A Categorical Powerdomain Construction,"The class of countably based bifinites (SFP objects) is the usual  mathematical framework for carrying out the constructions that arise in the  semantics of programming languages. However, A. Jung showed that the  construction used to define the domain-theoretic semantics of polymorphic  lambda calculus, is not closed on this category. This motivates the search  for a suitable category that is closed under all the constructions used in  programming language semantics. T. Coquand developed categories of embeddings  as a categorical generalization of the domain-theoretic structures used to  give semantics of polymorphism. In this paper, we present a category- theoretic powerdomain construction that is closed on the (extensional)  categories of embeddings. The construction is shown to have universal  properties that resemble the universal properties of the Plotkin powerdomain.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6857,Inductive Inference without Overgeneralization from Positive Examples,"Language learnability is investigated in the Gold paradigm of inductive  inference from positive data. Angluin gave a characterization of learnable  families in this framework. Here, learnability is studied when the learner  obeys certain constraints. These constraints have been suggested by some  studies of child language acquisition. Learnable families are characterized  for learners with the following types of constraints: (a) conservative,  consistent, and responsive, (b) conservative and responsive, (c) conservative  and consistent, and (d) conservative. It is shown that the class of learnable  families strictly increases going from (a) to (b) and from (b) to (c), while  it stays the same going from (c) to (d).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6858,A Domain-Theoretic Model for a Higher-Order Process Calculus,"In this paper we study a higher-order process calculus, a restriction of one  due to Boudol, and develop an abstract, model for it. By abstract we mean  that the model is constructed domain-theoretically and reflects a certain  conceptual viewpoint about observability. It is not constructed from the  syntax of the calculus or from computation sequences. We describe a new  powerdomain construction that can be given additional algebraic structure  that allows one to model concurrent composition, in the same sense that  Plotkin's powerdomain can have a continuous binary operation defined on it to  model choice. We show that the model constructed this way is adequate with  respect to the operational semantics. The model that we develop and our  analysis of it is closely related to the work of Abramsky and Ong on the lazy  lambda calculus.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6859,An Example of a Theorem that has Contradictory Relativizations and a Diagonalization Proof,"We construct a computable space bound $S(n)$, with $n^{2} less than S(n) less than n^{3}$ and  show by diagonalization that  DSPACE [$S(n)$] = DSPACE [$S(n)$ log $n$]. Moreover, we can show that there exists an oracle $A$ such that DSPACE  [$S(n)$] $\neq$  DSPACE$^{A}$[$S(n)$ log $n$]. This is a counterexample to the belief that is a theorem has contradictory  relativizations, then is cannot be proved using standard techniques like  diagonalization [7].",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6860,Planning and Executing Robot Assembly Strategies in the Presence of Uncertainty,"Robot control systems are subject to significant uncertainty and error.   Typical robots are also equipped with sensors-force sensors, kinesthetic  positions sensors, tactile sensors, vision, and so forth. However, these  sensors are also subject to significant uncertainty. Finally, the geometrical  models of the robot and the environment (part, obstacles, etc.) cannot be  exact-they are accurate only to manufacturing tolerances, or to the accuracy  of the sensors used to acquire the models. Uncertainty is an absolutely  fundamental problem in robotics, and plans produced under the assumption of  no uncertainty are meaningless. What is needed is a principled theory of  planning in the presence of uncertainty. Such a theory must not only be  computational, but must also take uncertainty into account a priori. In  motion planning with uncertainty, we exploit compliant motion-sliding on  surfaces-in order to effect a ""structural"" reduction in uncertainty. Such  compliant motion plans can be synthesized from a computational analysis of  the geometry of the holonomic constraints. We will present a precise framework for motion planning with uncertainty. In  particular, given geometric bounds on the uncertainty in sensing and control,  we develop algorithms for generating and verifying compliant motion strategies  that are guaranteed to succeed as long as the sensing and control  uncertainties lie within the specified bounds. The first results in this  theory begin with Lozano-Perez, Mason, and Taylor [LMT], with subsequent  contributions by Mason [MA2], Erdmann [E], Donald [D], and others. This  research has led to a theoretical computational framework for motion planning  with uncertainty, which we explore in this focused survey paper.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6861,Quantifiers and Approximation,"We investigate the relationship between logical expressibility of NP  optimization problems and their approximation properties. First such attempt  was made by Papadimitriou and Yannakakis, who defined the class of NPO  problems MAX NP. We show that many important optimization problems do not  belong to MAX NP and that in fact there are problems in P which are not is  MAXNP. The problems we consider fit naturally in a new complexity class that  we call MAX II sub 1. We prove that several natural optimization problems  are complete for MAX II sub 1 under approximation preserving reductions.   All these complete problems are non-approximable unless P=NP. This motivates  the definition of subclasses of MAX II sub 1 that only contain problems  which are presumably easier with respect to approximation. In particular,  the class that we call RMAX(2), contains approximable problems and problems  like MAX CLIQUE that are not known to be non-approximable. We prove that MAX  CLIQUE and other natural optimization problems are complete for RMAX(2). All  the complete problems in RMAX(2) share the interesting property that they  either are non-approximable or are approximable to any degree of accuracy.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6862,Sequential Estimation Techniques for Quasi-Newton Algorithms,"Let $F$ be a mapping from real $n$-dimensional Euclidean space into itself.  In terms of solving for a zero of $F$, the quasi-Newton algorithms are based  on the generalized Newton iteration $x_{k+1} = x_{k} - B_{k}^{-1}F(x_{k})$, where $\{B_{k}\}$ is a sequence of nonsingular matrices. In this thesis some  geometrical sequential estimation techniques are applied to the calculation of  a $B_{k}$ as an estimate for the Jacobian matrix $F'(x_{k})$. The resulting  estimators manifest themselves as either rank-one or rank-two, symmetric  updates for $B_{k}$, together with an update for a matrix which is descriptive  of the error $E_{k} = B_{k} - F'(x_{k})$. These updates are in fact shown to  produce optimal estimates in the sense that they minimize the set size of a  certain bound for the error matrix $E_{k}$. It is shown that the use of the new updates in conjunction with the  generalized Newton iteration produces locally and Q-superlinearly convergent  algorithms. Moreover, under the requirement that the steps taken by the  algorithm satisfy a uniform linear independence condition, it is shown that  the R-order of convergence associated with the symmetric update is at least as  large as the positive root of $t^{n+1} - t^{n} - 1 = 0$. A similar but  somewhat lower rate of convergence bound is proved for the rank-one update.  The symmetric update is implemented in an algorithm for unconstrained  optimization which employs Powell's dog-leg step direction/length strategy as  a globalization technique. Analysis is presented which, under mild conditions  on the function to be minimized, shows that the algorithm is globally and  Q-superlinearly convergent. The results of some numerical experiments are  presented which show that the algorithm's performance compares favorably with  Powell's very successful MINFA.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6863,Building Problem Solving Environments In Constructive Type Theory,"We have developed powerful environments within the Nuprl Proof Development  System for problem solving in diverse domains. Definitions, proofs, and  programs are constructed naturally and at a high-level in these environments,  with decision procedures and other tactics providing a degree of automation  approaching that found in more specialized theorem provers. Our environments  have a wide range of applications that include: Ramsey theory, hardware  specification and verification, combinational logic synthesis from proofs,  CMOS circuit synthesis from boolean expressions, recursion theory, and  partial program development. Several of these applications establish new  theorem proving paradigms. We also provide an account of rewriting in type theory and related decision  procedures. We have implemented a very general rewrite package for reasoning  about arbitrary user defined relations, and we have used this package to  construct a number of sophisticated term normalizers, simplifiers, and  equality decision procedures. We demonstrate that one of these decision  problems deciding if two terms containing otherwise uninterpreted  associative-commutative function symbols and commutative variable binding  operators are equal, is polynomially equivalent to determining if two graphs  are isomorphic.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6864,Planar Graph Coloring is Not Self-Reducible Assuming $P \neq NP$,No abstract is available.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6865,Trade-offs Between Replication and Availability in Distributed Databases,"Distributed databases are generally built on top of standard communication  facilities such as leased phone lines. Often several applications, running in  different databases, use the same network for their communication. But the  applications that run in these databases have grown increasingly more complex  and demanding in their availability requirements, often with temporal  constraints (such as real-time databases). We argue in this paper that there  is a need for dedicated communication networks designed for specific  applications. To design such networks, we argue that it is necessary to  analyze the data access patterns in the applications that run on the top of  the networks. Such analysis would give a network designer an insight into  where and how much to replicate the data in the system. Replication can  increase availability of data, but too much replication can also hamper it.  Thus, for a given application, there exists a right balance between  replication and availability. Our goal is to find this balance and show how  to design a network of the cheapest cost that achieves it. In this paper, we  take the first step towards the design problem by precisely characterizing  the trade-offs between replication and availability and suggest a network  design strategy to exploit these trade-offs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6866,Partial Traces and the Semantics and Logic of CCS-Like Languages,"We consider the theory of CCS-Like languages when partial traces (simply  finite sequences of actions that the process may perform) are the only  observation. We characterize process equivalence, giving relational, logical,  and operational definitions and showing that they coincide. This relation  is adequate for all languages defined by a class of CCS-like rules; it is  fully abstract for any language including process copying and controlled  communication poeration. We also give a complete inequational axiom system  for this notion of process equivalence for finite processes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6867,Log-Based Recovery in Asychronous Distributed Systems,"Replication has been shown to be an important tool in the design of high- performance and highly-available distributed systems. When applied to data,  however, replication significantly complicates the problem of maintaining  consistency within a system. This problem is further complicated when  repositories of the data can potentially fail and recover. In this  dissertation, we describe a log-based mechanism for restoring consistent  states to replicated data objects after failures. A variety of techniques have been proposed for implementing consistency in a  system. Most of these techniques focus on preserving a form of consistency  based on serialization of updates. Although serializable consistency is  useful for building a large number of applications, there are also many  applications that do not require the full strength of consistency that  serializability provides. For these applications, the cost of implementing  serializable consistency can be prohibitive. A number of weaker and less  expensive consistency forms have therefore been proposed for building such  applications. In this dissertation, we focus on preserving a causal form of consistency  based on the notion of virtual time. Causal consistency has been shown to  apply to a variety of applications, including distributed simulation, task  decomposition, and mail delivery systems. Several mechanisms have been  proposed for implementing causally consistent recovery, most notably those of  Strom and Yemini, and Johnson and Zwaenepoel. Our mechanism differs from  these in two major respects. First, we implement a roll-forward style of  recovery. A functioning process is never required to roll-back its state in  order to achieve consistency with a recovering process. Second, our mechanism  does not require any explicit information about the causal dependencies  between updates. Instead, all necessary dependency information is inferred  from the orders in which updates are logged by the object servers. Our basic recovery technique appears to be applicable to forms of consistency  other than causal consistency. In particular, we show how our recovery  technique can be modified to support an atomic form of consistency that we  call grouping consistency. By combining grouping consistency with causal  consistency, it may even be possible to implement serializable consistency  within our mechanism.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6868,First-Class Synchronous Operations in Standard ML,"In [Reppy88], we introduced a new language mechanism, first-class synchronous  operations, for synchronous message passing. In our approach, synchronous  operations are represented by first-class values called events. Events can be  combined in various ways, allowing a user to define new synchronization  abstractions (e.g., remote procedure call), which have equal status with the  built-in operations. This paper describes this mechanism and presents a new implementation of events as part of a coroutine package for Standard ML. The coroutine package  is written entirely in SML, using first-class continuations, and provides  very light-weight processes. First-class continuations provide a natural way  to represent events that closely follows an operational semantics for events.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6869,On Inhibition and Atomicity in Asynchronous Consistent-cut Protocols,"In this paper, we investigate the existence of non-inhibitory consistent-cut  protocols: protocols which create without interfering with the actions of  the system in which they are running. Specifically, we consider systems in  which processors have only three kinds of events: sends, receives, and  internal events (which do not involve communication with another processor).   We show that there is no non-inhibitory consistent-cut protocol for such  systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6870,Complex Matrix Factorizations with CORDIC Arithmetic,"Matrix factorizations are important in many real-time signal processing  applications. In order to improve the performance of these algorithms,  special purpose VLSI processor arrays are being developed. Recently, the  Coordinate Rotation Digital Computer (CORDIC) algorithms have been applied to  the QR Decomposition (QRD) and the Singular Value Decomposition (SVD). In  this paper, the CORDIC arithmetic algorithms are extended to deal with complex  data. Novel CORDIC VLSI architectures for the QRD of a complex matrix, the  Eigenvalue Decomposition of a Hermitian matrix, and the SVD of a complex  matrix are presented. These architectures are suitable for VLSI implementation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6871,A Stochastic Analysis of the Performance of Distributed Databases With Site and Link Failures,"A stochastic model for analyzing the performance of a distributed database is  proposed. The database is prone to site and link failures, possible leading  to a partition of the underlying communication network. The system model is  parametrized to support very general assumptions about data replication,  transaction access patterns and network connectivity. For concreteness of  analysis, a concurrency control protocol based on Thomas' Majority Consensus  protocol and the Two-Phase Commit Protocol is used. A new performance measure  called expected system degradation is proposed; this measure is a combination  of availability of data and the transaction response time; this is the first  step towards the ultimate goal of defining the notion of availability for  real-time transaction systems. The model allows a database designer to  analyse the expected system performance and choose the right input parameters  that emphasize the relative importance of availability and response times.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6872,Can LCF Be Topped? Flat Lattice Models of Typed $\lambda$-Calculus,"Plotkin, [Plo77], examines the denotational semantics of PCF (essentially  typed $\lambda$-calculus with arithmetic and looping). The standard Scott  semantics $\bigvee$ is computationally adequate but not fully abstract; with  the addition of some parallel facilities, it becomes fully abstract, and with  the addition of an existential operator, denotationally universal. We consider  carrying out the same program for $\diamondsuit$, the Scott models built from  flat lattices rather than flat cpo's. Surprisingly, no computable extension of PCF can be denotationally universal;  perfectly reasonable semantic values such as supremum and Plotkin's ""parallel  or"" cannot be definable. There is an unenlightening fully abstract extension  $\pounds_{A}$(approx), based on Godel numbering and syntactic analysis.  Unfortunately, this is the best we can do; operators defined by PCF-style  rules cannot give a fully abstract language. (There is a natural and  desirable property, operation extensionality, which prevents full abstraction  with respect to $\diamondsuit$.) However, we show that Plotkin's program can  be carried out for a non-confluent evaluator.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6873,Generalized $PQ$-trees,"We introduce a new data structure, which we call generalized $PQ$-trees  because they behave like Booth and Lueker's $PQ$-trees. Given a ground set of  $n$ elements $S$, and $A = \{A_{1},\ldots,A_{k}\}$ a collection of subsets of  $S$, generalized $PQ$-trees allow us to efficiently represent which subsets  of $S$ never partially overlap with sets in $A$. We give an $O(kn)$ time  sequential algorithm and an $O(kn)$ processor parallel algorithm for  computing the generalized $PQ$-tree. Our new data structure can be used to  speed up other researchers algorithms for recognizing interval and parity  graphs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6874,Parallel Algorithms for the Split Decomposition,"We give a new $O(n^{2})$ time algorithm for finding Cunningham's split  decomposition of an arbitrary undirected graph. We can convert this algorithm  to an $NC$ algorithm that uses only $O(n^{3})$ processors. The related  composition operation is a generalization of the modular (also called  substitution of X-join) composition. The split decomposition is useful in  recognizing special classes of graphs, such as circle graphs, which are the  intersection graphs of arcs of a circle, and parity graphs, because these  graphs are closed under the inverse composition operation. The decomposition  can also be used to find $NC$ algorithms for some optimization problems on  special families of graphs, assuming these problems can be solved in $NC$ for  the indecomposable graphs of the decomposition. A new data structure, which we call a generalized $PQ$-tree, is used to make  the algorithm efficient. Generalized $PQ$-trees make it easy to find sets that  trivially intersect (one set is contained in the other or they are disjoint)  each other. All the calculations on these trees can be done efficiently. Two other important parts of the algorithm are finding a breadth-first search  tree and performing a modular decomposition of a graph. These computations  are the bottlenecks to an efficient parallel algorithm since they are the only  parts of the algorithm where $\omega (n^{2})$ processors are required.   However, they can be performed in $O(n^{2})$ time sequentially.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6875,Static Scheduling for Dynamic Dataflow Machines,"Dataflow machines can ""unravel"" loops automatically so that many iterations  of a loop can execute in parallel. Unbounded loop unraveling can strain the  resources available on the machine and, in extreme cases, deadlock can occur  due to overcommitment of resources. Previous efforts to address this problem  have focused mainly on runtime mechanisms of debatable utility. Loop  bounding, a compile-time technique, controls parallelism by introducing  dependencies between loop iterations. The loop is given enough resources for  the concurrent execution of some number of iterations, say $k$. The $K$ + 1st  iteration uses the same resources as the first iteration and starts only  after the first iteration is complete, and so on. Thus, the granularity of  resource allocation is based on the rather arbitrary syntactic notion of a  loop iteration. In this paper, we argue that loop bounding can lead to inefficient use of  resources and propose an alternative way of compiling loops for pipelined  execution. We introduce the notion of a stage decomposition of a loop,  which defines a partition of a loop iteration into stages. We show how the  problem of choosing a stage decomposition for a particular loop can be  tackled by applying compile-time analyses and static scheduling techniques.   Such techniques have been developed for scheduling loops on very long  instruction word (VLIW) machines which, like dataflow machines, can exploit  fine-grained parallelism in programs. These analyses permit the compiler to  allocate resources according to expected patterns of usage, thus reducing  overall resource requirements. Finally, we show how our schema can be  implemented on the Monsoon dataflow machine being built at M.I.T.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6876,"Processor Efficient Parallel Algorithms for the Two Disjoint Paths Problem, and for Finding a Kuratowski Homeomorph","We give an $NC$ algorithm for finding vertex disjoint $s_{1}, t_{1}$ and  $s_{2}, t_{2}$ paths in an undirected graph $G$. An important step in solving  the general problem is solving the planar case. A new structural property  yields the parallelization, as well as a simpler linear time sequential  algorithm for this case. We extend the algorithm to the non-planar case by  giving an $NC$ algorithm for finding a Kuratowski homeomorph, and, in  particular, a homeomorph of $K_{3}, 3$, in a non-planar graph. Our algorithms  are processor efficient; in each case, the processor-time product of our  algorithms is within a polylogarithmic factor of the best known sequential  algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6877,On the Importance of Being II2-Hard,"In this column, we show how a variety of interesting results in theory of  computation all follow from a simple observation about $\prod _{2}$-complete  sets of total machines. We easily derive:  a) representation independent independence results, b) non-recursive succinctness relations between different representations  of languages, c) the existence of incomplete languages in various complexity classes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6878,Logics of Programs,None Available,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6879,Interpolating Polynomials from Their Values,"A fundamental technique used by many algorithms in computer algebra is  interpolating polynomials from their values. This paper discusses two  algorithms for solving this problem for sparse multivariate polynomials, an  updated version of a probabilistic one and a new deterministic technique that  uses some ideas due to Ben-Or and Tiwari (1988). In addition, algorithms are  presented for quickly finding points that are not zeroes of sparse  multivariate polynomials - the zero avoidance problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6880,Placing the Largest Similar Copy of a Convex Polygon Among Polygonal Obstacles,"Given a convex polygon $P$ and an environment consisting of polygonal  obstacles, we find the largest similar copy of $P$ that does not intersect  any of the obstacles. Allowing translation, rotation, and change-of-size, our  method combines a new notion of Delaunay triangulation for points and edges  with the well-known functions based on Davenport-Schinzel sequences producing  an almost quadratic algorithm for the problem. Namely, if $P$ is a convex  $k$-gon and if $Q$ has $n$ corners and edges then we can find the placement of  the largest similar copy of $P$ in the environment $Q$ in time  $O (k^{4}n \lambda_{4}(kn)$ log$n$), where \lambda_{4} is one of the  almost-linear functions related to Davenport-Schinzel sequences. If the  environment consists only of points then we can find the placement of the  largest similar copy of $P$ in time $O (k^{2}n \lambda_{3}(kn)$ log $n$).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6881,An Explicit Separation of Relativised Random and Polynomial Time and Relativised Deterministic Polynomial Time,"Inthis note, we demonstrate that a certain class of naturally occuring  problems involving an oracle are solvable in random polynomial time, but not  in deterministic polynomial time. This class of problems is especially  interesting because a very slight change in the parameters of the problem  yields one that does have a polynomial solution.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6882,Trace-Based Network Proof Systems: Expressiveness and Completeness,"We consider incomplete trace-based network proof systems for safety  properties, identifying extensions that are necessary and sufficient to  achieve relative completeness. We then consider the expressiveness required  of any trace logic that encodes these extensions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6883,TransFig: Portable Figures for TEX Version 1.4-TFX Release 4,"TransFig is a mechanism for integrating figures into TEX documents. Several  ""graphics languages"" exist which achieve such integration, but none is  widely enough used to be called a standard. TransFig's goal is to maintain the  portability of TEX documents across printers and operating environments. The  central mechanism in TransFig is Fig code, a graphics editor. TransFig  provides an automatic and uniform way to Translate Fig code into various  graphics languages and to integrate that code into a TEX document.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6884,Extending Attribute Grammar and Type Inference Algorithms,"Gated attribute grammars and error-tolerant unification expand upon the usual  views of attribute grammars and unification. Normally, attribute grammars are  constrained to be noncircular; gated attribute grammars allow fairly general  circularities. Most unification algorithms do not behave well when given  inconsistent input; the new unification paradigm proposed here not only  tolerates inconsistencies but extracts information from them. The expanded  views prove to be useful in interactive language-based programming  environments. Generalized unification allows the environment to help the user  find the sources of type errors in a program, while gated attribute grammars  allow the environment to provide an interpreter for incremental reevaluation  of programs after small changes to the code. The defining feature of gated attribute grammars is the appearance of a gate  attribute (indicating where cycle evaluation should begin and end) within  every cycle. Attributes are ordered by collapsing strongly connected  components in the dependency graph and topologically sorting the result. The  smaller dependency graph for each component (ignoring edges leading to the  gate) can be recursively collapsed to provide further ordering. use of the  evaluation order defined in this manner allows gated attribute grammars to  do without the restrictions on functions within a component needed by the  other varieties of circular attribute grammars. Initial and incremental  evaluation algorithms are given, as well as a sample grammar allowing an  editor for a small language to become an incremental interpreter. Counting unification defines unique solutions to sets of input equations that  contain conflicting type information. These solutions are derived from the  potential variable constraints implied by the input equations. For each type  variable, each branch (a portion of a constraint) is assigned a weight  indicating the number of times the input set implied such a constraint. When  the input equations are derived from the static analysis of a program, the  relative branch weights for a conflicting variable give the overall pattern  of uses of that variable and can direct attention to parts of the program that  disagree with the majority of uses. A number of error-tolerant unification  algorithms are presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6885,A Fully Abstract Semantics for a Functional Language with Logic Variables,"We present a novel denotational semantics for a functional language with  logic variables intended for parallel execution. The intuition behind this  semantics is that equations represent equational constraints on data. Thus, a  system of equations can be viewed as defining a set of possibly inconsistent  constraints. The semantics is couched in terms of closure operators on a  Scott domain. This allows one to abstract away from all the complexities  associated with operational reasoning expressed in terms of concurrent  threads of execution. We define a structural operational semantics for the  language that expresses precisely the concurrent execution model that we have  in mind. We show that the abstract denotational semantics is fully abstract  with respect to the operational semantics. This is surprising, given how very  different the two semantic descriptions are. It also shows that thinking in  terms of constraints is an accurate substitute for thinking in terms of  explicit parallel execution. The proof of full abstraction is complicated by  the fact that there are potentially infinite objects in the domain.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6886,Parallel Algorithms for the Subgraph Homeomorphism Problem,"The subgraph homeomorphism problem for a fixed graph $H$ is stated as follows:  given a graph $G$, determine whether $G$ has a subgraph homeomorphic to $H$,  and obtain it. We study the parallel complexity of this problem for various  pattern graphs $H$ and present fast $NC$ algorithms for versions of this  problem. We also present an efficient $NC$ algorithm to check if a given graph  is outer-planar and to obtain its forbidden homeomorphs $K_{4}$ or $K_{2,3}$  if it is not.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6888,Nonexpressibility of Fairness and Signaling,"In this paper, we establish new expressiveness results for indeterminate  dataflow primitives. We consider choice primitives with three differing  fairness assumptions and show that they are strictly inequivalent in  expressive power. We also show that the ability to announce choices enhances  the expressive power of two of the primitives. These results are proved using  a very crude semantics and thus apply in any reasonable theory of process  equivalence.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6889,On p-Separability,We introduce the notion of p-separability in analogy with the  recursion-theoretic notion of recursive separability. The existence of  p-inseparable sets in NP is related to structural properties of complexity  classes. Sparseness is related to p-separability and structural conditions for  the existence of sparse p-inseparable sets NP are given. Using the notion we  obtain sets hard for the $\sum_{2}^{0}$ and $\prod_{2}^{0}$ levels of the  Kleene Arithmetic Hierarchy. Some independence results are shown to follow.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6890,NC Algorithms for the Clique Separator Decomposition,"We give the first NC algorithm for finding a clique separator decomposition of  a graph, that is, a series of cliques whose removal disconnects the graph.  This algorithm allows one to extend a large body of results which were  originally formulated for chordal graphs to other classes of graphs. Our  algorithm is a parallel version of Tarjan's sequential algorithm for solving  this problem. The decomposition can also be used to find NC algorithms for  some optimization problems on special families of graphs, assuming these  problems can be solved in NC for the prime graphs of the decomposition. These  optimization problems include: finding a maximum-weight clique, a minimum  coloring, a maximum-weight independent set, and a minimum fill-in elimination  ordering. We also give the first parallel algorithms for solving these  problems by using the clique separator decomposition. Our maximum-weight  independent set alforithm applied to chordal graphs yields the most efficient  known parallel algorithm for finding a maximum-weight independent set of a  chordal graph.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6891,Using Bounded Degree Spanning Trees in the Design of Efficient Algorithms on Claw Free Graphs,"Claw-free graphs are graphs that do not have $K_{1,3}$ as an induced subgraph. Line graphs, a special case of claw-free graphs, are the intersection graphs  of edges in simple graphs. We show how to compute efficiently in parallel a  binary tree that will be a rooted spanning tree of the claw-free graph. Every  binary tree contains at least one edge whose removal partitions the tree into  two subtrees of nearly equal cardinality, and this separator can be found  efficiently in parallel. We solve problems on claw-free graphs by a  divide-and-conquer strategy. The advantage of our partition is that the  vertices in each set induce a connected subgraph. The problems are solved for  the two subgraphs, and then the results are combined to get a solution for the  entire graph. Both the problem of finding a perfect matching in claw-free graphs and the  problem of reconstructing a root graph from a line graph are amenable to this  approach. We present a nearly optimal parallel NC algorithm for computing a  perfect matching that runs in time $O(log^{2}n)$ with $O(n + m)$ processors on  an EREW PRAM. Also, we present an efficient parallel reconstruction of root  graphs form line graphs. If G = (V,E) denotes a line graph, then the algorithm  runs in $O(log\vert V \vert)$ time using $O(\vert E \vert)$ processors in the  CRCW PRAM model. It is optimal up to a polylogarithmic factor. Previously, it  was known how to reconstruct the root graph in NC using a large (though  polynomial) number of processors; this is the first algorithm that employs a  linear number of processors.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6892,On the Representation and Manipulation of Rigid Solids,"Solid modeling studies how to represent geometric properties of solids by  computer. A fundamental operation is the construction of representations of  solids. Algorithms for set ooperations construct boundary representations of  solids from boundary representations of other solids. A correct and efficient intersection algorithm for polyhedral solids that uses  boundary representations is described. A finite-precision implementation of  the slgorithm uses incidence tests that use symbolic inference in order to  limit errors due to finite-precision approximations. The incidence tests are  described and experimental evidence is presented to show that the incidence  tests are both empirically reliable and practical. The intersection algorithm uses a new boundary representation called the  Star-Edge representation. A complementation algorithm for solids that uses the  new representation is given, and an algorithm is given that uses the new  representation to determine if two boundary representations describe the same  solid. A canonical boundary representation for solids is described and used to  prove a lower bound for the same-object problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6893,"Complete, Effective and Abstract System For Reasoning About Networks of Processes",We present a complete recursive set of axioms for reasoning about networks of  bounded asynchronous processes with finite resources. We also present an  effective procedure for hiding internal channels of a network. Our processes  use finite resources and bounded asynchronous communication. Such processes  and networks can be physically realized. Our processes can be specified by  means of regular expressions and do not require the full theory of arithmetic.  The assertion language we use exploits this fact and allows us to specify all  such processes and networks and obtain a complete and effective use of  Ehrenfeucht games. An algorithm for channel hiding follows from the way these  processes can be modeled.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6894,Computing Power and Political Opportunism,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6895,A Syntactic Approach to Automatic Book Indexing,"Automatic publishing systems are now widely used to produce books and  documents of many types. As a result, large masses of text become available in  machine readable form for automatic processing. This study describes automatic  methods to generate back-of-the-book indexes, based on a syntactic analysis of  the text of book chapters followed by a phrase generation system that  identifies meaningful book indexing entries.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6896,An Efficient Algorithm for One-Step Planar Compliant Motion Planning with Uncertainty,"Uncertainty in the executin of robot motion plans must be accounted for in the  geometric computations from which plans are obtained, especially in the case  where position sensing is inaccurate. We give an $O(n^{2} log n)$ algorithm to  find a single commanded motion direction which will guarantee a successful  motion in the plane from a specified start to a specified goal whenever such a  one-step motion is possible. The plans account for uncertainty in the start  position and in robot control, and anticipate that the robot may stick on or  slide along obstacle surfaces with which it comes in contact. This bound  improves on the best previous bound by a quadratic factor, and is achieved in  part by a new analysis of the geometric complexity of the backprojection of  the goal as a function of commanded motion direction.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6897,An Improved Algorithm for Labeling Connected Components in a Binary Image,"In this note, we present an improved algorithm to Schwartz, Sharir and  Siegel's algorithm [8] for labeling the connected components of a binary  image. Our algorithm uses the same bracket marking mechanism as is used in the  original algorithm to associate equivalent groups. The main improvement of our  algorithm is that it reduces the three scans on each line required by the  original algorithm in its first pass into only one scan by using a recursive  group-boundary dynamic tracking technique, while maintaining the computation  on each pixel during scan still a constant time. This algorithm is fast enough  to handle images in real time and simple enough to allow an easy and very  economical hardware implementation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6898,Implementing Metamathematics as an Approach to Automatic Theorem Proving,"A simple but important algorithm used to support automated reasoning is called matching: given two terms it produces a substitution, if  one exists, that maps the first term to the second. In this paper the  matching algorithm is used to illustrate the approach to automating  reasoning suggested in the title. In Section 3 the algorithm is  derived and verified in the Nuprl proof development system following  exactly an informal presentation of it in Section 2. The example serves to introduce a particular automated reasoning system, Nuprl, as well as the idea of deriving programs from constructive proofs. The treatment of this example also suggests  how these systems can be soundly extended by the addition of constructive metatheorems about themselves to their libraries of results.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6899,Guaranteed-Quality Triangular Meshes,"There are a number of applications for which it is desirable to divide a given  region in the plane into nicely shaped triangles. One important such  application is the finite element method, a method widely used to obtain  approximate solutions to a wide variety of engineering problems. For this kind  of application, not just any triangulation will do; error bounds are best if  all the triangles are as close as possible to equilateral triangles.  Presently, either these triangles are produced by hand or they are produced  automatically using one of a number of heuristic techniques. For these  heuristic techniques, certain cases can require human intervention to  eliminate flat triangles. In this paper, we present an efficient new  technique (based on Delauney triangulations) for automatically producing  desirable triangulations. Unlike most previous techniques, this one comes with  a guarantee: the angles in the resulting triangles are all between 30 and 120  degrees, and the edge lengths are all between h and 2h where h is a parameter  chosen by the user. Additional useful properties include (1) the worst-case  time to produce a triangulation is linear in the final number of triangles,  and (2) the user can control the element density, producing smaller triangles  in areas where more accuracy is desired.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6900,Exploiting Fast Matrix Multiplication Within the Level 3 BLAS,"The Level 3 BLAS (BLAS3) are a set of specifications of Fortran 77 subprograms  for carrying out matrix multiplications and the solution of triangular systems  with multiple right-hand sides. They are intended to provide efficient and  portable building blocks for linear algebra algorithms on high performance  computers. We describe algorithms for the BLAS3 operations that are  asymptotically faster than the conventional ones. These algorithms are based  on Strassen's method for fast matrix multiplication, which is now recognized  to be a practically useful technique once matrix dimensions exceed about 100.  We pay particular attention to the numerical stability of these ""fast  BLAS3"". Error bounds are given and their significance is explained and  illustrated with the aid of numerical experiments. Our conclusion is that fast  BLAS3, although not as strongly stable as conventional implementations, are  stable enough to be suitable for many applications.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6901,Information Retrieval Based on Axiomatic Decision Theory,"The main objective of this paper is to establish a coherent framework for  information retrieval based on the axiomatic decision theory. In information  retrieval one has to deal with two difficult problems (knowledge  representation and query formulation), both of which are absent in  conventional database systems. It is argued that the axiomatic decision theory  provides a useful framework to study these complex issues. Two quantitative  representation systems are introduced. One is developed from the expected  utility model and the other is derived from the concepts of  evidential  reasoning. An inductive learning algorithm is suggested for constructing a  user query. The experimental results seem to provide some support for the  theoretical arguments presented here. Although the focus in this paper is mainly on information retrieval, the  current work may be viewed as a preliminary effort towards unifying symbolic  and numeric reasoning with incomplete or uncertain information.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6902,On Planar Point Matching Under Affine Transformation,,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6903,"An Architecture for General Purpose Physical System Simulation--Integrating Geometry, Dynamics, and Control","Simulation of physical systems has long been of interest to scientists and  engineers, and significant efforts have been directed toward the development  of general purpose computer aided design and analysis systems. To date,  however, success has been largely limited to the production of tools suited  only for particular aspects of design: computer aided design systems have  primarily emphasized specification of geometry; simulation systems from the  mechanical engineering field have concentrated mainly on formulation and  integration of an unchanging set of equations describing object behavior; and  work by computer graphics and animation researchers has been aimed at  producing good-looking animations without much regard for whether the  generated motions were physically realistic. Flexible systems integrating all  aspects of design and analysis have not yet been built. This thesis addresses the issues involved in developing fundamentally more  powerful simulation systems. A system architecture for general purpose  physical system simulation is proposed, and a prototype implementation, the  newton system, is described. The architecture is based on a rich model-based  object representation and provides a level of automatic analysis that  encourages the kind of experimentation necessary for successful design. In  particular, it is argued that by using geometric modeling techniques to  include a full description of object geometry, previously  difficult-to-incorporate simulation system features, such as collision  detection and resolution, can be handled much more naturally. The Newton architecture incorporates a uniform exceptional event handling  mechanism that allows the system to respond to a variety of simulation events  that necessitate modification of object behavior descriptions. Combined with a  general method for the formulation of object motion equations, the event  handling mechanism supports automatic handling of collisions, changing contact  relationships, control program state changes, and other events that can cause  discontinuities in object motions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6904,Experiments with Generalized Binary Probabilistic Independence Model,"This paper reports experiments with the generalized binary probabilistic  independence model in which more complete statistical information is used. Two  basic sets of experiments, referred to as nonpredictive and predictive, have  been performed on two standard test collections. In the nonpredictive  experiments, the complete relevance information was used to determine the  optimal performance of the model. On the other hand, in the predictive  experiments only partial relevance information was used to demonstrate the  predictive power of the model. Although a simple method for estimating the  parameters was used in the designed tests, significant improvements were  obtained for both test collections. These preliminary results suggest that  further work on the generalized model is worthwhile.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6905,On the Use of Clustered File Organization in Information Search and Retrieval,"In modern retrieval environments, collection searches are normally conducted  on-line under user control. Iterative collection searches can then be  performed where tentative queries are initially processed, to be successively  improved and refined during the search process. When searches are carried out  directly by the users, classified document organizations are especially  useful, because collection browsing becomes possible, and access is provided  to complete groups of related documents. The state-of-the-art in automatic document classification is summarized in  the present study, and evaluation data are provided to demonstrate the  effectiveness and efficiency of clustered file search operations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6906,A Note on Inverse Document Frequency Weighting Scheme,"Based on the Shannon information theory, a measure for term value is  introduced. This study is an attempt to provide a theoretical justification  for the inverse document frequency (IDF) weighting scheme. The argument  presented in this paper is somewhat different from those suggested earlier.  It is shown that IDF weights can be derived from the proposed approach by  assuming that each index term has an even distribution within a subset of  documents. A critical comment on the signal-noise ratio (S/N) weighting  method is also included.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6907,Towards a Notion of Module for Data Abstraction,"Traditionally, programming languages support data abstraction through some  kind of module construct for partitioning large systems into manageable units.  These constructs typically control access to data since program decomposition  is usually guided by information hiding. As mechanisms for encapsulating  implementations of data types, however, such constructs are too inflexible.  Substituting one implementation (module) for another, in a client, may require  the client to be revised for reasons related to representation. A more  flexible notion of module is presented that is designed solely for the  purpose of encapsulating implementations of data types. D.3 [Software]: Programming Languages; D.3.2 [Programming Languages]:  Language Classifications - applicative languages; D.3.3 [Programming  Languages]: Language Constructs - abstract data types, modules, packages;  D.3.4 [Programming Languages]: Processors - compilers; F.3 [Theory of  Computation]: Logics and Meanings of Programs; F.3.3 [Logics and Meanings of  Programs]: Studies of Program Constructs - type structure. Additional Key Words and Phrases: representation independence, modules,  functional programming, types.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6908,Formalization and Evaluation of Linear Relevance Feedback,"This study outlines an adaptive method which constructs improved query vectors  based on the user preference judgments on sample document pairs. In  particular, the user states that some documents are preferred to other  documents and the system is then expected to rank the preferred documents  ahead of the others. In the adaptive system, all needed parameter values are  provided within the model, and a solution query vector is constructed under  well defined conditions. Certain relationships between the new adaptive and the conventional relevance  feedback systems are discussed and evaluation data are provided to demonstrate  the effectiveness of the system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6909,On the Automatic Generation of Content Links in Hypertext,"Text structuring systems that provide links between text portions have been  widely proposed as aids for text preparation and text manipulation. In  principle, it is easy to follow available links between related text portions; it is much harder, however, to put in place useful links that relate document  sections with related text content. An approach is described in this note for the automatic generation of content  links based on global term and phrase matches between sentence and document  texts. Tentative evaluation data are included to demonstrate the usefulness of  the proposed procedures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6910,"Godel, von Neumann and the P=?NP Problem","In a 1956 letter, Godel asked von Neumann about the computational complexity  of an NP complete problem. In this column, we review the historic setting of  this period, discuss Godel's amazing letter and why von Neumann did not solve  the P = ?NP problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6911,The Role of Inhibition in Asynchronous Consistent-Cut Protocols,"We present results relevant to the development of consistent-cut protocols. Consistent-cut protocols are those which are based on finding a consistent  global state in an underlying distributed computation; they are used for a  variety of applications such as system checkpointing and deadlock detection.  We formally define what it means for a protocol to be non-inhibitory, which  intuitively means that it does not prevent any actions from occurring in an  underlying system computation. We prove that there is no non-inhibitory  consistent-cut protocols for FIFO systems of one message per bidirectional  channel (up to $\frac {1}{2} (n^{2} - n$, for completely connected networks).  We present two protocols, one non-inhibitory requiring up to two messages  between each pair of neighboring nodes in a network and the other inhibitory  and requiring only $3(n - 1)$ messages total. In most networks, these results  illustrate a tradeoff between the amount of necessary communication and the  willingness to inhibit actions of the underlying system. Additionally, our  inhibitory protocol also works for non-FIFO systems, thus illustrating that  the inhibitory condition is exactly what is required to develop  consistent-cut protocols for non-FIFO systems which satisfy our model.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6912,Concurrency Control for Transactions with Priorities,"Priority inversion occurs when a process is delayed by the actions of another  process with less priority. With atomic transactions, the concurrency control  mechanism can cause delays, and without taking priorities into account can be  a source of priority inversion. In this paper, three traditional concurrency  control algorithms are extended so that they are free from unbounded priority  inversion. Keywords: Priority inversion, concurrency control, real-time databases.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6913,Non-Canonical Extensions of Bottom-Up Parsing Techniques,"A bottom-up parsing technique which can make non-leftmost possible reductions  in sentential forms is said to be non-canonical. Nearly every existing parsing  technique can be extended to a non-canonical method which operates on larger  classes of grammars and languages than the original technique. Moreover, the  resulting parsers run in time linearly proportional to the length of their  input strings. Several such extensions are defined and analyzed from the points of view of  both power and decidability. The results are presented in terms of a general  bottom-up parsing model which yields a common decision procedure for testing  membership in many of the existing and extended classes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6914,The Expressive Power of Delay Operators in SCCS,"We investigate the relative expressive power of finite delay operators in  SCCS. These were introduced by Milner and by Hennessy to study fairness  properties of processes in the context of SCCS. We show that the context  sensitive delay operator introduced by Hennessy is more expressive than the  finite delay operator introduced by Milner. This result is closely related to  recent results by Panangaden and Stark on the expressive power of fair merge  in asynchronous dataflow (Kahn) networks. It indicates that the  expressiveness results obtained there are not sensitive to the precise  computational model since SCCS, unlike Kahn networks, is synchronous and  permits expansion of recursively defined processes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6915,User-System Interaction in Automatic Information Retrieval,Information retrieval activities are now routinely conducted on-line under  the control of search intermediaries or end users. Examples are presented of  advanced aids that permit the user to control the search process and obtain  improved retrieval output.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6916,Harary Networks: Connectivity for Highly Available Real-Time Distributed Databases,"A methodology, called network designing by the desirable partition, for designing Underlying communication networks for distributed databases is proposed. It exploits the fact that in most real-life databases, the data is not fully replicated, and the transactions access pattern is highly local. The methodology consists of identifying a desirable partition of the sites based on the notion of dependencies between sites; the latter is defined by the replication of data and the transaction data access patterns. A hierarchical communication network, called a Harary Network, is then constructed for the identified partition. The notion of desirability takes into account the cost of connection, and thus provides the most desirable construction for a given cost. The method is probabilistic in the sense that in presence of failures, the probability of the occurrence of the desirable partition is higher than that of all other partitions; this results in very high expected availability. It is shown that for most intuitive formulations of the problem, finding the most desirable partition is NP-Hard. However, good and often optimal approximation algorithms exist for this problem. The methodology is particularly suited for designing communication support for real-time distributed databases.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6917,The Weyl Computer Algebra Substrate,No abstract is available.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6918,On Two Different Notions of Type,No abstract is available.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6919,Schematic Modeling for Simulation of Physical Systems,"This paper proposes a method for classifying and implementing schematic  representation in multiple domains within a simulation system. Our initial  work is restricted to the modeling of rigid components for kinematic and  dynamic simulations. We hope to demonstrate that the use of abstract schematic  representation will significantly reduce the effort needed to create models of  physical systems, which will in turn greatly simplify the effective modeling  and simulation of large, complicated physical systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6920,Verification Conditions for $\omega$-Automata and Applications to Fairness,"We present sound and complete verification conditions for proving that a  program satisfies a specification definied by a deterministic Rabin  automaton. Our verification conditions yield a simple method for proving that  a program terminates under general fairness constraints. As opposed to  previous approaches, our method is syntax-independent and does not require  recursive applications of proof rules. Moreover using a result by Safra, we  obtain the first direct method for proving that a program satisfies a Buchi  automaton specification. Finally, we show that our method generalized two  earlier methods.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6921,Automatically Increasing the Fault-Tolerance of Distributed Algorithms,,,,Technical Report
oai:ecommons.cornell.edu:1813/6922,Partitioning Using PAQ,"The so-called PAQ problem is concerned with the solution of sparse systems of  linear equations $Ax=b$ using the transformation $PAQy=Pb, x=Qy$. An algorithm  is given for choosing $P$ and $Q$ to partition the matrix $A$ into its  irreducible components. A theorem on which this algorithm is based has long  been known, yet no simple, easily understood proof appears in the literature.  Such a proof is given here. Remarks are made concerning some unsolved problems  related to the PAQ problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6923,Approaches to Text Retreival for Structured Documents,"Documents such as textbooks, dictionaries, and encyclopedias are inherently  structured, in the sense that they are meant to be used selectively by  skipping from section to section instead of reading sequentially from one end  to the other. Experiments are described to provide selective reading lists  for textbook materials in answer to questions submitted by the user  population. A textbook in information science is used for experimental  purposes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6924,Compiler Parallelization of SIMPLE for a Distributed Memory Machine,"In machines like the Intel iPSC/2 and the BBN Butterfly, local memory operations are much faster than inter-processor communication. When writing  programs for these machines, programmers must worry about exploiting spatial  locality of reference. This is tedious and reduces the level of abstraction  at the which the programmer works. We are implementing a parallelizing  compiler that will shoulder much of that burden. Given a sequential, shared  memory program and a specification of how data structures are to be mapped  across the processors, our compiler will perform process decomposition to  exploit locality of reference. In this paper, we discuss some experiments in  parallelizing SIMPLE, a large scientific benchmark from Los Alamos, for the  Intel iPSC/2.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6925,Type Definitions in Polya,"The programming language Polya maintains a clear separation between a type  and its implementation through a new construct called the transform. Polya  allows user to define their own data types and transforms to implement them.  The type definition facility of Polya has capabilities not found in existing  languages; in short, it allows a more comprehensive description of the  properties that determine whether a program is well-formed. Two such  properties are the scope of variables and the bounded polymorphic nature of  some operations. One can specify the scope of any local variables that an  operation introduces and express that the well-formedness of an operation  depends on whether some overloaded function name stands for a function of a  certain type. Also novel, is the ability to define literal classes for types  and to specify both an abstract and concrete syntax for operations. With these  capabilities, it becomes possible to define the syntax of a block-structured  language within Polya itself.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6926,Simulating Synchronized Clocks and Common Knowledge in Distributed Systems,,,,Technical Report
oai:ecommons.cornell.edu:1813/6927,Parallel Resultant Computation,"A resultant is a purely algebraic criterion for determining when a finite  collection of polynomials have a common zero. It has been shown to be a  useful tool in the design of efficient parallel and sequential algorithms in  symbolic algebra, computational geometry, computational number theory, and  robotics. We begin with a brief history of resultants and a discussion of some of their  important applications. Next we review some of the mathematical background in  commutative algebra that will be used in subsequent sections. The  Nullstellensatz of Hilbert is presented in both its strong and weak forms. We  also discuss briefly the necessary background on graded algebras, and define  affine and projective spaces over arbitrary fields. We next present a  detailed account of the resultant of a pair of univariate polynomials, and  present efficient parallel algorithms for its computation. The theory of  subresultants is developed in detail, and the computation of polynomial  remainder sequences is derived. A resultant system for several univariate  polynomials and algorithms for the gcd of several polynomials are given.  Finally, we develop the theory of multivariate resultants as a natural  extension of the univariate case. Here we treat both classical results on the  projective (homogeneous) case, as well as more recent results on the affine  (inhomogeneous) case. The u-resultant of a set of multivariate polynomials is  defined and a parallel algorithm is presented. We discuss the computation of  generalized characteristic polynomials and relate them to the decision  problem for the theories of real closed and algebraically closed fields.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6928,Complexity of Finitely Presented Algebras,"An algebra $\cal A$ is finitely presented if there is a finite set G of  generator symbols, a finite set O of operator symbols, and a finite set  $\Gamma$ of defining relations $x \equiv y$ where $x$ and $y$ are well-formed  terms over G and O, such that $\cal A$ is isomorphic to the free algebra on G  and O modulo the congruence induced by  $\Gamma$. The uniform word problem, the finiteness problem, the triviality problem  (whether $\cal A$ is the one element algebra), and the subalgebra membership  problem (whether a given element of $\cal A$ is contained in a finitely  generated subalgebra of $\cal A$) for finitely presented algebras are shown to  be $\leq^{m}_{\log}$-complete for P. The schema satisfiability problem and  schema validity problem are shown to be $\leq^{m}_{\log}$-complete for NP and  co-NP, respectively, Finally, the problem of isomorphism of finitely presented  algebras is shown to be polynomial time many-one equivalent to the problem of  graph isomorphism.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6929,Flow in Planar Graphs with Vertex Capacities,"Max-flow in planar graphs has always been studies with the assumption that  there are capacities only on the edges. Here we consider a more general  version of the problem when the vertices as well as edges have capacity  constraints. In the context of general graphs considering only edge  capacities in not restrictive, since one can reduce the vertex capacity  problem to the edge capacity problem. However, in the case of planar graphs  this reduction does not maintain planarity and cannot be used. We study  different versions of the planar flow problem (all of which have been  extensively investigated in the context of edge capacities).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6930,Deterministic Simulations of Shared Memory on Bounded Degree Networks,"The Parallel Random Access Machine (PRAM) is an abstract parallel machine  consisting of a synchronous collection of $n$ processors connected to a shared  memory of $m$ cells. The essential feature of the PRAM is that the processors  can access any $n$-tuple of distinct cells in a single machine cycle. While  the PRAM is an attractive and widely used framework for the design and  analysis of parallel algorithms, it does not reflect the constraints of  realistic multiprocessors. This thesis explores the problem of efficient  deterministic simulations of PRAM computations on bounded degree networks of  processors, a model of parallel machines closer to what can be built in  practice. It is shown that an arbitrary step of a PRAM with $n$ processors and  $m \geq n$ cells of shared memory can be simulated in $O$(log($(m/n)$ log $n$/log log $n$ + log $n$ log log $n$ (log log $(m/n)$ -  log log log $n$)) time in the worst-case on an $n$-node bounded degree network with a particular  expander-based structure. This simulation is more efficient than all deterministic simulations  previously known both with respect to time and space. In the case where $m/n$  is polylogarithmic in $n$, the worst-case time to simulate a single PRAM step  is at most $O$(log $n$ log log $n$) which is within a factor of $O(log log  $n$ the diameter of the network. The space requirements for our algorithm are  at most $O$($m$(log $(m/n))^{3})$ overall.  The simulation may also be  adapted to run on to an $n$-processor augmented mesh-of-trees architecture  with a running time of  $O$ (log $n$ log log $n$ (log log $(m/n)$ - log log log $n$) + log $(m/n))$ Overall, these results suggest that, in principle at least, it is feasible to  provide the abstraction of a shared memory on distributed models of parallel  computation with only modest degradation in performance in the worst case.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6931,On Laziness and Optimality in Lambda Interpreters: Tools for Specification and Analysis,"In this paper, we introduce a new formal system, $\Lambda CCL$, based on  Curien's Categorical Combinators [Cur86a]. We show that $\Lambda CCL$ has  properties that make it especially suitable for analysis and implementation  of a wide range of $\lambda$-reduction schemes using shared environments,  closures, or $\lambda$-terms. In particular, the term structure of  $\Lamda CCL$ is very closely related to the structure of existing abstract  machines for $\lambda$-reduction. $\Lambda CCL$ is powerful enough to mimic  arbitrary (strong) reduction in the $\lambda$-calculus, yet in contrast to  the systems in [Cur86a] it is also confluent (on ground terms).As an example  of the practical utility of this formalism, we use it to specify a simple  lazy interpreter for the $\lambda$-calculus, whose correctness follows  trivially from the properties of $\LambdaCCL$. We then describe a labeled variant of $\Lambda CCL, \Lambda CCL^{L}$, which  can be used as a tool to determine the degree of ""laziness"" possessed by  various $\lambda$-reduction schemes. In particular, $\Lambda CCL^{L}$ is  applied to the problem of optimal reduction in the $\lambda$-calculus. A  reduction scheme for the $\lambda$-calculus is optimal if the number of redex  contractions that must be performed in the course of reducing any  $\lambda$-term to a normal form (if one exists) is guaranteed to be minimal.  Results of Levy [Lev78, Lev80] showed that for a natural class of reduction  strategies allowing shared redexes, optimal reductions were, at least in  principle, possible. He conjectured that an optimal reduction strategy might  be realized in practice using shared closures and environments as well as  shared $\lambda$-terms. However, using $\Lambda CCL^{L}$, we show that the  sharing allowed by environments and closures in $\Lambda CCL$ as implemented  using standard term graph-rewriting techniques [BvEG$^{+}$87] is insufficient  to implement optimal reduction.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6932,A Globally and Superlinearly Convergent Algorithm for Convex Quadratic Programs with Simple Bounds,"We present a globally and superlinearly convergent algorithm for solving  convex quadratic programs with simple bounds. We develop our algorithm using a  new formulation of the problem: the minimization of an unconstrained piecewise  quadratic function that has the same optimality conditions as the original  problem. The major work at each iteration is the Cholesky factorization of a  positive definite matrix with the size and structure of the Hessian of the  quadratic. Hence our algorithm is suitable for solving large sparse problems  and for implementation on parallel computers. We implemented our algorithm and  tested it on a sequential computer on a variety of dense problems, and we  present numerical results which show that our algorithm solves many problems  quickly. Keywords: quadratic programming, interior point methods, simple bounds, box  constraints, large sparse minimization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6933,Incremental Attribute Evaluation and Multiple Subtree Replacements,"The standard model for incremental attribute evaluation allows single subtree  replacements followed by attribute reevaluation to restore consistency to a  derivation tree. This thesis advocates an extended model that allows multiple  subtree replacements. A static (tree-walking) algorithm for performing  incremental updating after such changes is developed. The algorithm cannot  be used with all attribute grammars, but is restricted to grammars contained  in the new class of ""globally partitionable attributer grammars"" (GPAGs). A  test for determining whether an attribute grammar is GPAG is described. The multiple subtree replacement algorithm (GPAG-evaluate) in this thesis  improves on two shortcomings of existing algorithms. First, many evaluators  have a running time that depends linearly on the size of the derivation tree  of on the number of concurrent subtree replacements. GPAG-evaluate has a  running time of $O$(log $n \cdot$ |AFFECTED|), where $n$ is the number of  nodes in the derivation tree and AFFECTED is the set of attributes needing  reevaluation. Second, experience with incremental, attribute grammar-based  environments demonstrates that dynamic evaluators are noticeably slower than  static evaluators because they require time-consuming data structure  manipulations. Most existing algorithms for multiple subtree replacements are  dynamic, but GPAG-evaluate is static. A second problem treated in this thesis is asynchronous subtree replacements,  that is, allowing changes to be made while propagation continues after  previous changes. A method for analyzing the efficiency of asynchronous  subtree replacement algorithms is presented. An asynchronous evaluator  (ASYNCH-evaluate) is described that, like GPAG-evaluate, guarantees that no  attributes will be evaluated unnecessarily. Under some restrictions,  ASYNCH-evaluate is as efficient as GPAG-evaluate. In particular, propagation  in trees containing dynamically generated, nonlocal dependency edges can be  supported. Both GPAG-evaluate and ASYNCH-evaluate must find lowest common ancestors of  nodes in a tree where subtree replacements were made. A simple technique  performs this operation in time $O(n)$. To make the evaluators more  efficient, this thesis describes an algorithm that uses self-adjusting binary  trees to perform the necessary operations in amortized $O$(log $n$) time.  These operations are not restricted to attributed derivation trees, but can  be used for any application using trees.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6934,Time and Message Efficient Reliable Broadcasts,No abstract is available.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6935,Provably Good Approximation Algorithms for Optimal Kinodynamic Planning for Cartesian Robots and Open Chain Manipulators,"We consider the following problem: given a robot system, find a minimal-time  trajectory from a start state to a goal state, while avoiding obstacles by a  speed-dependent safety-margin and respecting dynamics bounds. In [CDRX] we  developed a theoretical, provably good approximation algorithm for the  minimum-time trajectory problem for a robot system with decoupled dynamics  bounds (e.g. a point robot in). This algorithm differs from previous work in  three ways. It is possible (1) to bound the goodness of the approximation by  an error term $\epsilon$; (2) to polynomially bound the computational  complexity of our algorithm; and (3) to express the complexity as a polynomial  function of the error term. Hence, given the geometric obstacles, dynamics  bounds, and the error term $\epsilon$, the algorithm returns a solution that  is $\epsilon$-close to optimal and requires only a polynomial  (in ($\frac{1}{\epsilon}$)) amount of time. We extend the results of [CDRX] in two ways. First, we reanalyze the [CDRX]  algorithm for robots with decoupled dynamics bounds. We halve the exponent in  the polynomial bounds and prove a better approximation accuracy. These new  results indicate that an implementation of the theoretical algorithm could be  reasonable. We report on a preliminary implementation of the extended  algorithm and experiments. Second, we extend [CDRX] to $d$-link, revolute-joint 3D robots will full  rigid body dynamics. Specifically, we first prove a generalized trajectory- tracking lemma for robots with coupled dynamics bounds. Then, using this  result we describe polynomial-time approximation algorithms for Cartesian  robots obeying $L_{2}$ dynamics bounds and open kinematic chain manipulators  with revolute and prismatic joints; the latter class includes most industrial  manipulators. We obtain a general $O(n^{2}$(log$n$) ($\frac{1}{\epsilon})^{6d-1})$ algorithm, where $n$ is the geometric  complexity.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6936,Parallel Algorithms for Intersection Graphs,"Intersection graphs have often been used to model special structure in graph  problems for both practical and theoretical reasons. Often problems can be  solved efficiently for a restricted class of graphs that are provably hard for  graphs in general.  In this thesis, we examine parallel (i.e. $NC$)  algorithms for exploiting the special structure of different types of  intersection graphs to solve common graph problems. First, we show how to  recognize whether a graph belongs to one of the special families of  intersection graphs. Only after this has been done can we take advantage of  the properties of a class of intersection graphs. Let $\cal F$ be a family of nonempty sets. Then the intersection graph of  $\cal F$ is obtained by representing each set in $\cal F$ by a vertex and  connecting two vertices if and only if their corresponding sets have a  nonempty intersection. In this dissertation, several types of intersection  graphs will be examined, among them interval, comparability, chordal, path,  and circle graphs. Interval and comparability graphs arise often when solving  scheduling problems. Chordal graphs have applications in solving sparse  systems of linear equations and in relational database theory.  Each of these classes of intersection graphs is closed under a natural graph  composition operation, namely one of modular composition, clique  identification, and split composition. In this thesis, we show that the  number of intersection representations for a graph in one of these classes  depends on how the graph was composed from indecomposable graphs. Also, we  show how to efficiently decompose any graph (i.e. perform that inverse of the  above composition operations) in parallel. Often if we can solve a problem  efficiently on the indecomposable pieces of a graph, then we can solve this  same problem efficiently on the graph itself in parallel. Thus we can extend  many of our results on special classes of intersection graphs to more general  classes of graphs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6937,Mathematical Questions in Robotics,No abstract is available.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6938,Preconditioning for Boundary Integral Equations (Preliminary Version),"We propose new classes of preconditioners for the linear systems arising from a boundary integral equation method. The problem under consideration is Laplace's equation in three dimensions. The system arising in this context is dense and unsymmetric. Our preconditioners, which are based on solving small linear systems at each node, reduce the number of iterations in some cases by a factor of 20. Two iterative methods are considered: conjugate gradient on the normal  equations and GMREES of Saad and Shultz. For a simple model problem,  we demonstrate the exact relationship between the preconditioners  and the resulting condition number of the preconditioned system is decreased by a factor asymptotically greater than any constant.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6939,Quadratic Programming is in NP,"Quadratic programming is an important example of optimization with applications to engineering design, coombinatorical optimization,  game theory, and economics.  Garey and Johnson [1979] state that  quadratic programming is NP-hard. In this report we show that it  lies in NP, thereby proving that it is NP-complete.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6940,Limit Operators and Convergence Measures for $\omega$-Languages with Applications  to Extreme Fairness,"Methods of program verification for liveness and fairness rely on measuring  ""progress"" of finite computations towards satisfying the specification.  Previous methods are based on explaining progress in terms of well-founded  sets. These approaches, however, often led to complicated transformations or  inductive applications of proof rules. Our main contribution is a simpler measure of progress based on an ordering  that is not well-founded. This ordering is a variation on the Kleene-Brouwer  ordering on nodes of a finite-path tree. It has the unusual property that for  any infinite ordered sequence of nodes, the liminf of the node depths  (levels) is finite. This novel view of progress gives a precise mathematical characterization of  what it means to satisfy very general program properties. In particular, we  solve the problem of finding a progress measure for termination under extreme  fairness.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6941,The Inhibition Spectrum and the Achievement of Causal Consistency,"We consider the problem of distinguishing causally-consistent global states  in asynchronous distributed systems. Such states are fundamental to  asynchronous systems, because they correspond to possible simultaneous global  states; their detection arises in a variety of distributed applications,  including global checkpointing, deadlock detection, termination detection, and  broadcasting. We consider a spectrum of protocol capabilities based on the  type of inhibition that occurs, i.e. the extent to which the protocol delays  events of the underlying system. For the first time we distinguish local  versus global inhibition and prove fundamental relationships between  these concepts and determining causally-consistent states. In local  inhibition, processors only delay events until they have performed some  number of local actions; in global inhibition, they delay events while  waiting for some communication from other processors. Based on a variety of  system and protocol characteristics, including the ability to locally or  globally inhibit particular types of events, we give several new  impossibility results and examine some existing protocols. We are then able  to present a thirty-six-case summary of protocols and impossibility results  for the determination of causally-consistent states as a function of those  characteristics. In particular, we demonstrate that local inhibition is  necessary and sufficient to solve this problem for general FIFO systems,  while global send inhibition is necessary for general non-FIFO systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6942,An Introduction to Proofs of Program Correctness for Teachers of College-Level Introductory Programming Courses,No abstract is available.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6943,ISIS and META Projects: Progress Report,No abstract is available.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6944,An Efficient Algorithm for Nonlinear Minimax Problems,We present a new method for solving a nonlinear minimax problem. This new  algorithm exploits the structure and characterisation of the solution  whenever possible. The exploitation is based on the results that have been  established in [13]. The algorithm is globally convergent with a superlinear  convergence rate. Numerical results indicate the efficacy of the new method.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6945,A Computer Science View Obtained by Automatic Document Processing,"Automatic document classification techniques have been widely advocated for  the study of various fields of learning, the identification of individual  research topics and of influential contributors in a given field, and for  information storage and retrieval purposes. Several thousand research documents in computer science are automatically  classified in the present study, leading to the generation of a taxonomy  which reflects the state of computer science as of 1974. The popularity of  various subject areas in the field is assessed, and the clustering  characteristics of particular document classes and authors is given.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6946,Convergence Measures,"General methods of verification for programs defining infinite computataions  rely on measuring progress or convergence of finite computations towards  satisfying the specification. Traditionally, progress is measured using  well-founded orderings, but this often involves syntactic transformations. Our main result is that program verification can take place by direct  measurement of convergence for programs that are analytic ($\sum^{1}_{1}$)  sets and specifications that are coanalytic ($\prod^{1}_{1}$) sets. We use  orderings that are not well-founded, but that ensure well-foundedness of  limits of finite trees. Our results can also be seen as a new approach to parts of descriptive set  theory. In fact, Souslin's Theorem-that every set in $\sum^{1}_{1} \cap  \prod^{1}_{1}$ is Borel-is a simple corollary of our main result.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6947,A Comparison of Term Value Measurements for Automatic Indexing,"A number of automatic theories have been proposed over the last few years  leading to the assignment of significance values to linguistic entities in  accordance with their importance for purposes of content representation.  Among these are methodologies based on decision theory, information theory,  communication theory, vector space transformation and others. An attempt is made to compare these theories by exhibiting the formal  frequency characteristics which underlie them. The effectiveness of the  various approaches is also evaluated in experimental situations by using   collections of documents in the areas of aerodynamics, medicine and world  affairs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6948,Planar Sliding With Dry Friction 1: Limit Surface and Moment Function,"We present two geometric descriptions of the net frictional force and moment  between a rigid body and a planar surface on which it slides. The limit  surface LS, from classical plasticity theory, is the surface in load space  which bounds the set of all possible frictional forces and moments that can  be sustained by the frictional interface. Zhukovskii's moment function is the  net frictional moment about the body's instantaneous center of rotation (COR)  as a function of its location. Both of these descriptions implicitly contain  the full relation between slip motion and frictional load. While Zhukovskii's  moment function applies only to ordinary isotropic Coulomb friction, the  limit surface applies to a wider class of friction laws that includes, for  example, contact mediated by massless rigid wheels. Both the limit surface  and the moment function can be used to deduce results concerning the motion  of sliding rigid bodies.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6949,Planar Sliding With Dry Friction 2: Dynamics of Motion,"Some problems in the dynamics of sliding of planar rigid bodies are treated  by geometric methods based on the limit surface description of friction  (Goyal, Ruina, Papadopoulos [1990]). The problems we consider, where the  normal force is known a priori, have unique solutions although the friction  force (and torque) may be a discontinuous function of the direction of  motion. When a freely sliding object comes to rest it always does so with one  of several definite ratios of translation to rotation. These special  generalized velocity directions, termed eigen-directions, depend on the  friction law used, the contact pressure distribution and the mass  distribution. The eigen-directions correspond to local extrema of the  generalized frictional load |P| on the limit surface, i.e. to direction in  load space where P is parallel to the generalized motion direction q. For  most objects, if the radius of gyration is sufficiently larger than the  radius of the contact region final motion is always pure rotation about the  center of mass; if the mass distribution is sufficiently central the final  motion is a pure translation. A simple model of a car with locked rear wheels  shows the effect of speed and orientation on skid stability at finite speeds.  Sliders have a propensity to rotate about points of support.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6950,"Brown's Method and Some Generalizations, With Applications to Minimization Problems","Newton's method attempts to find a zero of $f \in C^{1}(IR^{n})$ by taking a  step which is intended to make all components of $f$ vanish at once. In this  respect Newton's method processes the components of $f$ in parallel.  Contrasting to this, Brown's method and the generalizations thereof considered  in this thesis process the components of $f$ serially, one after another. One  major iteration of these methods may be described as follows: given the  starting point (i.e. current major iterate) $y_{0}$, linearize the first  component $f_{1}$ of $f$ at $y_{0}$ and find a point $y_{1}$ in the $n-1$  dimensional hyperplane $H_{1}$ on which this linearization vanishes; in  general, having found a point $y_{k} (1 \leq k less than n)$ in the $n-k$ dimensional  hyperplane $H_{k}$ on which the heretofore constructed linearizations vanish,  restrict $f_{k+1}$ to $H_{k}$, linearize this restriction at $y_{k}$, and find  a point $y_{k+1}$ in the $n-(k+1)$ dimensional hyperplane $H_{k+1}$ on which  this linearization vanishes; stop when $Y_{n}$ has been found and let $y_{n}$  be the next major iterate. When $f$ is a general nonlinear function and finite  differences are used to construct the linearizations, this approach must do  work equivalent to approximating only about half the components of $f'$ and  thus requires only about half as many function evaluations per major  iteration  as the corresponding finite difference Newton's method, while still  enjoying the same rate of local convergence.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6951,Optimal Enclosure Problems,"We consider the following ""fence enclosure"" problem: Given a set $S$ of $n$  points in the plane with values $v_{i} \geq 0$, we wish to enclose a subset  of the points with a fence (a simple closed curve) so as to maximize the  ""value"" of the enclosure. The value of the enclosure is defined to be the  sum of the values of the enclosed points minus the cost of the fence. We  consider various versions of the problem, such as allowing $S$ to consist of  points and/or simple polygons. Other versions of the problems are obtained  by restricting the total amount of fence available and also allowing the  enclosure to consist of up to $K$ connected components. We show that the  problem for a bounded length fence is $NP$-complete . Additionally we provide  polynomial-time algorithms for many versions of the fence problem when an  unrestricted amount of fence is available. When the set $S$ consists of  points and the fence is unrestricted in length we solve the problem via an  $O(n^{3})$ time sweep-line algorithm; we give an alternative $O(n^{3})$ time  algorithm based on finding shortest paths in directed graphs, and generalize  it to handle various cases in which $S$ is a set of polygons. When $K greater than 1$  components are permitted we obtain a polynomial-time algorithm (for  consistent $K$).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6952,Determining Frictional Inconsistency for Rigid Bodies is NP-Complete,"The computational complexity of computing the forces between bodies in  contact is presented. The bodies are restricted to be perfectly rigid bodies  that contact at finitely many points. It has been known for some time that  under the Coulomb model of friction, some configurations of bodies are  inconsistent; that is, no contact forces satisfying the constraints of the  Coulomb friction model exist for the configuration. The main result of this  paper is a proof that determining if a configuration is inconsistent is an  NP-complete problem. An immediate corollary of this proof is that computing  the contact forces for a configuration of bodies is NP-hard. Computing  contact forces remains NP-hard even if configurations are restricted to be  consistent.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6953,Approaches to Global Text Analysis,"The current approaches to the analysis of natural language text are not  viable for documents of unrestricted scope. A global text analysis system is  proposed designed to identify homogeneous text environments in which the  meaning of text words and phrases remains unambiguous, and useful term  relationships may be automatically determined. The proposed methods include  document clustering methods, as well as comparisons of local document  excerpts in specified global contexts, leading to structured text  representations in which similar texts, or text excerpts, are appropriately  linked.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6954,Parallelizing Programs with Recursive Data Structures,"Interference estimation is a useful tool in developing parallel programs  and is a key aspect of automatically parallelizing sequential programs.   Interference analysis and disambiguation mechanisms for programs with simple  data types and arrays have become a standard part of parallelizing and  vectorizing compilers. However, efficient and implementable techniques for  interference analysis in the presence of dynamic data structures have yet to  be developed. This thesis addresses the problem of estimating interference and parallelizing  programs in the setting of an imperative language that supports dynamic data  structures. By focusing on analysis methods for recursively defined pointer  data structures such as trees and DAGs, we have developed efficient and  implementable interference analysis tools and parallelization techniques. The interference analysis methods are based on estimating the relationships  between accessible nodes in a data structure. We define a data abstraction  for estimating relationships that leads to an efficient interference  analysis. Analysis functions are provided for SIL, a simple imperative  language that includes conditionals, loops and recursive procedures. The  analysis is proven sound with respect to the standard semantics for SIL.  Based on the interference analysis tools, a collection of parallelization  techniques are developed and the coarse-grain techniques are used to develop  a simple system for parallelizing programs for a shared memory machine. The  analysis techniques and parallelization system have been implemented, and  examples illustrating the methods are provided.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6955,Interactive Query Formulation and Feedback Experiments in Information Retrieval,"The effective use of information retrieval systems by end-users has been  limited by their lack of knowledge on the particular organization of the  databases searched and by their limited experience on how to formulate and  modify search statements. This thesis explores and evaluate two mechanisms  to improve retrieval performance by end-users. The first mechanism complements the formulation of a query by allowing users  to interactively add term phrases. These phrases are generated either from  the query text of from known relevant documents. This addition of term  phrases to a query is suggested by the term discrimination model as a  precision enhancement device. An interactive front-end for the SMART  information retrieval system was developed to perform the interactive  experiments needed to evaluate different phrase addition strategies. The second aspect of retrieval improvement studied is the evaluation of two  database organizations that can be used to obtain new relevant documents by  looking in the neighborhood of known relevant documents, browsing. Browsing  in cluster hierarchies and nearest-neighbor networks is compared to relevance  feedback in non-restrictive experiments. The results obtained for the phrase addition methodology showed that simple  non-interactive addition of phrases can perform as well as interactive  addition. Even an optimal selection of the phrases based on the relevant  documents not yet retrieved, did not significantly improve performance over  simply adding all the phrases generated. Many useful phrases are not selected  by users because they look like random association of terms. The usefulness  of these phrases comes from the fact that either they are pieces of larger  (semantically meaningful) phrases, or they are made up of local synonyms  specific to the document collection used. The browsing experiments in cluster hierarchies and nearest-neighbor networks  showed that the second organization consistently performs better than  relevance feedback in different collections. Cluster browsing is more  dependent on the characteristics of the collections; but when the  circumstances are favorable, cluster browsing can produce larger improvements  on retrieval that network browsing. Retrieval in both structures is much  faster than relevance feedback since only a small portion of the database  needs to be inspected.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6956,Directory Design and Record Allocation for List and Cluster Files,"Most file organizations for on-line econdary key retrieval consist of two  subcomponents - a structural file and a data file. The structural file  provides, a physical access path in the data base for each query, so that  searches can be restricted to small portions of the data file. The data file  contains the data records where information is stored. Hence, the file design  problem consists of (1) an efficient design of the structural file, and (2)  an allocation of data records in the data file so that a given set of data  records can be jointly retrieved at mimimum cost. List structure organizations  and clustered organizations are shown to be important structures for secondary  key retrieval. This thesis studies the design aspects of the structural and  data files for both of the above organizations. The most popular list structure files are the inverted list and the multilist  organizations. It is shown that either organization is a special case of a new  class of hybrid list organizations. File elements in this class are  characterized by a list length parameter $\cal l_{th}$, and a list is stored  as an inverted list or as a multilist depending on whether its length is  larger than $\cal l_{th}$ or not. Analytical and simulation results indicate  that neither a pure inverted list organization nor a pure multilist  organization is normally the best choice for all elements in the class. A new method is also introduced for the structure of combined indices for list  structure files. A combined index is created only if its component keys  co-occur frequently in the queries. Experimental results show that such  combined indices do improve the search performances for both inverted list and  multilist organizations. Search methods and physical implementations of clustered organizations are  discussed. The balancing of cluster trees is shown to be an important concept.  A search model is established to obtain optimal branching ratios for cluster  trees. The optimal branching ratio is seen to be dependent on certain  statistical characteristics of the data base. The last part of the thesis concerns itself with the arrangement of records in  the dataa file. The data records are assigned to blocks in the disk like  devices. The goal is to minimize the average number of block accesses in  processing the query set in the system. This problem turns out to be a  polynomial complete problem. Heuristic algorithms are therefore used for the  record block assignment. Experimental results show that a record organization  produced by the heuristic algorithms is more efficient than a random  assignment of records to the blocks.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6957,Structural Complexity Theory: Recent Surprises,This paper reviews the impact of some recent results on the research  paradigms in structural complexity theory.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6958,On Computing Boolean Connectives of Characteristic Functions,"We study the existence of polynomial time Boolean connective functions for  languages. A language $L$ has an AND function if there is a polynomial time  $f$ such that $f(x,y) \in L \Longleftrightarrow x \in L$ and $y \in L$. $L$  has an OR function if there is a polynomial time $g$ such that  $g(x,y) \in L \Longleftrightarrow x \in L$ or $y \in L$. While all NP-complete  sets have these functions, we show that Graph Isomorphism, which is probably  not complete, also has them. We characterize the complete sets for the  classes $D^{P}$ and $P^{NP[O(log n)]}$ in terms of AND and OR, and we relate  these functions to the structure of the Boolean hierarchy and the query  hierarchies. We show that the sets that are complete for levels above the  second level of the Boolean hierarchy do not have AND and OR unless the  polynomial hierarchy collapses. We show that most of the structural  properties of the Boolean hierarchy and query hierarchies depend only on the  existence of AND and OR functions for NP-complete sets.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6959,A Quadratically-Convergent Algorithm for the Linear Programming Problem with Lower and Upper Bounds,"We present a new algorithm to solve linear programming problems with finite  lower and upper bounds. This algorithm generates an infinite sequence of  points guaranteed to converge to the solution; the ultimate convergence rate  is quadratic. The algorithm requires the solution of a linear least squares  problem at each iteration - it is similar in this respect to recent interior  point and ""Karmarkar-like"" methods. However, the algorithm does not require  feasibility of the iterates; instead, monotonic decrease of an augmented  linear $l_{1}$ function is maintained. A penalty parameter is not required.  This method is particularly attractive for large-scale problems in that the  number of iterations required to obtain high accuracy is relatively  insensitive to problem size and is typically quite small. We provide results  of numerical experiments.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6960,Full Abstraction and Fixed-Point Principles for Indeterminate Computation,"Recently, there has been much interest in the problem of finding semantic  models for various kinds of concurrent systems. A common property of  concurrent systems is indeterminate behavior, either because of unpredictable  interactions between processes, or because of abstractions removing the  temporal details of the interaction. As a result, the study of the semantics  of indeterminacy is necessary and important to the understanding of  concurrency. The goal of any semantic model is that is capture our intuitions  about the operational behavior of the underlying system and aid in our  reasoning about it. Two properties of semantic models that we find useful in  achieving this goal are full abstraction and fixed-point principles. In this  thesis we investigate the problem of finding semantic descriptions with these  properties for indeterminate systems. We begin by looking at a simple imperative language containing unbounded  indeterminacy, based on one studied by Apt and Plotkin. We use  category-theoretic techniques to develop a fixed-point semantics that, while  not fully abstract, reduces to a fully abstract semantics via a simple  abstraction functor. We then concentrate on the more general setting of dataflow networks and the  hierarchy of indeterminate merge primitives. We show that the straighforward  generalization of Kahn's semantics based on the input-output relations fails  to be compositional for any class of indeterminate dataflow networks, thereby  providing a model considerably more general than Kahn's. This generalization has the drawback that it does not have a simple  fixed-point principle. We proceed to study a class of networks that models  purely internal indeterminacy, called oraclizable networks, and show that for  this class a generalization of Kahn's semantics to sets of functions is both  fully abstract and has a natural fixed-point principle. We also show that the  oraclizable networks are in fact universal for this representation. Finally,  we use this representation to compare the class of oraclizable networks to  other classes, and discover new relations among the classes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6961,A Global and Quadratically-Convergent Method for Linear $L_{\infty}$ Problems,We propose a new global and quadratically convergent algorithm for the linear  $l_{\infty}$ problem. This method works on the piecewise $l_{\infty}$ problem  directly by generating descent directions - via a sequence of weighted least  squares problems - and using piecewise linear linesearches to ensure a  decrease in the $l_{\infty}$ function at every step. We prove that ultimately  full Newton-like steps are taken where the Newton step is based on the  complementary slackness condition holding at the solution. Numerical results  suggest a very promising method; the number of iterations required to achieve  high accuracy is relatively insensitive to problem size.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6962,Real-Time Robot Motion Planning Using Rasterizing Computer Graphics Hardware,"We present a real-time robot motion planner that is fast and complete to a  resolution. The technique is guaranteed to find a path if one exists at the  resolution, and all paths returned are safe. The planner can handle any  polyhedral geometry of robot and obstacles, including disjoint and highly  concave unions of polyhedra. The planner uses standard graphics hardware to rasterize configuration space  obstacles into a series of bitmap slices, and then uses dynamic programming  to create a navigation function (a discrete vector-valued function) and to  calculate paths in this rasterized space. The motion paths which the planner  produces are minimal with respect to an $L_{1}$ (Manhattan) distance metric  that includes rotation as well as translation. Several examples are shown illustrating the competence of the planner at  generating planar rotational and translational plans for complex two and  three dimensional robots. Dynamic motion sequences including complicated and  non-obvious backtracking solutions, can be executed in real time.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6963,A Completeness Theorem for Kleene Algebras and the Algebra of Regular Events,"We give a finite axiomatization of the algebra of regular events involving  only universal Horn formulas.  Unlike Salomaa's axiomatizations, ours is  sound for all interpretations over Kleene algebras.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6964,On the Structure of Uniquely Satisfiable Formulas,"This paper presents some new results on the computational complexity of the  set of uniquely satisfiable Boolean formulas (USAT). Valiant and Vazirani  showed that USAT is complete for the class $D^{P}$ under randomized  reductions. In spite of the fact that the probability bound of this reduction  is low, we show that USAT captures many properties possessed by $D^{P}$  many-one complete sets. We show that the structure of USAT can affect the  structure of $D^{P}$ and the entire Polynomial Hierarchy (PH) as well. That is, 1. if USAT $\equiv^{P}_{m} \overline{USAT}$, then $D^{P}$ = co-$D^{P}$ and  PH collapses. 2. if USAT $\in$ co-$D^{P}$, then PH collapses. 3. if USAT is closed under disjunctive reductions, then PH collapses. The third result implies that the probability bound in the Valiant-Vazirani  reduction cannot be amplified by repeated trials unless the Polynomial  Hierarchy collapses. These results show that even sets complete under  ""weak"" randomized reductions can capture properties of many-one complete  sets.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6965,Text Linking and Retrieval Experiments for Textbook Components,"Experiments are described designed to retrieve individual paragraphs of  textbook material in answer to user-submitted queries. The retrieval  strategies are based on the global comparison of paragraph texts, as  well as on the local processing of text sentences. Furthermore, the  retrieved items may be freely chosen, or may alternatively be restricted  to certain areas in a clustered arrangement of book paragraphs. The  retrieval results indicate that high retrieval values are obtainable for  the more refined retrieval strategies, ranging between 0.70 and 0.80 in  search precision.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6966,On Valid and Invalid Methodologies for Experimentala Evaluations of EBL,"A number of experimental evaluations of explanation-based learning (EBL) have  appeared in the literature on machine learning. Closer examination of  experimental methodologies used in the past reveals certain methodological  flaws that call into question the conclusions drawn from these experiments.  This paper illustrates some of the more common methodological problems,  proposes a novel experimental framework for future empirical studies of EBL,  and presents an example of an experiment performed within this new framework.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6967,On Large Scale Planar Manipulation,No abstract is available.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6968,"Aspects of the P-Norm Model of Information Retrieval: Syntactic Query Generation, Efficiency, and Theoretical Properties","A practical information retrieval system must be easy to use by untrained  users, and it must provide prompt responses to a user's search requests. In  this thesis, these practical aspects of the p-norm model of information  retrieval are explored. In addition, a study of theoretical properties of the  p-norm model is presented. A syntactic method for generating p-norm queries from parse trees generated  by the PLNLP syntactic analyzer is presented. The effectiveness of the syntactically generated queries is shown to be comparable to the effectiveness of manually constructed queries, and much better than that of  statistically generated queries. The efficiency of a p-norm retrieval is significantly improved with a new  p-norm retrieval algorithm which evaluates the entire document collection in  one recursive traversal of the query tree. This algorithm is compared against  the straightforward algorithm, which requires a traversal of the query tree  for each document that is evaluated. The new algorithm is shown to be better both asymptotically and experimentally. The infinity-one model is introduced as a means of approximating the p-norm  model without requiring exponentiation. Experimental results show that  infinity-one retrieval is essentially as effective as p-norm retrieval, but  much faster. List pruning methods for further efficiency improvements are also introduced and are shown to reduce retrieval time significantly without  affecting the precision of top-ranked documents. The retrieval time of the  infinity-one model with list pruning is shown to be comparable to that of  pure Boolean retrieval. A theoretical study is also presented in which certain Boolean algebra properties, such as associativity, are shown to be unsatisfiable by any  extended Boolean system with weak operators. The p-norm model is shown to  satisfy all those properties that can be satisfied. In addition, the p-norm  model is evaluated with respect to the Waller-Kraft wish list for extended  Boolean systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6969,On IP=PSPACE and Theorems with Narrow Proofs,"Very recently, it was shown that the class of languages with interactive  proofs, IP, is exactly the class PSPACE. This surprising result elegantly  places IP in the standard classification of feasible computations.   Furthermore, the IP = PSPACE result reveals some very interesting and  unsuspected properties of mathematical proofs. In this column, we define the width of a proof in a formal system $\cal F$  and show that it is an intuitively satisfying and robust definition. Then,  using the IP = PSPACE result, it is seen that the width of a proof (as  opposed to the length) determines how quickly one can give overwhelming  evidence that a theorem is provable without showing the full proof.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6970,Incremental Reduction in the Lambda Calculus,"An incremental algorithm is one that takes advantage of the fact that the  function it computes is to be evaluated repeatedly on inputs that differ only  slightly from one another, avoiding duplication of common computations. We define here a new notion of incrementality for reduction in the untyped  $\lambda$-calculus and describe an incremental reduction algorithm,  $\Lambda^{inc}$. We show that $\Lambda^{inc}$ has the desirable property of  performing non-overlapping reductions on related terms, yet is simple enough  to allow a practical implementation. The algorithm is based on a novel  $\lambda$-reduction strategy that may prove useful in a non-incremental  setting as well. Incremental $\lambda$-reduction can be used to advantage in any setting  where an algorithm is specified in a functional or applicative manner.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6971,On Kleene Algebras and Closed Semirings,"Kleene algebras are an important class of algebraic structures that arise in  diverse areas of computer science: program logic and semantics, relational  algebra, automata theory, and the design and analysis of algorithms. The  literature contains at several inequivalent definitions of Kleene algebras  and related algebraic structures [2, 13, 14, 5, 6, 1, 9, 7].   In this paper we establish some new relationships among these structures.   Our main results are: (1) There is a Kleene algebra in the sense of [6] that is not *-continuous. (2) The categories of *-continuous Kleene algebras [5, 6], closed semirings  [1, 9] and S-algebras [2] are strongly related by adjunctions. (3) The axioms of Kleene algebra in the sense of [6] are not complete for  the universal Horn theory of the regular events. This refutes a conjecture  of Conway [2, p. 103]. (4) Right-handed Kleene algebras are not necessarily left-handed Kleene  algebras. This verifies a weaker version of a conjecture of Pratt [14].",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6972,Black-box complexity of local minimization,"We study the complexity of local minimization in the black-box model, that is, the model in which the objective function and possibly its gradient are available as external subroutines. This is the model used, for example, in all the optimization algorithms in the 1983  book by Dennis and Schnabel. Our first main result is that the  complexity grows polynomially with the number of variables n, in  contrast to other related black-box problems (global minimization,  Brouwer fixed points) for which the worst case complexity is exponential in n. Our second contribution is the construction of a  family of functions that are bad cases for all possible black-box  local optimization algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6973,An Elementary Formal Semantics for the Programming Language PL/CS,"The PL/CS language is an instructional variant of PL/C designed to provide a  simple, easy-to-understand tool to teach a disciplined style of programming  (see [Conway 1976]). This report gives a complete formal semantic  specification of the language, following the style of [Scott and Strachey  1972]. In keeping with the goal of simplicity in the design of PL/CS, the  formal definition is presented in an hierarchical fashion and uses only  elementary mathematical concepts, such as set, relation, and recursive  definition. Key Words: programming language semantics, denotational semantics, recursive  functions, Pl/I, PL/C, PL/CS.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6974,An Evaluation of Text Matching Systems for Text Excerpts of Varying Scope,"When large text collections must be processed, it is not possible to limit  the scope of the subject matter of interest. In such a situation the standard  content analysis methods that are based on the use of knowledge bases to  represent the relevant subject areas are not applicable. Necessarily, the  text themselves must then serve as the main basis for the content analysis  operations. Experiments are described in this note designed to evaluate text matching  operations for text excerpts of varying scope, including in particular text  paragraphs and text sentences extracted from book size materials. The  evaluation shows that when the global text similarity between distinct text  paragraphs is high, while at the same time local similarities also exist for  particular text sentences included in these paragraphs, the presumption is  that the paragraphs cover related subject matter. One concludes that text  matching systems may prove useful for text linking and information retrieval.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6975,On Some Central Problems in Computational Complexity,"In this thesis we examine some of the central problems in the theory of  computational complexity, like the trade-offs between time and memory, the  power of nondeterminism and parallelism, and the speed gained by adding new  operations to random access machines. Our main result is the cahracterization  of the power of multiplication in random access acceptors: we show, in  Chapter 3, that for such models nondeterministic and deterministic  computations are polynomially related and that there is a polynomial  relationship between the amount of time required for acceptance by random  access machines with multiplication, and the amount of tape required by Turing  machines. Thus, the additional power gained by using multiplication is the  same as that of memory over time (if any). We derive similar results for some  other interesting instruction sets. We also have some results for probabilistic and nondeterministic computations:  we define threshold machines and show how probabilistic Turing machines may  simulate them, and exhibit a set of complete problems for threshold machines.  For nondeterministic computations, we present a hierarchy of the elementary  recursive languages obtained by polynomially bounded quantification over  objects of higher and higher type, which represent nondeterministic time  bounded computations with larger and larger bounds. Finally, we discuss some  deterministic computations, and conclude with a look at some open problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6976,Tools for Distributed Application Management,"Distributed application management consists of monitoring and controlling an application as it executes in a distributed  environment. It encompasses such activities as configuration,  initialization, performance monitoring, resource scheduling, and failure response. In this paper we describe the Meta system: a collection of tools for constructing distributed application management software. Meta provides the mechanism, while the programmer specifies the policy  for application management. The policy is manifested as a control program which is a soft real-time reactive program. The underlying  application is instrumented with a variety of built-in and user- defined sensors and actuators. These define the interface between the control program and the application. The control program also  has access to a database describing the structure of the application  and the characteristics of is environment. Some of the more difficult problems for application management occur when pre-existing, nondistributed programs are integrated into a  distributed application for which they may not have been intended.  Meta allows management functions to be retrofitted to such programs  with a minimum effort. Keywords: Distributed application management, configuration management, distributed operating systems, dynamic reconfiguration,  monitoring distributed systems, rule-based systems, Isis.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6977,A Simple Syntactic Approach for the Generation of Indexing Phrases,"A syntactic approach is described for generating indexing phrases usable for  the content identification of natural-language texts. The phrase generation  method is based on a simple language analysis system that determines the  syntactic function of individual text words with a high degree of accuracy,  and chooses of indexing phrases based on weights assigned to the phrase  components. The proportion of phrases that appear to be acceptable for  content identification ranges from 96 to 98 percent.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6978,The ISIS Project-Real Experience with a Fault-Tolerant Programming System,"The ISIS project has developed a distributed programming toolkit [2,3] and a  collection of higher level applications based on these tools. ISIS is now in  use at more than 300 locations world-wide. Here, we discuss the lessons (and  surprises) gained from this experience with the real world.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6979,Knowledge and Inhibition in Asynchronous Distributed Systems,"In an asynchronous distributed system, processes communicate only via message  passing along channels with unbounded transmission time. Relative process  speeds are arbitrary and processes do not have access to a common clock. For  such systems, a useful means of providing temporal structure is the causality  relation. Causality imposes a partial order on the events of an execution  based on the necessity of certain events preceding other events. Causality  can be used to give a sensible definition of a distributed global state in an  asynchronous system, known as a consistent cut. We present a new knowledge-theoretic logic, with formal semantic definitions,  for reasoning about causality and consistent cuts. The logic includes  concurrent common knowledge, a new form of distributed agreement, which has  an analogous role to that of common knowledge in synchronous systems. It is  shown to be a necessary and sufficient condition for performing concurrent  actions in asynchronous systems, and has a role in many distributed  applications such as checkpointing, deadlock detection, and broadcasting.  Concurrent common knowledge is also shown to be attainable by class of  protocols termed distinguishable-consistent-cut-protocols or DCCPs. We examine four simple and efficient DCCPs and trade-offs between them. These  trade-offs involve message complexities, necessity of FIFO channels, and the  degrees to which events of the underlying system are suspended during  execution of the protocols. We call such suspensions inhibition and formally  define multiple forms of inhibition that are used in distributed protocols.  We classify the DCCPs in this work according to their inhibitory  characteristics, and prove new results which demonstrate close relationships  between inhibition and the existence of DCCPs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6980,Design of a Microprocessor Driven Generic Controller for a Mobile Robot Base,"The primary project goal is to design and fabricate a controller to be used in  an autonomous mobile robot which is consistent with the generic controller  concept set forth by the Mobile Robotics Group. A generic controller must be  capable of controlling interfacing units such as sonar and motor drive  systems without any hardware modifications. Thus, any sensor or actuator  applicable for use in mobile robotics can be utilized by providing the  appropriate interface to, and programming for, the generic controller.  Communication between generic controllers is needed to pass data from sensors  to actuators. The most important design considerations are interface flexibility, size,  power consumption, and robustness. The generic controller provides the  following capabilities as specified by the Mobile Robotics Group. These  include interboard communication capability, on-board memory, debug and  download capability through the use of a dedicated communication channel, a  pulse width generator for motor control, an interrupt arbitration scheme, and  a multi-port I/O device with separate ports for an array of light emitting  diodes, preset dual inline switches and external pendent control capability.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6981,MTP: An Atomic Multicast Transport Protocol,"This paper describes MTP: a reliable transport protocol that utilizes the  multicast strategy of applicable lower layer network architectures. In  addition to transporting data reliably and efficiently, MTP provides the  client synchronization necessary for agreement on the receipt of data and the  joining of the group of communicants.  Keywords: reliable transport, multicast, broadcast, atomic broadcast,  agreement.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6982,Efficient Parallel Algorithms for Disjoint Paths and Connectivity,"This thesis is concerned with the problem of designing efficient parallel  algorithms for various graph-theoretic problems. Our larger goal is to  identify ""tools"" that would be useful in designing parallel algorithms for  various graph-theoretic problems. We show that the concept of bridges plays a  crucial role in the design of algorithms for the kinds of problems we  consider. The specific problems we consider are the following. We give an $NC$ algorithm for finding vertex-disjoint $s_{1}, t_{1}$ and  $s_{2}, t_{2}$ paths in an undirected graph. An important step in solving the  general problem is solving the planar case. A new structural property yields  the parallelization, as well as a simpler linear time sequential algorithm  for this case. We extend the algorithm to the non-planar case by giving an  $NC$ algorithm for finding a Kuratowski homeomorph, and, in particular, a  homeomorph of $K_{3,3,}$ in a non-planar graph. We also present an efficient parallel algorithm for testing whether a graph  is $k$ vertex-connected. To develop our algorithm we design an efficient  parallel algorithm for the following disjoint $s-t$ paths problem: Given a  graph and two specified vertices $s$ and $t$, find $k$ vertex-disjoint paths  between $s$ and $t$, if they exist. If no such paths exist, find a set of at  most $k$ - 1 vertices whose removal disconnects $s$ and $t$. We show how to  modify the algorithm to find $k$ edge-disjoint paths, if they exist. This  yields an efficient parallel algorithm for testing whether a graph is $k$  edge-connected. Finally, we describe more applications of the disjoint $s-t$  paths algorithm. This algorithm is also used as a subroutine in the algorithm  for the two paths problem mentioned earlier.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6983,On-line Algorithms for Weighted Matching and Stable Marriages,"We give an on-line deterministic algorithm for the bipartite weighted matching  problem that achieves a competitive ratio of $O(n)$. In fact, this algorithm  is almost optimal - the lower bound on the performance ratio of any  deterministic online algorithm is $\Omega (n/ \sqrt{log n})$.   We also study the stable marriage problem, where we are interested in the  number of unstable pairs produced. We show that the simple ""first come,  first served"" deterministic algorithm yields on the average $O(n$ log $n$)  unstable pairs, but in the worst case no deterministic or randomized on-line  algorithm can do better that $\Omega(n^{2})$ unstable  pairs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6984,Asynchronous Signals is Standard ML,"We describe the design, implementation and use of a mechanism for handling  asynchronous signals, such as user interrupts, in the New Jersey  implementation of standard ML. Providing this kind of mechanism is a  necessary requirement for the development of real-world application programs.  Our mechanism uses first-class continuations to represent the execution state  at the time at which a signal occurs. It has been used to support pre-emptive  scheduling in concurrency packages and for forcing break-points in debuggers,  as well as for handling user interrupts in the SML/NJ interactive environment.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6985,Flexible Concurrency Control by Reasoning About Database Queries and Updates,"A number of database management problems involve reasoning about queries and  updates. Concurrency control is the most important example: two transactions  should not be executed simultaneously if it is possible that an update  command issued by one transaction might change information used in answering  a query issued by the other. Existing concurrency control schemes are based  on the idea of protecting discrete items of data. This thesis describes a  concurrency control scheme called adaptive locking that is based instead on  logical reasoning. The central notion is that of independence. Informally, a query is independent  of an update if executing the update cannot change the result of evaluating  the query. First the general properties of the concept of independence are  investigated, using a formal model-theoretic definition in the context of  deductive databases. Then proof-theoretic sufficient conditions are obtained  for the independence of queries and updates. These results apply to arbitrary  queries and updates, and they take into account integrity constraints and  recursive rules. For the special case where a query and an update are both specified by  conjunctive relational algebra expressions, a decision procedure for  independence is given. The procedure is of practical use because typically it  requires linear time, and it produces answers that are precise enough to be  relied upon. The procedure takes into account functional dependencies, so it  constitutes a solution to an open problem identified by Blakeley, Coburn, and  Larson. It is of theoretical interest for two reasons. First, its quadratic  worst-case time complexity cannot be improved unless the reachability problem  for directed graphs can be solved in sublinear time. Second, it applies to  the widest possible natural class of queries, since deciding independence is  NP-hard for nonconjunctive queries and updates.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6986,The Relationship Between Multiway and Two-Way Fair Merges,"In the context of communicating systems of autonomous processes, we study two  kinds of processes - a two-way fair merge, that interleaves two possibly  infinite sequences into one, and a multiway fair merge, that interleaves more  than two possibly infinite sequences into one. We describe two constructions.  The first one shows how the effect of any arbitrary number of two-way fair  merges in a finite network can be exactly obtained by a single multiway fair  merge and some determinate processes. The second one shows how the effect of  a single multiway fair merge with any number of input channels can be exactly  obtained by a finite network of two-way fair merges.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6987,The Expressiveness of Indeterminate Dataflow Primitives,"This thesis establishes that there are different kinds of indeterminacy in an  asynchronous distributed computation setting by studying expressiveness and  inexpressiveness situations. We use a particular model of asynchronous  distributed computation, called the dataflow model. This model very naturally  portrays the situation of autonomous computing agents communicating  asynchronously to each other along fixed one-way paths called channels. The  nature of computation is studied both in an operational setting, and in a  more abstract setting, and equivalences are proved between them so that one  may freely move between them. We use the operational semantics of Lynch and  Stark to describe the operational behavior of processes in the dataflow  model.  We show how one can abstract out the low-level operational behavior  and obtain ""traces"" that are well-suited for reasoning about network  behavior, once the properties of tract sets have been fully described using  the operational semantics from which they arise. We consider several forms of indeterminacy in this context, modeling them as  different fairness guarantees on merge primitives, that try to merge two  sequences of values into one, and choice primitives, that split one sequence  of values into two. The main contribution here has been to show that there is  a surprising hierarchy of different notions of indeterminacy. This cannot  simply be described using degree of branching - bounded versus unbounded. We  use the trace of sets of these primitives for these proofs. The description  of this hierarchy clarifies the expressibility situation for indeterminacy  in an asynchronous distributed setting. It is our hope that by concentrating  on specific properties of agents that are really relevant to their behavior  in any particular system, one would obtain simpler and more convenient  semantics to describe this behavior. In most of this thesis, we consider static dataflow - a fixed set of  processes communicating along a fixed set of channels. In one of the final  chapters, we consider recursively defined dataflow networks whose behavior  involves the creation of processes and channels. We prove the equivalence of  an operational and an abstract semantics there for determinate networks.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6988,A Note on Tape Bounds for SLA Language Processing,"In this note we show that the tape bounded complexity classes of languages  over single letter alphabets are closed under complementation. We then use  this result to show that there exists an infinite hierarchy of tape bounded  complexity classes of sla languages between log n and log log n tape bounds.  We also show that every infinite sla language recognizable on less than log n  tape has infinitely many different regular subsets, and, therefore, the set of  primes in unary notation, P, requires exactly log n tape for its recognition  and every infinite subset of P requires at least log n tape.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6989,Parallel Evaluation in Attribute Grammar-Based Systems,"Attributed context-free grammars provide a rigorous basis for the semantic  analysis and translation of tree-structured objects and have been used to  build a variety of systems. A number of programming language compiler,  compiler generators, and language-based editor generators employing attribute  grammars have been described in the literature. Many of these systems make  use of l-ordered attribute grammars, attribute grammars for which  particularly efficient methods for attributing derivation trees have been  described. Derivation trees representing constructs of only moderate size may contain  thousands of nodes and tens of thousands of attribute instances, and  attribution of such trees on uniprocessor systems may require a significant  amount of time. One possibility for reducing this time is to find techniques  that exploit opportunities for parallelism in the attribution process and  allow attribution to be performed on multiprocessor systems. Such techniques  would permit attribute grammars to serve as a rigorous foundation for the  development of parallel compilation systems and other parallel applications. We present several methods for the parallel attribution of trees derived from  l-ordered attribute grammars. These methods take advantage of parallelism  implicit in the attribution process and, thus, do not require any special  considerations to be taken when constructing grammars. Methods appropriate  for use on tightly - and loosely-coupled multiprocessor architectures and for  use when complete and incremental tree attribution are required are presented. We present preliminary performance results obtained from implementations of  some of the methods on a simple shared-memory multiprocessor simulator  embedded within an attribute grammar-based editor generator system. The  results suggest that the methods may provide useful reductions in attribution  time in some cases.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6990,Bisimulation Can't Be Traced,"In the concurrent languages CCS, two programs are considered the same if they  are bisimilar. Several years and many researchers have demonstrated that the  theory of bisimulation is mathematically appealing and useful in practice.  However, bisimulation makes too many distinctions between programs. There are  two programs P and Q which are not bisimilar, but nontheless are  interchangeable: one may be substituted for the other anywhere in a CCS  program and no difference can be seen. Bisimulation is thus not fully abstract. We consider the problem of adding operations to CCS to make bisimulation  fully abstract. It is trivial to add an operation achieving full abstraction,  but this operation is rather peculiar. We show that bisimilation is not fully  abstract with respect to any extension of CCS by CCS-like operations. We give  a formal description of ""CCS-like,"" as GSOS and argue by proofs and  counterexamples that this is indeed the right class. In the proof of non-full-abstraction a coarser version of bisimulation  arises, a notion called ready simulation. We investigate the theory of ready  simulation, showing that it possesses the basic properties which make  bisimulation attractive. Like bisimulation, it possesses equivalent relational  and logical characterizations; it has two additional equivalent  characterizations as congruence with respect to all GSOS languages, and with  respect to CCS extended by process copying and controlled communication  operations. In particular, it is fully abstract for a sensible extension of  CCS. As a corollary, we show that bisimulation cannot be fully abstract with  respect to any CCS-like languages, observing traces.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6991,Extracting Constructive Content from Classical Proofs,"This thesis is concerned with the relationship between classical and  constructive mathematics. It is well-known that in many constructive logics,  we can interpret mathematical sentences as program specifications, and we can  interpret a constructive proof of such a sentence as a program which meets  this specification. It is also well-known that many classical logics do not  have the property, as shown by Brouwer's counterexamples to some theorems of  analysis. Kreisel and Friedman showed that for certain classes of sentences  $(\Pi_{2}^{0})$, the classical theories conservatively extend their  constructive counterparts, and furthermore give effective translations from  classical proofs to constructive proofs. This thesis consists of two parts. In the first, we describe our  implementation of Friedman's translation results, and their use in  translating Higman's Lemma, a nontrivial theorem of combinatorics. To do  this, we delineate a subtheory of a constructive type theory (Nuprl) for  which Friedman's translation is guaranteed to succeed. We also extend the  Nuprl type theory with impredicative $\Pi$-quantification, and use this to  provide a classical proof of Higman's Lemma, which we go on to mechanically  translate to a constructive proof. In the second part, we discuss connections that we have discovered between  Friedman's translation and a standard compilation technique,  continuation-passing-style (CPS) translation. We demonstrate that a classical  proof of a $(\Pi_{2}^{0})$ sentence $\Phi$ is a program which meets the  specification $\Phi$. We demonstrate that we can consistently give  algorithmic content to the only constructively problematic rule of classical  logic, the rule of  double-negation elimination. This algorithmic content is  the nonlocal control operator $C$ (a relative of  call-with-current-continuation). Moreover, we show that Friedman's  translation is exactly a CPS-translation on the classical ""program""  (with $C$), converting it into a pure functional program (without $C$). Our work provides a semantic account of Friedman's translation, in terms of  its effect on programs, making the connections (and the differences) between  classical and constructive systems clearer and more precise. Moreover, we  provide the first steps towards integrating nonlocal control operators into a  type-theoretic explanation of computation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6992,Dependence Flow Graphs: An Algebraic Approach to Program Dependencies,"The topic of intermediate languages for optimizing and parallelizing  compilers has received much attention lately. In this paper, we argue that  any good representation must have two crucial properties: first, the  representation of a program must be a data structure that can be rapidly  traversed to determine dependence information; second, the representation  must be a program in its own right, with a parallel, local, model of  execution. In this paper, we illustrate the importance of these points by  examining algorithms for standard optimization-global constant propagation. We  discuss the problems in working with current representations. Then, we  propose a novel representation called the dependence flow graph which has  each of the properties mentioned above. In this representation, dependencies  are part of the computational mode, in that there is an algebra of operators  over dependencies. We show that this representation leads to a simple  algorithm, based on abstract interpretation, for solving the constant  propagation problem. Our algorithm is simpler than, and as fast as, the best  known algorithms for the problem. An interesting feature of our  representation is that it naturally incorporates the best aspects of many  other representations, including continuation-passing style, data and program  dependence graphs, static single assignment form and dataflow program graphs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6993,Progress Measures and Finite Arguments for Infinite Computation,"We establish principles for proving properties about infinite computations by  reasoning about finite ones. We apply these principles to show that for a  wide variety of verification problems - involving nondeterminism, fairness,  and liveness - there are assertional verification methods that directly  relate program and specification. Most previous research relies on transformations of programs in order to  reduce a verification problem to problems that can be solved using classical  techniques such a refinement mappings and well-founded orderings. Progress  measures, the key innovation of this thesis, provide direct,  syntax-independent verification techniques for a wide range of specifications. We exhibit progress measures for the language containment problem for  nondeterministic automata; for verification with general fairness  constraints; and for verification of very general specifications, including  infinitary temporal logics. We obtain and optimal solution (in a  recursion-theoretic sense) to the problem of verifying infinite computations  by reasoning about finite ones. This result establishes a link between  descriptive set theory and the theory of verification.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6994,Random Reductions in the Boolean Hierarchy are Not Robust.,"We investigate random reductions from complete sets in the Boolean Hierarchy  to their complements. We show that under the assumption that the Polynomial  Hierarchy is infinite, the error probability of such reductions cannot be  significantly lower than a constant. This constant depends on the classes  in question. Thus, random reductions in the Boolean Hierarchy are not robust.  We also show that the trivial random reductions between classes at the second  level of the Boolean Hierarchy are optimal.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6995,Making Real-time Reactive Systems Reliable,No Abstract is Available.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6996,Realizing Boolean Functions on Disjoint Sets of Variables,"For switching functions $f$ let $C(f)$ be the combinatorial complexity of $f$. We prove that for every $\varepsilon greater than 0$ there are arbitrarily complex functions $f:\{0,1\}^{n} \rightarrow \{0,1\}^{n}$ such that $C(fxf) \leq (1+ \varepsilon) C(f)$ and arbitrarily complex functions $g:\{0,1\}$ such that $C(v c(fxf)) \leq (1 + \varepsilon)C(f)$. These results and the techniques developed to obtain them are used to show, that Ashenhurst decomposition of switching functions does not always yield optimal circuits and to prove a new result concerning the trade-off between circuit size and monotone circuit size.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6997,A Note on Wavelet Bases for Two-Dimensional Surfaces,"Recent work by Beylkin, Coifman and Rokhlin has demonstrated that integral  equations for functions on $IR$ can be solved rapidly by expressing the  integrands in a wavelet basis. Boundary element methods for solving partial  differential equations in three dimension rely on integral equations for  functions defined on surfaces embedded in $IR^{3}$. Accordingly, it is of  interest to extend the wavelet work to functions defined on surfaces. In this report, we define a basis of piecewise constant functions on surfaces  in $IR^{3}$ with properties akin to a wavelet basis. The basis we define is  not useful for numerical computation because piecewise constant functions  have poor approximation properties, but this work suggests an approach to  define smoother wavelet bases for surfaces.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6998,Flexible Text Matching for Information Retrieval,"Very large text databases now exist in machine-readable form, covering  arbitrary subject matter in unrestricted discourse areas. The conventional  text retrieval approaches are not easily used in such circumstances, because  the knowledge needed to understand unrestricted subject matter is not readily  available for practical use. A new approach is outlined for text structuring and retrieval, based on  flexible text matching methods using different context granularities. When  global as well as local similarities exist between distinct texts, the  presumption is that the texts cover semantically similar subject areas. This  leads to the automatic introduction of links between related texts, and to  the retrieval of text excerpts in response to available user queries.  Evaluation results are given to demonstrate the effectiveness of the text  matching approach.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/6999,The Molecule Problem: Determining Conformation from Pairwise Distances,"The molecule problem is that of determining the coordinates of a set of  points in space from a (usually sparse) set of pairwise distance  measurements. As its name implies, it has applications in the determination  of molecular conformation. Unfortunately, the molecule problem is NP-hard. We present an approach to the molecule problem that uses a very specialized  divide-and-conquer technique. Instead of solving a single large problem we  try to solve a sequence of smaller, presumably easier ones. These small  problems consist of subsets of points whose relative locations can be  determined uniquely. Once such a subset is positioned, its points can  collectively be treated as a rigid body. This can greatly reduce the number  of degrees of freedom in the problem. Identifying subsets of points whose relative locations can be uniquely  determined requires exploiting some very special structure inherent in the  molecule problem.  We reduce this identification to a purely combinatoric  characterization that ignores the actual distances. We develop necessary graph  theoretic conditions for a set of points to have a unique solution, along  with efficient algorithms to find subgraphs with these properties. These  characterizations and algorithms combine ideas from matching theory,  differential topology and matrix computations. These ideas have been implemented in ABBIE, a program to solve  three-dimensional instances of the molecule problem. ABBIE combines the  recursive decomposition described above with a nonlinear global optimizer to  perform the coordinate determinations. Detail of this implementation are  described, and numerical results of simulated chemical data are presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7000,Tools for Constructing Distributed Reactive Systems,"Many distributed applications can be cast as reactive systems, where a reactive system consists of an instrumented program that is monitored and controlled by an input-driven control program. Examples of non-real-time reactive systems include monitoring and debugging  systems, tool integration services, and network and distributed  application managers. There is currently little support for building  reactive systems. This paper describes the Meta toolkit that provides  such support. Using Meta, a distributed system can be instrumented with a sensor and actuator abstraction that exposes the state of the  system for purposes of control. Then, a control program can be written that interacts with the instrumented system using guarded commands. Of particular concern is the efficiency of control, so Meta allows the  control program to be distributed in order to take advantage of  locality as much as possible.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7001,Solving Nonlinear Matrix Equations on a Hypercube,"Nonlinear matrix equations arise frequently in applied probability,  especially in the numerical solution of many stochastic models in queueing,  inventory, communications, and dam theories. Due to the huge amount of  computations involved in these nonlinear matrix equations, the existing  algorithms for the solutions have not been satisfactory. With the advent of  parallel computers, the door is open for efficient parallel algorithms to  tackle the problem. This paper is an effort in this direction. A parallel  algorithm on distributed computer systems is devised, and numerical  experiment is done on the hypercube.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7002,"Some Kripke Models for ""one universe"" Martin-Lof Type Theory","We define several Kripke models sound for inhabited formulas of the  ground-level intensional and extensional Martin-Lof Type theories with one  universe. They are Kripke model versions of the realizability style semantics  developed by various authors, amongst them Allen, Beeson, and Aczel.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7003,Realizability and Kripke Forcing,"Realizability, developed by Stephen Kleene, is a type-free device for  extracting computations from logical specifications. Realizability analyzes  the computational content of reasoning: it models the universe of recursive  mathematics. Kripke and associated Categorical interpretations give a  broader, topological/algebraic semantics for constructive reasoning which is  complete for intuitionistic logic. They are, therefore, a powerful and  indispensable tool for modelling computationally meaningful formal systems.  How are the two semantical paradigms related ? In this paper, we construct  several Kripke and Categorical Models which are elementarily equivalent to  Syntactic Realizability. By merging the two approaches we provide a new class  of models and a framework for reasoning about computational evidence and the  process of term extraction itself.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7004,Concepts and Conditions for Confinement,"THe confinement problem is concerned with preventing a computaitonal service  from divulging information entrusted to it. A model of computer protection is  presented and used to formally define the problem and its relation to  protection mechanisms. Two types of confinement, one concerned with preventing  the direct sending of messages and the other with also preventing the use of  covert channels, are explored. For both types, conditions sufficient to insure  confinement in terms of the capabilities of computations are presented. The  conditions make it possible to identify exactly those objects, if any, which  can serve as potential channels. Means for plugging the potential channels are  also discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7005,Designing Application Software in Wide Area Network Settings,"Progress in methodologies for developing robust local area network software  has not been matched by similar results for wide-area settings. In this  paper, we consider the design of application software spanning multiple local  area environments. For important classes of applications, simple design  techniques are presented that yield fault-tolerant wide area programs. An  implementation of these techniques as a set of tools for use within the ISIS  system is described.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7006,A Note on Term Weighting and Text Matching,"In information retrieval, it is not uncommon to be faced with large  collections of unrestricted natural-language text. In such circumstances, the  text analysis and retrieval operations must be based mainly on a study of the  text collections actually under construction. Two main operations are of  interest: a text analysis operation designed to assign content identifiers to  the stored texts, and a text comparison system designed to identify texts  covering particular subject areas. In the present note, some details are given concerning the usefulness of term  weighting systems for the content analysis of natural-language texts, and of  text matching strategies designed to identify relevant text items in answer  to available search requests. A sample collection of electronic mail messages  is used for experimental purposes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7007,Progress Measures for Verification Involving Nondeterminism,"Using the notion of progress measures, we give a complete verification method  for proving that a program satisfies a property specified by an automaton  having bounded nondeterminism. Such automata can express any safety property.  Previous methods, which can be derived from the method presented here, either  rely on transforming the program or are not complete.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7008,Language Learning without Overgeneralization,"Language learnability is investigated in the Gold paradigm of inductive  inference from positive data. Angluin gave a characterization of learnable  families in this framework. Here, learnability of families of recursive  languages is studied when the learner obeys certain natural constraints.  Exactly learnable families are characterized for prudent learners with the  following types of constraints: (0) conservative, (1) conservative and  consistent, (2) conservative and responsive, and (3) conservative,  consistent, and responsive. The class of learnable families is shown to  strictly increase going from (3) to (2) and from (2) to (1), while it stays  the same going from (1) to (0). It is also shown that, when exactness is not  required, prudence, consistency and responsiveness, even together, do not  restrict the power of conservative learners.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7009,Density Graphs and Separators,"We propose a class of graphs that would occur naturally in finite-element  problems, and we prove a bound on separators for this class of graphs. For  three-dimensional graphs, our separator bound is $O(N^{2/3})$. We also  propose a simple randomized algorithm to find this separator in $O(N)$ time.  Such an algorithm would be used as a preprocessing step for the domain  decomposition method of efficiently solving a finite-element problem on a  parallel computer. This paper generalizes ""local graphs"" of Vavasis [1990] to the case of  graphs with varying densities of nodes. It also generalizes aspects of Miller  and Thurston's [1990] ""stable graphs.""",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7010,Efficiently Using Invariant Theory and Grouping Information for Model-Based Matching,"This paper presents a method for efficiently maintaining and searching a  database of three-dimensional models so they can be reliable recognized from  arbitrary two-dimensional projections in the presence of noise and occlusion.  The core of the process is the topologically-defined network of invariants  which breaks three-dimensional models down into small, local groups of  features and indexes these groups using translation, rotation, scaling, and  orthographic projection invariant functions. The network encodes the  geometrical relationships between these groups so that grouping information  can be used to increase the speed of matching.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7011,Improving Known Solutions is Hard,"In this paper, we study the complexity of computing better solutions to  optimization problems given other solutions. This is done in the context of  the counterexample computation model introduced in [KPS90]. Assuming  $PH \neq \sum^{P}_{3}$, we prove that PTIME transducers cannot compute  optimal solutions for many problems, even given $O(n^{1-\epsilon})$  non-trivial solutions. These results are used to establish sharp lower bounds  for several problems in the counterexample model. We extend the model by  defining probabilistic counterexample computations and show that our results  hold even in the presence of randomness.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7012,Approximation Algorithms for Concave Quadratic Programming,"We consider $\epsilon$-approximation schemes for concave quadratic  programming. Because the existing definition of $\epsilon$-approximation for  combinatorial optimization problems is inappropriate for nonlinear  optimization, we propose a new definition for $\epsilon$-approximation. We  argue that such an approximation can be found in polynomial time for fixed  $\epsilon$ and $k$, where $k$ denotes the number of negative eigenvalues. Our  algorithm is polynomial in 1/$\epsilon$ for fixed $k$, and superexponential  in $k$ for fixed $\epsilon$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7013,Nested Dissection for Sparse Nullspace Bases,We propose a nested dissection approach to finding a fundamental cycle basis in a planar graph. the cycle basis corresponds to a fundamental  nullspace basis of the adjacency matrix. This problem is meant to model sparse null basis computations occurring in a variety of settings. We achieve an O(n**3/2) bound on the nullspace basis size  and an O(nlogn) bound on the size in the special case of grid graphs.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7014,Closure Operator Semantics for Concurrent Constraint Logic Programming,"This paper develops a denotation and abstract model based on closure  operators for concurrent constraint logic programming. The denotational  semantics is built domain theoretically and not from the computation  sequences. The denotational semantics is related to an operational semantics.  The operational semantics distinguishes successful and unsuccessful  computations and observes intermediate results of divergent computations. The  paper extends to the indeterminate setting, previous work on functional  languages with logic variables [9].",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7015,A Simulator for Exploring Replication and Locality of Access in a Distributed Database,"In fault-tolerant distributed databases, one method of increasing data  availability is through increased data replication. However, with increased  data replication comes an increase in the time to perform transactions. What  is needed is a way in which this and other problems involved with configuring  distributed databases can be explored. This paper describes a simulator which  provides an accurate model of many different distributed environments when  given a set of parameters describing failures, data replication, and site  organization. Such a simulator is a useful tool for exploring the behavior of  possible distributed database configurations as well as for verifying  theoretical results.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7016,"Relations Between Diagonalization, Proof Systems, and Complexity Gaps","In this paper we study diagonal processes over time-bounded computations of  one-tape Turing machines by diagonalizing only over those machines for which  there exist formal proofs that they operate in the given time bound. This  replaces the traditional ""clock"" in resource bounded diagonalization by formal  proofs about running times and establishes close relations between properties  of proof systems and existence of sharp time bounds for one-tape Turing  machine complexity classes. Furthermore, these diagonalization methods show  that the Gap Theorem for resource bounded computations does not hold for  complexity classes consisting only of languages accepted by Turing machines  for which it can be formally proven that they run in the required time bound.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7017,First Order Predicate Logic Without Negation is NP-Complete,Techniques developed in the study of the complexity of finitely presented  algebras are used to show that the problem of deciding validity of positive  sentences in the language of first order predicate logic with equality is  $\leq_{\log}$-complete for NP.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7018,General Flow Problems and Graph Grammars,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7019,A Constructive Completeness Proof for Intuitionistic Propositional Calculus,"This paper presents a constructive proof of completeness of Kripke models for  the intuitionistic propositional calculus. The computational content of the  proof is a form of the tableau decision procedure. If a formula is valid, the  algorithm produces a proof of the formula in the form of an inhabitant of the  corresponding type; if not, it produces a Kripke model and a state in the  model such that the formula is not forced at that state in that model.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7020,On the Probabilistic Analysis of Normal Form Computation of a Sparse Matrix,"An $(s, t)$-sparse matrix has $s$ non-zero entries per column and $t$ per row.  $(s, t)$-sparse integer matrices arise in the computation of integral  homology. In this paper, a probabilistic analysis is given for diagonalizing  an integer $(s, t)$-sparse matrix into normal formal. By normal form of a  matrix, we mean the diagonalization of the matrix over the ring of integers.  We prove that under high probability the expected running time can be  achieved with probability very close $(s, t)$-sparse matrix, i.e. this  expected running time can be achieved with probability very close to 1 when  $(s, t)\ll n$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7021,"Global Convergence of Damped Newton's Method for Nonsmooth Equations, via the Path Search","A natural damping of Newton's method for nonsmooth equations is presented.  This damping, via the path search instead of the traditional line search,  enlarges the domain of convergence of Newton's method and therefore is said to  be globally convergent. Convergence behavior is like that of line search  damped Newton's method for smooth equations, including Q-quadratic  convergence rates under appropriate conditions. Applications of the path search include damping Robinson-Newton's method for  nonsmooth normal equations corresponding to nonlinear complementarity  problems and variational inequalities, hence damping both Wilson's method  (sequential quadratic programming) for nonlinear programming and  Josephy-Newton's method for generalized equations. Computational examples from nonlinear programming are given.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7022,Proving Polynomial-Time for Sphere-Constrained Quadratic Programming,"Recently Ye and Karmarkar have proposed similar algorithms for minimizing a  nonconvex quadratic function on a sphere. These algorithms are based on  trust-region work going back to Levenberg and Marquardt. Although both  authors state that their algorithm is polynomial time, neither makes estimates  necessary to prove that conclusion in a formal sense. In this report we  derive estimates for the convergence of the algorithm. Our estimates are  based on bounds for separation of roots of polynomials. These bounds prove  that the underlying decision problem is polynomial time in the Turing machine  sense.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7023,On Computing the Homology Type of a Triangulation,"We analyze an algorithm for computing the homology type of a triangulation.  By triangulation, we mean a finite simplicial complex; its homology type is  given by its homology groups (with integer coefficients). The algorithm could  be used in computer-aided design to tell whether two finite-element meshes or  Bezier-spline surfaces are of the same ""topological type,"" and whether they  can be embedded in $\Re^{3}$. Homology computation is a purely combinatorial  problem of considerable intrinsic interest. While the worst-case bounds we  obtain for this algorithm are poor, we argue that many triangulations (in  general) and virtually all triangulations in design are very ""sparse,"" in a  sense we make precise. We formalize this sparseness measure, and perform a  probabilistic analysis of the sparse case to show that the expected running  time of the algorithm is roughly quadratic in the geometric complexity  (number of simplices) and linear in the dimension.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7024,A Relationship between Difference Hierarchies and Relativized Polynomial Hierarchies.,"Chang and Kadin have shown that if the difference hierarchy over NP collapses to level $k$, then the polynomial hierarchy (PH) is equal to the  $k$th level of the difference hierarchy over $\Sigma_{2}^{p}$. We simplify  their proof and obtain a slightly stronger conclusion: If the difference  hierarchy over NP collapses to level $k$, then PH =  $\left(P_{(k-1)-tt}^{NP}\right)^{NP}$. We also extend the result to classes  other than NP: For any class $C$ that has $\leq_{m}^{p}$-complete sets and  is closed under $\leq_{conj}^{p}$- and $\leq_{m}^{NP}$-reductions, if the difference hierarchy over $C$ collapses to level $k$, then  $PH^{C} = $\left(P_{(k-1)-tt}^{NP}\right)^{C}$. Then we show that the exact  counting class $C_{=}P$ is closed under $\leq_{disj}^{p}$- and  $\leq_{m}^{co-NP}$-reductions. Consequently, if the difference hierarchy over  $C_{=}P$ collapses to level $k$ then $PH^{PP}$ is equal to  $\left(P_{(k-1)-tt}^{NP}\right)^{PP}$. In contrast, the difference hierarchy  over the closely related class PP is known to collapse. Finally, we consider two ways of relativizing the bounded query class $P_{k-tt}^{NP}$: the restricted relativization $P_{k-tt}^{NP^{C}}$, and the  full relativization $\left(P_{k-tt}^{NP}\right)^{C}$. If $C$ is NP-hard, then  we show that the two relativizations are different unless $PH^{C}$ collapses.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7025,Programming with Process Groups: Group and Multicast Semantics,"Process groups are a natural tool for distributed programming, and are increasingly important in distributed
computing environments. However, there is little agreement on the most appropriate semantics
for process group membership and group communication. These issues are of special importance in the
Isis system, a toolkit for distributed programming. Isis supports several styles of process group, and
a collection of group communication protocols spanning a range of atomicity and ordering properties.
This flexibility makes Isis adaptable to a variety of applications, but is also a source of complexity that
limits performance. This paper reports on a new architecture that arose from an effort to simplify Isis
process group semantics. Our findings include a refined notion of how the clients of a group should be
treated, what the properties of a multicast primitive should be when systems contain large numbers of
overlapping groups, and a new construct called the causality domain. A system based on this architecture
is now being implemented in collaboration with the Chorus and Mach projects.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7026,The EIGHT Manual: A System for Geometric Modelling and Three-Dimensional Graphics on the Lisp Machine.,"We describe a simple geometric modelling system called Eight which supports  interactive creation, editing, and display of three-dimensional polyhedral  solids.  Perspective views of a polyhedral environment may be generated, and  hidden surfaces removed. Eight proved useful for creating world models, and  as an underlying system for modelling object interactions in robotics  research and applications. It is documented here in order to make the facility  available to others.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7027,Tools for Monitoring and Controlling Distributed Applications.,"The Meta system is a UNIX--based toolkit that assists in the construction of  reliable reactive systems, such as distributed monitoring and debugging  systems, tool integration systems and reliable distributed applications. Meta  provides mechanisms for instrumenting a distributed application and the  environment in which it executes, and Meta supplies a service that can be  used to monitor and control such an instrumented application.  The Meta  toolkit is built on top of the ISIS toolkit; they can be used together in  order to build fault-tolerant and adaptive distributed applications.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7028,An Interactive Version of the PL/C Compiler,"The paper discusses a conceptual model of a terminal as an ""internal  procedure"" in an interactive system for a block-structured language. A  specific implementation is described, following this model, for the Cornell  PL/I compiler.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7029,On the Semigroup of Strongly Connected Automata,"In 1964 Weeg [6] has posed a question asking which semi-groups admit strongly  connected automata. The presumed answer was given in 1971 by Oehmke [5]  through the following statement: A semigroup admits strongly connected  automaton if it has a homomorphic image either a nontrivial finite group or  semigroup of the transformations of some right zero semigroup. This theorem  can be reformulated as follows: A semigroup is a characteristic semigroup of  strongly connected automaton if it has a homomorphic image either a nontrivial  finite group or a semigroup of transformations of some right zero semigroup.  In this paper the ""only if"" part of this theorem has been overthrown. Some  related problems concerning strongly connectedness of finite automata are also  investigated. Key Words and Phrases: semigroup, characteristic semigroup of an automaton,  strongly connected automaton.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7030,Finitely Presented Algebras and the Polynomial Time Hiercharchy,"Let $S_{n}(V_{n})=\{less than \Gamma, Q_{1}v_{1}\cdots Q_{k}v_{k} s \equiv j greater than |  \Gamma$ is a finite presentation of $\cal A, Q_{1} \cdots Q_{k}$ is a string  of quantifiers with $n$ alterations, the outermost an $\exists (\forall),  \cal A \Gamma Q_{1} v_{1} \cdots Q_{k} v_{k} s \equiv t\}$. It is shown that $S_{n} (V_{n})$ is complete for $\Sigma^{P}_{n} (\Pi^{P}_{n})$, and $\stackrel{\stackrel{\infty}{\bigcup}}{n=0} S_{n} \cup  V_{n}$ is complete for PSPACE, answering a question of [1] and generalizing a  result of Stockmeyer and Meyer [2].",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7031,On Linear and Extended Linear Realization of Generalized Automata Extensions,"The relation between ordinary automata, their fixed analogs of extensions,  fixed analogs of generalized state-input extension with fixed mappings on  input alphabet and characteristic semigroups are considered. The necessary and  sufficient conditions for a fixed analog of an extension and generalized  state-input extension with fixed mappings on input alphabets of the ordinary  automaton to be linearly realizable over the field GF(p) are given. The  equations describing fixed analogs of an extension and generalized state-input  extension with fixed mappings on input alphabets are also stated.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7032,Assignment to Subscripted Variables,"The assignment b(r):=e is investigated using two axiomatic definitions in  order to gain an understanding of the problems involved with using arrays. It  is seen that assignment to array elements leads to many of the difficulties  encountered with pointers or references. The axiomatic definition is extended  to cover the multiple assignment statement to both simple and subscripted  variables, and a proof of correctness for a nontrivial program is outlined   using the new definition.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7033,Tools for Constructing Distributive Reactive Systems,"Many distributed applications can be cast as a reactive system, where a  reactive system consists of an instrumented program that is monitored and/or  controlled by an input-driven control program.  Examples of non-real-time  reactive systems include monitoring and debugging systems, tool integration  services, and network and distributed application managers. There is  currently little support for building reactive systems. This paper describes  the Meta toolkit that provides such support. Using Meta, a distributed  system can be instrumented with a sensor and actuator abstraction that  exposes the state of the system for purposes of control. Then, a control  program can be written that interacts with the instrumented system using  guarded commands. Of particular concern is the efficiency of control, so Meta  allows the control program to be distributed in order to take advantage of  locality as much as possible.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7034,Fast Ordered Multicasts,"In this thesis, we present new protocols that provide reliable ordered  multicasts to multiple overlapping process groups in the presence of  failures. Our protocols provide two kinds of message delivery ordering -  causal ordering and total ordering. Message delivery is also ordered with  respect to the observation of group membership changes, a property known as  virtual synchrony. Initially we examine solutions for the case of a single  process group, and subsequently extend our solutions to encompass multiple  overlapping process groups. In comparison with previous protocols for these  problems, our protocols are cheaper and scale up better. An initial  implementation of our protocols as part of the ISIS toolkit has produced  encouraging performance results.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7035,Nineteen Ways to Compute the Exponential of a Matrix,"In principle, the exponential of a matrix could be computed in many ways.  Methods involving approximation theory, differential equations, the matrix  eigenvalues, and the matrix characteristic polynomial have been proposed. In  practice, consideration of computational stability and efficiency indicates  that some of the methods are preferable to others, but that none are  completely satisfactory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7036,Automatic Text Structuring and Retrieval- Experiments in Automatic Encyclopedia Searching,"Many conventional approaches to text analysis and information retrieval prove  ineffective when large text collections must be processed in heterogeneous  subject areas. An alternative text manipulation system is outlined useful  for the retrieval of large heterogeneous texts, and for the recognition of  content similarities between text excerpts, based on flexible text matching  procedures carried out in several contexts of different scope. The methods  are illustrated by search experiments performed with the 29-volume Funk and  Wagnalls encyclopedia.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7037,On the Complexity of Shattering Using Arrangements,"A subdivision $\cal S$ of $\Re^{d}$ is said to shatter a set of objects if  each object is contained within the closure of its own cell of $\cal S$. In  this paper, we examine the problem of shattering a set of bounded polyhedral  objects in $\Re^{d}$ by a subdivision formed by an arrangement of  hyperplanes. We show for $\Re^{d}, d \geq$ 2 that finding a minimum-- cardinality set of hyperplanes whose arrangement shatters a set of points  is NP-Complete. We then give algorithms to find a linear-size set of  shattering hyperplanes for a set of $n$ bounded polyhedral objects in  $\Re^{d}$, if one exists. For $d=2$, we provide two algorithms with worst-case  time complexities $O(E+N$log$N+n^{2}$log$n$) and  $O(E+N$log$N+C$log$n+nC^{.695})$, where $E$ is the size of the visibility  graph of the objects, $N$ is the total number of vertices, and $C$ is the  number of candidate lines considered (at worst min\{$E,n^2$\}). Our final  algorithm has worst-case time complexity $O(N^{d+1})$ for $d \geq 3$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7038,A Note on Time-Space Bounded Interactive Protocols.,"In this paper, we examine the power of time-space bounded interactive  protocols with private coins. The class of languages having logspace,  polynomial-time bounded private coin protocols is exactly PSPACE. We  generalize this result to other time-space bounded protocols. As a  consequence we obtasin that EXPSPACE is exactly the class of languages having  polynomial-space, exponential-time bounded private coin interactive  protocols. This coupled with earlier work by Condon, Fortnow and Lund gives  us the following characterization of standard complexity classes in terms of  time-space bounded interactive protocols.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7039,Shattering Configurations of Points With Hyperplanes.,"An arrangement of hyperplanes $\cal A$ in $\Re^d$ is said to shatter a point  set $\cal O$ if each point of $\cal O$ is contained within the interior  of its own cell of $\cal A$. In this paper, we investigate the number of  hyperplanes required by an arrangement that shatters a set of $n$ points in general position. We show that such sets can require between  $\Omega(\sqrt[d]{n})$ and $\Omega(n)$ shattering hyperplanes. We also provide  an algorithm that finds a linear-size shattering for such sets. The number of  hyperplanes produced exceeds the requirements of the worst known example in  $\Re^d$ by at most constant, which depends only on $d$. We also give some  results for when the points are in general convex position.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7040,Consistent Detection of Global Predicates,"A fundamental problem in debugging and monitoring is detecting whether the state of system satisfies some predicate. If the system is distributed,  then the resulting uncertainty in the state of the system makes such dectection, in general, ill-defined. This paper presents three algorithms  for detecting global predicates in a well-defined way. These algorithms do so by interpreting predicates with respect to the communication that has occured in the system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7041,Rabin Measures and Their Applications to Fairness and Automata Theory,"Rabin conditions are general class of properties of infinite sequences that emcompass most known automata-theoretic acceptance conditions and notions of fairness. In this paper we show how to determine whether a program satisfies a Rabin condition by reasoning about single transitions instead of infinite computations. We introduce a concept, called a Rabin measure, which  in a precise sense expresses progress for each transition toward satisfaction of the Rabin condition. When applied to termination problems under fairness constraints, Rabin measures constitute a simpler verification method than previous approaches, which  often are syntax-dependent and require recursive applications of proof rules to syntactically transformed programs. Rabin measures also generalize  earlier automata-theoretic verification methods. Combined with a result by  Safra, our result gives a method for proving that a program satisfies a  nondeterministic Buchi automaton specification.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7042,Improving Sampling and Reconstruction Techniques for Radiosity,"The view-independent global illumination problem is rephrased as one  determining a radiance function across each surface in the environment. A new  methodology for diffuse environments, based on the sampling and  reconstruction of these functions is introduced. Within this context, the following problems are investigated: (i) where the radiance functions should be samples; (ii) how to evaluate a radiance function at each sample; and  (iii) how to reconstruct a radiance function for the set of samples. The new  methodology relaxes some of the assumptions built into current radiosity algorithms. Results are presented which show that the new methodology yields significantly higher accuracy than existing radiosity methods.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7043,Numerical Methods for Hypersingular and Near-Singular Boundary Integrals in Fracture Mechanics,"The boundary integral equation is one of several equivalent forms of  governing equations that can be used to compute approximate solutions to boundary value problems in elasticity and potential flow analysis.   Since it determines the entire solution in terms of values only on the  boundary, there are possible order-of-magnitude advantages in solution        time and geometric complexity over better known `domain-based' methods such as finite elements and finite differences.   In practice, it has been hard to capitalize on these advantages.  Many of the difficulties center around inablility to perform certain numerical  integrations.  This thesis presents (a) a systematic `modal' method of converting singular integrals to easier integrals over `far' surfaces (b)  an otimal quadrature method for the `nearly singular' integration problem. An existence proof is given to show that all surface integrals arising from the 3D boundary integral can be converted to easier contour integrals if basis functions are constructed in a cartesian sense, rather than the  common parametric formulations. Strokes vectors needed to make this result useful are demonstrated for the Laplace equation and for some cases  elasticity. Comparison to analytic benchmark cases shows that the method produces  accurate stress intensity factors for 3-dimensional fracture analysis.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7044,Proving Nondeterministically Specified Safety Properties Using Progress Measures,"Using the notion of progress measures, we discuss verification methods for  proving that a program satisfies a property specified by an automaton having  finite nondeterminism. Such automata can express any safety property.  Previous methods, which can be derived from the method presented here, either  rely on transforming the program or are not to complete. In contrast, our ND  progress measures describe a homomorphism from the unaltered program to a  canonical specification automaton and constitute a complete verification  method. The canonical specification automaton is obtained from the classical  subset construction and a new subset construction, called historization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7045,Minimum Norm Symmetric Quasi-Newton Updates Restricted to Subspaces,"The Davidson-Fletcher-Powell and Broyden-Fletcher-Goldfarb-Shanno updates have  been the two most successful quasi-Newton updates for a variety of  applications. One reason offered in explanation is that they constitute, in an  appropriate norm and metric, the minimum norm change to the matrix, or its  inverse, being approximated which preserves symmetry and obeys the  quasi-Newton equation. Recent methods have reason to consider updates  restricted to certain subspaces. In this paper we derive the general minimum  norm symmetric quasi-Newton updates restricted to such subspaces. In the same  appropriate norm and metric, the minimum norm change update to the matrix or  its inverse is shown to be, respectively, the rank-two update which is a  particular projection of the DFP or BFGS onto this subspace.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7046,The State of Retrieval System Evaluation,"Substantial misgivings have been voiced over the years about the methodologies used to evaluate information retrieval procedures, and about the credibility of many of the available test results. In this note, an attempt is made to  review the state of retrieval evaluation and to separate certain misgivings about the design of retrieval test from conclusions that can legitimately be drawn from the evaluation results.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7047,Beyond Keyframing: An Algorithmic Approach to Animation,"The recent explosion of interest in physical system simulation may soon lead to realistic animation of passive objects, such as sliding blocks or bouncing balls.  However, complex active objects (like human figures and insects) need control mechanism to direct their movements.  We present a paradigm that  combines the advantages of physical simulation and algorithmic specification of movement.  The animator writes an algorithm to control the object and run this algorithm on physical simulator to produce the animation.  Algorithms can  be reused or combined to produce complex sequences of movement , eliminating  the need for tedious keyframing.  We have applied this paradigm to control a  walking biped. The walking algorithm is presented along with the results from testing with Newton simulation system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7048,Robust Point Location in Approximate Polygons,"This paper presents a framework for reasoning about robust geometric  algorithms. Robustness is formally defined and a data structure called an  approximate polygon is introduced and used to reason about polygons  constructed of edges whose positions are uncertain. A robust algorithm for point location in an approximate polygon is presented. The algorithm uses only the signature of the point (not its location) to  determine whether the point is inside or outside the polygon.  An approximate polygon could, by shifting its edges back and forth within their error bounds, induce a large number of different line arrangements. The cell $C_{a}$ with signature $\alpha$ in one such arrangement will be  different than the cell ${C'}_{a}$ with signature $\alpha$ in another  arrangement. This paper proves that, regardless of their position and shapes,  the cells $C_{a}$ and ${C'}_{a}$ are always to the same side of the polygons  which induce their respective arrangements.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7049,Rational Function Decomposition,"This paper presents a polynomial time algorithm for determining whether a  given univariate rational function over an arbitrary field is the composition  of two rational functions over that field, and finds them if so.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7050,On the Complexity of ML Typability with Overloading,"We examine the complexity of type checking in an ML-style type system that  permits functions to be overloaded with different types.  In particular, we  consider the extension of the ML Type system proposed by Wadler and Blott in the appendix of [WB89], with global overloading only, that is, where the only overloading is that which exists in an initial type assumption set; no local overloading via over and inst expressions is allowed. It is shown that  under a correct notion of well-typed terms, the problem of determining  whether a term is well typed with respect to an assumption set in this system  is undecidable. We then investigate limiting recursion in assumption sets, the source of the undecidability. Barring mutual recursion is considered, but this proves too weak, for the problem remains undecidable. Then we consider a  limited form of recursion called parametric recursion. We show that although the problem becomes decidable under parametric recursion, it appears harder  than conventional ML typability, which is complete for DEXPTIME [Mai90].",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7051,The Effectiveness of the Thesaurus Method in Automatic Information Retrieval,"Term grouping and thesaurus methods have frequently been incorporated into  automatic content analysis programs as devices for the recognition of  synonymous expressions and of linguistic entities that may be semantically  similar but syntactically distinct. While it has frequently been asserted that  the recognition of synonyms is essential in language analysis, actual proofs  of the usefulness of a thesaurus in automatic information retrieval are  outstanding. In the present study, formal proofs are given of the effectiveness under  well-defined conditions of the thesaurus method in information retrieval. It  is shown, in particular, that when certain semantically related terms are  added to the information queries originally submitted by the user population,  a superior retrieval system is obtained in the sense that for every level of  the recall the retrieval precision is at least as good for the altered queries  as for the original ones.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7052,A Globally Convergent Method for Lp Problems,"The $l_p$ norm discrete estimation problem $min_{x \epsilon \Re}{n}$  $\|b-A^{T}x\|_{p}$ is troblesome when $p$ is close to unity because the  objective function approaches a discontinuous form. In this paper, we present  an efficient approach for solving $l_p$ norm problems for all  $1\leq p less than 2$. When  $p=1$, it is essentially the method presented in [4], which is globally  and quadratically convergent algorithm under some nondegeneracy assumptions.   The existing iteratively reweighted least squares (IRLS) can be obtained from  the new approach by updating some ""dual multipliers"" in a special fashion.  The new method is globally convergent. It is superlinearly convergent when  there is no zero residual at the solution. The main computational cost of our  new methos is the same as the IRLS method: a reweighted least squares solve.   Numerical experiments indicate this method is significantly faster than  popular iteratively reweighted least squares method when $p$ is close or  equal to one.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7053,An Evaluation Semantics for Classical Proofs,"We show how to interpret classical proofs as programs in a way that agrees  with the well-known treatment of constructive proofs as programs and moreover  extends it to give a computational meaning to proofs claiming the existence  of a value satisfying a recursive predicate. Our method turns out to be  equivalent to H. Friedman's proof by ""A-translation"" of the conservative  extention of classical over constructive arithmetic for $\Pi^{0}_{2}$  sentences. We show that Friedman's result is a proof-theoretic version of a  semantics-preserving CPS-translation from a nonfunctional programming  language (with the ""control"" (C, a relative of call/cc) operator) back to a  functional programming language. We present a sound evaluation semantics for  proofs in classical number theory (PA) of such sentences, as a modification  the standard semantics for proofs in constructive number theory (HA). Our  results soundly extend the proofs-as-programs paradigm to classical logics  and to programs with C.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7054,Symoblic/Numeric Techniques in Modeling and Simulation,"Modeling and simulating collections of physical objects which are subject to a wide variety of physical forces and interactions is exceedingly difficult. The construction of a single simulator capable of dealing with all possible  physical processes is completely impractical and, it seems to us,  wrong-headed. Instead, we propose to build custom simulators for single,  particular collections of physical objects and where pre-specified physical  phenomena are involved. For such an approach to be practical, an environment  needs to be provided that facilitates the quick construction of these  simulators. In this paper we describe the essential features of such an  environment and describe in some detail how a general implementation of the  weight residual method, one of the more general classes of numerical  integration techniques, can be used.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7055,"Classical Proofs as Programs: How, What and Why","We recapitulate Friedman's conservative extension result of(suitable)  classical over constructive systems for $\Pi_{2}^{0}$sentences, viewing it  in two lights: as a translation of programs from an almost-functional language (with $\cal C$) back to its functional core, and as a translation of a  constructive logic for a functional language to a classical logic for an  almost-functional language. We investigate the computational properties of  the translation and of classical proofs and characterize the classical proofs  which give constructions in concrete, computational terms, rather than  logical terms.  We characterize different versions of Friedman's translation as translating slightly different almost-functional languages to a functional  language, thus giving a general method for arriving at a sound reduction  semantics for an almost-functional language with a mixture of eager and lazy constructors and destructors, as well as integers, pairs, unions, etc. Finally, we describe how to use classical reasoning in a disciplined manner  in giving classical (yet constructivizable) proofs of sentences of greater  complexity than $\Pi_{2}^{0}$. This direction offers the possibility of  applying classical reasoning to more general programming problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7056,On Parallelism in Turing Machines,"A model of parallel computation based on a generalization of nondeterminism in  Turing machines is introduced. Complexity classes //T(n)-TIME, //L(n)-SPACE,  //LOGSPACE, //PTIME, etc. are defined for these machines in a way analogous to  T(n)-TIME, L(n)-SPACE, LOGSPACE, PTIME, etc. for deterministic machines. It is  shown that, given appropriate honesty conditions,  217z L(n)-SPACE $\subseteq$ //L$(n)^{2}$-TIME T(n)-TIME $\subseteq$ //log T(n)-SPACE //L(n)-SPACE $\subseteq$ exp L(n)-TIME //T(n)-TIME $\subseteq$ T$(n)^{2}$-SPACE thus //EXPTIME = EXPSPACE //PSPACE = EXPTIME //PTIME = PSPACE //LOGSPACE = PTIME ? = LOGSPACE That is, the deterministic hierarchy LOGSPACE $\subseteq$ PTIME $\subseteq$  PSPACE $\subseteq$ EXPTIME $\subseteq \ldots$ shifts by exactly one level when  parallelism is introduced. We give a natural characterization of the polynomial time hierarchy of  Stockmeyer and Meyer in terms of parallel machines. Analogous space  hierarchies are defined and explored, and a generalization of Savitch's result  NONDET-L(n)-SPACE $\subseteq$ L$(n)^{2}$-SPACE is given. Parallel finite automata are defined, and it is shown that, although they  accept only regular sets, in general, $2^{2^{k}}$ states are necessary and  sufficient to simulate a k-state parallel finite automaton deterministically.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7057,"Derivation of Sequential, Real-Time, Process-Control Programs","The use of weakest-precondition predicate tranformers in the derivation of  sequential, process-control software is discussed.  Only one extension to Dijkstra's calculus for deriving ordinary sequential programs was found to be  necessary: function-valued auxiliary variables. These auxiliary variables are needed for reasoning about states of a physical process that exist during  program transitions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7058,When Is Partial Trace Equivalence Adequate?,"Two processes are partial trace equivalent if they can perform the same  sequences of actions in isolation. Partial trace equivalence is perhaps the  simplest possible notion of process equivalence. In general, it is too simple: it is not usually an adequate semantics. We investigate the circumstances  under which it is adequate, which are surprisingly rich.  We give two  substantial classes of language for which partial traces are adequate. In one  class, partial trace equivalence suffices for total correctness, and  operations such as true sequencing are possible: but all processes are  determinate and silent moves are not possible. The other class admits  indeterminacy and silent moves, but partial traces only suffice for partial  correctness and true sequencing is not definable.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7059,Theory of R-functions and Applications: A Primer,"An R-function is real-valued function characterized by some property that is completely determined by the corresponding property of its arguments, e.g., the sign of some real functions is completely determined by the sign of their  arguments. More generally, such a property could be determined by some  partition of the real axis. If the axis is partitioned  into $k$ subsets, each $R$-function corresponds to a companion function of $k$-valued logic. This  relationship allows one to represent a logical predicate of $n$ variable by a  real-valued function of $n$ arguments. The latter can be evaluated,  differentiated, and possesses many other interesting properties. V.L. Rvachev  first suggested $R$-functions in l963. Since then, he and his colleagues have  significantly developed the theory and found many applications. Their work is  described in  numerous books and articles, unfortunately mostly in Russian.   A complete list of references through l987 can be found in [Shi88]. An important application of $R$-functions is in the description of geometric objects. Any object defined by a predicate on ""primitive"" geometric regions (e.g. regions defined by a system of inequalities) can now be represented by a  single inequality, or equation. Furthermore, these real-valued functions can   be constructed so that they have certain useful logic and differential  properties. Application of theory of $R$-functions could have a profound effect on many problems where geometric information can be accounted for analytically. For example, according to [Rva82], $R$-functions have found applications in  many unexpected areas, such as study of stability of motion, medical  diagnostics, and chemical engineering, in addition to those described in this  report. This primer summarizes some basic results from the theory of $R$-functions and  decribes (rather superficially) some of the applications studied in the Soviet Union. As far as I know, this is the first such introduction to $R$-functions in English. Its main purpose is to stimulate interest in $R$-functions in the research community; it is not intended to serve as a comprehensive reference. While this document contains no original results, absorbing, translating,  interpreting, and condensing the contents of the references did require a  substantial judgement on my part.  The original sources offer a wealth of  additional material that was omitted for the sake of simplicity and coherence of this document. Thus, I also accept the responsibility for all mistakes,  misinterpretations, and omissions in this report. While the main applications of $R$-functions have been in the description of geometric objects, the  developed theory does not seem to rely on many known results in combinatorial,  algebraic, and computational geometry and topology.  In an effort to preserve the spirit of the original work, I resisted making ""improvements"" in the  presentation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7060,Abstract Semantics for a Higher order Functional Language with Logic Variables,"The addition of logic variables to functional languages gives the programmer  novel and powerful tools such as incremental definition of data structures  through constraint intersection.  A number of such ""hybrid"" languages, like  FGL + LV [11], Id [17] and Qute [24], have been implemented and are in active  use.  Pure functional and logic programming languages can be given elegant  abstract semantics as functions and relations over values. The definition of  such an abstract semantics for a functional language with logic variables has  remained an open problem. In an earlier paper, we gave such a semantics for  the special case of a first-order functional languages with logic variables  by reducing the problem to that of solving simultaneous fixpoint equations  involving closure operators over a Scott domain [9]. In fact, we obtained the  rather strong result that the denotational semantics was fully abstract with  respect to the operational semantics. However, the problem for higher-order  languages remain open, in part because higher-order functions can interact  with logic variables in complicated ways to give rise to behavior reminiscent  of own variables in Algol-60. This problem is solved completely in this  paper. We show that in the presence of logic variables, higher-order  functions may be modeled extensionally as closure operators on graphs ordered  a way reminiscent of the ordering on extensible records in studies of  inheritance [1]. We then extend the equation solving semantics of the  first-order subset to the full language, and prove the usual soundness and  adequacy theorems for this semantics. These results show that a higher-order  functional language with logic variables can be viewed as a language of  incremental definition of functions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7061,Generation and Search of Clustered Files,"A classified, or clustered file is one where related, or similar records are  grouped into classes, or clusters of items in such a way that all items within  a cluster are jointly retrievable. Clustered files exhibit substantial  advantages in many retrieval environments over the more conventional inverted  list or multilist technologies. An inexpensive file clustering method applicable to large files is given  together with appropriate file search methods. An abstract model is used to  predict the retrieval effectiveness of various search methods in a clustered  file environment, and experimental evidence is introduced to confirm the  usefulness of the model. As an example, a collection of research papers in  computer science is clustered automatically, and the resulting research  clusters are compared with exissting, manually constructed taxonomies for the  computer field.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7062,Boundry-Based Separation for B-rep $\rightarrow$ CSG Conversion,"We have shown earlier that one of the most difficult steps in performing  b-rep $\rightarrow$ CSG conversion for a curved solid object consists of  determining a set of halfspaces that is sufficient for a CSG representation  of the solid. This usually requires the construction of additional halfspaces  whose boundaries do not contribute to the boundary of the solid. Such  halfspaces are called separating halfspaces because their purpose is to  separate certain subsets of $E^{3}$ inside the solid from those outside of  the solid. Construction of separating halfspaces is specific to a particular  geometric domain, but several generic approaches are possible.   A boundary-based separation is a construction of separating halfspaces that relies on the information present in the boundary of the solid being converted While boundary-based separation for solids with non-planar edges is not well  understood, we study the contraints on the degree of separating halfspaces,  and show that a set of linear separating halfspaces exists for any solid whose boundary contains only planar edges.  We apply the boundary-based separation to solids bounded by general quadric surfaces. Specifically, we prove that a sufficient set of linear separating  halfspaces exists for any such solid, and consider the required constructions in several common situations.  Implications for more general solids are also discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7063,Trade-offs in True Concurrency: Pomsets and Mazurkiewicz Traces,"We compare finite pomsets and Mazurkiewicz traces, two models of true  concurrency which generalize strings.  We show that Mazurkiewicz traces are equivalent to a restricted class of pomsets.  The restrictions lead to extra structure, with results analogous to the differences between simply typed and untyped languages.  For example, traces are consistently complete in the  prefix order, while pomsets are not; also, traces can be distinguished by  observing sequences of actions, in contrast to the elaborate scheme required  for distinguishing pomsets. Finally, we discuss the operations of sequential  and parallel composition in the two models. This is part of an ongoing effort  to relate models of concurrency.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7064,Efficient Sequential and Parallel Algorithms for Maximal Bipartite Sets,"A maximal bipartite set (MBS) in an undirected graph $G = (V, E)$ is a  maximal collection of vertices $B \subseteq$ V$ whose induced subgraph is  bipartite. In this paper we present efficient sequential (linear time) and  parallel (NC) algorithms for constructing an MBS.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7065,Unreliable Failure Detectors for Asynchronous Systems,,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7066,Modeling Arbitrary Smooth Objects with Algebraic Surfaces,"Representing, manipulating, and reasoning about physical objects is a central area of research in a wide range of applications, including solid modeling, computeraided design, computer graphics, and robotics. In these applications,  complex physical objects are modeled using free-form surfaces, surfaces that  are smooth but otherwise arbitrary. Traditionally, free-form surfaces are  constructed from parametric patches, which are very successful as far as  design and rendering are concerned. However, manipulating and reasoning about physical objects with parametric patches poses fundamental difficulties. For example, the difficulty of evaluating and respresenting the intersection of  parametric patches has hindered the development of solid modeling systems based on parametric patches alone. This thesis addresses the problem of constructing free-form surfaces using low degree implicit patches, which facilitate manipulating and reasoning about physical objects.  We establish the fact that quadric patches and cubic  patches are flexible enough for free-form surface constructions: (i) given  an arbitrary polyhedron, we show how to fit a smooth piecewise quadric  surface through the vertices of the polyhedron without splitting its facets;  (ii) given an arbitrary polyhedron with arbitrarily prescribed tangent planes  at its vertices, we present an algorithm that fits a smooth piecewise cubic  surface through the vertices of the polyhedron so that the surface is tangent  to the prescribed tangent plane at each vertex. In constructing free-form  surfaces, we also study three related issues. First, we examine the power and  limitations of blending techniques. We show that on the one hand, blending  techniques can be used to improve the efficiency of free-form surface  constructions; on the other, blending techniques have their fundamental  limitations. Second, we provide a complete understanding of the weight  functions for quadric surfaces meeting with geometric continuity. Finally, we  tackle some shape control issues of implicit patches. In particular, we  demonstrate how to achieve the convexity of a quadric or cubic patch by  manipulating its control points.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7067,The Information Revolution - Myth or Reality,"The early work in the design of automatic information systems, exemplified by  the contributions of H. P. Luhn and others, now goes back nearly twenty years.  It may be useful to ask whether a great deal has changed in these twenty  years, and if so, what contributions have been most influential and indicative  of future trends. Two contradictory opinions are often heard: the optimists  speak of the information revolution and think of mechanized international  information networks; the pessimists, on the other hand, assert that little  has changed and point to the continued use for well over twenty years of  substantially unchanged file organizations, indexing systems, and search  techniques. An attempt is made to separate fact from fiction by describing where we have  stood still, and where progress has occurred. In particular, the technological  environment which has evolved in many directions is distinguished from most of  the intellectual components of information retrieval which have remained  unchanged. Suggestions are also made relating to the design and operations of  future automatic information systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7068,Automatic Indexing Using Term Discrimination and Term Precision Measurements,A variety of abstract automatic indexing models have been developed in recent  times in an effort to produce indexing methods that are both effective and  usable in practice. Among these are thee term discrimination model and the  term precision system. These two indexing systems are briefly described and  experimental evidence is cited showing that a combination of both theories  produces better retrival performance than either one alone. Appropriate  conclusions are reached concerning viable automatic indexing procedures usable  in practice.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7069,"The Theory and Pratice of Robust Geometric Computation, or, How toBuild Robust Solid Modelers","The field of solid modeling makes extensive use of a variety of geometric  algorithms. When implemented on a computer, these algorithms often fail  because the computer only provides floating point arithmetic, while the  agorithms are expecting infinite precision arthmetic on real numbers. These algorithms are not robust. This dissertation presents a theory of robustness. With this theory, a  robust point location algorithm is developed. This algorithm determines  whether a point lies inside a polygon, where both the point and the polygon  are represented approximately. The elegant theoretical approach to robustness is not viable in practice:  algorithms like those used in solid modeling are generally too complex for this approach. This dissertation presents a practical alternative to the formal  theory of robustness; this alternative is called local robustness. Local robustness is applied to the design of a polyhedral intersection  algorithm, which is an important component in many solid modelers. The  intersection algorithm has been implemented, and, in extensive tests, has  never failed to produce a valid polyhedron of intersection. A concise  characterization of the locally robust intersection algorithm is presented; this characterization can be used to develop variants of the intersection algorithm, and to develop robust versions of other solid modeling algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7070,Polymorphic Type Inference for Languages with Overloading and Subtyping,"Many computer programs have the property that they work correctly on a  variety of types of input; such programs are called polymorphic. Polymorphic type systems support polymorphism by allowing programs to be given multiple  types. In this way, programs are permitted greater flexibility of use, while  still receiving the benefits of strong typing. One especially successful polymorphic type system is the system of Hindley, Milner, and Damas, which is used in the programming language ML. This type  system allows programs to be given universally quantified types as a means of  expressing polymorphism. It has two especially nice properties. First, every  well-typed program has a ""best"" type, called the principal type, that  captures all the possible types of the program. Second, principal types can be inferred, allowing programs to be written without type declarations.   However, two useful kinds of polymorphism cannot be expressed in this type  system: overloading and subtyping. Overloading is the kind of polymorphism  exhibited by a function like addition, whose types cannot be captured by a  single universally quantified type formula. Subtyping is the property that one type is contained in another, as, for example, $int \subseteq real$. This dissertation extends the Hindley/Milner/Damas type system to incorporate overloading and subtyping. The key device needed is constrained universal  quantification, in which quantified variables are allowed only those  instantiations, that satisfy a set of constraints.  We present an inference  algorithm and prove that it is sound and complete; hence it infers principal  types. An issue that arises with constrained quantification is the satisfiability of constraint sets. We prove that it is undecidable whether a given  constraint set is satisfiable; this difficulty leads us to impose restrictions on overloading. An interesting feature of type inference with subtyping is the necessity of simplifying the inferred types-the unsimplified types are unintelligible. The simplification process involves shape unification, graph algorithms such as  strongly connected components and transitive reduction, and simplifications  based on the monotonicities of type formulas.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7071,Investigations Into Abstraction and Concurrency,"Abstract semantics serves as an interface between a language and the user: the interface serving to hide a significant degree of operational detail and  present a simpler view of program execution to the user. What are the  properties that an abstract semantics should satisfy? It was an insight of  Strachey [4l] that the abstract semantics must be compositional; thus, one  must be able to ""build up"" the abstract meaning of a program from the  abstract meanings of its components.  Note that it is not immediately obvious  how one thinks of recursive programs in this manner. This is the role of  fixpoint theory developed by Scott [62]. Informally, fixpoint theory  formalisms the intuitive inductive arguments that one uses in reasoning about recursive programs. The theory developed by Scott works for determinate  programs: programs that yield one output for every input. Thus, the theory is  inadequate to handle indeterminate programs: programs that can yield more  than one output for a given input. Powerdomains, that can be viewed as the  computable analogue of the powerset, were developed to enlarge the scope of  the theory of Scott to handle indeterminate computations [52,64]. Domain  theory, enriched with powerdomain constructions to handle indeterminacy has  been successful in serving as a mathematical formalism powerful enough to  specify abstract semantics for tranformational programs: programs that take  a input, compute in isolation and return an output. Thus, programs are  usually denoted by functions in the determinate case and as Input-Output  relations in the indeterminate case. The semantics is termed abstract because  it hides significant degree of internal operational detail and presents an  extensional view of programs.  The situation is not as clear for interactive programming systems: systems  built out of processes which engage in communication with the environment  and/or other processes while computing. The key difference from  transformational systems is that the output produced by a process can  influence its input. Static, determinate dataflow [32] is the prime example  of the few models interactive systems that are amenable to extensional  treatment.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7072,An Operational Semantics of First-class Synchronous Operations,"First-class synchronous operations are a new approach to synchronization and communication in concurrent languages. They have been informally described in [Rep88], and [Rep91a]; this paper presents an operational semantics for an  untyped language with first-class synchronous operations. This language in- cludes a large fraction of the concurrency primitives of Concurrent ML CML),  a concurrent extension of SML, and is the first step toward formalizing the  definition of CML.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7073,"Practical Utility of Knowledge-Based Analyses: Optimizations and Optimality for an Implementation of Asynchronous, Fail-Stop Processes (Extended Abstract).","The Group Membership Problem is concered with propagating changes in the  membership of a group of processes to the members of that group. A restricted version of this problem allows one to implement a fail-stop failure model of  processes in an asynchronous environment assuming a crash failure model.  While the ISIS Toolkit relies on this for its Failure Detector, the current  specification of GMP sheds no light on how to implement it. We present a  knowledge-based formulation, cast as a commit-style problem, that is not only  easier to understand, but also makes clear where optimizations to the ISIS  implementation are and are not possible. In addition, the epistemic  formulation allows us to use the elegant results of knowledge-acquisition  theory to discover a lower bound on the required number of messages,  construct a minimal protocol, and discuss the tradeoffs between the  message-minimal protocol and the optimized ISIS implementation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7074,Computional Learning of Languages,"This thesis focuses on the Gold model of inductive inference from positive  data. There are several aspects in which the model appears unsatisfactory for language learning: the class of families of learnable languages is highly restricted; even if a family is learnable, there exists no uniform method to obtain a learner for it, and the learner itself is complex. In this thesis,  some such criticisms are being addressed. It is shown that no automatic synthesis of a learner from the description of a learnable family is possible. Nevertheless, in some special cases, this synthesis can be achieved and a general result is developed. In order to make the learner simpler, it is stipulated that the learner can change its guess only when the guess is inconsistent with the input evidence. Such a  conservative learner never overgeneralizes. Exactly learnable families are  characterized for prudent learners with the following types of constraints:  (0) conservative, (1) conservative and consistent, (2) conservative and  responsive, and (3) conservative, consistent and responsive. It is also shown  that, when exactness is not required, prudence, consistency and  responsiveness, even together, do not restrict the power of conservative  learners. Conservative learners are simple in only one respect; even though it is easy  to determine when to make a new guess, it is still hard to know what this guess should be. Finally, a learner that exploits pattern evident in the input is developed. Absence of a particular string over a suitable interval of the  input can be viewed as a kind of ""indirect negative evidence"". Now, the  learning criterion needs to be weakened to allow limited failure. It is shown  that any family of languages can be learned with probability 1 from  stochastic input, provided something is known about the probability  distribution according to which the input is presented. Given the family, the  learner is uniformly constructible. Further, the behavior of the learner is  simpler in many aspects. It is expected that a variety of other natural  constraints can be imposed on this learner without additional cost.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7075,Metalogical Frameworks,"In computer science we speak of implementing a logic; this done in a  programming language, such as Lisp, called here the implementation language.  We also reason about the logic, as in understanding how to search for proofs  or in knowing it is consistent; in the terminology of mathematical logic,  these arguments are conducted in the metalanguage of the object language being  implemented. We also reason about the implementation itself, say to know it is  correct. This is done in a programming logic. How do all these logics relate?  This paper considers that question and more. We show that by taking the view that the metalogic is primary, these other  parts are related in standard ways. The metalogic must be suitably rich so  that the object logic can be presented as an abstract data type, and it must  be suitably computational (or constructive) so that an instance of that type  is an implementation. The data type abstractly encodes all that is relevant  for metareasoning, i.e. not only the term constructing functions but also the  principles for reasoning about arbitrary terms and computing with them. Our work can also be seen as an approach to the task of finding a generic  way to present logics and their implementations, which is for example the  goal of the Edinburgh Logical Frameworks (ELF) effort. This approach extends well beyond proof-construction and includes computational metatheory as well.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7076,Large-Scale Numerical Optimization: Introduction and Overview,"We give an introductory overview of the field of large-scale numerical  optimization; some of the basic research issues and recent developments are described.  Our emphasisis on  methods, techniques, and practical concerns.  We hope this article will be of interest to both users and students of  numerical optimization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7077,Deterministic On-Line Routing on Area-Universal Networks,"Two deterministic routing networks are presented: the pruned butterfly and  the sorting fattree. Both networks are area-universal, i.e., they can  simulate any other routing network fitting in similar area with  polylogarithmic slowdown. Previous area-universal networks were either for  the off-line problem, where the message set to be routed is known in advance  and substantial precomputation is permitted, or involved randomization,  yielding results that hold only with high probability. The two networks  introduced here are the first that are simultaneously deterministic and  on-line, and they use two substantially different routing techniques. The  performance of their routing algorithms depends on the difficulty of the  problem instance, which is measured by a quantity $\lambda$ known as the load  factor. The pruned butterfly algorithm runs in time $O$($\lambda$ log$^{2}$  $N$), where $N$ is the number of possible sources and detinations for  messages and $\lambda$ is assumed to be poylnomial in $N$. The sorting fat-tree algorithm runs in $O$ ($\lambda$ log $N$ + log$^{2}$ $N$) time for a  restricted class of message sets including partial permutations. Other  results of this work include a new type of sorting circuit and an area-time  lower bound for routers.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7078,Putting Time into Proof Outlines,,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7079,The Complexity of Resolution Procedures for Theorem Proving in the Propositional Calculus,"A comparative study on the complexity of various procedures for proving that  a set of clauses is contradictory is described. All the procedures either use  the resolution rule in some form or are closely related to procedures which  do. Among the procedures considered are 1. resolution 2. regular resolution  3. Davis Putnam procedure 4. resolution with extension 5. bounded (and  iterated bounded) resolution 6. enumeration procedures 7. semantic trees.  The results include: a. exponential lower bounds for the run-time of most of the procedures, b. realtions between the various procedures, c. implications to the comlexity of integer programming routines.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7080,Maintaining Consistency in Distributed Systems,"How should distributed systems preserve consistency in the presence of concurrency and failures? For systems designed as assemblies of independently developed components, concurrent access to data or data structures would normally arise within individual programs, and be controlled using mutual exclusion constructs, such as semaphores and monitors. Where data is persistent and/or sets of operations are related to one another, transactions or linearizability may be more appropriate. Systems that incorporate cooperative  styles of distributed execution often replicate or distribute  data within groups of components. In these cases, group-oriented consistency properties must be maintained, and tools based on the virtual synchrony execution model greatly simplify the task confronting an application  developer. All three styles of distributed computing are likely to be seen in  future systems - often, within the same application. This leads us to propose  an integrated approach that permits applications that use virtual synchrony to  with concurrent objects that respect a linearizability constraint, and vice versa. Transactional subsystems are treated as a special case of  linearizability. Keywords and phrases: Transaction, atomicity, monitors, serializability, linearizability, virtual synchrony, object-oriented programming, distributed computing, federated databases, fault-tolerance.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7081,Automatic Structuring of Text Files,"In many practical information retrieval situations, it is necessary to process heterogeneous text databases that vary greatly in scope and coverage, and deal with many different subjects. In such an environment it is important to  provide flexible access to individual text pieces, and to structure the collection so that related text elements are identified and appropriately  linked. Methods are described in this study for the automatic structuring of  heterogeneous text collections, and the construction of browsing tools and  access procedures that facilitate collection use.  The proposed methods are illustrated by performing searches with a large automated encyclopedia.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7082,Covering a Triangle with Disks Centered on its Boundary,"Let $\cal P$ be a triangle and $\cal D_{1}, \cal D_{2}$ be disks centered on the boundary of $\cal P$ with radii $r_{1}$, $r}_{2}$. The disks are  chosen so that $\cal D_{1}$ $\cup$ $\cal D$$_{2}$ covers $\cal P$ and  $r_{1}$ + $r_{2}$ is minimized. We show that an optimal covering must exist  with $r_{2}$ = 0. In such a single disk covering, $\cal D_{1}$ is always  located on the longest side of $\cal P$. The exact location and and size  depend on the angles of $\cal P$; we provide a complete characterization and  then generalize it to convex polygons. We show that the minimum covering disk  can be determined in $\cal O (n)$ time for a convex polygon with $n$ sides.  However, it is open for $n \geq$ 4 whether there is always a single disk  covering that is optimal.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7083,Incremental Reduction in the Lambda Calculus and Related Reduction Systems,"An incremental algorithm is one that computes a function repeatedly on a series of inputs that differ only slightly from one another, yet avoids  unnecessary duplication of computations from one input to the next. This thesis is a study of incremental computation in a general class of  reduction systems, focusing particularly on the untyped lambda calculus and term rewriting systems. We also study implementation techniques used for such reduction systems and the question of the existence of optimal reduction strategies. Most of our results are based on a new class of reduction systems we define  called regular replacement systems. These systems combine an abstract reduction relation with a notion of structure defined by a Brouwerian algebra. The reduction relation defines a computation system, while the  algebra is used to define what constitutes an incremental change to some  object. Numerous reduction systems, including many term and graph rewriting systems and a variant of the lambda calculus, constitute regular replacement  systems. Among our results is a generalization of the lattice-theoretic  reduction theory of Levy to regular replacement systems. This theory makes it possible to give a precise and intuitively appealing definition of what it means for both incremental and non-incremental  computations to be optimal. We then investigate a family of term rewriting systems centered around a  system we call $\bf \Lambda${\bf CCL}. Each of these systems is capable of  simulating a normalizing reduction strategy in the lambda calculus. However,  unlike the lambda calculus, the notion of substitution is an explicit part  of $\bf \Lambda${\bf CCL}'s semantics, rather than being relegated to the  status of meta-theory. Our study culminates with the definition of a $\bf \Lambda${\bf CCL}-based  incremental reduction algorithm. This algorithm is optimal, yet it is simple enough to allow a practical implementation. We believe that appropriate generalizations of the ideas embodied in the algorithm can be used in a  variety of practical settings, particularly those in which an algorithm is  expressed in a functional or applicative manner.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7084,On The Structure Of NP Computations Under Boolean Operators,"This thesis is mainly concerned with the structural complexity of the Boolean Hierarchy. The Boolean Hierarchy is composed of complexity classes constructed using Boolean operators on NP computations. The thesis begins with a  description of the role of the Boolean Hierarchy in the classification of the  complexity of NP optimization problems. From there, the thesis goes on to  motivate the basic definitions and properties of the Boolean Hierarchy. Then, these properties are shown to depend only on the closure of NP under the  Boolean operators, AND$_{2}$ and OR$_{2}$. A central theme of this thesis is the development of the hard/easy argument which shows intricate connections between the Boolean Hierarchy and the  Polynomial Hierarchy. The hard/easy argument shows that the Boolean Hierarchy cannot collapse unless the Polynomial Hierarchy also collapses. The results shown in this regard are improvements over those previously shown by Kadin. Furthermore, it is shown that the hard/easy argument can be adapted for  Boolean hierarchies over incomplete NP languages. That is, under the  assumption that certain incomplete languages exist, the Boolean hierarchies  over those languages must be proper (infinite) hierarchies. Finally, this  thesis gives an application of the hard/easy argument to resolve the  complexity of a natural problem - the unique satisfiability problem. This  last refinement of the hard/easy argument also points out some long-ignored  issues in the definition of randomized reductions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7085,Real Functions for Representation of Rigid Solids,"A range of values of a real function $f$ : $E^{d} $\rightarrow \Re$ can be  used to implicitly define a subset of Euclidean space $E^{d}$. Such `implicit  functions' have many uses in geometric and solid modeling. This paper focuses  on the properties and construction of real functions for the representation  of rigid solids (compact, semi-analytic, and regular subsets of $E^{d}$). We  review some known facts about real functions defining compact semi-analytic  sets, and their applications. The theory of $R$-functionsdeveloped in [Rva82]  provides means for constructing real function representations of solids  described by the standard (non-regularized) set operations. But solids are not closed under the standard set operations and such  representations are rarely available in modern modeling systems. More  generally, assuring that a real function $f$ represents a regular set may be  difficult. Until now, the regularity has either been assumed, or treated in an ad hoc fashion. We show that topological and extremal properties of real  functions can be used to test for regularity, and discuss procedures for  constructing real functions with desired properties for arbitrary solids.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7086,SimLab: Automatically Creating Physical Systems Simulators,"SimLab, a software environment for creating simulators directly from  computer-readable physics models, is based on the following concept: creating  physical systems simulators should be as simple as describing the underlying  physics to a colleague. Rather than programming in a conventional programming language, a SimLab user  expresses physics models (and thus simulators) directly in terms of the  concepts, quantities, and equations familiar to a scientist or engineer. The benefits of the SimLab approach include: 1) reducing the time  and effort required to create simulators, 2) providing more understandable and reliable simulators, and 3) support for more sophisticated simulators, e.g.,  for multiple domain problems, which have proved intractible in the past.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7087,A Rational Rotation Method for Robust Geometric Algorithms (Extended Abstract),"Algorithms in computational geometry often use the real-RAM model of  computation. In particular, this model assumes that exact real numbers can be  stored in and retrieved from memory in constant $O$ (1) time, and that field  operations (+, -, *, /) and certain other operations (like square root, sine  and cosine) are also ""exact,"" and can be applied in constant time.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7088,Sensor Interpretation and Task-Directed Planning Using Perceptual Equivalence Classes,"We consider how a robot may interpret its sensors and direct its actions so as to gain more information about the world, and to accomplish manipulation tasks. The key difficulty is uncertainty, in the form of noise in sensors, error in  control, and unmodelled or unknown aspects of the environment. Our research focuses on general techniques for coping with uncertainty, specifically, to  sense ther state of the task, adapt to changes, and reason to select actions  to gain information and achieve the goal. Sensors yield partial information about the world. When we interrogate the  environment through our sensors, we in effect view a projection of the world  onto the space of possible sensor values. We investigate the structure of this  sensor space and its relationship to the world. We observe that sensors  partition the world into perceptual equivalence classes, that can serve as  natural ""landmarks."" By analyzing the properties of these equivalence  classes we develop a ""lattice"" and a ""bundle"" structure for the  information available to the robot through sensing and action. This yields a  framework in which we develop and characterize algorithms for sensor-based  planning and reasoning.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7089,Tools and Techniques for Adding Fault Tolerance to Distributed and Parallel Programs,"The scale of parallel computing systems is rapidly approaching dimensions  where fault tolerance can no longer be ignored. No matter how reliable the  individual components may be, the complexity of these systems results in a  significant probability of failure during lengthy computations. In the case of distributed memory multiprocessors, fault tolerance techniques developed for  distributed operating systems and applications can be applied also to parallel  computations. In this paper we survey some of the principal paradigms for  fault-tolerant distributed computing and discuss their relevance to parallel  processing. One particular technique - passive replication - is explored in  detail as it forms the basis for fault tolerance in the Paralex parallel  programming environment. Keywords: Parallel processing, reliability, transactions, checkpointing, recovery, replication, reliable broadcast, causal ordering, Paralex.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7090,Paralex: An Environment for Parellel Programming in Distributed Systems,"Modern distributed systems consisting of powerful workstations and high-speed  interconnection networks are an economical alternative to special-purpose  super computers. The technical issues that need to be addressed in exploiting  the parallelism inherent in a distributed system include heterogeneity,  high-latency communication, fault tolerance and dynamic load balancing.  Current software systems for parallel programming provide little or no  automatic support towards these issues and require users to be experts in  fault-tolerant distributed computing. The Paralex system is aimed at exploring the extent to which the parallel application programmer can be liberated from  the complexities of distributed systems. Paralex is a complete programming  environment and makes extensive use of graphics to define, edit, execute and  debug parallel scientific applications. All of the necessary code for  distributing the computation across a network and replicating it to achieve  fault tolerance and dynamic load balancing is automatically generated by the  system. In this paper we give an overview of Paralex and present our  experiences with a prototype implementation",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7091,Run-time Support for Dynamic Load Balancing and Debugging in Paralex,"Paralex is a programming environment for developing and executing parallel  applications in distributed systems. The user is spared complexities of  distributed programming including remote execution, data representation, communication, synchronization and fault tolerance as they are handled  automatically by the system. Once an application starts execution in a  distributed system, it may be interacted with at two levels: by Paralex itself to achieve automatic fault tolerance and dynamic load balancing; or by the  user in association with performance tuning and debugging. In this paper, we  describe the set of monitors and control mechanisms that constitute the  Paralex run-time system and their use for implementing dynamic load balancing  and debugging.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7092,Fault-Tolerant Management of Distributed Applications Using the Reactive System Architecture,"Distributed applications are becoming increasingly pervasive, and difficult to  manage. Examples of distributed applications include operating system servers  and clients on a network, programs performing distributed computations, and  systems constructed by integrating stand-alone programs. This thesis argues  that distributed applications can be managed efficiently by using a reactive  system architecture. A reactive system consists of a control component  continuously responding to changes in an environment component. This structure is applied to distributed application management by casting the programs  making up the application as the environment and super-imposing a layer of  control. By acting upon conditions sensed in the environment, the control  layer can respond to changes in the distributed application, ensuring that it  functions in a well-behaved manner. This thesis also presents the Meta  toolkit, which provides primitives for controlling distributed applications  using the reactive system architecture. The application components are  instrumented with sensors and actuators - routines that respectively read and  modify the application state. Control of the application is carried out via  guarded commands, which are distributed for execution by either stubs  coresident with programs in the application or by special servers.  Distributing the control program results in greater responsiveness and  efficiency but requires certain consistency problems to be addressed.  Furthermore, the Meta toolkit supports fault-tolerant execution of guarded  commands through the use of replicated servers. This toolkit has been  implemented and is completely functional, and this thesis contains extensive  performance figures for the toolkit.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7093,Constructive Recognizability for Task-Directed Robot Programming,"The primary goal of our research is task-level planning. We approach this goal  by utilizing a blend of theory, implementation, and experimentation. We  investigate task-level planning for autonomous agents, such as mobile robots,  that function in an uncertain environment. These robots typically have very  approximate, inaccurate, or minimal models of the environment. For example,  although the geometry of its environment is crucial to determining its  performance, [footnote:I.e., what the geometry is will have a key role in  determining the robot's actions or behavior.] a mobile robot might only have  a partial, or local ""map"" of the world. Similarly, the expected effects of  a robot's actuators critically influence its selection of actions to  accomplish a goal, but a robot may have only a very approximate, or local  predictive ability with regard to forward-simulation of a control strategy.  While mobile robots are typically equipped with sensors in order to gain  information about the world, and to compensate for errors in actuation and  prediction, these sensors are noisy, and in turn provide inaccurate  information. We investigate an approach whereby the robot attempts to acquire  the necessary information about the world by planning a series of experiments [footnote: The robot (not the researchers!) performs the experiments, to gain  information about the world.] using the robot's sensors and actuators, and  building data-structures based on the robot's observations of these  experiments. A key feature of this approach is that the experiments the robot  performs should be driven by the information demands of the task. That is, in  performing some task, the robot may enter a state in which making progress  towards a goal requires more information about the world (or its own state).  In this case, the robot should plan experiments which can disambiguate the  situation. When this process is driven by the information demands of the task, we believe it is an important algorithmic technique to effect task-directed  sensing. This introductory survey article discusses: 1. A theory of sensor interpretation and task-directed planning using  perceptual equivalence classes, intended to be applicable in highly uncertain  or unmodelled environments, such as for a mobile robot. 2. Algorithmic techniques for modelling geometric constraints on  recognizability, and the building of internal representations (such as maps)  using these constraints. 3. Explicit encoding of the information requirements of a task using a lattice (information hierarchy) of recognizable sets, which allows the robot to  perform experiments to recognize a situation or a landmark. 4. The synthesis of robust mobot programs using the geometric constraints,  constructive recognizability experiments, and uncertainty models imposed by  the task. We discuss how to extend our theory and the geometric theory of planning to  overcome challenges of the autonomous mobile robot domain. One of our most  important goals is to show how our theory can be made constructive and  algorithmic. We propose a framework for mobot programming based on  constructive recognizability, and discuss why it should be robust in uncertain environments. Our objective is to demonstrate the following: When  recognizability is thusly constructive, we naturally obtain task-directed  sensing strategies, driven by the information demands encoded in the structure of the recognizable sets. A principled theory of sensing and action is crucial in developing task-level  programming for autonomous mobile robots. We propose a framework for such a  theory, providing both a precise vocabulary and also appropriate computational machinery for working with issues of information flow in and through a robot  system equipped with various types of sensors and operating in a dynamic,  unstructured environment. We are implementing the theory and testing it on  mobile robots in our laboratory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7094,Task-Level Planning and Task-Directed Sensing for Robots in Uncertain Environments,"The primary goal of our research is task-level planning. We approach this goal  by utilizing a blend of theory, implementation, and experimentation. We  propose to investigate task-level planning for autonomous agents, such as  mobile robots, that function in an uncertain environment. These robots  typically have very approximate, inaccurate, or minimal models of the  environment. For example, although the geometry of its environment is crucial  to determining its performance, a mobile robot might only have a partial, or  local ""map"" of the world. Similarly, the expected effects of a robot's  actuators critically influence its selection of actions to accomplish a goal,  but a robot may have only a very approximate, or local predictive ability  with regard to forward-simulation of a control strategy. While mobile robots  are typically equipped with sensors in order to gain information about the  world, and to compensate for errors in actuation and prediction, these sensors are noisy, and in turn provide inaccurate information. We propose to investigate an approach whereby the robot attempts to acquire the necessary  information about the world by planning a series of experiments using the  robot's sensors and actuators, and building data-structures based on the  robot's observations of these experiments. A key feature of this approach is  that the experiments the robot performs should be driven by the information  demands of the task. That is, in performing some task, the robot may enter a  state in which making progress towards a goal requires more information about  the world (or its own state). In this case, the robot should plan experiments  which can disambiguate the situation. When this process is driven by the  information demands of the task, we believe it is an important algorithmic  technique to effect task-directed sensing. Plan projects focus on: 1. A theory of sensor interpretation and task-directed planning using  perceptual equivalence classes, intended to be applicable in highly uncertain  or unmodelled environments, such as for a mobile robot. 2. Algorithmic techniques for modelling geometric constraints on  recognizability, and the building of internal representations (such as maps)  using these constraints. 3. Explicit encoding of the information requirements of a task using a lattice (information hierarchy) of recognizable sets, which allows the robot to  perform experiments to recognize a situation or a landmark. 4. The synthesis of robust mobot programs using the geometric constraints,  constructive recognizability experiments, and uncertainty models imposed by  the task. We propose to (a) continue our research and develop the theory fully, (b) use  tools and concepts from the geometric theory of planning where appropriate, and (c) extend our theory and the geometric theory of planning where necessary to  overcome challenges of the autonomous mobile robot domain. One of our most  important goals is to show how our theory can be made constructive and  algorithmic. We propose a framework for mobot programming based on  constructive recognizability, and discuss why it should be robust in uncertain environments. Our objective is to demonstrate the following: When  recognizability is thusly constructive, we naturally obtain task-directed  sensing strategies, driven by the information demands encoded in the structure of the recognizable sets. A principled theory of sensing and action is crucial in developing task-level  programming for autonomous mobile robots. We propose a framework for such a  theory, providing both a precise vocabulary and also appropriate computational machinery for working with issues of information flow in and through a robot  system equipped with various types of sensors and operating in a dynamic,  unstructured environment. We will implement the theory and test it on mobile  robots in our laboratory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7095,Computing Integrals Involving the Matrix Exponential,A new algorithm for computing integrals involving the matrix exponential is  given. The method employs diagonal Pade approximation with scaling and  squaring. Rigorous truncation error bounds are given and incorporated in a  FORTRAN subroutine. The computational aspects of this program are discussed  and compared with existing techniques.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7096,The Data Structure Accelerator Architecture,"We present a fine grained, massively parallel SIMD architecture called the  data structure accelerator and demonstrate its use in a number of problems in  computational geometry. This architecture is extremely dense and highly  scalable. Systems of 10$^6$ processing elements can be feasibly embedded in  work stations. We advocate that this architecture be used in tandem with  conventional single sequence machines and with small scale, shared memory  multiprocessors. We present a language for programming such heterogeneous  systems that smoothly encorporates the SIMD instructions of the data structure accelerator with conventional single sequence code.  [footnote: This is an expanded version of a paper that was presented at the  Jerusalem Conference on Information Technology, October 1990.]",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7097,Design Alternatives for Process Group Membership and Multicast,"Process groups are a natural tool for distributed programming, and are  increasingly important in distributed computing environments. However, there  is little agreement on the most appropriate semantics for process group  membership and group communication. These issues are of special importance in  the Isis system, a toolkit for distributed programming [Bir91]. Isis supports  several styles of process group, and a collection of group communication  protocols spanning a range of atomicity and ordering properties. This  flexibility makes Isis adaptable to a variety of applications, but is also a  source of complexity that limits performance. This paper reports on a new  architecture that arose from an effort to simplify Isis process group  semantics. Our findings include a refined notion of how the clients of a group  should be treated, what the properties of a multicast primitive should be when systems contain large numbers of overlapping groups, and a new construct  called the causality domain. As an illustration, we apply the architecture to  the problem of converting processes into fault-tolerant process groups in a  manner that is ""transparent"" to other processes in the system. A system  based on this architecture is now being implemented in collaboration with the  Chorus and Mach projects. Keywords: distributed computing, fault-tolerance, Isis, process groups, virtual synchrony, causal multicast, atomic broadcast.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7098,On Dexterous Rotations of Polygons,"Dexterous manipulation, which is the reorientation of objects inside robot  hands, is an active area of robotics research, whose progress has been slow.  In this paper, we present an algorithm for dexterous rotations of polygons by  finger tracking. The algorithm involves simple finger motions, it can achieve  arbitrarily large rotations, and it is robust in the presence of computational uncertainties.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7099,Saving Queries With Randomness,"In this paper, we provide tight bounds on the success probabilities of  randomized reductions between various classes in the Boolean and Bounded Query  Hierarchies. The P$^{SAT\Vert[k]}$ $\leq^{P}_{m}$ - complete language  randomly reduces to a language in P$^{SAT\Vert[k-1]}$ with a one-sided error  probability of 1/$\lceil$k/2$\rceil$. If two-sided error is allowed, then we  show that a much lower error probability of 1/($k$ + 1) can be achieved.  We prove that both these reductions are almost optimal by showing that the  error probabilities cannot be reduced by even 1/poly, unless the PH collapses.  These tight bounds precisely characterize the power and limitations of  randomness in saving a query to SAT. These results can be used to identify optimal probability thresholds which  determine when languages complete under randomized reductions inherit the  hardness properties associated with $\leq^{P}_{m}$ - complete languages.  Using these thresholds we prove hardness properties for some languages in  these classes which are not $\leq^{P}_{m}$ - complete in certain relativized  worlds. We also explore the relationship between randomization and functions  computable using bounded queries to SAT. For any function $h (n) = O(log $n$), we show that there is a function $f$ computable using $h(n)$ nonadaptive  queries to SAT, which cannot be computed correctly with probability 1/2+1/poly by any randomized machine which makes less than $h(n)$ adaptive queries to any oracle, unless PH collapses.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7100,A Formal Definition of Unnecessary Computation In Functional Programs,"Our goal is to develop a new and highly flexible approach to program  optimization. Instead of applying rote, high-level transformations, we seek to  derive optimizations automatically from broad and intuitive principles. Toward  that end this paper presents a new formalism for first-order, purely  functional programs, then uses the formalism to give a rigorous statement of  a principle of optimization. The formalism occupies three levels. At the  lowest level is the trace graph, a finite, graph-like structure that describes a single terminating path of execution through a functional program. At the  middle level is the trace graph set, which describes a set of paths of  execution; a certain kind of trace graph set, the executable set, describes  the full set of paths for a single deterministic program. At the highest  level is the trace grammar, a graph grammar that generates a trace graph set.  While trace graph sets may be infinite, trace grammars are finite objects  with a natural, subroutine-like recursive structure. We use the formalism to  give a rigorous statement of a well-known principle of optimization, namely,  that programs should not make any unnecessary computations. This principle  is so obvious that it is often overlooked, but it underlies many common  compiler optimizations and other, more exotic program transformations. Our  formal statement of the principle unifies and illuminates many optimizing  transformations. Our work in progress is the construction of an optimizer  that derives optimizations directly from our formal principle. This paper  concludes with an overview of this optimizer and some preliminary experimental results.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7101,On Isomorphisms and Density of NP and Other Complete Sets,"If all NP complete sets are isomorphic under deterministic polynomial time  mappings (p-isomorphic) then P $\neq$ NP and if all PTAPE complete sets are  p-isomorphic then P $\neq$ PTAPE. We show that all NP complete sets known  (in the literature) are indeed p-isomorphic and so are the known PTAPE  complete sets. Thus showing that, in spite of the radically different origins  and attempted simplification of these sets, all the known NP complete sets are  identical but for polynomially time bounded permutations. Furthermore, if all NP complete sets are p-isomorphic then they must have  similar densities and, for example, no language over a single letter alphabet  can be NP complete, nor can any sparse language over an arbitrary alphabet be  NP complete. We show that complete sets in EXPTIME and EXPTAPE cannot be  sparse and therefore they cannot be over a single letter alphabet. Similarly,  we show that the hardest context-sensitive languages cannot be sparse. We also  relate the existence of sparse complete sets to the existence of simple  combinatorial circuits for the corresponding truncated recognition problem of  these languages.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7102,Logics and Models of Real Time: A Survey,"We survey logic-based and automata-based languages and techniques for the  specification and verification of real-time systems. In particular, we discuss  three syntactic extensions of temporal logic: time-bounded operators, freeze  quantification, and time variables. We also discuss the extension of  finite-state machines with clocks and the extension of transition systems with  time bounds on the transitions. All of the resulting notations can be  interpreted over a variety of different models of time and computation,  including linear and branching time, interleaving and true concurrency,  discrete and continuous time. For each choice of syntax and semantics, we  summarize the results that are known about expressive power, algorithmic  finite-state verification, and deductive verification.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7103,Timed Transition Systems,"We incorporate time into an interleaving model of concurrency. In timed  transition systems, the qualitative fairness requirements of traditional  transition system are replaced (and superseded) by quantitative lower-bound  and upper-bound timing constraints on transitions. The purpose of this paper  is to explore the scope of applicability for the abstract model of timed  transition systems. We demonstrate that the model can represent a wide  variety of phenomena that routinely occur in conjunction with the timed  execution of concurrent processes. Our treatment covers both processes that  are executed in parallel on separate processors and communicate either  through shared variables or by message passing, and processes that time-share  a limited number of processors under a given scheduling policy. Often it is  this scheduling policy that determines if a system meets its real-time  requirements. Thus we explicitly address such questions as time-outs,  interrupts, static and dynamic priorities.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7104,A Brief Survey of Convergence Results for Quasi-Newton Methods,This paper highlights the important theoretical developments in the study of  quasi-Newton or update methods and suggests avenues for future research. An  attempt is made to present this material in a way reasonably compatible with  history but organized for the novice.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7105,Primary-Backup Protocols: Lower Bounds and Optimal Implementations,"We present a formal specification of primary-backup. We then prove lower  bounds on the degree of replication, failover time and worst-case response  time to client requests assuming different failure models. Finally, we  outline primary-backup protocols and indicate which of our lower bounds are  tight. Keywords: Fault-tolerance, reliability, availability, primary-backup,  lower bounds, optimal protocols.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7106,Performance in Flexible Distributed File Systems,"There are many existing distributed file systems. Each file system provides a  different degree of performance and safety. In this context, performance is  the time required to satisfy individual requests, and safety is the set of  guarantees that the file system provides to users. In this thesis, we  characterize many of the trade-offs between performance and safety. We include  numerical relationships whenever possible. As a corollary, it is shown that a  flexible file system - one that provides a wide range of possible safety  properties - can also have very good performance. This thesis uses two main approaches, practical and theoretical. The practical  approach centers around the Deceit File System. Deceit supports file  replication, file migration and a sophisticated update control protocol.  Deceit can behave like a plain Sun Network File System (NFS) server and can  be used by any NFS client without modifying any client software. Deceit  servers are interchangeable and collectively provide the illusion of a single  large server machine to its clients. The theoretical approach presents several results that are applicable to all  distributed file systems. A careful analysis of many systems yielded insights  into the behavior of successful file systems. We formalize the relationships  between safety conditions exposed by this analysis. We also determine the  cost of reading and writing a file given different sets of safety conditions. In conclusion, we find that Deceit does not totally meet the goal of being  efficient under all possible sets of requirements. Deceit is highly efficient  for cases that require a high degree of replication and safety, but it is  inefficient in cases where very specific optimizations are possible. However,  the flexibility that Deceit provides is still very useful. For example, we  show that writing to a file with three replicas costs a factor of 5 more  messages more than writing to a file with one replica. Allowing asynchronous  disk writes instead of synchronous writes can decrease latency by a factor of  more than 30. Since Deceit allows the user to choose among these  possibilities, dramatic performance gains can be achieved in many cases.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7107,Quality Mesh Generation in Three Dimensions,"We show how to triangulate a three dimensional polyhedral region with holes. Our triangulation is optimal in the following two senses: First, our  triangulation achieves the best possible aspect ratio up to a constant.  Second, for any other triangulation of the same region into $m$ triangles with  bounded aspect ratio, our triangulation has size $n$ = $O$($m$).  Such a triangulation is desired as an initial mesh for a finite element mesh  refinement algorithm. Previous three dimensional triangulation schemes either  worked only on a restricted class of input, or did not guarantee well-shaped  tetrahedra, or were not able to bound the output size. We build on some of  the ideas presented in previous work by Bern, Eppstein and Gilbert, who have  shown how to triangulate a two dimensional polyhedral region with holes, with  similar quality and optimality bounds.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7108,On The Local Convergence of The Byrd-Schnabel Algorithm For Constrained Optimization,"Most reduced Hessian methods for equality constrained problems use a basis  for the null space of the matrix of constraint gradients and posess  superlinearly convergent rates under the assumption of continuity of the  basis. However, computing a continuously varying null space basis is not  straightforward. Byrd and Schnabel [2] propose an alternative implementation  that is independent of the choice of null space basis, thus obviating the  need for a continuously varying null space basis. In this note we prove that  the primary sequence of iterates generated by one version of their algorithm  exhibits a local 2-step Q-superlinear convergence rate. We also establish  that a sequence of ""midpoints"", in a closely related algorithm, is (1-step)  Q-superlinearly convergent. Key words: constrained optimization, null space, superlinear convergence,  reduced Hessian.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7109,Integrating Security in a Group Oriented Distributed System,"A distributed security architecture is proposed for incorporation into group  oriented distributed systems, and in particular, into the Isis distributed  programming toolkit. The primary goal of the architecture is to make common  group oriented abstractions robust in hostile settings, in order to  facilitate the construction of high performance distributed applications that  can tolerate both component failures and malicious attacks. These  abstractions include process groups and causal group multicast. Moreover, a  delegation and access control scheme is proposed for use in group oriented  systems. The focus of the paper is the security architecture; particular  cryptosystems and key exchange protocols are not emphasized.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7110,Shape and Motion from Image Streams: a Factorization Method: Full Report on the Orthographic Case,"Inferring scene geometry and camera motion from a stream of images is  possible in principle, but is an ill-conditioned problem when the objects are  distant with respect to their size. We have developed a factorization method  that can overcome this difficulty by recovering shape and motion without  computing depth as an intermediate step. An image stream can be represented by the 2$F$ x $P$ measurement matrix of  the image coordinates of $P$ points tracked through $F$ frames. We show that  under orthographic projection this matrix is of rank 3. Using this observation, the factorization method uses the singular value  decomposition technique to factor the measurement matrix into two matrices  which represent object shape and camera motion, respectively. The method can  also handle and obtain a full solution from a partially filled-in measurement  matrix, which occurs when features appear and disappear in the image sequence  due to occlusions or tracking failures. The method gives accurate results, and does not introduce smoothing in either  shape or motion. We demonstrate this with a series of experiments on  laboratory and outdoor image streams, with and without occlusions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7111,On Polynomial Time Isomorphism of Complete Sets,"IN this note we show that the recently discovered NP complete sets arising in  number theory, the PTAPE complete sets arising in game theory and EXPTAPE  complete sets arising from algebraic word problems are polynomial time  isomorphic to the previously known complete sets in the corresponding  categories.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7112,Fault-Tolerant Broadcasts and Multicasts: The Problem of Inconsistency and Contamination,"An increasingly important paradigm for designing fault-tolerant applications  for distributed systems is based on processes that communicate exclusively  via fault-tolerant broadcasts and multicasts. Most broadcasts that are  described in the literature, such as reliable broadcast, causal broadcast,  atomic broadcast and the corresponding multicasts, specify the behavior of  correct processes, but do not impose requirements on the behavior of faulty  processes. Such specifications allow a process that fails during a broadcast  to reach an ""inconsistent"" state (e.g., by omitting the delivery of a  message), and to continue execution from that state. This faulty process may  later broadcast messages that ""contaminate"" the correct processes. In this thesis, we argue that such inconsistency and contamination can  complicate the design of applications, and we present fault-tolerant  broadcast and multicast protocols that prevent inconsistency and contamination. We begin by formally defining a hierarchy of different types of process  inconsistency; these definitions are general, and hence are valid for any  broadcast specification. Intuitively, contamination is the ""spread"" of  inconsistency from faulty processes to correct processes. We formalize this  concept and show that only two forms of contamination arise from our  hierarchy of types of inconsistency. Atomic broadcast and atomic multicast are powerful communication abstractions  that are central to many systems (e.g., Isis, and IBM's HAS), and to  Lamport's state machine approach to fault-tolerance. Using our general  definitions of inconsistency and contamination, we derive necessary and  sufficient conditions to prevent inconsistency and/or contamination when  processes communicate using atomic broadcast. We also derive similar  conditions for atomic multicast. Based on these conditions, we develop atomic  broadcast protocols that prevent inconsistency and/or contamination. In general, the prevention of inconsistency is a stronger requirement (and  more difficult and more expensive to enforce) than the prevention of  contamination. We characterize a class of problems for which the prevention  of contamination is as good as the prevention of inconsistency. We show that  an application that solves a problem in this class under the simplifying  assumption that both inconsistency and contamination are prevented remains  correct even if it uses a (less expensive) broadcast protocol that only  prevents contamination.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7113,From the Buffon Needle Problem to the Kreiss Matrix Theorem,"In this paper we present a theorem concerning the arc length on the Riemann  sphere of the image of the unit circle under a rational function. But our  larger purpose is to tell a story. We thought at first that the story began  in 1962 with the Kreiss matrix theorem, the application that originally  motivated us. However, our arc length question turns out to be more  interesting than that. The story goes back to the famous ""Buffon needle  problem"" of 1777.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7114,PL/CT - A Terminal Version of PL/C - Release 2,"PL/CT is a special version of PL/C designed to permit programs to be run  interactively from a typewriter terminal. It is completely compatible with  normal PL/C - that is, the source languages accepted by PL/C and PL/CT are  identical and the results of execution are exactly the same. Hence, a program  can be developed and tested under PL/CT and subsequently run under normal PL/C  (or vice versa). PL/CT permits the user to interact with the program during its execution.  Output will be printed on the terminal and input data may be requested from  the terminal. The course and rate of execution can be controlled from the  terminal. It is also possible to interrupt execution and display and alter the  values of variables. However, the source program itself cannot be changed  under PL/CT. PL/CT receives a complete program, compiles it, and then  executes it in interactive mode. But to make any change in the program it is  necessary to leave PL/CT, make the change under the CMS editor, and then  present the modified program to PL/CT for complete recompilation. This Guide provides only minimal information about CMS, perhaps sufficient for  very straightforward programming tasks.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7115,Dynamic Simulation of Non-Penetrating Rigid Bodies,"This thesis examines the problems and difficulties in the forward dynamic  simulation of rigid bodies subject to non-penetration constraints. By adopting  a simple but well-defined model of rigid body dynamics, we are able to focus  on and gain insight into some of the inherent difficulties of rigid body  simulation. Additionally, computationally practical solutions to some of the  problems encountered in this thesis are presented. Enforcing non-penetration constraints is essentially a two step process. The  first step of the simulation involves the detection of potential contacts  between bodies. This thesis presents collision detection algorithms for the  dynamic simulation of bodies that are composed of both polyhedra and convex  closed curved surfaces. The collision detection algorithms exploit temporal  coherence to achieve fast running times and are a practical solution to the  problem of collision detection during simulation. The second step of the simulation involves the computation of the contact  forces between bodies that maintain the non-penetration constraint. This  thesis considers first the problem of computing contact forces between a pair  of bodies that contact at a point without friction. A mathematical formulation  for the contact force between the bodies is presented, and then modified to  yield a formulation that is computationally practical for use in a simulator.  After considering the dynamics of single point contacts, systems with multiple  contacts are considered both in terms of computational complexity measures  and practical solution methods. The methods used in this thesis to compute  constraint forces are also theoretically and practically compared with a  popular method for preventing inter-penetration called the ""penalty method"". After considering frictionless systems, this thesis considers systems of  bodies that behave according to the classical Coulomb model of friction (which  includes both sliding and dry friction). This leads us to consider systems in  which there are no solutions to the classical constraint force equations, as  well as systems which admit multiple solutions for the constraint force  equations and whose subsequent behavior is thus indeterminate. Both  computational and practical complexity results for simulating such systems are  discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7116,Tactic-Based Theorem Proving and Knowledge-Based Forward Chaining: An Experiment with Nuprl and Ontic.,Abstract not available.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7117,Using Consistent Subcuts for Detecting Stable Properties,"We present a general protocol for detecting whether a property holds in a  distributed system, where the property is a member of a subclass of stable  properties we call the locally stable properties. Our protocol is based  on a decentralized method for constructing a maximal subset of the local  states that are mutually consistent, which in turn is based on a weakened  version of vector time stamps. The structure of our protocol lends itself to  refinement, and we demonstrate its utility by deriving some specialized  property-detection protocols, including two previously-known protocols that  are known to be efficient.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7118,Access Normalization: Loop Restructuring for NUMA Compilers,"A common feature of many scalable parallel machines is non-uniform memory  access - a processor can access data in its local memory ten to a thousand  times faster than it can access non-local data. In addition, when a number of  remote accesses must be made, it is usually more efficient to use block  transfers of data rather than to use many small messages. To run well on such  machines, software must exploit these features. We believe it is too onerous  for a programmer to do this by hand, so we have been exploring the use of  restructuring compiler technology for this purpose. In this paper, we start  with a language like FORTRAN-D with user-specified data distributions and  develop a systematic loop transformation strategy called access  normalization that restructures loop nests to exploit both locality and block  transfers wherever possible. We demonstrate the power of our techniques using  routines from the BLAS (Basic Linear Algebra Subprograms) library. Our loop  transformation strategy is expressed in the framework of invertible  matrices and integer lattice theory and it is an important generalization of  Banerjee's framework of unimodular matrices.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7119,Provably-Good Approximation Algorithms for Optimal Kinodynamic Robot Motion Plans,"The kinodynamic planning problem is to synthesize a robot motion obeying  simultaneous kinematic and dynamics constraints. To maximize robot  performance we can consider optimal kinodynamic planning: for a given robot  system, find a minimal-time trajectory that goes from a start state to a goal  state, avoids obstacles by a speed-dependent safety margin, and respects the  dynamics laws and dynamics bounds governing the system. In general, previous  work on algorithmic motion planning does not address dynamics; furthermore,  even in simple cases, finding exact globally-optimal solutions is  $\cal NP$-hard. In response, we obtain provably-good, polynomial-time  approximation algorithms that synthesize optimal kinodynamic trajectories.  These algorithms forge new mathematical links between control theory and  complexity theory, and our analysis investigates how discrete-control  trajectories can approximate optimal solutions We cast optimal kinodynamic planning into the form of an  $\epsilon$-approximation problem in which $\epsilon greater than 0$ characterizes  closeness to optimality in terms of trajectory time, observance of the safety  margin and closeness to the start and goal states If $T_{opt}$ is the time of an optimal trajectory, then an $\epsilon$-optimal  trajectory takes at most (1 + $\epsilon$)$T_{opt}$ time. We present  (pseudo)-polynomial-time $\epsilon$-approximation algorithms for a family of  robot classes, including fully-controllable open kinematic chains. These  algorithms run in time polynomial in $\frac{1}{\epsilon}$ and the geometric  complexity of the constraints. The basic idea behind the algorithms is to reduce the trajectory planning  problem to a shortest-path problem on a polynomial-sized reachability graph  embedded in the robot state space. These graphs are generated by control  primitives and a timestep that the algorithm chooses to ensure $\epsilon$- optimality. To obtain our complexity and approximation results, we introduce  both continuous and combinatorial tools to analyze the robot's dynamical  system. These include scaling-tracking proof methods that capture the key  insight necessary for provably-good results, tracking lemmas on how  closely we can approximate an optimal or time-rescaled optimal trajectory,  constructive trajectory proofs, adversary game proofs and Time-Safety  planning trade-offs. We also decribe an implementation and experiments in  a restricted domain.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7120,Stable Numerical Algorithms for Equilibrium Systems,"An equilibrium system (also known as a KKT system, a saddlepoint system or a  sparse tableau) is a square linear system with a certain structure. G. Strang  has observed that equilibrium systems arise in optimization, finite elements, structural analysis and electrical networks. Recently, G. W. Stewart  established a norm bound for a type of equilibrium system in the case that  the ""stiffness"" portion of the system is very ill-conditioned. In this  paper, we investigate the algorithmic implications of Stewart's result. We  show that all standard textbook algorithms for equilibrium systems are  unstable. Then we show that a certain hybrid method has the right stability  property.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7121,On Parsing Context Free Languages in Parallel Environments,"Non-canonical generalization of several bottom-up parsing methods, including  Simple Precedence, LR(k), SLR(k), and LALR(k) are considered. It is seen that  these methods can readily be made to generate many concurrent reductions and  thus can be used to advantage in parallel environments. it is suggested that  such methods could be used to produce practical parsers for such parallel  computers as the CDC Star-100. Further, the grammar classes defined by these  parallel methods are studied and compared with the grammar classes defined by  a number of serial parsing techniques.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7122,Area-Universal Interconnection Networks for VLSI Parallel Computers,"A central issue in the design of a general-purpose parallel computer is the  choice of an interconnection network and an associated algorithm for routing  messages through it. The main results of this thesis are two new  interconnection networks, the pruned butterfly and the sorting fat-tree  and deterministic routing algorithms for them. Both networks are  area-universal, i.e., they can simulate any other routing network fitting in  similar VLSI chip area with only polylogarithmic slowdown. Previous  area-universal networks were either for the off-line problem, where the  message set to be routed is known in advance and substantial precomputation is  permitted, or involved randomization, yielding results that hold only with  high probability. The two networks introduced here are the first that are  simultaneously deterministic and on-line and they use two substantially  different routing techniques. The performance of the routing algorithms  depends on the difficulty of the problem instance, which is measured by a  quantity $\lambda$ known as the load factor. The pruned butterfly algorithm  runs in time $O$ ($\lambda log^2$ $N$), where $N$ is the number of possible  sources and destinations for messages and $\lambda$ is assumed to be  polynomial in $N$. The sorting fat-tree algorithm runs in $O$  ($\lambda log N + log^2 N$) time for a restricted class of message sets  including partial permutations. Several related results are also presented in this thesis. A nontrivial lower  bound on wire area is proven for a class of tree-based networks that do not  modify the content of messages are shown to be subject to an area-time  tradeoff.  This lower bound implies the sorting fat-tree's area-time  performance is optimal for a wide range of possible values for $\lambda$.  Other results of this work include a new type of sorting circuit and an  area-universal VLSI circuit.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7123,On Branching Numbers of Normal Manifolds,"Let $\cal M$ be a finite piecewise linear (pl) manifold of $IR^n$, and $P$  : $IR^n \rightarrow IR^n$ be pl with respect to $\cal M$, i.e. $P$ is  affine on each set in $\cal M$. The branching number of $\cal M$, Kuhn  and Lowen [8], is the maximum number of sets in $\cal M$ that can contain  any common face of codimension 2. [8, Thm. 5.3] shows that if $\cal M$ has  branching number less than or equal to 4, then $P$ is a homeomorphism if  and only if it is coherently oriented, i.e. the determinants of $P$ on the  sets in $\cal M$ have the same nonzero sign. Let $C$ be a nonempty polyhedral convex set in $IR^n$, and $A \in  IR^{nxn}$. Robinson [14] defines a finite pl manifold $\cal N_C$ of $IR^n$  called the normal manifold of $C$; and the normal map $A_C$ :  $IR^n \rightarrow IR^n$ induced by ($A, C$), which is pl with respect to  $\cal N_C$. [14, Thm. 4.3] shows that $A_C$ is homeomorphic if and only if it  is coherently oriented. We show that $\cal N_C$ has branching number less than or equal to 4, hence  Robinson's result is actually a corollary of Kuhn and Lowen's. Key Words: Piecewise linear, piecewise affine, branching number, normal  map, pl-normal, normal manifold, homeomorphism, coherently oriented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7124,The Inherent Cost of Achieving Causal Consistency,"We consider the problem of distinguishing causally-consistent global states  in asynchronous distributed systems. Such states are fundamental to  asynchronous systems, because they correspond to possible simultaneous global  states; their detection arises in a variety of distributed applications,  including global checkpointing, deadlock detection, termination detection and  broadcasting. A consistent-cut protocol is a protocol which in every run will  designate for each processor a state, in such a way that these states  together form a consistent cut. We analyze the cost of achieving causal  consistency in terms of the extent to which a consistent-cut protocol delays  events of the underlying system, and the message-complexity required by any  such protocol. We refer to the delaying action of a protocol as inhibition.  We consider a spectrum of protocol capabilities based on the type of  inhibition that occurs: we distinguish local versus global inhibition and  prove fundamental relationships between these concepts and the ability to  determine causally-consistent states. A protocol using local inhibition may  cause the delay of some of a processor's events until that processor has  performed some number of local actions; a protocol using global inhibition  may force the delay of some of a processor's events until that procesor has  received some communication from other processors. Based on a variety of  system and protocol characteristics, including the ability to locally or  globally inhibit particular types of events, we give several impossibility  results and examine some existing protocols. We are then able to present a  thirty-six-case summary of protocols and impossibility results for the  determination of causally-consistent states as a function of those  characteristics. In particular, we demonstrate that local inhibition is  necessary and sufficient to solve this problem for general FIFO systems,  while global send inhibition is necessary and sufficient for general non-FIFO  systems. Regarding message complexity, we demonstrate that a globally  inhibitory consistent-cut protocol requires $O (N)$ messages where $N$ is  the number of processors in the system. This is true whether the protocol is  designed to work for FIFO or non-FIFO systems; the exact lower bounds,  however, differ in the two cases. We also prove that a consistent-cut  protocol which uses local inhibition only requires $O$ ($N^{2}$) messages,  or, more precisely, $O$ ($\vert \cal C \vert$), where $\cal C$ is the channel  set of the system. This latter result illustrates a trade-off between the  message complexity of a consistent-cut protocol and the degree of inhibition  which it requires.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7125,Higher-Order Concurrency,"Concurrent programming is a useful technique for structuring many important  classes of applications such as interactive systems. This dissertation  presents an approach to concurrent language design that provides a new form of  linguistic support for constructing concurrent applications. This new approach  treats synchronous operations as first-class values in a way that is analogous  to the treatment of functions as first-class values in languages such as ML.  The mechanism is set in the framework of the language Concurrent ML (CML),  which is a concurrent extension of Standard ML. CML has a domain of  first-class values, called events, that represent synchronous operations.  Synchronous message passing operations are provided as the base-event values,  and combinators are provided for constructing more complex events from other  event values. This mechanism allows programmers to define new synchronization  and communication abstractions that are first-class citizens, which gives  programmers the flexibility to tailor their concurrency abstractions to their  applications. The dissertation is organized into three technical parts. The first part  describes the design and rationale of CML and shows how first-class  synchronous operations can be used to implement many of the communication  mechanisms found in other concurrent languages. The second part presents the  formal operational semantics of first-class synchronous operations and proves  that the polymorphic type system used by CML is sound. The third part  addresses practical issues. It describes the use of CML in non-trivial  applications, describes the implementation and performance of CML on a  single-processor computer, and discusses issues related to the use and  implementation of CML on a shared-memory multiprocessor.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7126,Automatic Structuring and Retrieval of Large Text Files,"In many operational environments, large text files must be processed covering  a wide variety of different topic areas. Aids must then be provided to the  user that permit collection browsing and make it possible to locate particular  items on demand. The conventional text analysis methods based on  preconstructed knowledge-bases and other vocabulary-control tools are  difficult to apply when the subject coverage is unrestricted. An alternative approach, applicable to text collections in any subject area,  is introduced which uses the document collections themselves as a basis for  the text analysis, together with sophisticated text matching operations  carried out at several levels of detail. Methods are described for relating  semantically similar pieces of text, and for using the resulting hypertext  structures for collection browsing and information retrieval.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7127,A Formal Syntax for PL/CS,"This document contains a formal syntax for the PL/CS programming language. As  is customary, the defining context-free grammar generates a somewhat larger  language than PL/CS. That is, only those restrictions conveniently expressed  by context-free productions are incorporated in the definition. However, all  legal PL/CS programs are contained in the language defined. With some exceptions, the formal syntax defines the language described in:  Conway, R., ""PL/CS - A Highly-Disciplined Subset of PL/C"", Dept. of Computer  Science, Cornell University, TR 76-273. The present report supersedes this earlier report as the document defining the  syntax of the PL/CS subset.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7128,Using Content-Addressable Search Engines To Encrypt and Break DES,A very simple parallel architecture using a modified version of  content-addressable memory can be used to cheaply and efficiently encipher and  decipher data with DES-like systems. The paper will describe how to implement  DES on these modified content-addressable memories at speeds approaching some  of the best specialized hardware. The chips can also be used to build a large  scale engine for exhaustively searching the entire keyspace of DES.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7129,"Using the ISIS Resource Manager for Distributed, Fault-Tolerant Computing","Under the current versions of the UNIXtm operating system, it is difficult  to take advantage of the massive computing power of idle or lightly-loaded  workstations on a network. This paper introduces the ISIS Resource  Manager, a distributed, fault-tolerant application capable of recapturing  this processing power, as well as providing a transparent interface to network  computing resources.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7130,Abstract Value Constructors: Symbolic Constants for Standard ML,"Standard ML (SML) has been used to implement a wide variety of large systems,  such as compilers, theorem provers, graphics libraries and even operating  systems. While SML provides a convenient, high-level notation for programming  large applications, it does have certain deficiencies. One such deficiency is  the lack of a general mechanism for assigning symbolic names to constant  values. In this paper, we present a simple extension of SML that corrects this  deficiency in a way that fits naturally with the semantics of SML. Our  proposal is a generalization of SML's datatype constructors: we introduce  constants that generalize nullary datatype constructors (like nil), and",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7131,Pseudospectra of the Linear Navier-Stokes Evolution Operator and Instability of Plane Poiseuille and Couette Flows: (preliminary report),"This is a rough, interim report on some new results concerning the stability  of plane Poiseuille and Couette fluid flows, following upon recent work by  Henningson and Reddy, Butler and Farrell, Gustavsson and others. We emphasize  that the conclusions proposed here have not yet been checked carefully and  are subject to change. Our principal results are as follows: 1. Plots of the spectra of the ""full"" Navier-Stokes operator for  Poiseuille and Couette flows, i.e., without restriction to a wave number pair  ($\alpha, \beta$) or to even or odd modes ($\S\S$4,5). 2. Analogous plots for the pseudospectra of this operator. Comparison  of the pseudospectra with the spectra gives a new interpretation of why the  physics of these linear flow problems is not controlled by the location of  the most unstable eigenvalue ($\S\S$4,5). 3. Demonstration that these pseudospectra predict the Butler-Farrell  ""optimal"" transient energy growth ratios to within a factor of about 2  ($\S$6). 4. Demonstration that about 90% of the Butler-Farrell growth can be  achieved by a 3$\times$3 linear model obtained by projecting the Navier-Stokes  problem onto the space spanned by three dominant eigenmodes, for Couette flow,  or four in the case of Poiseuille flow ($\S$8). 5. Demonstration that although 1 Orr-Sommerfeld mode and 3 Squire modes  suffice for the 4$\times$4 model in the Poiseuille case, in keeping with a  recent result of Gustavsson, one can do equally well with 2 modes of each kind  or with 3 Orr-Sommerfeld modes and 1 Squire mode ($\S$8). 6. Demonstration that the minimal operator perturbation required to  destabilize a stable flow has norm of order $R^-$$^2$, where $R$ is  the Reynolds number, though the distance of the least stable eigenvalue from  the real axis is $O (R^-$$^1$) ($\S$7). 7. Presentation of a 2$\times$2 model illustrating that if the linear  problems described above are capable of transient energy growth of order $M$  (e.g., $M\approx$1000 according to Butler and Farrell), a weak and  intrinsically energy-conserving nonlinear term can ""bootstrap"" that growth  to a higher order such as $M^2$. This supports the view that although  nonlinear terms are of course essential to the subcritical instability of  fluid flows, the detailed nature of the nonlinear interactions may sometimes  be relatively unimportant ($\S$2). 8. Adaptation of this ""bootstrapping"" idea to the fluid flows  considered earlier, particularly the 3$\times$3 approximation for Couette  flow with $R$=1000.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7132,On Invariants of Sets of Points or Line Segments Under Projection,"We consider the problem of computing invariant functions of the image of a set  of points or line segments in $\Re^3$ under projection. Such functions are in  principle useful for machine vision systems, because they allow different  images of a given geometric object to be described by an invariant `key'. We  show that if a geometric object consists of an arbitrary set of points or line  segments in $\Re^3$, and the object can undergo a general rotation, then there  are no invariants of its image under projection. For certain constrained  rotations, however, there are invariants (e.g., rotation about the viewing  direction). Thus, we precisely delimit the conditions for the existence or  nonexistence of invariants of arbitrary sets of points or line segments under  projection.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7133,The Weakest Failure Detector for Solving Consensus,,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7134,A Singular Loop Transformation Framework Based on Non-Singular Matrices,"In this paper, we discuss a loop transformation framework that is based on  integer non-singular matrices. The transformations included in this framework  are called $\Lambda$-transformations and include permutation, skewing and  reversal, as well as a transformation called loop scaling. This  framework is more general than the existing ones; however, it is also more  difficult to generate code in our framework. This paper shows how integer  lattice theory can be used to generate efficient code. An added advantage of  our framework over existing ones is that there is a simple completion  algorithm which, given a partial transformation matrix, produces a full  transformation matrix that satisfies all dependences. This completion  procedure has applications in parallelization and in the generation of code  for NUMA machines.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7135,Periodic Updates in Processor Networks,"In implementing parallel scientific applications, the crux is often efficiency  in communication. So, it becomes important to abstract out and study  frequently occurring patterns of communication. We describe one such  abstraction, periodic update, which arises in such diverse areas as  computational molecular dynamics, distributed systems and n-body simulations. Consider a synchronous network of processors. Every processor needs to know  the status of every other processor. The status keeps changing and it is more  important to know the correct status of nearer processors. The work done in  maintenance of status information should be as little as possible. The   periodic update problem is that of sending (and receiving) periodic status  updates from every processor to every other processor in the network in order  to maintain status information. The time interval between successive updates  from one processor to another is given by some increasing function (the  periodicity function) of the distance between them. Given a network and a  periodicity function, we wish to find efficient protocols for the  periodic update problem which have minimum delay (time elapsed between the  sending of an update and its receipt) and minimum peak bandwidth (maximum  number of updates sent across any edge in one time-step). We present a general design paradigm and construct periodic update  protocols for the one and two dimensional mesh networks for both polynomial  and exponential periodicity functions. Given a periodicity function, we  demonstrate a trade-off between delay and peak bandwidth. Then,   using two general techniques, we transform minimum delay protocols into  families of highly efficient protocols with performances spanning the entire  spectrum from minimum delay to minimum peak bandwidth.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7136,The Motion of Planar Compliantly-Connected Rigid Bodies in ContactWith Applications to Automatic Fastening,"We consider the problem of planning and predicting the motion of a flexible  object amidst obstacles in the plane. We model the flexible object as a rigid  ""root"" body, attached to compliant members by torsional springs. The root's  position may be controlled, but the compliant members move in response to  forces from contact with the environment. Such a model encompasses several  important and complicated mechanisms in mechanical design and automated  assembly: snap-fasteners, latches, ratchet and pawl mechanisms, and  escapements. The problem is to predict the motion of such a mechanism amidst  fixed obstacles. For example, our algorithm could be used to determine  whether a snap-fastener design can be assembled with a certain plan. In this paper, we analyze the physics of these flexible devices, and develop  combinatorially precise algorithms for predicting their movement under a  motion plan. Our algorithms determine when and where the motion will  terminate, and also computes the time-history of contacts and mating forces.  In addition to providing the first known exact algorithm that addresses  flexibility in motion planning, we also note that our approach to compliance  permits an exact algorithm for predicting motions under rotational  compliance, which was not possible in earlier work. We discuss the following issues: the relevance of our approach to engineering  (which we illustrate through the examples we ran using our system), the  computational methods employed, the algebraic techniques for predicting  motions in contact with rotational compliance, and issues of robustness and  stability of our geometric and algebraic algorithms. Our computational  viewpoint lies in the interface between differential theories of mechanics,  and combinatorial collision detection algorithms. From this viewpoint, subtle  mathematical difficulties arise in predicting motions under rotational  compliance, such as the forced non-genericity of the intersection problems  encountered in configuration space. We discuss these problems and their  solutions. Finally, we extend our work to predict the forces on the  manipulated objects as a function of time, and show how our algorithm can  easily be extended to include uncertainty in control and initial conditions.  With these extensions, we hope that our system could be used to analyze and  design objects that are easy to assemble, even given control and sensing  errors, and that require more force to disassemble than to mate.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7137,Solving Alignment using Elementary Linear Algebra,"Data and computation alignment is an important part of compiling sequential programs to architectures with non-uniform memory access times. In this paper, we show that elementary matrix methods can be used to determine communication-free alignment of code and data. We also solve the problem of replicating read-only data to eliminate communication. Our matrix-based approach leads to algorithms which are simpler and faster than existing algorithms for the alignment problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7138,Multicast Flow Control on Local Area Networks,"The primary LAN  technologies in use today --- ethernet, FDDI, and token-ring --- all provide hardware support for broadcast and multicast capability. However, distributed systems have traditionally used unicast messaging exclusively, even when multicast communication patterns arise. As the number of distributed applications grows, the load on networks caused by unnecessary unicasts will increase. In addition, for some applications performance and group size are limited by using unicast technologies for multicast. If multicast technologies are exploited, the network load caused by ""redundant"" packets will be reduced. Exploiting multicast will also improve the performance and scalability of some distributed applications. However, as  distributed systems move towards exploiting multicast, multicast flow control protocols are becoming more important. Finding a general, effective solution for multicast flow control will help facilitate the exploitation of the multicast primitives provided in LANs and Wide Area Networks (WANs).  This dissertation presents the results of an investigation into multicast performance on local area networks. An analysis of multicast flow control is presented which distinguishes between {\it rate reservation} and {\it rate control}, followed by a discussion of the major design issues associated with multicast flow control and a presentation of a proposed protocol family. The proposed protocol family is based on send-rate control.  An unreliable and a reliable multicast flow control protocol based on the proposed family are presented. A study of the performance of these protocols is also presented. This dissertation concludes with an investigation into how well the proposed reliable multicast flow control protocol performs when used to disseminate messages. This dissertation argues that direct rate control has merit as a technique for multicast flow control on local area networks.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7139,Efficient Geometric Algorithms for Robot Sensing and Control,"This thesis addresses the problem of automatically generating solutions to robotics tasks that are specified at a high level. In particular, we consider the problems of robot motion planning and the planning of sensor placements.  These problems are made difficult by a number of inherent factors.  Foremost among these are uncertainty and geometric complexity.  Uncertainty arises from the fact that the actions of robots are subject to error.  Geometric complexity reflects the fact that real-world task environments are often complex. If we want robot strategies that are both practical and robust, we must develop algorithms that successfully deal with uncertainty and complex geometry.  Much of the previous work in the area of task-level planning for robots fails to address at least one of these issues.  Many theoretical approaches are algorithmically sophisticated, but do not handle uncertainty, and may be unimplementable in practice.  On the other hand, real robot systems often employ simplistic strategies that do not take into account complex geometric interactions.  This thesis seeks to bridge the gap between these two extremes.  We present efficient planning algorithms for motion and sensing that are both practical and algorithmically sophisticated.  Our motion planning algorithm computes one-step motion strategies that guarantee reaching a specified goal in the plane.  To deal with uncertainty in robot control, we employ a control model that allows the robot to slide along obstacle surfaces, or comply with the environment.  Our analysis of this algorithm yields a precise characterization of the complexity of one-step compliant motion planning with uncertainty.  Sensors are needed within autonomous systems to provide execution-time feedback.  In this thesis we develop a framework for planning sensing strategies in a principled way.  In particular, we present algorithms for computing the set of placements from which a sensor can monitor a region within a task environment.  This work has many applications in the areas of assembly planning, cooperating robots, and robot surveillance.  We have demonstrated the practicality of our approach by building a system of robot surveillance with mobile robots employing our strategies for sensor planning.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7140,A Quasi-Newton $L_{2}$-Penalty Method for Minimization Subject toNonlinear Equality Constraints,We present a modified $L_{2}$ penalty function method for equality constrained optimization problems. The pivotal feature of our algorithm is that at every iterate we invoke a special change of variables to improve the ability of the algorithm to follow the constraint level sets. This change of variables gives rise to a suitable block diagonal approximation to the Hessian which is then used to construct a quasi-Newton method.  We show that the complete algorithm is globally convergent with a local Q-superlinearly convergence rate. Preliminary computational results are given for a few problems.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7141,Verification Methods for the Divergent Runs of Clock Systems,"We present a methodology for proving temporal properties of the divergent 
 runs of reactive systems with real-valued clocks.  A run diverges if time advances beyond any bound.  Since the divergent runs of a system may satisfy liveness properties that are not satisfied by some convergent runs, the standard proof rules are incomplete if only divergent runs are considered.  First, we develop a sound and complete proof calculus for divergence, which is based on translating clock systems into discrete systems.  Then, we show that simpler proofs can be obtained for stronger divergence assumptions, such as unknown epsilon-divergence, which requires that all delays have a minimum duration of some unknown constant epsilon. We classify all real-time systems into an infinite hierarchy, according to how well they admit the translation of eventuality properties into equivalent safety properties.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7142,Undecidability Results for Hybrid Systems,"We illuminate the boundary between decidability and undecidability  for hybrid systems.  Adding any of the following decorations to a timed automaton makes the reachability problem undecidable: 1. a single stopwatch with weak (less than or equal to, greater than or equal to) edge guards 2. a single skewed clock with variable equality tests 3. a single two-slope clock with weak edge guards 4. a single memory cell with weak edge guards As a corollary, we obtain undecidability for linear hybrid systems with triangular differential inclusions, which have invariants of the form x' less than or equal to y'.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7143,Automatic Hypertext Construction,"The unprecedented growth of the World Wide Web illustrates the importance of hypertext as a method for organizing the rapidly  expanding amount of on-line text.  As document collections become larger and more dynamic, however, it is not feasible to construct more than an occasional hypertext manually.  This thesis presents entirely automatic methods for gathering documents for a hypertext, linking them, and annotating those connections with a description of the type or nature of the link.  The problem of automatically collecting related documents is addressed in Chapter 2, where robust Information Retrieval methods are applied to form high-quality links between documents.  A local context check identifies links where ambiguous vocabulary erroneously suggests a relationship.  Dynamic part retrieval is employed to select the portions of documents which are most related, allowing parts to be linked when it is more appropriate to link subtopics than entire documents.  Chapter 3 presents a taxonomy of hypertext link types and defines the following three classes of links: ""pattern-matching"" links can be found using simple string-matching methods, ""manual"" links require substantial application of natural language understanding methods (which are currently beyond the state of the art), and ""automatic"" links are those which can be found using the methods of this thesis.  Chapter 4 begins the work of automatic link typing by describing two novel graphical techniques for visualizing the relationship between two or more documents.  ""Uniform"" visuals display the relationship between documents or document parts without regard to their relative sizes, whereas ""varying"" visuals include information about sizes and locations.  Both methods highlight relationships between documents and motivate the automatic techniques of Chapter 5.  Chapter 5, thus, demonstrates automatic methods for identifying the relationships depicted in the visualizations.  Using an approach based upon graph simplification, this method automatically identifies revision, summary, expansion, equivalence, comparison, contrast, tangential, and aggregate links.  Chapter 6 discusses an informal evaluation of the link typing.  Though somewhat inconclusive, the evaluation demonstrates that automatic document linking performs well, but also indicates that much work remains to be done toward understanding automatic link typing.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7144,"Localization, Mapmaking, and Distributed Manipulation with Flexible,Robust Mobile Robots","Current mobile robots (mobots) have extremely limited usefulness in real-world applications, due primarily to low capability and low reliability. Current mobots cannot navigate in environments which have not been extensively engineered to be mobot-friendly; they are also incapable of performing useful duties at their destination.  They often have poorly designed hardware and primitive software-development environments, making the development of new mobile robot protocols slow and difficult.       In this thesis, we describe three ways to make mobile robots more usable. We present algorithms for mobile robot self-localization, a design paradigm for reliable mobile robots, and protocols for cooperative large-scale manip- ulation by mobile robots.       Localization is the process of determining the robot's location within its environment.  More precisely, it is a procedure which takes as input a geometric map, a current estimate of the robot's pose, and sensor readings, and produces as output an improved estimate of the robot's current pose (position and orientation).  We describe an algorithm which performs mobile robot localization using a geometric model of the world and a point-and-shoot rang ing device.  We also describe a rasterized version of this algorithm which we've implemented on a real mobile robot equipped with a laser rangefinder we designed.       We next focus on the mobile robots themselves.  We have designed and built several mobile robots at Cornell, that feature robustness, flexibility, and ease of programming.  Using a modular design approach, we've attained an unusual state for a university robotics lab: our mobots are almost always functional.  In their basic configuration, the robots can perform many tasks; also, it is easy to add sensors and actuators to our mobile robots, allowing their use in many different applications (e.g. manipulation).  We are interested in protocols for manipulation of large objects (e.g., boxes, wheeled carts) by cooperating mobile robots, particularly protocols that are asynchronous, on-line, and use no communication between mobots.  We've developed a Pusher-Steerer model for cooperative manipulation, which enables two mobots to manipulate objects through complex paths.  We describe and anal yze the model and describe its performance in several real experiments.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7145,On the Number of Small Cuts in a Graph,We prove that in an undirected graph there are at most $O(n^2)$ cuts of size strictly less than $\frac{3}{2}$ the size of the minimum cut.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7146,Election Vs. Consensus in Asynchronous Systems,"It was shown in 1985 that the {\em Consensus problem} cannot be solved in an asynchronous system if even a single crash failure can occur.  In this paper, we show that there are other problems that cannot be solved in an asynchronous system, and for the same intuitive reason: it is impossible to distinguish a very slow processor from a crashed processor. However, these problems are harder than Consensus, in that there are contexts in which Consensus can be solved but these other problems cannot.  More precisely, the weakest failure detector that is needed to solve these problems is a Perfect Failure Detector, which is strictly stronger than the weakest failure detector that is needed to solve Consensus.  We use a formulation of the Election problem as the prototype for these problems that are harder than Consensus.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7147,Incorporating System Resource Information into Flow Control,"Upcall-based distributed systems have become widespread in recent years.  While upcall-based systems provide some obvious advantages, experiences with these systems have exposed unanticipated problems of unpredictability and inefficiency. Incorporating system resources information into flow control is essential in solving these problems. Variants of window-based flow control suitable for distributed systems are investigated. Next, message packing, which improves network bandwidth usage efficiency, and, consequently, message throughput, is presented. Finally, a back pressure mechanism which controls admission of messages into the system by blocking applications at high load is presented. The combination of the window mechanism and the back pressure mechanism provides end-to-end management of system resources.  The former manages network resources, while the latter manages operating system resources. The combination maintains good throughput even under high load.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7148,Preserving Privacy in a Network of Mobile Computers,"Even as wireless networks create the potential for access to information from mobile platforms, they pose a problem for privacy. In order to retrieve messages, users must periodically poll the network. The information that the user must give to the network could potentially be used to track that user. However, the movements of the user can also be used to hide the user's location if the protocols for sending and retrieving messages are carefully designed.  We have developed a replicated memory service which allows users to read from memory without revealing which memory locations they are reading. Unlike previous protocols, our protocol is efficient in its use of computation and bandwidth. In this paper, we will show how this protocol can be used in conjunction with existing privacy preserving protocols to allow a user of a mobile computer to maintain privacy despite active attacks.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7150,A Determinizable Class of Timed Automata,"We introduce the class of event-recording timed automata (ERA). An event-recording automaton contains, for every event A, a clock  that records the time of the last occurrence of A.   The class ERA is, on one hand, expressive enough to model (finite) timed transition systems and, on the other hand, determinizable and  closed under all boolean operations.   As a result, the language inclusion problem is decidable for  event-recording automata.   We present a translation from timed transition systems to event-recording automata, which leads to an algorithm for checking  if two timed transition systems have the same set of timed behaviors.   We also consider event-predicting timed automata (EPA), which contain clocks that predict the time of the next occurrence of an event. The class of event-clock automata (ECA), which contain both  event-recording and event-predicting clocks, is a suitable specification  language for real-time properties.   We provide an algorithm for checking if a timed automaton meets a specification that is given as an event-clock automaton.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7151,Achieving Critical Reliability With Unreliable Components andUnreliable Glue,"Even the most aggressive quality assurance procedures yield at best probabilistic confidence in the reliability of complex systems.  Distributed systems, because of their large numbers of components, are enormously complex engineering artifacts, and hence may appear to be inherently unreliable -- despite the best efforts of researchers and developers.  A cellular distributed systems architecture offers the hope of drastically improving the reliability of current technologies in settings where reliability is critical. The approach combines a stateful style of distributed computing within cells with a loosely coupled probabilistic inter-cell computing model based on a probabilistic broadcast primitive.  We give an implementation of this primitive, called pbcast, and demonstrate how to use it to implement this methodology.  Our approach is compatible with the use of popular distributed computing and reliability technologies, while offering considerable isolation against the spread of failures among cells.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7153,Hypervisor-based Fault-tolerance,"Protocols to implement a fault-tolerant computing system are described.  These protocols augment the hypervisor of a virtual machine manager to coordinate a primary virtual machine and its backup.  The result is a fault-tolerant computing system that does not require modifying the hardware, operating system, or applications programs.  A prototype system was constructed for HP's PA-RISC instruction-set architecture.  Using this prototype, engineering issues and performance implications of the approach were explored.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7154,The Expressive Power of Clocks,"We investigate the expressive power of timing restrictions on labeled  transition systems. In particular, we show how constraints on clock variables together with  a uniform liveness condition---the divergence of time---can  express Buchi, Muller, Streett, Rabin, and weak and strong fairness conditions on a given labeled transition system.   We then consider the effect, on both timed and time-abstract expressiveness, of varying the following parameters: time domain (discrete or dense), number of clocks, number of states,  and size of constants used in timing restrictions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7155,Hybrid Automata with Finite Mutual Simulations,"Many decidability results for hybrid automata rely upon the  finite region bisimulation of timed automata [AD94]. Rectangular automata do not have finite bisimulations [Hen95], yet have many decidable verification problems [PV94,HKPV95]. We prove that every two-dimensional rectangular automaton A  with positive-slope variables has a  finite mutual simulation relation, which is the intersection of the region bisimulations defined by the extremal slopes of the variables of A. While the mutual simulation is infinite for two-dimensional automata with one variable taking both positive and negative slopes, it forms a regular tesselation of the plane, and therefore can be encoded by one counter. As a corollary, we obtain the decidability of model checking linear temporal logic on these automata.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7156,Caching Intermediate Results for Program Improvement,"A systematic approach is given for symbolically caching intermediate results useful for deriving incremental programs from non-incremental programs.  We exploit a number of program analysis and transformation techniques, centered around effective caching based on its utilization in deriving incremental programs, in order to increase the degree of incrementality not otherwise achievable by using only the return values of programs that are of direct interest.  Our method can be applied straightforwardly to provide a systematic approach to program improvement via caching.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7157,Incremental Computation for Transformational Software Development,"Given a program $f$ and an input change $\oplus$, we wish to obtain an incremental program that computes $f(x\oplus y)$ efficiently by making use of the value of $f(x)$, the intermediate results computed in computing $f(x)$, and auxiliary information about $x$ that can be inexpensively maintained.  Obtaining such incremental programs is an essential part of the transformational-programming approach to software development and enhancement.  This paper presents a systematic approach that discovers a general class of useful auxiliary information, combines it with useful intermediate results, and obtains an efficient incremental program that uses and maintains these intermediate results and auxiliary information.  We give a number of examples from list processing, VLSI circuit design, image processing, {\it etc}.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7158,Horus: A Flexible Group Communications System,"The Horus system offers flexible group communication support for distributed applications.  It is extensively layered and highly reconfigurable, allowing applications to only pay for services they use, and for groups with different communication needs to coexist in a single system.  The approach encourages experimentation with new communication properties and incremental extension of the system, and enables us to support a variety of application-oriented interfaces.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7159,Analyzing the Effectiveness of Extended Boolean Models in InformationRetrieval,"Many extended Boolean models such as fuzzy set, $p$-norm, et al. have been proposed in the information retrieval literature to support ranking facility for the Boolean retrieval system. They can be explained within the same framework, and each extended Boolean model is characterized by evaluation formulas for AND and OR operations. A variety of operators have been also developed in the area of fuzzy set theory for AND and OR operations, and can be used in extended Boolean models. In this paper we analyze the behavioral aspects of various operators for AND and OR operations, and address important properties in terms of retrieval effectiveness. Our analyses show that the four properties, namely single operand dependency, negative compensation, double operand dependency and unequal importance decrease retrieval effectiveness in some circumstances. This suggests that the two properties, namely positive compensation and equal importance might help retrieval effectiveness. We also provide the experimental results that coincide with our analyses.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7160,Combining Multiple Evidence from Different Properties of WeightingSchemes,"It has been known that using different representations of either queries or documents, or different retrieval techniques retrieves different sets of documents. Recent work suggests that significant improvements in retrieval performance can be achieved by combining multiple representations or multiple retrieval techniques. In this paper we propose a simple method for retrieving different documents within a single query representation, a single document representation and a single retrieval technique. We classify the types of documents, and describe the properties of weighting schemes. Then, we explain that different properties of weighting schemes may retrieve different types of documents. Experimental results show that significant improvements can be obtained by combining the retrieval results from different properties of weighting schemes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7161,Randomized Graph Drawing with Heavy-Duty Preprocessing,"We present a graph drawing system for general undirected graphs with straight-line edges. It carries out a rather complex set of preprocessing steps, designed to produce a topologically good, but not necessarily nice-looking layout, which is then subjected to downhill-only version of Davidson and Harel's simulated annealing beautification algorithm. The intermediate layout is planar for planar graphs and attempts to come close to planar for non-planar graphs. The system's results are better and faster than what the annealing approach is able to achieve on its own.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7162,EFFICIENT ACCESS TO KNOWLEDGE VIA FORWARD CHAINING TACTICS,"The goal of this work is to explore efficient ways to use knowledge in interactive development of formal arguments.  The challenge in automatically applying knowledge from a large knowledge base is in defining useful and tractable approximations to the deductive closure of the knowledge base.  For an approximation to be useful, it must be deep in some directions.  For it to be tractable, it must not be deep in all directions.  Further, it must be easy to control this directedness.  Thus, we need to make selective inferences from a large knowledge base that are sensitive both to its internal structure and to the query under consideration.  To do this, most interactive systems employ a combination of heuristics and explicit user commands. The interaction of these two is intricate: to efficiently give hints to a heuristic prover requires developing a model of reasoning that is both efficiently implementable and easy to understand and use, i.e., fast, having a concise command language and predictable results.  Rule-based specifications of approximations is the starting point for the contribution of this thesis in solving the problem described above.  In this thesis, we analyze the use of rule-based forward chaining inference procedures and develop several extensions to the basic approach.  We propose a new language for forward chaining tactics that can be used to specify goal-directed inference from large knowledge bases.  This provides a modular approach to programming the heuristics for theorem proving.  The tactic language has clean theoretical properties that make it appropriate for automated analysis and optimization. From the software engineering perspective, this thesis contains an assessment of the new software engineering approach of the theorem prover Ontic: specifying high performance theorem provers in a bottom-up logic programming framework.  This perspective provides a much needed link between the Ontic project and other established research paradigms.  The analysis tools developed for evaluating the forward chaining approach to obvious reasoning should have broad applications in evaluating other semi-automated approaches and systems.  We also develop a language for declarative specification of control for forward chaining reasoning that is analogous to the role of LCF tacticals for specifying control in refinement-style reasoning, as embodied in Nuprl.  We arrived at promising conclusions about the potential for combining these two styles of tactic programming in such problems as the integration of decision procedures and rewriting into interactive theorem provers.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7163,Protocol Composition in Horus,"Horus is a communication architecture that treats a protocol as an abstract data type.  Protocol layers can be stacked on top of each other in a variety of ways, at run-time.  This paper starts out with describing the many classes of protocols that can be supported this way.  Next, we describe the Horus object model that we designed for this technology, and the interface between the layers that makes it all work.  We then present an example layer which implements a group membership protocol.  Then, we look at a example stack of protocols, which provides fault-tolerant, totally ordered communication between a group of processes.  We conclude with presenting some remaining challenges in our project.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7164,Using Virtual Synchrony to Develop Efficient Fault TolerantDistributed Shared Memories,"This paper shows how to define consistency conditions for distributed shared memories in virtually synchronous environments. Such definitions allow to develop fault tolerant implementations of distributed shared memories, in which during normal execution, operations can be performed very efficiently, and only those operations which take place during a configuration change must be delayed. Three well known consistency conditions, namely, linearizability, sequential consistency, and causal memory, are redefined for virtually synchronous environments. It is then shown how to provide efficient fault tolerant implementations for these definitions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7165,Length Normalization in Degraded Text Collections,"Optical character recognition (OCR) is the most commonly used technique to convert printed material into electronic form. Using OCR, large repositories of machine readable text can be created in a short time. An information retrieval system can then be used to search through large information bases thus created. Many information retrieval systems use sophisticated term weighting functions to improve the effectiveness of a search. Term weighting schemes can be highly sensitive to the errors in the input text, introduced by the OCR process. This study examines the effects of the well known cosine normalization method in the presence of OCR errors and proposes a new, more robust, normalization method. Experiments show that the new scheme is less sensitive to OCR errors and facilitates use of more diverse basic weighting schemes. It also yields significant improvements in retrieval effectiveness over cosine normalization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7166,An Incremental Drawing Algorithm for Planar Graphs,"We present a new algorithm for drawing planar graphs on the plane. It can be viewed as a generalization of the algorithm of Chrobak and Payne, which in turn, is based on an algorithm by de Fraysseix, Pach and Pollack.  Our algorithm improves the previous ones in that it does not require a preliminary triangulation step; triangulation proves problematic in drawing graphs ``nicely"", as it has the tendency to ruin the structure of the input graph. The new algorithm retains the positive features of the previous algorithms: It embeds a graph of $n$ vertices on a grid of size $(2n-4)\times (n-2)$ in linear time.  We have implemented the algorithm as part of a software system for drawing graphs nicely.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7167,Enhancing the Nuprl Proof Development System and Applying it toComputational Abstract Algebra,"This thesis describes substantial enhancements that were made to the software tools in the Nuprl system that are used to interactively guide the production of formal proofs. Over 20,000 lines of code were written for these tools.  Also, a corpus of formal mathematics was created that consists of roughly 500 definitions and 1300 theorems. Much of this material is of a foundational nature and supports all current work in Nuprl.  This thesis concentrates on describing the half of this corpus that is concerned with abstract algebra and that covers topics central to the mathematics of the computations carried out by computer algebra systems.  The new proof tools include those that solve linear arithmetic problems, those that apply the properties of order relations, those that carry out inductive proof to support recursive definitions, and those that do sophisticated rewriting.  The rewrite tools allow rewriting with relations of differing strengths and take care of selecting and applying appropriate congruence lemmas automatically.  The rewrite relations can be order relations as well as equivalence relations. If they are order relations, appropriate monotonicity lemmas are selected.  These proof tools were heavily used throughout the work on computational algebra. Many examples are given that illustrate their operation and demonstrate their effectiveness.  The foundation for algebra introduced classes of monoids, groups, rings and modules, and included theories of order relations and permutations.  Work on finite sets and multisets illustrates how a quotienting operation hides details of datatypes when reasoning about functional programs.  Theories of summation operators were developed that drew indices from integer ranges, lists and multisets, and that summed over all the classes mentioned above.  Elementary factorization theory was developed that characterized when cancellation monoids are factorial.  An abstract data type for the operations of multivariate polynomial arithmetic was defined, and the correctness of an implementation of these operations was verified. The implementation is similar to those found in current computer algebra systems. This work was all done in Nuprl's constructive type theory.  The thesis discusses the appropriateness of this foundation, and the extent to which the work relied on it.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7168,Faster Possibility Detection by Combining Two Approaches,"A new algorithm is presented for detecting whether a particular computation of an asynchronous distributed system satisfies $\Poss\Phi$ (read ""possibly $\Phi$""), meaning the system could have passed through a global state satisfying $\Phi$.  Like the algorithm of Cooper and Marzullo, $\Phi$ may be any global state predicate; and like the algorithm of Garg and Waldecker, $\Poss\Phi$ is detected quite efficiently if $\Phi$ has a certain structure.  The new algorithm exploits the structure of some predicates $\Phi$ not handled by Garg and Waldecker's algorithm to detect $\Poss\Phi$ more efficiently than is possible with any algorithm that, like Cooper and Marzullo's, evaluates $\Phi$ on every global state through which the system could have passed. A second algorithm is also presented for off-line detection of $\Poss\Phi$.  It uses Strassen's scheme for fast matrix multiplication. The intrinsic complexity of off-line and on-line detection of $\Poss\Phi$ is discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7169,On Presenting Monotonicity and On EA=>AE,"Two independent topics are treated. First, the problem of weakening/strengthening steps in calculational proofs is discussed and a form of substantiating such steps is proposed. Second, a simple proof of (Ex| R.x: (Ay| S.y: P.x.y)) greater than or equal to (Ay| S.y: (Ex| R.x: P.x.y)) is presented, which uses the idea of a witness for an existnetial quantification.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7170,Automatic Symbolic Verification of Embedded Systems,"We present a model-checking procedure and its implementation for the 
   automatic verification of embedded systems.
   The system components are described as 
   Hybrid Automata---communicating machines with finite control and 
   real-valued variables that represent continuous environment parameters such 
   as time, pressure, and temperature.
   The system requirements are specified in a temporal logic with stop watches,
   and verified by symbolic fixpoint computation.
   The verification procedure---implemented in the Cornell Hybrid Technology
   Tool, HyTech---applies to hybrid automata whose continuous dynamics is 
   governed by linear constraints on the variables and their derivatives.
   We illustrate the method and the tool by checking safety, liveness, 
   time-bounded, and duration requirements of digital controllers, schedulers, 
   and distributed algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7171,Dienst: Implementation Reference Manual,"We describe the architecture and implementation of Dienst:  a protocol and server that provides distributed document libraries over the World Wide Web.   Dienst is based on a document model that incorporates unique document names, multiple document formats, and multiple document decompositions. Interoperability among Dienst servers provides the user with a single logical document collection, even though the actual collection is distributed across multiple servers. The Dienst protocol uses HTTP (the protocol of the World Wide Web) as a transport layer, making Dienst servers accessible from any WWW client. Dienst is currently used as the infrastructure for a distributed computer science technical report library by a number of U.S. universities.  This document is intended as a guide for Dienst site administrators and  implementors of other digital library systems.  It describes the architecture of an individual server and network of Dienst servers and includes the server installation instructions.  Appendices describe copyright issues and retrospective conversion of the Cornell technical report collection.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7172,Estimating the Attainable Accuracy of Recursively Computed ResidualMethods,"Many conjugate gradient-like methods for solving linear systems $Ax=b$ use recursion formulas for updating residual vectors, instead of  computing the residuals directly.  For such methods it is shown that the difference between the actual residuals and the updated  approximate residual vectors generated in finite precision arithmetic depends on the machine precision $\epsilon$ and on the maximum norm of  an iterate divided by the norm of the true solution. It is often observed numerically, and can sometimes be proved, that the norms of the updated approximate residual vectors converge to zero, or, at least, become orders of magnitude smaller than the machine precision.  In such cases, the actual residual norm reaches the level $\epsilon \| A \| \| x \|$ times the maximum ratio of the norm of an iterate to that of the  true solution.  Using exact arithmetic theory to bound the size of the iterates, we give a priori extimates of the size of the final residual for a number of algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7173,Improved Curve Detection Through Decomposition of the Hough Transform,"This paper describes techniques to perform fast and accurate curve detection using a variant of the Hough transform. It is shown that the Hough transform can be decomposed into many small subproble ms, where each subproblem considers only curves that pass through some subset of the points.  These curves correspond to a manifold in the parameter space. This property allows the effects of localization error to be modeled more accurately than previous systems.  The additional use of randomization techniques leads to efficient algorithms. The time required by this method is $O(n)$, where $n$ is the number of edge poin ts in the image, if we are only required to find curves that are significant wit h respect to the complexity of the image.  Results are given showing the detecti on of lines and circles in real images.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7174,Efficient Algorithms for Optimal Video Transmission,"This paper addresses the problem of sending an encoded video stream over a channel of limited bandwidth.  When there is insufficient bandwidth available, some data must be dropped.  For many video encodings, some data are more important than others, leading to a natural prioritization of the data.  In this paper we give fast algorithms to determine a prioritization which optimizes the visual quality of the received data.  By ""optimized visual quality,"" we mean that the expected maximum interval of unplayable frames is minimized.  Our results are obtained in a model of encoded video data that is applicable to many encoding technologies.  The highlight of the model is an interesting relationship between the play order and dependence order of frames. The property allows fast determination of optimal send orders by dynamic programming and is satisfied by all MPEG sequences.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7175,A Complete Gentzen-style Axiomatization for Set Constraints,"Set constraints are inclusion relations between expressions denoting sets of ground terms over a ranked alphabet.  They are the main ingredient in set-based program analysis.  In this paper we provide a Gentzen-style axiomatization for sequents $\Phi\force\Psi$, where $\Phi$ and $\Psi$ are finite sets of set constraints, based on the axioms of termset algebra.  Sequents of the restricted form $\Phi\force\bottom$ correspond to positive set constraints, and those of the more general form $\Phi\force\Psi$ correspond to systems of mixed positive and negative set constraints.  We show that the deductive system is (i) complete for the restricted sequents $\Phi\force\bottom$ over standard models, (ii) incomplete for general sequents $\Phi\force\Psi$ over standard models, but (iii) complete for general sequents over set-theoretic termset algebras.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7176,"Newtonian Graphs, Riemann Surfaces and Computation","In this thesis we study the Newtonian graph and how to compute it.
 We show different applications of this computation, ranging from
 numerical root finding to computing the genera of algebraic Riemann
 surfaces.
 
 Newton's method in the complex plane gives rise to a vector field.
 Certain curves of flow in this field are of particular interest as
 they form a connected graph, the Newtonian graph.  The faces of the
 graph are regions corresponding to roots of the input function, and
 Newton's method on each region ""should"" converge to that root.  We
 give a symbolic algorithm to compute the Newtonian graph for
 rational functions.  The resulting structure can be used to improve
 Newton's method to guarantee convergence.
 
 We also show how to extend the notion of Newtonian flow to a
 Riemann surface of an algebraic function.  Again we obtain a
 Newtonian graph, now living on the abstract Riemann surface.  We
 show how the graph is a tiling of the surface, and can therefore be
 used to compute the genus of the surface.  Then we extend our
 earlier graph computation to cover the algebraic functions as well.
 All this computation is very efficient in the sense that it can all
 be done within the NC complexity class.  This gives the first NC
 algorithm to compute the genus of algebraic Riemann surfaces.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7177,Avoiding the Undefined by Underspecification,We use the appeal of simplicity and an aversion to complexity in selecting a method for handling partial functions in logic. We conclude that avoiding the undefined by using underspecifi- cation is the preferred choice.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7178,HyTech : The Cornell HYbrid TECHnology Tool,"This paper is addressed to potential users of HyTech, the Cornell Hybrid 
 Technology Tool, an automatic tool for analyzing hybrid systems.
 We review the formal technologies that have been incorporated into HyTech,
 and we illustrate the use of HyTech with three nontrivial case studies.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7179,Fast Compiled Logic Simulation Using Linear BDDs,"This paper presents a new technique for compiled zero delay logic
 simulation, and includes extensive experiments that demonstrate its
 performance on standard benchmarks. Our compiler partitions the
 circuit into fanout-free regions (FFRs), transforms each FFR
 into a linear sized BDD, and converts each BDD into executable code.
 In our approach, the computation is sublinear in the number of
 variables within each partition because only one path, from root to
 leaf, of the BDD is executed; therefore in many cases, substantial
 computation is avoided. In this way, our approach gets some of the
 advantages of oblivious as well as demand-driven evaluation. We
 investigated the impact of various heuristics on performance, and
 based on this data, we recommend good values for design parameters. A
 performance improvement of up to 67% over oblivious simulation is
 observed for our benchmarks.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7180,Lower Bounds for Fully Dynamic Connectivity Problems in Graphs,"We prove lower bounds on the complexity of maintaining fully dynamic $k$-edge or $k$-vertex connectivity in plane graphs and in $(k-1)$-vertex connected graphs.  We show an amortized lower bound of $\Omega (\log n / {k (\log \log n} + \log b))$ per edge insertion,  deletion, or query operation in the cell probe model, where $b$ is the word size of the machine and $n$ is the number of vertices in $G$. We also show an amortized lower bound of $\Omega( \log n /(\log \log n + \log b))$ per operation for fully dynamic planarity testing in embedded graphs.  These are the first lower bounds for fully dynamic connectivity problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7181,Efficient Dynamic Network Flow Algorithms,"Dynamic network flows model transportation.  A dynamic network
 consists of a graph with capacities and transit times on its
 edges.  Flow moves through a dynamic network over time.  Edge
 capacities restrict the rate of flow and edge transit times
 determine how long each unit of flow spends traversing the network.
 Dynamic network flows have been studied extensively for decades. 
 
 This thesis introduces the first polynomial algorithms to solve
 several important dynamic network flow problems.  We solve them
 by computing chain-decomposable flows, a new class of structured
 dynamic flows.
 
 We solve the quickest transshipment problem.  An instance of this
 problem consists of a dynamic network with several sources and
 sinks.  Each source has a specified supply and each sink a
 specified demand of flow.  The goal is to move the appropriate
 amount of flow out of each source and into each sink within the
 least overall time.  Previously, this problem could only be
 solved efficiently in the special case of a single source and
 single sink.
 
 Our quickest transshipment algorithm depends on efficient
 solutions to the dynamic transshipment problem and the
 lexicographically maximum dynamic flow problem.  The former is a
 version of the quickest transshipment problem in which the time
 bound is specified.  The latter is a maximum flow problem in a
 dynamic network with prioritized sources and sinks; the goal is
 to maximize the amount of flow leaving each high-priority subset
 of sources and sinks.
 
 We also consider the universally maximum dynamic flow problem.  A
 universally maximum dynamic flow sends flow between a source and
 sink so that the sink receives flow as quickly as possible;
 subject to that, the source releases flow as late as possible. 
 We describe the first polynomial algorithm 
 to approximate a universally maximum dynamic flow within 
 a factor of $(1+\eps)$, for any $\eps>0$.  
 We also describe the first polynomial
 algorithm to compute the value of a universally maximum dynamic
 flow at a single specified moment of time.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7182,"A Subspace, Interior, and Conjugate Gradient Method for Large-ScaleBound-Constrained Minimization Problems","A subspace adaptation of the Coleman-Li trust region and interior
 method is proposed for solving large-scale bound-constrained
 minimization problems.  This method can be implemented with either
 sparse Cholesky factorization or conjugate gradient computation.
 Under reasonable conditions the convergence properties of this
 subspace trust region method are as strong as those of its full-space
 version.
 
 Computational performance on various large-scale test problems are
 reported; advantages of our approach are demonstrated.  Our experience
 indicates our proposed method represents an efficient way to solve
 large-scale bound-constrained minimization problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7183,Geometric Bicriteria Optimal Path Problems,"A bicriteria optimal path simultaneously satisfies two bounds on two
 measures of path quality.  The complexity of finding such a path
 depends on the particular choices of path quality.  This thesis studies
 bicriteria path problems in a geometric setting using several pairs of
 path quality, including:  path length measured according to different
 norms ($L_{p}$ and $L_{q}$); Euclidean length within two or more
 classes of regions; total turn and Euclidean length;  total turn and
 number of links; and Euclidean length and number of links.
 
 For several cases, finding the bicriteria optimal path is shown to be
 NP-hard. These NP-hard cases include minimizing path length in two
 different norms, minimizing travel through two regions, and minimizing
 length and total turn.  In the last case, an $O(En^{2}N^{2})$
 pseudo-polynomial time algorithm to find an approximate answer is
 presented.  In contrast, when the two measures of path quality are
 total turn and number of links, an $O(E^{3}n \log^{2} n)$ exact
 algorithm is given.
 
 A main result of this thesis examines minimizing the Euclidean length
 and number of links of a path.  When the geometric setting of this
 problem is a polygon without holes, this thesis presents an
 $O(n^{3}k^{3} \log(N k/ \epsilon^{1/k}) )$ algorithm to find a $k$-link
 path with Euclidean length at most $1+\epsilon$ times the length of the
 shortest $k$-link path.  A faster algorithm for a relaxed case, when
 the output path is allowed to have $2k$ links, is presented for a
 polygon with or without holes.
 
 Finally, some approximation algorithms are outlined for finding a
 minimum link path among polyhedral obstacles.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7184,Packing Messages as a Tool for Boosting the Performance of TotalOrdering Protocols,"This paper compares the throughput and latency of four protocols that provide total ordering. Two of these protocols are measured with and without message packing. We used a technique that buffers application messages for a short period of time before sending them, so more messages are packed together. The main conclusion of this comparison is that message packing influences the performance of total ordering protocols under high load overwhelmingly more than any other optimization that was checked in this paper, both in terms of throughput and latency. This improved performance is attributed to the fact that packing messages reduces the header overhead for messages, the contention on the network, and the load on the receiving CPUs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7185,Exploring Query Expansion Strategies for MEDLINE,"This paper evaluates the retrieval effectiveness of query expansion strategies on a MEDLINE test collection using Cornell University's Smart retrieval system. Two expansion strategies are tested on their ability to identify appropriate MeSH terms for user queries: expansion using an inter--field statistical thesaurus and expansion via pure retrieval feedback. These expansion strategies do not require prior relevance decisions. The study compares retrieval effectiveness using the original  unexpanded and the alternative expanded user queries on a collection of 75 queries and 2,334  MEDLINE citations. Retrieval effectiveness is assessed using eleven point average precision scores (11-AvgP). Expansion by retrieval feedback gives the best improvement of 16.4\% over a baseline performance of 0.5169 11-AvgP. Query expansion using the inter--field thesaurus gives a significant but lower performance improvement (9.9\%) over the same baseline. This study recommends query expansion using retrieval feedback for adding MeSH search terms to a user's initial query.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7186,Document Length Normalization,"In the TREC collection -- a large full-text experimental text collection with widely varying document lengths -- we observe that the likelihood of a document being judged relevant by a user increases with the document length.  We show that a retrieval strategy, such as the vector-space cosine match, that retrieves documents of different lengths with roughly equal probability, will not optimally retrieve useful documents from such a collection. We present a modified technique that attempts to match the likelihood of retrieving a document of a certain length to the likelihood of documents of that length being judged relevant, and show that this technique yields significant improvements in retrieval effectiveness.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7187,Feature-Based Algorithms for Detecting and Classifying Scene Breaks,"We describe a new approach to the detection and classification of scene breaks
 in video sequences.  Our method can detect and classify a variety of scene
 breaks, including cuts, fades, dissolves and wipes, even in sequences
 involving significant motion.  We detect the appearance of intensity edges
 that are distant from edges in the previous frame.  A global motion
 computation is used to handle camera or object motion.  The algorithms we
 propose withstand compression artifacts such as those introduced by JPEG and
 MPEG, even at very high compression rates.  Experimental evidence demonstrates
 that our method can detect and classify scene breaks that are difficult to
 detect with previous approaches.  An initial implementation runs at
 approximately 2 frames per second on a Sun workstation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7188,Issues in Ordered Multicast Performance:  A Simulation Study,"Process groups are an increasingly popular tool for programming          distributed systems.  Such groups consist of collections of processes that work together to provide reliability, fault tolerance, task distribution, or some other abstraction.  A combination of group actions, reliable failure detection, and ordered message delivery are used to provide group functionality. {\em Causal ordering}, one form of message ordering, is fundamental in process group systems.  Its cost is therefore an important determinant of overall performance. In order to gain more insight into the behavior of causal order protocols, two  simulations of process group systems were developed.  The first, a detailed simulation of all system processes, groups, and interconnection networks, was used to study small systems. Using this model, a number of parameters were identified as having the greatest impact on ordered multicast performance. These parameters were used as indices to a set of precomputed probability distribution tables used by the second simulation.  The second simulation focused only on key  processes --- packet originators and processes in multiple overlapping groups --- and used precomputed probability tables to reduce simulation overhead.  Simulations using this model showed that the delays imposed by the ordering protocols result in a tendency for packets to become ""convoyed"" together.  Consequences are larger delays and greater system and network burstiness.  We speculate that this tendency for systems to become more bursty, or less uniform, is a general principle.  That is, any system which delays actions on a ""microscopic"" level results in burstiness at a ""macroscopic"" level.  The more times such delays occur, the greater the degree of burstiness.  Such a principle would imply that systems with this characteristic are limited in scale by the size of the largest burst that can be handled.  It also suggests that protocols that minimize the number and length of delays and which optimize the handling of bursts should be used.  In the context of process group systems, burstiness can be limited by minimizing the number of groups through which a packet is filtered and by protocol designs which minimize the number of delays used to control out-of-order message arrival.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7189,A User Guide to HyTech,"HyTech is a tool for the automated analysis of embedded systems.  This document, designed for the first-time user of HyTech, guides the  reader through the underlying system model, and through the input  language for describing and analyzing systems.  The guide gives  several examples of usage, some hints for gaining maximal  computational efficiency from the tool, and the complete grammar for  the input language.    The version of HyTech described in this guide was released in August  1995, and is available through anonymous ftp from ftp.cs.cornell.edu  in the directory ~pub/tah/HyTech, and through the World-Wide Web  via HyTech's home page http://www.cs.cornell.edu/Info/People/tah/hytech.html",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7190,A Consistent and Complete Deductive System for the Verification of Parallel Programs,"The semantics of a simple parallel programming language is presented in two  ways: deductively, by a set of Hoare-like axioms and inference rules, and  operationally, by means of an interpreter. It is shown that the deductive  system is consistent with the interpreter. It would be desirable to show that  the deductive system is also complete with respect to the interpreter, but  this is impossible since the programming language contains the natural  numbers. Instead it is proven that the deductive system is complete relative  to a complete proof system for the natural numbers; this result is similar to  Cook's relative completeness for sequential programs. The deductive semantics given here is an extension of an incomplete deductive  system proposed by Hoare. The key difference is an additional inference rule  which provides for the introduction of auxiliary variables in a program to be  verified.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7191,On the Formal Specification of Group Membership Services,"The problem of group membership has been the focus  of much theoretical and experimental work  on fault-tolerant distributed systems.  This has resulted in a voluminous literature  and several formal specifications  of this problem have been given.  In this paper, we examine the two most referenced formal specifications  of group membership and show that they are unsatisfactory:  One has flaws in the formalism and allows undesirable executions,  and the other can be satisfied by useless protocols.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7192,Unreliable Failure Detectors for Reliable Distributed Systems,"We introduce the concept of unreliable failure detectors and study how they can be used to solve Consensus in asynchronous systems with crash failures. We characterise unreliable failure detectors in terms of two properties --- completeness and accuracy. We show that Consensus can be solved even with unreliable failure detectors that make an infinite number of mistakes, and determine which ones can be used to solve Consensus despite any number of crashes, and which ones require a majority of correct processes. We prove that Consensus and Atomic Broadcast are reducible to each other in asynchronous systems with crash failures; thus the above results also apply to Atomic Broadcast. A companion paper shows that one of the failure detectors introduced here is the weakest failure detector for solving Consensus [CHT92].",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7193,Automatic Analysis of Hybrid Systems,"Hybrid systems are real-time systems that react to both discrete and continuous activities (such as analog signals, time, temperature, and speed).  Typical examples of hybrid systems are embedded systems, timing-based communication protocols, and digital circuits at the transistor level. Due to the rapid development of microprocessor technology, hybrid systems directly control much of what we depend on in our daily lives. Consequently, the formal specification and verification of hybrid systems has become an active area of research. This dissertation presents the first general framework for the formal specification and verification of hybrid systems, as well as the first hybrid-system analysis tool--HyTech. The framework consists of a graphical finite-state-machine-like language for modeling hybrid systems, a temporal logic for modeling the requirements of the hybrid systems, and a computer procedure that verifies modeled hybrid systems against modeled requirements. The tool HyTech is the implementation of the framework using C++ and Mathematica. More specifically, our hybrid-system modeling language,  Hybrid Automata, is an extension of timed automata with discrete and general continuous variables whose dynamics are governed by differential equations.  Our requirement modeling language, ICTL, is a branching-time temporal logic, and is an extension of TCTL with stop-watch variables. Our verification procedure is a symbolic model-checking procedure that verifies linear hybrid automata against ICTL formulas. To make HyTech more efficient and effective, we designed and implemented model-checking strategies and abstract operators that can expedite the verification process. To enable HyTech to verify nonlinear hybrid automata, we also introduce two translations from nonlinear hybrid automata to linear hybrid automata that can be fed into HyTech for automatic analysis. We have applied HyTech to analyze more than 30 hybrid-system benchmarks. In this dissertation, we show the application of HyTech to three nontrivial hybrid systems taken from the literature.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7194,Strong and Weak Virtual Synchrony in Horus,"A formal definition of {\em strong virtual synchrony}, capturing the semantics  of virtual synchrony as implemented in Horus, is presented.  This definition has the nice property that every message is delivered within  the view in which it was sent.  However, it is shown that in order to implement strong virtual synchrony,  the application program has to block messages during view changes.  An alternative definition, called {\em  weak virtual synchrony}, which can  be implemented without blocking messages, is then presented.  This definition still guarantees that messages will be delivered within the  view in which they were sent, only that it uses a slightly weaker notion of  what the view in which a message was sent is.  An implementation of weak virtual synchrony that does not block messages  during view changes is developed, and it is shown how to use a system that  provides weak virtual synchrony even when strong virtual synchrony is  actually needed.    To capture additional ordering requirements, the definition of  {\em ordered virtual synchrony} is presented.  Finally, it is discussed how to extend the definitions in order to cope with  the fact that a process can become a member of more than one group.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7195,Processor Controlled Off-Processor I/O,"The performance of modern RISC processors on operating system code is well below application code performance. The kernel code implementing communication services across the network is not an exception. Modern networking technologies are characterized by a small packet size, which further increases the communication overhead.    We took the approach of removing the kernel layer from the cross-machine communication path while still providing protection. The presence of a programmable communication processor on the network adapter made this experiment possible. The firmware running on the communication processor implements a Virtual Communication Machine (VCM); applications communicate with the VCM through shared memory without having to switch to kernel mode.  Data is transferred directly between application buffers and the network without any intermediate buffering in the user or kernel spaces. The VCM architecture makes this possible; in particular, the VCM can be programmed to access any location in the address space of an application. The main processor controls the communication but it is not directly involved with it; as a consequence, the overhead on the main processor is very low. The design not only provides very low latencies, but also minimizes the effect of communication on the main processor data caches.  We implemented the datagram subset of the Berkeley sockets interface on top of the VCM interface and integrated it with a user-level thread package. Multicast capabilities were added to the interface. Performance measured at both the VCM and socket layers is presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7196,THE DESIGN AND IMPLEMENTATION OF A PRIVATE MESSAGE SERVICE FOR MOBILE COMPUTERS,"Even as wireless networks create the potential for access to information from mobile platforms, they pose a problem for privacy. In order to retrieve messages, users must periodically poll the network. The information that the user must give to the network could potentially be used to track that user. However, the movements of the user can also be used to hide the user's location if the protocols for sending and retrieving messages are carefully designed.  In this thesis, we will present a protocol for a replicated memory service which allows users to read from memory without revealing which memory locations they are reading. Unlike previous protocols, this protocol is efficient in its use of computation and bandwidth. We will then show how this protocol can be used in conjunction with existing privacy preserving protocols to allow a user of a mobile computer to maintain privacy despite active attacks.  Allowing users to retrieve messages anonymously introduces a new problem. In order to limit memory usage, it is necessary to remove old messages from the system. However, since users may become disconnected from the network for periods of time, it is important that the system hold onto messages until they have been retrieved by their intended recipients. The result is a conflict between the system's need for information and users' desire for privacy. We will present the design of a vacation service which we have developed which stores messages for users which are disconnected which does not require users to reveal any private information.  Finally, we will describe the implementation of the private message service and discuss the performance estimates that we derived for the system based on experimental results. As we will show, the potential throughput of the private message service is reasonable.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7197,Implementation Issues in an Open Architectural Framework for Digital ObjectServices,"We provide high level designs for implementing some key aspects of the Kahn/Wilensky Framework for Distributed Digital Object Services.  We focus on five aspects of the architecture: 1) Negotiation on terms and conditions initiated by requests for stored digital objects.  2) Replication of handle server data and the notion of a primary handle server, 3) The mechanisms for replicating digital objects in multiple repositories and the assertions concerning such replication. 4) The meaning of mutable and immutable states for digital objects and the mechanisms for changing these states. 5) The basic services that the Repository Access Protocol (RAP) needs to support the infrastructure.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7198,What's Decidable About Hybrid Automata?,"Hybrid automata model systems with both digital and analog components, such as embedded control programs.  Many verification tasks for such programs can be expressed as reachability problems for hybrid automata.  By improving on previous decidability and undecidability results, we identify the precise boundary between decidability and undecidability of the reachability problem for hybrid automata. On the positive side, we give an (optimal) PSPACE reachability algorithm for the case of initialized rectangular automata, where all analog variables follow trajectories within piecewise-linear envelopes and are reinitialized whenever the envelope changes.  Our algorithm is based on the construction of a timed automaton that contains all reachability information about a given initialized rectangular automaton.  The translation has practical significance for verification, because it guarantees the termination of symbolic procedures for the reachability analysis of initialized rectangular automata.  The translation also preserves the $\omega$-languages of initialized rectangular automata with bounded nondeterminism. On the negative side, we show that several slight generalizations of initialized rectangular automata lead to an undecidable reachability problem.  In particular, we prove that the reachability problem is undecidable for timed automata augmented with a single stopwatch.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7199,SplitThreads - Split-C Threads,"SplitThreads are enhancements to Split-C by user level non pre-emptive threads. The primary motivation for SplitThreads comes from the fact that the SPMD paradigm of Split-C is a limitation for some important problems. At the same time, Split-C is very efficient and is tunable for good performance. Other related approaches such as Nexus have a large amount of overhead in providing threads capability. This paper presents the addition of a lightweight user-level threads package to Split-C. The performance numbers obtained show significant improvement over existing comparable approaches such as Nexus. The underlying thread library core is QuickThreads. QuickThreads provides minimal support for thread management. Additional functionality is provided by SplitThreads on top of this core. Finally, SplitThreads provides higher level user objects such as I-structures and M-structures",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7200,INEXACT REFLECTIVE NEWTON METHODS FOR LARGE-SCALE OPTIMIZATION  SUBJECT TOBOUND CONSTRAINTS,"This thesis addresses the problem of minimizing a large-scale nonlinear function subject to simple bound constraints. The most popular methods to handle bound constrained problems, active-set methods, introduce a combinatorial aspect to the problem. For these methods, the number of steps to converge may be related to the number of constraints.  For large problems, this behavior is particularly detrimental.  Reflective Newton methods avoid this problem by staying strictly within the constrained region.  As a result, these methods have strong theoretical properties.  Moreover, they behave experimentally like an unconstrained method: the number of steps to a solution is not strongly correlated with problem size.  In this thesis, we discuss the reflective Newton approach and how it can be combined with inexact Newton techniques, within a subspace trust-region method, to efficiently solve large problems.  Two algorithms are presented.  The first uses a line search as its globalizing strategy.  The second uses a strictly trust-region approach to globally converge to a local minimizer.  Global convergence and rate of convergence results are established for both methods.  We present computational evidence that using inexact Newton steps preserves the properties of the reflective Newton methods: the iteration counts are as low as when ""exact"" Newton steps are used. Also, both the inexact and exact methods are robust when the starting point is varied.  Furthermore, the inexact reflective Newton methods have fast convergence when negative curvature is encountered, a trait not always shared by similar active-set type methods.  The role of negative curvature is further explored by comparing the subspace trust-region approach to other common approximations to the full-space trust-region problem.  On problems where only positive curvature is found, these trust-region methods differ little in the number of iterations to converge.  However, for problems with negative curvature, the subspace method is more effective in capturing the negative curvature information, resulting in faster convergence.  Finally a parallel implementation on the IBM SP2 is described and evaluated; the scalability and efficiency of this implementation are shown to be as good as the matrix-vector multiply routine it depends on.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7201,Classification and Lower Bounds for MEMS Arrays and Vibratory Parts Feeders:What Programmable Vector Fields Can (and Cannot) Do --- Part I,"Programmable vector fields can be used to control a variety of flexible planar parts feeders.  These devices can exploit exotic actuation technologies such as arrayed, massively-parallel microfabricated motion pixels or transversely vibrating (macroscopic) plates.  These new automation designs promise great flexibility, speed, and dexterity---we believe they may be employed to orient, singulate, sort, feed, and assemble parts.  However, since they have only recently been invented, programming and controlling them for manipulation tasks is challenging. By chaining together sequences of vector fields, the equilibrium states of a part in the field may be cascaded to obtain a desired final state.  The resulting strategies require no sensing and enjoy efficient planning algorithms.  This paper begins by describing our experimental devices. In particular, we describe our progress in building the {\sc M-Chip} (\underline{m}anipulation \underline{chip}), a massively parallel array of programmable micro-motion pixels.  As proof of concept, we demonstrate a prototype {\sc M-Chip} containing over 11,000 silicon actuators in one square inch.  Both the {\sc M-Chip}, as well as macroscopic devices such as transversely vibrating plates, may be programmed with vector fields, and their behavior predicted and controlled using our {\em equilibrium analysis}. We demonstrate lower bounds (i.e., impossibility results) on what the devices {\em cannot} do, and results on a classification of control strategies yielding design criteria by which well-behaved manipulation strategies may be developed. We provide sufficient conditions for programmable fields to induce well-behaved equilibria on every part placed on our devices. We define {\em composition operators} to build complex strategies from simple ones, and show the resulting fields are also well-behaved. We discuss whether fields outside this class can be useful and free of pathology.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7202,New and Improved Manipulation Algorithms for MEMS Arrays and Vibratory PartsFeeders: What Programmable Vector Fields Can (and Cannot) Do --- Part II,"This paper explores how to use programmable vector fields to control flexible planar parts feeders.  For a description of these devices and their actuation technology, see our companion paper, Part~I~\cite{BohringerDonaldMacDonald96b}\ifDRAFT{}\else{, also submitted to ICRA}\fi .  When a part is placed on our devices, the programmed vector field induces a force and moment upon it.  Over time, the part may come to rest in a dynamic equilibrium state.  By chaining together sequences of vector fields, the equilibria may be cascaded to obtain a desired final state. By analyzing and constraining the equilibria of programmable vector fields, we can generate and execute plans to orient and sort parts.  These plans require no sensing.  This paper describes new manipulation algorithms using the tools developed in Part~I~\cite{BohringerDonaldMacDonald96b}.  In particular, we improve existing planning algorithms by a quadratic factor, and the plan-length by a linear factor.  Using our new and improved strategies, we show how to simultaneously orient and pose any part, without sensing, from an arbitrary initial configuration.  We relax earlier dynamic and mechanical assumptions to obtain more robust and flexible strategies.  Finally, we consider parts feeders that can only implement a very limited ""vocabulary"" of vector fields (as opposed to the pixel-wise programmability assumed above).  We show how to plan and execute parts-posing and orienting strategies for these devices, but with a significant increase in planning complexity and some sacrifice in completeness guarantees.  We discuss the tradeoff between mechanical complexity and planning complexity.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7203,"DESIGN, FABRICATION, AND CHARACTERIZATION OF SINGLE CRYSTAL SILICON LATCHINGSNAP FASTENERS FOR MICRO ASSEMBLY","A snap fastener is a deformable device consisting of a pair of mating surfaces that ""snap"" together during assembly.  Because of the simple, linear assembly motion, such latching micro fasteners have a wide range of applications in micro assembly tasks, e.g.\ for devices with multiple or layered components, or micro opto-mechanical plugs.  At the micro scale, conventional types of fasteners like screws and hinges are unlikely to work due to present fabrication constraints and large friction forces.  Micro snap fasteners also have great potential to be used as sensors with memory.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7204,Sensorless Manipulation Using Transverse Vibrations of a Plate,"The existing industrial parts feeders move the parts through a sequence of mechanical filters that reject parts in unwanted orientations.  In this paper we develop a new setup that uses a different vibratory mechanism to systematically manipulate parts, by actively orienting and localizing them.  The idea is to generate and change dynamic modes for a plate by varying the applied frequency of oscillation. Depending on the node shapes of the plate for these frequencies, the position and orientation of the parts can be controlled. We develop an analysis of the underlying dynamics, and show that it can be used to predict the behavior of objects placed on the vibrating plate. Using this analysis, we propose that the applied frequencies can be automatically sequenced to obtain a ""sensorless"" strategy for manipulating a given object.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7205,On the Impossibility of Group Membership,"We prove that the primary-partition group membership problem cannot be solved in  	asynchronous systems with crash failures,  	even if one allows the removal or killing of non-faulty processes  	that are erroneously suspected to have crashed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7206,Selective Text Traversal,"In information retrieval and text processing, the size of the available databases and text collections has grown enormously in the past few years, and users find it difficult to cope with the amount of text that is potentially of interest.  As a result, there is growing interest in approaches capable of breaking down large texts into smaller constituent units, and in using short text passages for storage and retrieval purposes.  Methods are described in this study for identifying important text passages in large texts, and suggestions are made for implementing useful text reading and text traversal strategies that provide selective text access in accordance with user needs.  Some evaluation results for selective text access are appended.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7207,Approximating Perfect Failure Detectors in Asynchronous Distributed Systems,"Systems that provide group membership services (e.g., Isis) can be used
 to solve many canonical problems in distributed systems, such as  Consensus and Leader Election.  However, solving these problems has  been shown to require {\em failure detectors} of various strengths, all  of which are impossible to implement in an asynchronous system.  It has  been shown that it is possible to solve Consensus in an asynchronous  distributed system using a very weak failure detector.  However,  existing group membership systems do not appear to implement this type  of failure detector.  Furthermore, there are other problems that can be  solved with group membership services, such as Leader Election, that  are harder than Consensus and cannot be solved without a perfect  failure detector.  This leads to an apparent contradiction:  how can  provably impossible problems be solved in existing group membership  systems?   In this dissertation, we investigate {\em approximations} to perfect  failure detectors in order to obtain acceptable and practical solutions  to otherwise-impossible problems such as Election.  We argue that  approximating a perfect failure detector yields approximate solutions  to these problems, and define a notion of approximation that yields  solutions that are useful in practice.  We give a formal specification  of an approximately-perfect failure detector, give two protocols that  implement our approximation, and derive upper bounds on the number of  tolerable failures for any such protocol.  The approximately-perfect  failure detector presented in this dissertation is similar to that used  in Isis; this implies that the failure detector implemented in group  membership services such as Isis are actually approximately-perfect  failure detectors, and that the resulting solutions to Consensus,  Election, and other problems are approximate solutions.  Furthermore,  the protocols that implement our specification are very simple and can  be easily implemented.  Such an implementation could be used in  existing or future group membership services, or by other systems  programmers for whom group membership services are not necessary but  for whom failure detection would be useful.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7208,Incremental Computation: A Semantics-Based Systematic Transformational Approach,"Incremental computation takes advantage of repeated computations on
 inputs that differ slightly from one another, computing each new output incrementally by making use of the previous output rather than  from scratch.   This thesis concerns the theory, design, and implementation of a  general approach to incremental computation.  It also elucidates the  essence of improving the efficiency of computations by relating it to  incremental computation.  Our general approach allows incremental   computation to be obtained systematically from non-incremental   computation and program efficiency to be systematically improved.   This research focuses on identifying the fundamentals of efficient  incremental computation out of domain-specific properties and  language-specific features, devising a general framework that  accommodates these fundamentals, and developing a systematic approach  based on the framework that exploits program semantics.   Three fundamental aspects of incremental computation are identified:  avoiding repeated identical computations, caching useful intermediate  results, and discovering appropriate auxiliary information.  Given a  program $f$ and an operation $\oplus$, an incremental program is  developed to compute $f(x\oplus y)$ efficiently by using $f(x)$, the  intermediate results computed in computing $f(x)$, and auxiliary  information about $x$ that can be inexpensively maintained.   The approach in this thesis is formalized for a simple functional  language, but the underlying principles also apply to other  programming languages.  It exploits program semantics to discover  incrementality that is not directly embedded in primitive operators  and takes into consideration properties of application domains as  well.  It is composed of step-wise program analysis and transformation  modules that can, for the most part, be mechanized.   Since every non-trivial computation proceeds by iteration (or  recursion), the approach is used straightforwardly for achieving  efficient computation in general, by computing each iteration  incrementally using an appropriate incremental program.  This method  is applied to problems in interactive systems, optimizing  compilers, transformational program development, {\it etc}.  The  design and implementation of a prototype system, CACHET, for obtaining  incremental programs is also described.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7209,A Newton Acceleration of the Weiszfeld Algorithm for Minimizing the Sum ofEuclidean Distances,"The Weiszfeld algorithm for continuous location problems can be considered as an iteratively reweighted least squares method. It exhibits linear convergence. In this paper, a Newton type algorithm with similar simplicity is proposed to solve a continuous multifacility location problem with Euclidean distance measure. Similar to the Weiszfeld algorithm, at each iteration the main computation can be solving a weighted least squares problem. A Cholesky factorization of a symmetric positive definite band matrix, typically with a relatively small band width (e.g., a band width of two  for a Euclidean location problem on a plane) is required. This new algorithm can be regarded as a Newton acceleration to the Weiszfeld algorithm with fast global and local convergence. The simplicity and efficiency of the proposed algorithm makes it particularly suitable for large-scale Euclidean location problems and parallel implementation. Computational experience also suggests that the proposed algorithm performs remarkably well in the presence of degeneracy and near degeneracy. In addition, it is proven to be globally convergent. Although the local convergence analysis is still under investigation, computation results suggest that it is typically superlinearly convergent.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7210,"Building ""Computational Intuition"" in Freshman Scientists and Engineers","Undergraduate programs in science and engineering should foster the development of intuition in computational science  courses taken during the freshman year, says the author in  the first of a two-part series. The second part, to be  published in the October issue of SIAM News, will  examine the important role of examples in building intuition and communicating the excitement of computational  science.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7211,Deciding in Partitionable Networks,"Motivated by Chandra and Toueg's work, we
 study decision protocols in a model that closely approximates  ""real"" distributed systems.  Our results show how the weakest  failure detector and associated consensus algorithm  can be adapted to a network in  which omission failures can occur during periods when processes  suspect one-another as faulty.  For protocols in which a majority subset of the participants  can reach decisions on behalf of the system as a whole, we also  characterize a series of stages that necessarily arise during execution.  Jointly, these findings establish a direct relationship between an  extended version of the three-phase commit protocol, which makes progress  even when a traditional three-phase commit would block, and the consensus  protocol of Chandra and Toueg.   Although we do not explore the linkage  here, our results should also be applicable to other agreement  protocols for systems of this sort, such as leader election and  dynamic group membership.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7212,Automatic Text Decomposition Using Text Segments and Text Themes,"With the widespread use of full-text information retrieval,  passage-retrieval techniques are becoming increasingly  popular.  Larger texts can then be replaced by important  text excerpts, thereby simplifying the retrieval task and  improving retrieval effectiveness.  Passage-level  evidence about the use of words in local contexts is also useful  for resolving language ambiguities and improving retrieval output.  Two main text decomposition strategies are introduced in this study, including a chronological decomposition into {\em text segments}, and semantic decomposition into {\em text themes}. The interaction between text segments and text themes is then used to characterize text structure, and to formulate specifications for information retrieval, text traversal, and text summarization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7213,Pseudospectra of linear operators,"The advent of ever more powerful computers has brought with it a new way of conceiving some of the fundamental eigenvalue problems of applied mathematics. If a matrix or linear operator $A$ is far from normal, its eigenvalues or more generally its spectrum may have little to do with its behavior as measured by quantities such as $\|A^n\|$ or $\EtA$.\ \ More may be learned by examining the sets in the complex plane known as the {\it pseudospectra} of $A$, defined by level curves of the norm of the resolvent, $\Resz$.  Five years ago, the author published a paper that presented computed pseudospectra of thirteen highly non-normal matrices arising in various applications.  Since that time, analogous computations have been carried out for differential and integral operators.  This paper, a companion to the earlier one, presents ten examples, each chosen to illustrate one or more mathematical or physical principles.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7214,The efficient computation of sparse Jacobian matrices using automaticdifferentiation,"This paper is concerned with the efficient computation of sparse Jacobian matrices of nonlinear vector maps using automatic differentiation (AD). Specifically, we propose the use of a graph coloring technique, bi-coloring, to exploit the sparsity of the Jacobian matrix $J$ and thereby allow for the efficient determination of $J$ using AD software. We analyze both a direct scheme and a substitution process. We discuss the results of numerical experiments indicating significant practical potential of this approach.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7215,A Design for Inter-Operable Secure Object Stores (ISOS),"We describe a distributed object-based design for repositories in a digital library infrastructure.  This design for Inter-operable Secure Object Stores, ISOS, defines the interfaces to secure repositories that inter-operate with each other, clients, and other services in the infrastructure.  We define the interfaces to ISOS as class definitions in a distributed object system.  We also define an extension to CORBA security that is used by repositories to secure access to themselves and their contained objects.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7216,On Regularity-Preserving Functions,We give a characterization of regularity-preserving functions.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7217,Pivoted Document Length Normalization,"Document length normalization is an important aspect of term weight assignment in an automatic information retrieval system. In this study, we observe that a normalization scheme that retrieves documents of all lengths with similar chances as their likelihood of relevance will outperform another scheme which retrieves documents with chances very different from their likelihood of relevance. We show that the retrieval probabilities for a particular normalization method deviate systematically from the relevance probabilities across different collections. We present pivoted normalization a technique that can be used to reduce the gap between the relevance and the retrieval probabilities. Training pivoted normalization on one collection, we can successfully use it on other (new) text collections, yielding a robust, collection independent normalization technique. We use the idea of pivoting with the well known cosine normalization scheme. We point out some shortcomings of the cosine normalization function and present two new normalization functions --- pivoted unique normalization and pivoted byte size normalization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7218,Faster Algorithms for the Nonemptiness of Streett Automata and forCommunication Protocol Pruning,"This paper shows how a general technique, called {\it lock-step search}, developed for dynamic graph algorithms, can be used to improve the running time of two problems arising in program verification and communication protocol design. (1) We consider the {\it nonemptiness problem for Streett automata}: We are given a directed graph $G=(V,E)$ with $n=|V|$ and $m=|E|$, and a collection of pairs of subsets of vertices, called {\em Streett pairs}, $\langle L_i, U_i \rangle, i= 1..k$.  The question is whether $G$ has a cycle (not necessarily simple) which, for each $1 \leq i \leq k$, either contains no vertex from $L_i$ or contains a vertex of $U_i$. Let $b= \sum_{i=1..k} |L_i|+|U_i|$.  The previously best algorithm takes time $O((m+ b)\min\{n,k\})$. We present an algorithm that takes time $O(m \min \{ \sqrt{m \log n}, k, n\} + b \min \{\log n, k\})$. (2) In {\it communication protocol pruning} we are given a directed graph $G=(V,E)$ with $l$ special vertices. The problem is to efficiently maintain the strongly-connected components of the special vertices on a restricted set of edge deletions.  Let $m_i$ be the number of edges in the strongly connected component of the $i$th special vertex. The previously best algorithm repeatedly recomputes the strongly-connected components which leads to a running time of $O(\sum_i m_i^2)$.  We present an algorithm with time $O(\sqrt{l}\sum_i m_i^{1.5})$.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7219,Improved Sampling with Applications to Dynamic Graph Algorithms,"We state a new sampling lemma and use it to improve the running time of dynamic graph algorithms.  For the dynamic connectivity problem the previously best randomized algorithm takes expected time $O(\log^3n)$ per update, amortized over $\Omega(m)$ updates.  Using the new sampling lemma, we improve its running time to $O(\log^2n)$. There exists a lower bound in the cell probe model for the time per operation of $\Omega(\log n/\log \log n)$ for this problem. Similarly improved running times are achieved for the following dynamic problems: (1) $O(\log^3 n)$ to maintain the bridges in a graph (the 2-edge connectivity problem); (2) $O(k \log^2n)$ to maintain a minimum spanning tree in a graph with $k$ different weights (the $k$-weight minimum spanning tree problem); (3) $O(\log^2n \log U/\epsilon')$ to maintain a spanning tree whose weight is a $(1+\epsilon')$-approximation of the weight of the minimum spanning tree, where $U$ is the maximum weight in the graph (the $(1+\epsilon')$-approximate minimum spanning tree problem); and (4) $O(\log^2 n)$ to test if the graph is bipartite (the bipartiteness-testing problem).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7220,Kleene algebra with tests and commutativity conditions,"We give an equational proof, using Kleene algebra with tests and commutativity conditions, of the following classical result: every while program can be simulated by a while program with at most one while loop.  The proof illustrates the use of Kleene algebra with extra conditions in program equivalence proofs.  We also show, using a construction of Cohen, that the universal Horn theory of *-continuous Kleene algebras is not finitely axiomatizable.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7221,Metatheory of the $\pi$-Calculus,"Milner's {$\pi$}-calculus is a very influential process algebra in which communication channels are first-class objects.  One of the basic concepts in the language is the transmission of one channel along another.  This leads to immensely powerful programming techniques, which have been used for modelling things from cellular telephones to object-oriented languages. However, the {$\pi$}-calculus lacks many operations, such as  broadcasting a value to many processes, interrupting processes, checkpointing, and even such basics as sequencing and \t{while}-loops in full generality. Adding all useful operations to the {$\pi$}-calculus would make it unusably large and complex.  We thus propose a \e{rule format}, called \metapi. The {$\pi$}-calculus, and a vast range of other calculi treating channels as first-class data, can be expressed with {\metapi} rules. Any operations defined by {\metapi} rules have the same essential theory as the {$\pi$}-calculus.  For example, all such operations respect the appropriate notion of strong bisimulation.   Furthermore, the {$\pi$}-calculus, and all the operations in the previous paragraph, have {\metapi} equivalents.   {\metapi} describes the heart of the {$\pi$}-calculus without prejudice towards the particular communication mechanisms of the calculus, and thus gives a general framework for working with {$\pi$}-like calculi.  Further, it can be argued that the {\metapi} rule format is the most general of its kind, in the sense that any obvious extensions to the format would cause important language properties to be violated.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7222,Fault-tolerant Wait-free Shared Objects,"Wait-free implementations of shared objects tolerate the failure of processes, but not the failure of base objects from which they are implemented. We consider the problem of implementing shared objects that tolerate the failure of both processes and base objects. We identify two classes of object failures: responsive and non-responsive. With responsive failures, a faulty object responds to every operation, but its responses may be incorrect. With non-responsive failures, a faulty object may also ""hang"" without responding. In each class, we define crash, omission, and arbitrary modes of failure. We show that all responsive failure modes can be tolerated. More precisely, for all responsive failure modes F, object types T, and t, we show how to implement a shared object of type T which is t-tolerant for F. Such an object remains correct and wait-free even if up to t base objects fail according to F. In contrast to responsive failures, we show that even the most benign non-responsive failure mode cannot be tolerated. We also show that randomization can be used to circumvent this impossibility result. Graceful degradation is a desirable property of fault-tolerant implementations: the implemented object never fails more severely than the base objects it is derived from, even if all the base objects fail. For several failure modes, we show whether this property can be achieved, and, if so, how.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7223,Compiling Joy Into Silicon: a Formally Verified Compiler forDelay-Insensitive Circuits,"Manually designing delay-insensitive electronic circuits has proven to be difficult in practice.  As an alternative, we designed and implemented a compiler that automatically produces such circuits.  The source language for the compiler is  a language called ""Joy"", which is a simple but complete parallel language with a syntax similar to that of many procedural languages. The compiler's output is a netlist suitable for input into standard place-and-route tools. In this paper, we present the highlights of the compilation algorithm, and the proof of correctness for it.  This is among the first formally verified algorithms for compiling a general language into circuits.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7224,Analysis of Zero Clusters in Multivariate Polynomial Systems,"We consider a cluster of m zeros of a multivariate polynomial system which we interpret as a perturbation of a system with an m-fold zero.  By algebraic techniques, we find a first order correct representation of the primary ideal of the cluster zeros from which we obtain approximations for the individual zeros in the cluster.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7225,Connectionist Networks for Feature Indexing and Object Recognition,"Feature indexing techniques are promising for object recognition because of  their ability to eliminate many feature set matches from consideration without much computation.  This work exploits another property of such techniques.  They have inherently parallel structure and connectionist network formulations are easy to develop. Once indexing has been performed, a voting scheme such as geometric hashing [Lamdan et al. 1990]   can be used to generate object hypotheses in parallel. We give a framework for the connectionist implementation for such indexing and recognition techniques. With sufficient processing elements, recognition can be performed in a small number of time steps. The number of processing elements necessary to achieve peak performance and the fan-in/fan-out required for the processing elements is determined. These techniques have been simulated on a conventional architecture with good results.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7226,PIRANHA - A Hunter of Crashed CORBA Objects,"No matter how carefully a distributed application has been specified,  implemented, and tested, its network objects will crash unexpectedly due to power outages, human lapses, hardware faults, and software bugs. The OMG CORBA standard is becoming popular for interoperability and extensibility. However, fault-tolerance and reliability have not adequately been addressed yet. This paper describes the design and implementation of Piranha --- a CORBA-based, graphical availability management and application monitoring tool. Piranha is unique in that it can be used to increase the availability of many CORBA applications, without complicating their development.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7227,The Object Group Design Pattern,"This paper describes ``Object Group'', an object behavioral pattern for group communication and fault-tolerance in distributed systems. The Object Group pattern allows the implementation of replicated objects, of load sharing, and of efficient multicast communication over protocols like IP-multicast and UDP-broadcast. Application areas of the pattern are fault-tolerant  client/server systems, groupware, and parallel text retrieval engines. Events within an Object Group honor the Virtual Synchrony model. Owing to Virtual Synchrony, the size of an object group can be varied at run-time, while client applications are interacting with the object. A replicated state remains consistent in spite of objects entering and leaving the group dynamically and in spite of failures. The Object Group pattern has been implemented in the Electra and in the Orbix+Isis CORBA Object Request Broker.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7228,Performance of the Horus Asynchronous Group Communication System under HighLoad,"Horus is an asynchronous group communications system designed to support a variety of distributed and parallel applications. This paper reports the performance of continuous $n \times n$ multicasts for a Horus protocol stack that provides fully reliable communication over Ethernet supporting IP multicast. This communication pattern not only is highly demanding from the communications point of view, but also is common for an important class of distributed applications. Specific findings reported in this paper are: providing reliability is expensive under high loss; the cost of providing full reliability is modest compared to that of providing simple reliability; the lack of receivers' resources contributes to high loss; the lack of synchronization among group members also contributes to high loss; and controlling the send rate based on receivers' resource availability is a promising method for maintaining high throughput under high load.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7229,Design and Performance of Active Messages on the IBM SP-2,"This technical report describes the design, implementation, and   evaluation of Active Messages on the IBM SP-2.  The implementation   benchmarked here uses the standard TB2 network adapter firmware but   does not use any IBM software on the Power2 processor.  We assume   familiarity with the concepts underlying Active Messages.  The main   performance characteristics are a one-word message round-trip time   of 51.0 $\mu$s and an asymptotic network bandwidth of 34.3 MB/s.   After presenting selected implementation details, the paper focuses   on detailed performance analysis, including a comparison with IBM's   Message Passing Layer (MPL) and Split-C benchmarks.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7230,A Fault-Tolerant CORBA Name Server,"OMG CORBA applications require a distributed naming service in order to  install and to retrieve object references. High availability of the naming service is important as most CORBA applications need to access it at least once during their lifetime. Unfortunately, the OMG standards do not deal with availability issues, and the naming services of many of the commercially available CORBA object request brokers introduce single points of failure. In this paper we describe the design and implementation of a replicated, highly-available CORBA name server that adheres to the OMG Common Object Services Specification. Our naming service can be replicated at run-time,  while many applications are installing and retrieving object references. We compare our approach with the approaches taken by the ILU, NEO, Orbix, and DOME object request brokers. The performance of our name server is measured for various replication degrees.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7231,Stereo Matching with Non-Linear Diffusion,"One of the central problems in stereo matching (and other image registration tasks) is the selection of optimal window sizes for comparing image regions.  This paper addresses this problem with some novel algorithms based on iteratively diffusing support at different disparity hypotheses, and locally controlling the amount of diffusion based on the current quality of the disparity estimate. It also develops a novel Bayesian estimation technique which significantly outperforms techniques based on area-based matching (SSD) and regular diffusion.  We provide experimental results on both synthetic and real stereo image pairs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7232,Some Notes on Rational Spaces,"Set constraints are  inclusions between expressions denoting  set of ground   terms over a finitely   ranked alphabet $\Sigma$.  Rational   spaces are topological   spaces   obtained as  spaces  of   runs of   topological $\Sigma$-hypergraphs. They  were introduced by  Kozen in   \cite{K95a},   where the topological    structure of  the spaces  of   solutions  to  systems of  set constraints   was given in   terms of   rational spaces.   In this paper  we  continue the investigation of   rational spaces.  We  give a Myhill-Nerode like characterization  of   rational points,  which in turn is  used to re-derive  results about   the  rational  points   of  finitary rational  spaces.    We  define   congruences  on $\Sigma$-hypergraphs, investigate their interplay   with the  Myhill-Nerode characterization,  and finally we  determine   the computational complexity  of some decision problems related  to rational spaces.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7233,Understanding the Message Logging Paradigm for Masking Process Crashes,"Message logging is a popular technique for building systems that can tolerate process crashes and transient channel failures. The technique, which was first developed in the mid-80s, is popular because message-logging protocols are relatively simple and require process replication only when a process fails. Surprisingly, however, very little attention has been given to the formal specification of the consistency property that these protocols implement in order to be able to recover failed processes to a consistent state.  This dissertation presents the first such formal specification. From this specification, the two major classes of message-logging protocols, namely {\em optimistic} and {\em pessimistic}, are characterized. A third and new class of message-logging protocols, called {\em causal}, is introduced. A notion of optimality, based on three important performance metrics, is proposed, and it is shown that optimal implementations of causal message-logging protocols exist. In particular, it is shown that causal message-logging protocols combine the positive aspects of optimistic and pessimistic message logging.  A subclass of causal message-logging protocols, called {\em   family-based logging}, is developed. Family-based logging protocols are optimal and have the additional attractive characteristic that the smaller the maximum number of concurrent failures, the lower their overhead. Furthermore, several compression techniques can be used to reduce this overhead. Finally, it is shown that family-based logging protocols can be implemented in order to take advantage of the different patterns of communication that systems exhibit.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7234,Nuprl as a Generic Theorem Prover,"Logical Frameworks are one way to provide generic theorem provers.  This paper describes another method using loose semantics. In the paper, we explain loose semantics, describes its use in building a programming calculus in the style of Back's refinement calculus, and relates the idea to Logical Framework or General Logic. Viewing Nuprl as a generic theorem prover using loose semantics can be used to describe the inference engine of Nuprl 4. This is the first attempt to explain the system design of Nuprl and relate it to the code.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7235,Trading Consistency for Availability in Distributed Systems,"This paper shows that two important classes of actions, {\em non left commuting}\/ and {\em strongly non commuting}, cannot be executed by concurrent partitions in a system that provides serializable services. This result indicates that there is an inherent limitation to the ability of systems to provide services in a consistent manner during network partitions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7237,Implementing Replicated State Machines Over Partitionable Networks,"This paper presents an implementation of a replicated state machine in asynchronous distributed environments prone to node failures and network partitions. This implementation has two appealing properties: It allows minority partitions to continue providing service for idempotent requests, and it guarantees that progress will be made whenever a majority of replicas can communicate with each other.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7238,Kleene Algebra with Tests: Completeness and Decidability,"Kleene algebras with tests provide a rigorous framework for equational specification and verification.  They have been used successfully in basic safety analysis, source-to-source program transformation, and concurrency control.  We prove the completeness of the equational theory of Kleene algebra with tests and *-continuous Kleene algebra with tests over language-theoretic and relational models.  We also show decidability.  Cohen's reduction of Kleene algebra with hypotheses of the form $r=0$ to Kleene algebra without hypotheses is simplified and extended to handle Kleene algebras with tests.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7239,Adding the Everywhere Operator to Propositional Logic,"Sound and complete modal propositional logic C is presented, in which ""P"" has the interpretation ""P is true in all states"". The interpretation is already known as the Carnapian extension of S5.  A new axiomatization  for C provides two insights.  First, introducing an inference rule ""textual  substitution"" allows seamless integration of the propositional and modal parts of the logic, giving a more practical system for writing formal proofs. Second, the two following approaches to axiomatizing a logic are  shown to be not equivalent: (i) give axiom schemes that denote an infinite number of axioms and  (ii) write a finite number of axioms in terms of propositional variables  and introduce a substitution inference rule.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7240,Optimal Parallel MPEG Encoding,"The Tcl/Tk extension, Tcl/Rivl, provides a suite of commands to manipulate audio and video data. Compressing long sequences of MPEG video requires a significant amount of computation power. This paper outlines a parallel algorithm that achieves real-time MPEG compression without specialized hardware.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7241,A Transparent Light-Weight Group Service,"Virtual synchrony, also known as view synchrony, has proven to be  a powerful paradigm to build   distributed applications. Informally, virtual synchrony provides to   each process group membership information in the form of {\em views}   and guarantees that all processes that install a given view have   delivered the same set of messages from the previous view.   Implementations of virtual synchrony usually require the use of failure   detectors and failure recovery protocols.   There is a range of applications that require the use of a large   number of groups with the same membership. In such applications,   significant performance gains can be attained if these groups share   the resources required to provide virtual synchrony. A service that   maps user groups into instances of a virtually synchronous   implementation is called a Light-Weight Group Service.   This paper proposes a new design for the Light-Weight Group Service   protocols that circumvents some of the limitations of previous   approaches. As a test case, the new protocols were implemented in   the Horus system, although the underlying principles can be applied   to other architectures as well. The paper also presents performance   results from this implementation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7242,MultiMATLAB: MATLAB on Multiple Processors,"MATLAB, a commercial product of The MathWorks, Inc., has become one of the principal languages of desktop scientific computing. A system is described that enables one to run MATLAB conveniently on multiple processors.  Using short, MATLAB-style commands like Eval, Send, Recv, Bcast, Min, and Sum, the user operating within one MATLAB session can start MATLAB processes on other machines and then pass commands and data between between these various processes in a fashion that maintains MATLAB's traditional user-friendliness.   Multi-processor graphics is also supported.  The system currently runs under MPICH on an IBM SP2 or a network of Unix workstations, and extensions are planned to networks of PCs. MultiMATLAB is potentially useful for education in parallel programming, for prototyping parallel algorithms, and for fast and convenient execution of easily parallelizable numerical computations on multiple processors.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7243,State Equivalences for Rectangular Hybrid Automata,"Three natural equivalence relations on the infinite state space of a hybrid automaton are language equivalence, simulation equivalence, and bisimulation equivalence. When one of these equivalence relations has a finite quotient, certain model checking and controller synthesis problems are decidable. When bounds on the number of equivalence classes are obtained, bounds on the running times of model checking and synthesis algorithms follow as corollaries. We characterize the time-abstract versions of these equivalence relations on the state spaces of rectangular hybrid automata (RHA), in which each continuous variable is a clock with bounded drift. These automata are useful for modeling communications protocols with drifting local clocks, and for the conservative approximation of more complex hybrid systems. Of our two main results, one has positive implications for automatic verification, and the other has negative implications. On the positive side, we find that the (finite) language equivalence quotient for RHA is coarser than was previously known by a multiplicative exponential factor. On the negative side, we show that simulation equivalence for RHA is equality (which obviously has an infinite quotient). Our main positive result is established by analyzing a subclass of timed automata, called one-sided timed automata (OSA), for which the language equivalence quotient is coarser than for the class all of timed automata. An exact characterization of language equivalence for OSA requires a distinction between synchronous and asynchronous definitions of (bi)simulation: if time actions are silent, then the induced quotient for OSA is coarser than if time actions are visible.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7244,SCOM: A Security and Privacy Layer for Horus,"A large number of distributed applications will soon be implemented for which the inclusion of some form of security will be important. While the programmers who design these applications may have expertise in the application area, they most likely will not be experts in the areas of distributed computing or security. In both of these areas, a firm knowledge of the subject is necessary in order to avoid subtle, hard to detect flaws in design. The Horus system was created to enable the design and implementation of distributed applications. The ultimate goal of this work is to allow for the implementation of efficient distributed applications while hiding many of the problems associated with the design of such applications from the applications programmer. In this paper, we describe work we have done to facilitate the implementation of secure distributed applications on top of the Horus system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7245,CLP(SC):  Implementation and Efficiency Considerations,"CLP(SC) is a constraint logic programming language over set constraints proposed by Kozen [7].  In this paper, we describe a complete C++ implementation of CLP(SC).  We describe the data structures used to represent systems of set constraints and an efficient algorithm, a modification of one given in [7], for unifying constraints.  In addition, we investigate two further techniques for increasing efficiency: keeping track of variable equalities and doing PROLOG-style unification.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7246,A Graphical Interface for CHIP,CHIP (Cornell Hypothetical Instructional Processor) [BBDS83] is a computer system designed as an educational tool for teaching undergraduate courses in operating system and machine architecture. This document describes CHIP's graphical interface and covers in a tutorial how the interface is used to debug and execute CHIP programs.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7247,Randomization and Failure Detection: A Hybrid Approach to SolveConsensus,"We present a Consensus algorithm that combines randomization and unreliable failure detection, two well-known techniques for solving Consensus in asynchronous systems with crash failures. This hybrid algorithm combines advantages from both approaches: it guarantees deterministic termination if the failure detector is accurate, and probabilistic termination otherwise. In executions with no failures or failure detector mistakes, the most likely ones in practice, Consensus is reached in only two asynchronous rounds.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7248,The Warwick Framework: A Container Architecture for Aggregating Sets ofMetadata,"We describe a result of the June 1996 Warwick Metadata II Workshop. This Warwick Framework is a container architecture for aggregating logically, and perhaps physically, distinct packages of metadata. This architecture allows separate administration and access to metadata packages, provides for varying syntax in each package in conformance with semantic requirements, and it promotes interoperability and extensibility by allowing tools and agents to selectively access and manipulate individual packages and ignore others.  At the conclusion of the paper we propose implementations of the Framework in HTML, MIME, SGML, and distributed objects.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7249,An Object Recognition System for Complex Imagery that Models theProbability of a False Positive,"This paper describes an object recognition system for use in  complex imagery that can perform recognition adaptively by setting the matching threshold such that the probability of a false positive is low.  In order to accurately model small, irregularly shaped objects, we represent the objects using dense sets of edge pixels with associated local orientations.  Three-dimensional objects are modeled by a set of two-dimensional views of the object.  We allow translation, rotation, and scaling of the views to approximate full three-dimensional motion of the object.  We use a version of the Hausdorff measure to determine which positions of an object model are good matches to an image.  These positions are determined efficiently through the examination of a hierarchical cell decomposition of the transformation space, which allows large volumes of the space to be pruned quickly.  Additional techniques are used to decrease the computation time of the method when matching is performed against a catalog of object models.  We then describe a new model of the matching process that allows the probability of a false positive to be estimated efficiently at run-time. Finally, we give results of this system recognizing object in infrared and intensity images.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7250,The Networked Computer Science Technical Report Library,"The Networked Computer Science Technical Report Library (NCSTRL) is a distributed digital library of research results from computer science departments and laboratories in the USA and abroad.  NCSTRL benefits readers, authors, and departments. Researchers throughout the world can use familiar Internet tools (the World Wide Web) to search for, browse, read, and download technical reports from participating institutions.  Authors benefit by reaching a wider audience.  Departments gain a clean, effective management system for distributing their technical reports and eliminate much of their current copying and mailing charges.  This article describes the design of NCSTRL, its historical basis in earlier work, and the expected course of the development.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7251,"Matrix Behaviour, Unitary Reducibility, and Hadamard Products","The question investigated here is: if two matrices $A$ and $B$ in $\CNN$ have identical behaviour in a unitarily invariant norm $\norm{\cdot}$, \ie,\ $\norm{p(A)} = \norm{p(B)}$ for every polynomial $p$ with complex   coefficients, what properties do $A$ and $B$ have in common?  After a   preliminary result about eigenvalues, it is shown with a mildly restrictive assumption that if $A$ is unitarily reducible, so is $B$.  A theorem is proved about Hadamard products of the form $H\circ\invt{H}$, where $H$ is Hermitian positive definite.  Finally, an example is produced where $A$ and $B$ have identical behaviour in the Frobenius norm, but are not related to each other in any simple way.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7252,Optimal Control Dependence Computation and the Roman Chariots Problem,"The control dependence relation plays a fundamental role in program restructuring and optimization. The usual representation of this relation is the  control dependence graph (CDG), but the size of the CDG can grow quadratically with the input program, even for structured programs.  In this paper, we introduce the augmented postdominator tree, APT, a data structure which can be constructed in space and time proportional to the size of the program, and which supports enumeration of a number of useful control-dependence sets in time proportional to their size. Therefore,  APT provides an  optimal representation of control dependence. Specifically, the  APT data structure supports enumeration of the set cd(e), which is the set of statements control dependent on control-flow edge e, of the set conds(w), which is the set of edges on which statement w is dependent, and of the set cdeq(w), which is the set of statements having the same control dependences as w. Technically, APT can be viewed as a factored representation of the CDG where queries are processed using an approach known as filtered search.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7253,The Complexity of Kleene Algebra with Tests,"Kleene algebras with tests provide a natural framework for equational specification and verification.  Kleene algebras with tests and related systems have been used successfully in basic safety analysis, source-to-source program transformation, and concurrency control.  The equational theory of Kleene algebras with tests has been shown to be decidable in at most exponential time by an efficient reduction to Propositional Dynamic Logic.  In this paper we prove that the theory is PSPACE-complete.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7254,Supporting Broad Internet Access to TACOMA,"Any provider of software is faced with a problem if that software must be installed on autonomous sites of a large network.  This paper reports experiences in addressing this network-software installation- problem for TACOMA, an internet agent infrastructure.  The paper describes a WWW-based scheme and an email-based scheme for avoiding software installation at all sites that might launch TACOMA agents.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7255,Cryptographic Support for Fault-Tolerant Distributed Computing,"In an open distributed system, agents comprising an application must not only survive (possibly malicious) failures of the hosts they visit, but they must also be resilient to the potentially hostile actions of other hosts.  In particular, faulty hosts that are not visited by agents can confound a naive replica-management scheme by spoofing.  Cryptographic protocols to solve this problem are summarized, as well as some experiments that show how replication can actually speed up some applications.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7256,The Theory of Rectangular Hybrid Automata,"A {\em hybrid automaton\/}  consists of a finite automaton interacting with a dynamical system. Hybrid automata are used to model embedded controllers and other systems that consist of interacting discrete and continuous components. A hybrid automaton is {\em rectangular\/} if each of its continuous variables~$x$ satisfies a nondeterministic differential equation of the form $a\le\frac{dx}{dt}\le b$, where $a$ and~$b$ are rational constants. Rectangular hybrid automata are particularly useful for the analysis of communication protocols in which local clocks have bounded drift, and for the conservative approximation of systems with more complex continuous behavior. We examine several verification problems on the class of rectangular hybrid automata, including reachability, temporal logic model checking, and controller synthesis. Both dense-time and discrete-time models are considered. We identify subclasses of rectangular hybrid automata for which these problems are decidable and give complexity analyses. An investigation of the structural properties of rectangular hybrid automata is undertaken. One method for proving the decidability of verification problems on infinite-state systems is to find finite quotient systems on which analysis can proceed. Three state-space equivalence relations with strong connections to temporal logic are bisimilarity, similarity, and language equivalence. We characterize the quotient spaces of rectangular hybrid automata with respect to these equivalence relations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7257,A calculational proof of Andrews's challenge,This space is left deliberately non-blank,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7258,Formal versus semiformal proof in teaching predicate logic,This space is left deliberately non-blank,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7259,View Synthesis Using Stereo Vision,"This thesis investigates the use of stereo vision for the application of view synthesis.  View synthesis --- the problem of creating images of a scene as it would appear from novel viewpoints --- has traditionally been approached using methods from computer graphics.  These methods, however, suffer from low rendering speed, limited achievable realism, and, most severely, their dependence on a global scene model, which typically needs to be constructed manually.     In this thesis, we present a new approach to view synthesis that avoids the above problems by synthesizing new views from existing images of a scene.  Using an image-based representation of scene geometry computed by stereo vision methods, a global model can be avoided, and realistic new views can be synthesized quickly using image warping.     The new application of stereo for view synthesis makes it necessary to re-evaluate the requirements on stereo algorithms.  We compare view synthesis to several traditional applications of stereo, and conclude that stereo vision is better suited for view synthesis than for applications requiring explicit 3D reconstruction.  We also discuss ways of dealing with partially occluded regions of unknown depth and with completely occluded regions of unknown texture, and present experiments demonstrating that it is possible to efficiently synthesize realistic new views even from inaccurate and incomplete depth information.     This thesis also contributes several novel stereo algorithms that are motivated by the specific requirements imposed by view synthesis. We introduce a new evidence measure based on intensity gradients for establishing correspondences between images.  This measure combines the notions of similarity and confidence, and allows stable matching and easy assigning of canonical depth interpretations in image regions of insufficient information.  We also present new diffusion-based stereo algorithms that are motivated by the need to correctly recover object boundaries.  In particular, we develop a novel Bayesian estimation technique that significantly outperforms area-based algorithms using fixed-sized windows.  We provide experimental results for all algorithms on both synthetic and real images.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7260,Using Group Communication Technology to Implement a Reliable andScalable Distributed IN Coprocessor,"In this paper we explore the use of group communication technology, developed in the Horus project to implement a reliable and scalable distributed IN coprocessor. The proposed implementation can handle up to 20,000 calls per second with 12 computing nodes, can tolerate a single node failure or recovery, and can recover from periods of overload.  Our work suggests that group communication technology can bring substantial benefits, including scalability, fault-tolerance, and real-time responsiveness to the most demanding telecommunications applications.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7261,Probabilistic Broadcast,"We present a class of scalable and probabilisticly reliable communication protocols.  The protocols are based on a probabilistic system model and thus their properties tend to be probabilistic in nature.  The protocols are scalable in two senses.  First, the message costs and latencies of the protocols grow slowly with the system size.  Second, the reliability of the protocols, expressed in terms of the probability of a failed run of a protocol, approaches 0 exponentially fast as the number of processes is increased.  This scalable reliability is achieved through a form of gossip protocol which is strongly self-stabilizing in a sense similar, although not identical to, the notion of self stabilizing systems proposed by Dijkstra.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7262,The Geobucket Data Structure for Polynomials,"The {\em geobucket\/} data structure is suitable as an intermediate representation of polynomials for performing large numbers of polynomial additions and lead term extractions.  A sum involving {$N$} terms has worst-case running time {$O(N\log{N})$} both online and offline, matching or surpassing the obvious/standard alternatives.  This makes the geobucket a good choice for performing the reduction step of \grobner\ basis computations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7263,Failure Detectors in Omission Failure Environments,"We study failure detectors in an asynchronous environment that admits message omission failures.  In such environments, processes may fail by crashing, but may also {\em disconnect\/} from each other. We adapt Chandra and Toueg's definitions of failure detection completeness and accuracy to the omissions failure model, and define a weak failure detector less than or greater than W(om) that allows any majority of the processes that become connected to reach a Consensus decision, despite any number of transient communication failures in their past. We provide a protocol that solves the Consensus problem in this model whenever a majority of the processes become connected, regardless of past omissions. Moreover, in our protocol it is not necessary to save and repeatedly send all past messages, which makes it more efficient than previous protocols in this model.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7264,Solving Problems in the Presence of Process Crashes and Lossy Links,"We study the effect of link failures on the solvability of problems in asynchronous systems that are subject to process crashes: given a problem that can be solved in a system with process crashes and reliable links, is the problem solvable even if links are lossy? We answer this question for two types of lossy links, and show that the answer depends on the maximum number of processes that may crash and the nature of the problem to be solved. In particular, we prove that the answer is positive if fewer than half of the processes may crash or if the problem specification does not refer to the state of processes that crash. However, in general, the answer is negative even if each link can loose only a finite number of messages.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7265,The Hierarchical Daisy Architecture for Causal Delivery,"In this paper, we propose the {\em hierarchical daisy architecture}\/, which provides causal delivery of messages sent to any subset of processes.  The architecture provides fault tolerance and maintains the amount of control information within a reasonable size.  It divides processes into {\em logical}\/ groups.  Messages inside a logical group are sent directly, while messages that need to cross logical groups' bounderies are forwarded by servers.  We proof the correctness of the daisy architecture and discuss possible optimizations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7266,A Dynamic Light-Weight Group Service,"The virtual synchrony model for group communication has proven to be a    powerful paradigm for building   distributed applications.  Implementations of virtual synchrony   usually require the use of failure detectors and failure recovery   protocols. In applications that require the use of a large number of   groups, significant performance gains can be attained if these groups   share the resources required to provide virtual synchrony. A service   that maps user groups onto instances of a virtually synchronous   implementation is called a Light-Weight Group Service.     This paper proposes a new design for the Light-Weight Group   protocols that enables the usage of this service in a transparent and   dynamic   manner. As a test case, the new design was implemented in the   Horus system, although the underlying principles can be applied to   other architectures as well. The paper also presents performance   results from this implementation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7267,Dynamic Light-Weight Groups,"The virtual synchrony model for group communication has proven to be a powerful paradigm for building distributed applications. In   applications that require the use of a large number of groups,   significant performance gains can be attained if these groups share   the resources required to provide virtual synchrony. A service that   maps user groups onto instances of a virtually synchronous   implementation is called a Light-Weight Group Service.  This paper discusses the usage of Light-Weight Group protocols in   dynamic environments, where mappings cannot be defined a priori and   may change over time. We show that it is possible to establish   mappings that promote sharing and, at the same time, minimize   interference. These mappings can be established in an automated   manner, using heuristics applied locally at each node. Experiments   using an implementation in the Horus system show that significant   performance improvements can be achieved with this approach.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7268,Optimizing Layered Communication Protocols,"Layering of protocols offers several well-known advantages, but typically leads to performance inefficiencies.  We present a model for layering, and point out where the performance problems occur in stacks of layers using this model.  We then investigate the common execution paths in these stacks and how to identify them.  These paths are optimized using three techniques: optimizing the computation, compressing protocol headers, and delaying processing.  All of the optimizations can be automated in a compiler with the help of minor annotations by the protocol designer.  We describe the performance that we obtain after implementing the optimizations by hand on a full-scale system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7269,Automated Analysis of Fault-Tolerance in Distributed Systems,"This paper describes a method for automated analysis of fault-tolerance properties of distributed systems.  The framework is based on ideas from stream-processing semantics for networks of processes and abstract interpretation of programs.  The stream-processing model provides modularity and a clean algorithmic basis for the analysis.  For efficiency, all aspects of a system's behavior can be approximated in the analysis, including: values (the data transmitted in messages), multiplicities (the number of times each value is sent), and orderings (the order in which values are sent).  The approximation mechanisms are based on abstract interpretation, symbolic computation, and partial orders.  Approximations are essential to support abstraction from aspects of a system's behavior that do not directly impact its fault-tolerance.  Another feature of our approach is that perturbations due to failures can be represented explicitly.  This allows fault-tolerance requirements to be expressed as bounds on the acceptable perturbations to a system's behavior as a consequence of certain failures.  This facilitates separation of fault-tolerance from other correctness requirements and sometimes enables more efficient analysis. The analysis has been implemented in a prototype tool.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7270,Condition Numbers of Random Triangular Matrices,"\begin{abstract} Let $L_n$ be a lower triangular matrix of dimension $n$ each of whose nonzero entries is an independent $N(0,1)$ variable, \ie, a random normal variable of mean $0$ and variance $1$. It is shown that $\kn$, the 2-norm condition number of $L_n$, satisfies \begin{equation*}  \sqrt[n]{\kn} \rightarrow 2 \:\:\: \text{\it almost surely} \end{equation*} as $n\rightarrow\infty$. This exponential growth of $\kn$ with $n$ is in striking contrast to the linear growth of the condition numbers of random {\it dense} matrices with $n$ that is already known.  This phenomenon is not due to small entries on the diagonal (\ie, small eigenvalues) of $L_n$. Indeed, it is shown that a lower triangular matrix  of dimension $n$ whose diagonal entries are fixed at $1$ with the subdiagonal entries taken as independent $N(0,1)$ variables is also exponentially ill-conditioned with the 2-norm condition number $\kn$ of such a matrix satisfying \begin{equation*}  \sqrt[n]{\kn}\rightarrow 1.305683410\ldots \:\:\:\text{\it almost surely} \end{equation*} as $n\rightarrow\infty$. A similar pair of results about complex random triangular matrices is established.  The results for real triangular matrices are generalized to triangular matrices with entries from any symmetric, strictly stable distribution.  \end{abstract}",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7271,Load Balancing Schemes for High-Throughput Distributed Fault-TolerantServers,"Clusters of workstations, connected by a fast network, are emerging as a viable architecture for building high-throughput fault-tolerant servers.  This type of architecture is more scaleable and more cost-effective than a tightly coupled multiprocessor and may achieve as good a throughput.  Two of the most important issues that a designer of such clustered servers must consider in order for the system to meet its fault-tolerance and throughput goals are the load balancing scheme and the fault-tolerance scheme that the system will use. This paper explores several combinations of such fault tolerance and load-balancing schemes, and compare their impact on the maximum throughout achievable by the system, and on its survivability.  In particular, we show that a fault-tolerance scheme may have an effect on the throughput of the system, while a load-balancing scheme may affect the ability of the system to override failures.  We study the scaleability of the different schemes under different loads and failure conditions. The validation of our schemes is done using data taken from emulations of an intelligent networking coprocessor of a telephone switch, which follows, for example, the SS7 signaling protocol.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7272,The Case for Enhanced Abstract Data Types,"Support for complex data in object-relational  database systems is based on abstract data types (ADTs). We argue that the current ADT approach inhibits the performance of queries that involve expensive operations on data types. Instead, we propose the Enhanced Abstract Data Type (E-ADT) paradigm, which treats operations on data types as declarative expressions that can be optimized. In this paper, we describe the E-ADT paradigm and PREDATOR, an object-relational database system based on E-ADTs. An E-ADT is an abstract data type enhanced with query optimization. Not only does an E-ADT provide operations (or methods) that can be used in SQL queries, it also supports internal interfaces that can be invoked to optimize these operations. This added functionality is provided without compromising the modularity of data types and the extensibility of the type system. Building such a database system requires fundamental changes in the architecture of the query processing engine; we present the system-level interfaces of PREDATOR that support E-ADTs, and describe the internal design details. Initial performance results from supporting image, time-series, and audio data as E-ADTs demonstrate an order of magnitude in performance improvements over the current ADT approach. Further, we describe how the E-ADT paradigm enables future research that can improve several aspects of object-relational query optimization. Consequently, we make the case that next-generation object-relational database systems should be based on E-ADT technology.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7273,Building a Virtually Fault-Tolerant System,"All schemes for implementing fault-tolerance involve some form of replication.  Replicas are assumed to fail independently, and each replica performs the same computation.  Replicas may execute in parallel or, in the case of primary-backup protocols, in response to failures. Replication only works, however, if replicas are coordinated.  Each replica must receive the same inputs in the same order, and each must be deterministic in its response to these inputs. The key engineering issue that the designer of a fault-tolerant computing system must address is deciding where in the system to implement replica coordination. Some of the alternatives include implementing replica coordination in the processor or network hardware, in the operating system, or in the applications software. A new solution is to implement replica coordination by augmenting the hypervisor of a virtual-machine manager and coordinating a primary virtual machine with its backup. This hypervisor-based fault-tolerance is transparent to the operating system and the applications programs executing above the hypervisor. In addition, this selection allows a single hypervisor design to be used for all processors in an architectural family. In this dissertation, we describe the protocols to implement hypervisor-based fault-tolerance.  To assess the practicality of the approach, we constructed a prototype system for HP's PA-RISC architecture.  The prototype hypervisor supports a single HP-UX virtual machine and implements the replica-coordination protocols.  The prototype hypervisor has been instrumented to measure the overhead of all hypervisor-based activity.  We have measured the performance of CPU-intensive workloads and disk I/O intensive workloads in this architecture and have built models allowing us to predict the performance for some alternative architectures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7274,The Maestro Group Manager: A Structuring Tool For Applications WithMultiple Quality of Service Requirements,"{\em Maestro} is a tool for managing sets of protocol stacks that satisfy varied quality of service or security requirements. Intended primarily for multimedia groupware settings, it permits a single application to efficiently operate over multiple side-by-side protocol stacks, each specialized to a different communication stream. Maestro can also be used to manage other sorts of external protocol stacks, for example to orchestrate connection setups that require coordinated actions at all endpoints in a multicast group. Our tools are fault-tolerant and secure; they can safely distribute session keys or handle delicate synchronization tasks that would otherwise complicate the managed stacks and potentially interfere with their quality-of-service objectives. Moreover, Maestro can automatically track subgroup membership on the basis of ``properties'', facilitating its use by developers who prefer not to work directly with multicast communication interfaces.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7275,Incorporating Memory Management into User-Level Network Interfaces,"User-level network interfaces allow applications direct access to the network without operating system intervention on every send and receive. Messages are transferred directly to and from user-space by the network interface while observing the traditional protection boundaries between processes. Current user-level network interfaces limit this message transfer to a per-process region of permanently-pinned physical memory to allow safe DMA. This approach is inflexible in that it requires data to be copied into and out of this memory region, and does not scale to a large number of processes. This paper presents an extension to the U-Net user-level network architecture (U-Net/MM) allowing messages to be transferred directly to and from any part of an application's address space. This is achieved by integrating a translation look-aside buffer into the network interface and coordinating its operation with the operating system's virtual memory subsystem. This mechanism allows network buffer pages to be pinned and unpinned dynamically. Two implementations of U-Net/MM are described, demonstrating that existing commodity hardware and commercial operating systems can efficiently support the architecture.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7276,Word Sense Disambiguation Using Numerical Constraint Satisfaction,"In this paper we present a description and evaluation of a word sense disambiguation mechanism that is an extension of the work by Ide and Veronis. The mechanism's underlying approach is a numerical constraint satisfaction algorithm applied to the network built using an on-line dictionary.  In this work we aim to duplicate the original results and extend the method to large-scale applications. To determine the scalability of the approach, we evaluate the mechanism on 20 ambiguous words taken in their contexts of different size from the Brown corpus.  We offer a discussion of encountered difficulties and describe several possible directions that can be investigated to improve the mechanism's performance and scalability.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7277,Formal Justification of Underspecification for S5,"We formalize the notion of underspecification as a means of  avoiding problems with partial functions in modal logic S5 and some semantically related logics. For these logics, underspecification respects validity, so incorporating it into their semantics leaves their classes of valid formulae unchanged.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7278,"Specification, Composition, and Automated Verification of LayeredCommunication Protocols","Horus is a general-purpose layered message-passing system for distributed programming. A programmer of a distributed application can select protocol layers from among those provided by Horus and arrange these in a stack, thereby creating a custom-built message-passing protocol with strong (or not so strong) properties underneath the application. For the full value of Horus's modularity to be exploited, an application programmer must be able to choose just the layers and stacking order that will provide the desired properties.  A programmer who is limited to only a few ``tried-and-true'' alternatives may end up paying a performance cost (such as excessive synchronization messages) for unnecessary properties, simply because he or she cannot confidently build a less costly stack underneath a given application. This dissertation describes a formal method that supports the engineering of new Horus protocol stacks by precisely specifying and mechanically verifying communication properties of these stacks.  Various communication properties can be described in English, but are also described succinctly in a mathematical model (the Temporal Logic of Actions) that supports sound reasoning about whether the properties are satisfied by an implementation.  Each protocol layer guarantees various properties at its interfaces, depending on what assumed properties its neighbors provide to it. Relatively straightforward formal reasoning can then show that certain properties will be provided to the applications at the top of the stack.  This method of reasoning about protocol stacks can efficiently be automated so that it can be used by practitioners.  A prototype of the verifier has been implemented in Java and published on the World Wide Web.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7279,On the Complexity of Reasoning in Kleene Algebra,"We study the complexity of reasoning in Kleene algebra and *-continuous Kleene algebra in the presence of extra equational assumptions $E$; that is, the complexity of deciding the validity of universal Horn formulas $E\imp s=t$, where $E$ is a finite set of equations.  We obtain various levels of complexity based on the form of the assumptions $E$.  Our main results are: for *-continuous Kleene algebra, \begin{itemize} \item if $E$ contains only commutativity assumptions $pq=qp$, the problem is $\Pi_1^0$-complete; \item if $E$ contains only monoid equations, the problem is $\Pi_2^0$-complete; \item for arbitrary equations $E$, the problem is $\Pi_1^1$-complete. \end{itemize} The last problem is the universal Horn theory of the *-continuous Kleene algebras.  This resolves an open question of Kozen (1994).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7280,Unified framework for sparse and dense SPMD code generation(preliminary report),We describe a novel approach to sparse {\em and} dense SPMD code generation: we view arrays (sparse and dense) as distributed relations and parallel loop execution as distributed relational query evaluation.  This approach provides for a uniform treatment of arbitrary sparse matrix formats and partitioning information formats.  The relational algebra view of computation and communication sets provides new opportunities for the optimization of node program performance and the reduction of communucation set generation and index translation overhead.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7281,Term Weighting Revisited,"Term weighting is an essential part of the modern information retrieval systems. Out of the three main components of a term weighting strategy --- term frequency, inverse document frequency, and document length normalization --- the term frequency factor has been investigated recently by researchers. In this work, we study the inverse document frequency, and document length normalization components of term weights. We observe that a document length normalization scheme that retrieves documents of all lengths with similar chances as their likelihood of relevance will outperform another scheme which retrieves documents with chances very different from their likelihood of relevance. We present {\em pivoted normalization\/}, a technique that can be used to modify normalization functions to reduce the gap between the relevance and the retrieval probabilities. We present two new normalization functions --- {\em pivoted unique normalization\/} and {\em pivoted byte size normalization}, both of which yield significant improvements over the previous state of the art normalization functions. When optical character recognition is used to create large information bases, term weighting schemes can be highly sensitive to the errors in the input text, introduced by the OCR process. This work examines the effects of the well known {\em cosine normalization\/} method in the presence of OCR errors, and proposes a new, more robust, normalization method. Experiments show that the new scheme is less sensitive to OCR errors and facilitates the use of more diverse basic weighting schemes. This study also explains why the use of cosine normalization in presence of the inverse document frequency factor is not advisable in large document collections. When a user types a natural language query for an IR system, certain keywords in the query are more pertinent to the user's information need than others. Most modern IR systems incorporate these distinctions by using an inverse document frequency ({\em idf\/}) factor in term weighting. Preliminary experiments show that the usefulness of an {\em idf\/} type function is high at low ranks. We observe that the main reason for this effect is the widened gap between the weights of the rare terms and the non-rare query terms. The standard {\em idf\/} function works very well across query sets. Experiments show that there is room for improvement in the {\em idf\/} function. Further studies are needed to discover a better replacement for the standard {\em idf\/} function.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7282,A Relational Approach to the Compilation of Sparse Matrix Programs,We present a relational algebra based framework for compiling efficient sparse matrix code from dense DO-ANY loops and a specification of the representation of the sparse matrix. We present experimental data that demonstrates that the code generated by our compiler achieves performance competitive with that of hand-written codes for important computational kernels.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7283,A Method and Tool for Analyzing Fault-Tolerance in Systems,"As computers are integrated into systems that have stringent fault-tolerance requirements, there is a growing need for techniques to establish that these systems actually satisfy those requirements. Informal arguments do not supply the desired level of assurance for critical systems.  This dissertation presents a rigorous, automated approach to analyzing distributed systems, with a focus on checking fault-tolerance requirements, and describes a prototype implementation of the analysis.  The analysis is a novel hybrid of ideas from stream-processing semantics of networks of processes, abstract interpretation of programs, and symbolic computation.  The underlying principles of the analysis method are general, but specialized techniques---such as the use of perturbations to represent changes to normal behavior caused by failures---are developed to deal efficiently with the types of systems and requirements that arise in establishing fault-tolerance.  The method is illustrated with three examples: the Oral Messages algorithm for Byzantine Agreement, due to Lamport, Shostak and Pease, a standard protocol for FIFO reliable broadcast, and a (subtly) flawed protocol for fault-tolerant moving agents.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7284,"Nagging: A General, Fault-Tolerant Approach to Parallel Search Pruning","For some interesting problems, all known algorithms rely, to some degree, on exhaustive search.  Since combinatorial search cannot scale to large problem instances, no general-case solutions to these problems are available.  However, because solutions to many of these problems have practical value, various software techniques have been developed to avoid or reduce search in a number of useful, special cases.  Unfortunately, different software techniques exhibit varying performance advantages from one problem instance to the next; given a particular problem instance, it is not always clear which approach would be most effective. This paper introduces a parallel search-pruning technique called nagging which is means of coordinating the activity of a number of different search procedures.  Under this technique, search-based problem solvers compete in parallel to solve parts of a particular problem instance.  Each problem solver contributes to advancing the search wherever it is the most effective. Nagging's intrinsic fault tolerance and scalability make it particularly suitable for commonly available, low-bandwidth, high-latency distributed computing environments.  It is sufficiently general to be effective in a number of domains.  A prototype implementation has been developed for first-order theorem proving, a domain both responsive to a very simple nagging model and amenable to many refinements of this model.  Nagging is evaluated by testing this implementation on a suite of well-known theorem proving problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7285,Evaluating the Performance Limitations of MPMD Communication,"The MPMD approach for parallel computing is attractive for  programmers who seek fast development cycles, high code re-use, and modular programming, or whose applications exhibit irregular computation loads and communication patterns. Remote method invocation is widely adopted as the communication abstraction for crossing address space boundaries. However, the communication overheads of existing RMI-based systems are usually an order of magnitude higher than those found in highly tuned SPMD systems. This problem has thus far limited the appeal of high-level programming languages based on MPMD models in the parallel computing community. This paper investigates the fundamental limitations of MPMD communication using a case study of two parallel programming languages, Compositional C++ (CC++) and Split-C, that provide support for a global name space. To establish a common comparison basis, a new implementation of CC++ was developed to use Active Messages and a native threads package. A series of micro-benchmarks compares the communication performance of this new CC++ implementation with Split-C on an IBM SP multi-computer. The impact of these costs on three applications is also evaluated and suggests that MPMD communication can be used effectively in many high-performance parallel applications.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7286,Heartbeat: A Timeout-Free Failure Detector for Quiescent ReliableCommunication,"We study the problem of achieving reliable communication with quiescent algorithms (i.e., algorithms that eventually stop sending messages) in asynchronous systems with process crashes and lossy links. We first show that it is impossible to solve this problem without failure detectors. We then show how to solve it using a new failure detector, called heartbeat. In contrast to previous failure detectors that have been used to circumvent impossibility results, the heartbeat failure detector is implementable, and its implementation does not use timeouts. These results have wide applicability: they can be used to transform many existing algorithms that tolerate only process crashes into quiescent algorithms that tolerate both process crashes and message losses. This can be applied to consensus, atomic broadcast, k-set agreement, atomic commitment, etc. The heartbeat failure detector is novel: it is implementable without timeouts and it does not output lists of suspects as typical failure detectors do. If we restrict failure detectors to output only lists of suspects, quiescent reliable communication requires less than or greater than P [ACT97a], which is not implementable. Combined with the results of this paper, this shows that traditional failure detectors that output only lists of suspects have fundamental limitations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7287,Quiescent Reliable Communication and Quiescent Consensus inPartitionable Networks,"We consider partitionable networks with process crashes and lossy links, and focus on the problems of reliable communication and consensus for such networks.  For both problems we seek algorithms that are quiescent, i.e., algorithms that eventually stop sending messages.  We first tackle the problem of reliable communication for partitionable networks by extending the results of [ACT97a]. In particular, we generalize the specification of the heartbeat failure detector HB, show how to implement it, and show how to use it to achieve quiescent reliable communication.  We then turn our attention to the problem of consensus for partitionable networks. We first show that, even though this problem can be solved using a natural extension of less than or greater than S, such solutions are not quiescent --- in other words, less than or greater than S alone is not sufficient to achieve quiescent consensus in partitionable networks.  We then solve this problem using less than or greater than S and the quiescent reliable communication primitives that we developed in the first part of the paper. Our model of failure detectors for partitionable networks, a natural extension of the model in [CT96], is also a contribution of this paper.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7288,Compiling Parallel Sparse Code for User-Defined Data Structures,We describe how various sparse matrix and distribution formats can be handled using the {\em relational} approach to sparse matrix code compilation.  This approach allows for the development of compilation techniques that are independent of the storage formats by viewing the data structures as relations and abstracting the implementation details as access methods.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7289,A Theory of Interleavers,"An interleaver is a hardware device commonly used in conjunction with error correcting codes to counteract the effect of burst errors.  Interleavers are in widespread use and much is known about them from an engineering standpoint. In this paper we propose a mathematical model that provides a rigorous foundation for the theoretical study of interleavers. The model captures precisely such notions as block and convolutional interleavers, spread, periodicity, causality, latency, and memory usage.  Using this model, we derive several optimality results on the latency and memory usage of interleavers.  We describe a family of block interleavers and show that they are optimal with respect to latency among all block interleavers with a given spread.  We also give tight upper and lower bounds on the memory requirements of interleavers.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7290,A Relational Approach to the Automatic Generation of Sequential SparseMatrix Codes,"This thesis presents techniques for automatically generating sparse codes from dense matrix algorithms through a process called \emph{sparse compilation}. We will start by recognizing that sparse computations are ubiquitous to scientific computation, that these codes are difficult to write by hand, and that they are difficult for conventional compilers to optimize. We will present the sparse compiler as an alternative to writing these codes by hand or using sparse libraries.   We will show how many aspects of sparse compilation can be modeled in terms of relational database concepts, These include the following: queries to express sparse computations, relations to model sparse matrices, the join operation to model simultaneous efficient access of sparse matrices. Using this model, the problem of sparse compilation can be seen as an instance of the query optimization problem.   We will discuss two basic strategies for sparse compilation based upon this relational approach. One strategy is targeted towards algorithms that can be described using inner join queries, which include matrix-vector multiplication and matrix-matrix multiplication. This approach is the one that we have currently implemented. The other can handle a larger class of dependence-free matrix algorithms. Although it is more general, the latter approach introduced does not generate as efficient code for some problems as the former approach. We will show that these two approaches are grounded in properties of the relational algebra and draw connections with previous work that has been described in the database literature. We also discuss how conventional dense optimizations and fill can be handled within the overall relational framework.  We will discuss the Bernoulli Sparse Compiler and use experimental results to show that this system is able to generate sparse implementations from non-trivial dense matrix algorithms that are as efficient as hand-written codes. In addition, this compiler provides a novel mechanism that allows the user to extend its repertoire of sparse matrix storage formats. Thus, the user is not only able to choose the data structures for storing the sparse matrices, but to describe these data structures as well.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7291,Towards Fault-tolerant and Secure Agentry,"Processes that roam a network--agents--present new technical challenges.  Two are discussed here.  The first problem, which arises in connection with implementing fault-tolerant agents, concerns how a voter authenticates the agents comprising its electorate.  The second is to characterize security policies that are enforceable as well as approaches for enforcing those policies.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7292,Formal Reasoning about Communication Systems I: Embedding ML into TypeTheory.,We present a semantically correct embedding of a subset of the Ocaml programming language into the type theory of NuPRL. The subset is that needed to build the Ensemble group communication system. We describe the    essential methodologies for representing language constructs by    type-theoretical expressions. Tactics representing derived inference rules    and a programming logic for these constructs will be discussed as well as    algorithms for translating an Ocaml-program into NuPRL-objects and vice    versa. The formal representations and the translation algorithms will serve  as the foundation for the development of automated reasoning tools for the    verification and optimization of a group communication systems.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7293,Building Adaptive Systems Using Ensemble,"Trends in networking and distributed computing are creating a new generation  of applications that must adapt as the environment within which they execute changes.  Examples of adaptations include switching protocols to overcome a security exposure or failure mode seen only in certain setting, changing data rates to accommodate a slow link, or adapting the behavior of a high level application to match the set of participants using the application.  We describe the Ensemble system, a tool for building adaptive distributed programs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7294,High-Performance Replicated Distributed Objects in PartitionableEnvironments,This paper presents an implementation of replicated distributed objects in asynchronous environments prone to node failures and network partitions. This implementation has several appealing properties: It guarantees that progress will be made whenever a majority of replicas can communicate with each other; it allows minority partitions to continue providing service for idempotent requests; it offers the application the choice between optimistic or safe message delivery.  Performance measurements have shown that our implementation incurs low latency and achieves high throughput while providing globally consistent replicated state machine semantics. The paper discusses both the protocols and interfaces to support efficient object replication at the application level.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7295,On the Weakest Failure Detector for Quiescent Reliable Communication,"We consider the problem of achieving reliable communication with quiescent algorithms (i.e., algorithms that eventually stop sending messages) in asynchronous systems with process crashes and lossy links, and show that, among failure detectors with bounded output size, less than or greater than P is the weakest one that can be used to solve this problem. Combined with a result in [ACT97a], this shows that failure detectors that are commonly used in practice, i.e., those that output lists of suspects, are not always the best ones to solve a problem.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7296,Combining Trust Region and Affine Scaling Linearly ConstrainedNonconvex Minimization,"An interior point method is proposed for a general nonlinear (nonconvex) minimization with linear inequality constraints. This method is a combination of the trust region idea for nonlinearity and affine scaling technique for constraints. Using this method, the original objective function is monotonically decreased. In the proposed approach, a Newton step is derived directly from the complementarity conditions. A trust region subproblem is formed which yields an approximate Newton step as its solution asymptotically. The objective function of the trust region subproblem is the quadratic approximation to the original objective function plus an augmented quadratic convex term. Similar to an augmented Lagrangian function, this augmentation adds positive curvature in the range space of the constraint normals. The global convergence is achieved by possibly using trust regions with different shapes. A reflection technique, which accelerates convergence, is described. Explicit sufficient decrease conditions are proposed. Computational results of a two-dimensional trust region implementation are reported for large-scale problems. Preliminary experiments suggest that this method can be effective; a relatively small number of function evaluations are required for some medium and large test problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7297,A Trust Region and Affine Scaling Interior Point Method for NonconvexMinimization with Linear Inequality Constraints,"A trust region and affine scaling interior point method (TRAM) is proposed for a general nonlinear minimization with linear inequality constraints in [8]. In the proposed approach, a Newton step is derived from the complementarity conditions. Based on this Newton step, a trust region subproblem is formed, and the original objective function is monotonically decreased. Explicit sufficient decrease conditions are proposed for satisfying complementarity, dual feasibility and second order optimality. The objective of this paper is to establish global and local convergence properties of the proposed trust region and affine scaling interior point method. It is shown that the proposed decrease conditions are sufficient for achieving complementarity, dual feasibility and second order optimality respectively. It is also established that a trust region solution is asymptotically in the interior of the proposed trust region subproblem and a damped trust region step can achieve quadratic convergence.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7298,Improving the Efficiency of Nuprl Proofs,"In order to use Nuprl system as a programming language with built-in verification one has to improve the efficiency of the programs extracted from the Nuprl proofs. In the current paper we consider proofs from the Nuprl automata library. In some of these proofs (pigeon-hole principle, decidability of the state reachability, decidability of the equivalence relation on words induced by the automata language) sources of exponential-time complexity have been detected and replaced by new complexity cautious proofs. The new proofs now lead to polynomial-time algorithms extracted by the same Nuprl extractor, thus eliminating all known unnecessary exponentials from the Nuprl automata library. General principles of efficient programming on Nuprl are also discussed. Key Words and Phrases: automata, constructivity, Myhill-Nerode theorem, Nuprl, program extraction, program verification, state minimization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7299,Mostly-Copying Collection: A Viable Alternative to ConservativeMark-Sweep,"Many high-level language compilers generate C code and then invoke a C compiler to do code generation, register allocation, stack management, and low-level optimization.  To date, most of these compilers link the resulting code against a conservative mark-sweep garbage collector in order to reclaim unused memory.  We introduce a new collector, MCC, based on mostly-copying collection, and characterize the conditions that favor such a collector over a mark-sweep collector.  In particular we demonstrate that mostly-copying collection outperforms conservative mark-sweep under the same conditions that accurate copying collection outperforms accurate mark-sweep: Specifically, MCC meets or exceeds the performance of a mature mark-sweep collector when allocation rates are high, and physical memory is large relative to the live data.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7300,Concurrent Refinement in Nuprl,"This dissertation reports on the design, implementation, and analysis of the  first parallel interactive theorem prover, called the MP refiner. The MP refiner is a shared memory multi-processor implementation of the inference engine of Nuprl. The inference engine of Nuprl is called the refiner. The MP refiner is implemented in the functional programming language Standard ML and is compatible with the refiner of Nuprl 4.1. Parallelism is provided in the MP refiner using an extension to the runtime system of the SML/NJ compiler for Standard ML. The MP refiner provides AND-parallelism and OR-parallelism expressed in terms of concurrent tactics. Concurrent tactics are created using the new tacticals PTHEN and  PORELSLEL. The process of evaluating concurrent tactics is called concurrent refinement. The MP refiner is a collection of threads operating as sequential refiners running on separate processors. Concurrent tactics exploit parallelism by spawning tactics to be evaluated by other refiner threads simultaneously. Tests conducted with the MP refiner running on a four processor Sparc shared--memory multi-processor reveal that concurrent refinement can significantly decrease the elapsed time of constructing proofs interactively. The concurrent tactics constructed with course-grain tactics gave speedups slightly less than two. On the other hand, the concurrent tactics using fine-grain tactics gave speedups close to three. The granularity of a tactic depends on the amount of primitive inferences it invokes. The poor speedups of concurrent tactics constructed with course-grain tactics resulted from bus contention between the multiple processors caused by the memory management of SML/NJ. The design of the MP refiner is based on a rigorous mathematical description of the refiner. The mathematical description includes a model of concurrent refinement. In addition, this disseration presents the first complete rigorous presentation of the Nuprl second order substitution algorithm and the first thorough description of the various components that make up the refiner.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7301,Hierarchical Message Stability Tracking Protocols,"Protocols which track message stability are an important part of reliable multicast protocols in fault-tolerant distributed systems. To reliably deliver multicast messages in a process group, each process maintains copies of all messages it sends and receives. If a member fails to receive a message, any process which has the message in its buffer can retransmit it. In order to prevent these buffers from growing out of bound, stability tracking protocols must be used. That is, whenever a process learns that a message has been received by everyone, it declares this message {\it stable} and releases it from the buffer. We investigate several message stability tracking protocols commonly used in a number of popular reliable multicast protocols with a focus on their performance in large scale settings with thousands of participants. To improve the scalability of these protocols significantly, we derive a set of new protocols using a spanning tree structure which scale to at least tens of thousands of participants.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7302,"PROGRAMMABLE FORCE FIELDS FOR DISTRIBUTED MANIPULATION, AND THEIRIMPLEMENTATION USING MICRO-FABRICATED ACTUATOR ARRAYS","Programmable force vector fields can be used to control a variety of flexible planar parts feeders such as massively-parallel micro actuator arrays or transversely vibrating (macroscopic) plates.  These new automation designs promise great flexibility, speed, and dexterity---they may be employed to position, orient, singulate, sort, feed, and assemble parts. A wealth of geometric and algorithmic problems arise in the control and programming of manipulation systems with many independent actuators.  The theory of programmable force fields represents the first systematic attack on massively-parallel distributed manipulation based on geometric and physical reasoning.  We show how to develop combinatorially precise planning algorithms that synthesize force field strategies for controlling a very large number of distributed actuators in a principled, geometric, task-level fashion. When a part is placed on our devices, the programmed force field induces a force and moment upon it.  Over time, the part may come to rest in a dynamic equilibrium state.  By chaining together sequences of force fields, the equilibrium states of a part in the field may be cascaded to obtain a desired final state.  The resulting strategies require no sensing and enjoy efficient planning algorithms. This thesis introduces new experimental devices that can implement programmable force fields.  In particular, we describe the M-Chip (Manipulation Chip), a massively-parallel array of programmable micro-motion pixels.  Both the M-Chip, as well as macroscopic devices such as transversely vibrating plates, may be programmed with force fields, and their behavior predicted and controlled using our equilibrium analysis.  We demonstrate lower bounds (i.e., impossibility results) on what the devices cannot do, and results on a classification of control strategies yielding design criteria by which well-behaved manipulation strategies may be developed.  We define composition operators to build complex strategies from simple ones, and show the resulting fields are also well-behaved. Finally, we consider parts feeders that can only implement a very limited ``vocabulary'' of force fields.  We show how to plan and execute parts-posing and orienting strategies for these devices, but with a significant increase in planning complexity and some sacrifice in completeness guarantees.  We discuss the tradeoff between mechanical complexity and planning complexity.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7303,An Exterior Newton Method for Convex Quadratic Programming,We propose an exterior Newton method for convex quadratic programming problems.,,application/postscript,Technical Report
oai:ecommons.cornell.edu:1813/7304,Random Fibonacci sequences and the number 1.13198824...,"\begin{abstract} For the familiar Fibonacci sequence --- defined by $f_1 = f_2 = 1$, and $f_n = f_{n-1} + f_{n-2}$ for $n greater than 2$ --- $f_n$ increases exponentially with $n$ at a rate given by the golden ratio $(1+\sqrt{5})/2=1.61803398\ldots$.  But for a simple modification with both additions and subtractions --- the {\it random} Fibonacci sequences defined by $t_1=t_2=1$, and for $n greater than 2$, $t_n = \pm t_{n-1} \pm t_{n-2}$, where each $\pm$ sign is independent and either $+$ or $-$ with probability $1/2$ --- it is not even obvious if $\abs{t_n}$ should increase with $n$. Our main result is that \begin{equation*} \sqrt[n]{\abs{t_n}} \rightarrow 1.13198824\ldots\:\:\: \text{as}\:\:\: n \rightarrow\infty \end{equation*} with probability $1$. Finding the number $1.13198824\ldots$ involves the theory of random matrix products, Stern-Brocot division of the real line, a fractal-like measure, a computer calculation, and a rounding error analysis to validate the computer calculation. \end{abstract}",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7305,From System F to Typed Assembly Language (Extended Version),"We motivate the design of a statically typed assembly language (TAL) and present a type-preserving translation from System F to  TAL.  The TAL we present is based on a conventional RISC assembly language, but its static type system provides support for enforcing high-level language abstractions, such as closures, tuples, and objects, as well as user-defined abstract data types.  The type system ensures that well-typed programs cannot violate these abstractions.  In addition, the typing constructs place almost no restrictions on low-level optimizations such as register allocation, instruction selection, or instruction scheduling. Our translation to TAL is specified as a sequence of type-preserving transformations, including CPS and closure conversion phases; type-correct source programs are mapped to type-correct assembly language.  A key contribution is an approach to polymorphic closure conversion that is considerably simpler than previous work.  The compiler and typed assembly language provide a fully automatic way to produce proof carrying code, suitable for use in systems where  untrusted and potentially malicious code must be checked for safety before execution.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7306,Distributed Communication in ML,"We present our experience in implementing a group communication toolkit in Objective Caml, a dialect of the ML family of programming languages. We compare the toolkit both quantitatively and qualitatively to a predecessor toolkit which was implemented in C. Our experience shows that using the high-level abstraction features of ML gives substantial advantages.  Some of these features, such as automatic memory management and message marshalling, allowed us to concentrate on those pieces of the implementation which required careful attention in order to achieve good performance.  We conclude with a set of suggested changes to both the ML language and the particular implementation we used.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7307,Proposal for A Framework for the High-Precision Identification ofLinguistic Relationships,"Current research in Information Retrieval and Information Extraction demands high-precision syntactic and semantic information from natural language text. We propose a plan for developing a framework to identify, with high-precision, the linguistic relationships between pairs of words in natural language text. Related research is reviewed and preliminary results are given. In our plan we outline the linguistic identification task: a new way to evaluate NLP systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7308,Superlinearly Convergent Variable Metric Algorithms for General Nonlinear Programming Problems,"In this paper variable metric algorithms are extended to solve general  nonlinear programming problems. In the algorithm we iteratively solve a  linearly constrained quadratic program which contains an estimate of the  Hessian of the Lagrangian. We suggest the variable metric updates for the  estimates of the Hessians and justify our suggestion by showing that, when  some well known update such as the Davidon-Fletcher-Powell update are so  employed, the algorithm converges locally with a superlinear rate. Our  algorithm is in a sense a natural extension of the variable metric algorithm  to the constrained optimization and this extension offers us not only a class  of effective algorithms in nonlinear programming but also a unified treatment  of constrained and unconstrained optimization in the variable metric approach.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7309,USING SOFTWARE DESIGN PATTERNS TO BUILD DISTRIBUTED ENVIRONMENTALMONITORING APPLICATIONS,"Tools developers face the challenge of exposing a development methodology to users while concealing details of the underlying system.  If that system is complex and subject to evolution, this problem can be particularly difficult.  Here, we discuss the use of software design patterns in conjunction with StormCast, a system of tools developed to support environmental and weather monitoring tasks in the Arctic.  Now entering its 5th generation, each version of StormCast has expanded the capabilities of the underlying distributed data management tools and computational facilities. This paper reviews StormCast 5.0, presents the design patterns used by developers, and describes several applications in terms of the application of these patterns.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7310,GSGC: An Efficient Gossip-Style Garbage Collection Scheme for ScalableReliable Multicast,"To deliver multicast messages reliably in a group, each member maintains copies of all messages it sends and receives in a buffer for potential local retransmission. The storage of these messages is costly and buffers may grow out of bound. Garbage collection is needed to address this issue. Garbage collection occurs once a process learns that a message in its buffer has been received by every process in the group. The message is declared stable and is released from the process's buffer.  This paper proposes a gossip-style garbage collection scheme called GSGC for scalable reliable multicast protocols. This scheme achieves fault-tolerance and scalability without relying on the underlying multicast protocols. It collects and disseminates information in the multicast group by making each group member periodically gossip information to a random subset of the group. Extending the global gossip protocol further, this paper also investigates a local gossip scheme that achieves improved scalability and significantly better performance. Simulations conducted in a WAN environment are used to evaluate the performance of both schemes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7311,A Variable Window Approach to Early Vision,"Early vision relies heavily on rectangular windows for tasks such as smoothing and computing correspondence.  While rectangular windows are efficient, they yield poor results near object boundaries.  We describe an efficient method for choosing an arbitrarily shaped connected window, in a manner which varies at each pixel.  Our approach can be applied to many problems, including image restoration and visual correspondence.  It runs in linear time, and takes a few seconds on traditional benchmark images.  Performance on both synthetic and real imagery with ground truth appears promising.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7312,Markov Random Fields with Efficient Approximations,"Markov Random Fields (MRF's) can be used for a wide variety of vision problems.  In this paper we address the estimation of first-order MRF's with a particular clique potential that resembles a well.  We show that the maximum {\em a posteriori} estimate of such an MRF can be obtained by solving a multiway cut problem on a graph.  This allows the application of near linear-time algorithms for computing provably good approximations.  We formulate the visual correspondence problem as an MRF in our framework, and show that this yields quite promising results on real data with ground truth.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7313,Precision Weighting - An Effective Automatic Indexing Method,"A great many automatic indexing methods have been implemented and evaluated  over the last few years, and automatic procedures comparable in effectiveness  to conventional manual ones are now easy to generate. Two drawbacks of the  available automatic indexing methods are the absence of reliable linguistic  inputs during the indexing process, and the lack of formal, analytical proofs  concerning the effectiveness of the proposed methods. The precision weighting procedure described in the present study uses  relevance criteria to weight the terms occurring in user queries as a function  of the balance between relevant and nonrelevant documents in which these terms  occur; this approximates a semantic know-how of term importance. Formal  mathematical proofs are given under well-defined conditions of the  effectiveness of the method.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7314,Implementing Multiple Protection Domains in Java,"Safe language technology can be used for protection within a single address space. This protection is enforced by the language's type system, which ensures that references to objects cannot be forged. A safe language alone, however, lacks many features taken for granted in more traditional operating systems, such as rights revocation, thread protection, resource management, and support for domain termination. This paper describes the J-Kernel, a portable Java-based protection system that addresses these issues. A number of micro-benchmarks are presented to characterize the costs of language-based protection, and an extensible web server based on the J-Kernel demonstrates the use of safe language techniques in a large application.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7315,Efficient Code Certification,"We introduce a simple and efficient approach to the certification of compiled code.  We ensure a basic but nontrivial level of code safety, including control flow safety, memory safety, and stack safety.  The system is designed to be simple, efficient, and (most importantly) relatively painless to incorporate into existing compilers. Although less expressive than the proof carrying code of Necula and Lee or typed assembly language of Morrisett et al., our certificates are compact and relatively easy to produce and to verify.  Unlike JAVA bytecode, our system operates at the level of native code; it is not interpreted and no further compilation is necessary.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7316,The Ensemble System,"Ensemble is a group communication system that demonstrably achieves a wide range of goals.  It is a general-purpose communication system intended for constructing reliable distributed applications; it is a flexible framework for carrying out research in group ware protocols; it is a large-scale, system-style implementation built in a state-of-the-art programming language\rc{lines of ML?}; and it is also a mathematical object designed to be amenable to formal analysis and manipulation.  Thus, Ensemble straddles a number of disciplines of computer science ranging from systems architectures to formal methods.  The principal advances described in this thesis are the creation of the Ensemble system and the demonstration that it exhibits the properties just mentioned. The thesis begins by presenting the Ensemble architecture, as well as background in group communication.  We describe the various components of the architecture, give examples of their interactions, and compare this architecture with that of other layered communication systems. The Ensemble protocols make heavy use of layered micro-protocols.  We describe optimization techniques that greatly reduce the performance overheads introduced by layering and show how the architecture facilitates these optimizations.  In addition we show how to formalize these optimizations in type theory and implement them using the Nuprl theorem prover. Ensemble is implemented in a dialect of the ML programming language. We describe how the use of ML impacted the system, and present a wide range of comparisons between Ensemble and a similar system implemented in C.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7317,ADMIT-1 : Automatic Differentiation and MATLAB Interface Toolbox,"ADMIT-1 enables you to compute {\em sparse} Jacobian and Hessian matrices, using automatic differentiation technology, from a MATLAB environment. You need only supply a function to be differentiated and ADMIT-1 will exploit sparsity if present to yield sparse derivative matrices (in sparse MATLAB form). A generic AD tool, subject to some functionality requirements, can be plugged into ADMIT-1;  examples include ADOL-C ~\cite{Griewank1996b} (C/C++ target functions) and ADMAT ~\cite{admat} (MATLAB target functions). ADMIT-1 also allows for the calculation of gradients and has several other related functions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7318,Enforceable Security Policies,"A precise characterization is given for the class of security policies that can be enforced using mechanisms that work by monitoring system execution, and a class of automata is introduced for specifying those security policies. Techniques to enforce security policies specified by such automata are also discussed.  READERS NOTE: A substantially revised version of this document is available as TR99-1759.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7319,Succinctness of Descriptions of Unambiguous Context-Free Languages,There is no recursive function bounding the succintness gained using ambiguous  grammars over unambiguous ones in the description of unambiguous context-free  languages.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7320,Programming Language Semantics in Foundational Type Theory,"There are compelling benefits to using foundational type theory as a framework for programming language semantics.  I give a semantics of an expressive programming calculus in the foundational type theory of Nuprl.  Previous type-theoretic semantics have used less expressive type theories, or have sacrificed important programming constructs such as recursion and modules. The primary mechanisms of this semantics for the core calculus are partial types, for typing recursion, set types, for encoding power and singleton kinds, which are used for subtyping and module programming, and very dependent function types, for encoding signatures.  I then extend the semantics to modules using phase-splitting.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7321,User's Guide to TSO-PL/CT,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7322,Addition Requirements for Rational Functions,"A notion of rank or independence for arbitrary sets of rational functions is  developed, which bounds from below the number of additions and subtractions  required of all straight-line algorithms which compute those functions. This  permits a uniform derivation of the best lower bounds known for a number of  familiar sets of rational functions.  The result is proved without the use of substitution arguments. This not only  provides an interesting contrast to standard approaches for arithmetic lower  bounds, but also allows the algebraic setting to be somewhat generalized.  Keywords: additions, algorithms, analysis of algorithms, arithmetic  complexity, computational complexity, dimensionality, lower bounds, matrix  multiplication, optimality, polynomials, rational functions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7323,Typed Kleene Algebra,"In previous work we have found it necessary to argue that certain theorems of Kleene algebra hold even when the symbols are interpreted as nonsquare matrices.  In this note we define and investigate typed Kleene algebra, a typed version of Kleene algebra in which objects have types s pointing to t.  Although nonsquare matrices are the principal motivation, there are many other useful interpretations: traces, binary relations, Kleene algebra with tests. We give a set of typing rules and show that every expression has a unique most general typing (mgt).  Then we prove the following metatheorem that incorporates the abovementioned results for nonsquare matrices as special cases.  Call an expression 1-free if it contains only the Kleene algebra operators (binary) +, (unary) +, 0, and ., but no occurrence of 1 or *.  Then every universal 1-free formula that is a theorem of Kleene algebra is also a theorem of typed Kleene algebra under its most general typing. The metatheorem is false without the restriction to 1-free formulas.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7324,A Case for Language-Based Protection,"The use of language mechanisms to enforce protection boundaries around software modules has become increasingly attractive. This paper examines the advantages and disadvantages of language-based protection over more traditional protection mechanisms, such as standard virtual memory protection hardware, software fault isolation, and capability systems. Arguably, state-of-the-art language-based protection is more flexible and as safe as these other mechanisms. Two major remaining issues are the performance of language-based protection, and the management of resources. Regarding the latter, techniques to build an operating system kernel capable of managing resources and revoking rights are presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7325,An Efficient Algorithm for Polymer Sequence Design,"Polymer sequence design is a natural inverse problem to protein structure prediction: given a target structure in three dimensions, we wish to design an amino acid sequence that will fold to it.  A model of Sun, Brem, Chan, and Dill casts this problem as an optimization on a space of sequences of hydrophobic (H) and polar (P) monomers; the goal is to find a sequence which achieves a dense hydrophobic core with few solvent-exposed hydrophobic residues.  Sun et al. developed a heuristic method to search the space of sequences, without a guarantee of optimality or near-optimality; Hart subsequently raised the computational tractability of constructing an optimal sequence in this model as an open question.  Here we answer this question by providing an efficient algorithm to construct optimal sequences; the method has a polynomial running time, and performs very efficiently in practice.  We illustrate the implementation of our method on structures drawn from the Protein Data Bank, and discuss some possible extensions of the model.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7326,Frequency vs. Probability Formats: Framing the Three Doors Problem,"Instead of subscribing to the view that people are unable  to perform Bayesian probabilistic inference, recent research suggests that the algorithms people naturally use to perform Bayesian inference are better adapted for information presented in a natural frequency format than in the common probability format.  We tested this hypothesis on the notoriously difficult three doors problem, inducing subjects to consider the likelihoods involved in terms of natural frequencies or in terms of probabilities.  We then examined their ability to perform the mathematics underlying the problem, a stronger indication of Bayesian inferential performance than merely whether they gave the correct answer to the problem.  With a robustness that may surprise people unfamiliar with the effects of information formats, the natural frequency group demonstrated dramatically greater normative mathematical performance than the probability group.  This supports the importance of information formats in a more complex context than in previous studies.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7327,Dead Code Elimination Through Type Inference,"We introduce a method to detect and eliminate dead code in typed functional   programming languages. Our approach relies on a type system with simple   subtypes for specifying dead code and a type inference algorithm for it.   Through a careful seperation of the type system and the problem-specific  assumptions we avoid \emph{ad hoc} rules in the type system. This, combined   with the fact that our approach makes the flow  information in a program   explicit and is based on well-understood concepts makes our approach a good   candidate for a general framework for program analysis. Our technique can be   used in optimizing compilers, optimization of programs extracted from theorem   provers, optimization of modular systems, and other areas of software   engineering.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7328,Admissibility of Fixpoint Induction over Partial Types,"Partial types allow the reasoning about partial functions in type theory.  The partial functions of main interest are recursively computed functions, which are commonly assigned types using fixpoint induction.  However, fixpoint induction is valid only on admissible types.  Previous work has shown many types to be admissible, but has not shown any dependent products to be admissible. Disallowing recursion on dependent product types substantially reduces the expressiveness of the logic; for example, it prevents much reasoning about modules, objects and algebras. In this paper I present two new tools, predicate-admissibility and monotonicity, for showing types to be admissible.  These tools show a wide class of types to be admissible; in particular, they show many dependent products to be admissible.  This alleviates difficulties in applying partial types to theorem proving in practice.  I also present a general least upper bound theorem for fixed points with regard to a computational approximation relation, and show an elegant application of the theorem to compactness.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7329,"Simple, Efficient Object Encoding using Intersection Types","I present a type-theoretic encoding of objects that interprets method dispatch by self-application (i.e., method functions are applied to the objects containing them) but still validates the expected subtyping relationships.  The naive typing of self-application fails to validate the expected subtyping relationships because it is too permissive and allows application to similarly typed objects that are not self.  This new encoding solves this problem by constraining methods to be applied only to self using existential and intersection types.  Using this typing, I give a full account of objects including self types and method update.  I also present another application of this object encoding to fully abstract, closure-passing closure conversion.  The typing constructs used in this encoding appear to be quite rich, but they may be axiomatized in a novel, restricted fashion that is metatheoretically simple.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7330,Failure Detection and Consensus in the Crash-Recovery Model,"We study the problems of failure detection and consensus in asynchronous systems in which processes may crash and recover, and links may lose messages.  We first propose new failure detectors that are particularly suitable to the crash-recovery model.  We next determine under what conditions stable storage is necessary to solve consensus in this model. Using the new failure detectors, we give two consensus algorithms that match these conditions: one requires stable storage and the other does not.  Both algorithms tolerate link failures and are particularly efficient in the runs that are most likely in practice --- those with no failures or failure detector mistakes.  In such runs, consensus is achieved within 3d time and with 4n messages, where d is the maximum message delay and n is the number of processes in the system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7331,Wavelength Conversion in Optical Networks,"In many models of optical routing, we are given a set of communication paths in a network, and we must assign a wavelength to each path so that paths sharing an edge receive different wavelengths.  The goal is to assign as few wavelengths as possible, in order to make as efficient use as possible of the optical bandwidth. Wilfong and Winkler considered the problem of placing wavelength converters in such a network: if a node of the network contains a converter, any path that passes through this node may change its wavelength.  Having converters at some of the nodes can reduce the number of wavelengths required for routing, down to the following natural {\em congestion bound}:  even with converters, we will always need at least as many wavelengths as the maximum number of paths sharing a single edge.  Thus Winkler and Wilfong defined a set $S$ of nodes in a network to be {\em sufficient} if, placing converters at the nodes in $S$, every set of paths can be routed with a number of wavelengths equal to its congestion bound.  They showed that finding a sufficient set of minimum size is NP-complete. In this paper, we provide a polynomial-time algorithm to find a sufficient set for an arbitrary directed network whose size is within a factor of $2$ of minimum.  For the special case of planar graphs with bi-directional edges, we obtain a polynomial-time approximation scheme.  Our techniques establish a connection between the problem of finding a minimum sufficient set and an interesting simultaneous generalization of the Vertex Cover and Feedback Vertex Set problems in undirected graphs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7332,Building Reliable Interoperable Distributed Objects with The MaestroTools,"This work presents the Maestro Tools for development of reliable interoperable object-oriented distributed applications.  We discuss the three fundamental parts of Maestro -- the object group tools, the client/object interoperability tools, and the group protocols which implement state machine replication of distributed objects -- with a special focus on practical usability and system integration issues.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7333,JRes: A Resource Accounting Interface for Java,"In order to better support the Internet the computing model on  server systems is undergoing several important changes. First, recent research ideas concerning dynamic operating system extensibility are finding their way into the commercial domain, resulting in designs of extensible databases and Web servers. Second, both ordinary users and service providers must deal with untrusted downloadable executable code of unknown origin and intentions. Across the board, Java has emerged as the language of choice for Internet-oriented software. We argue that, in order to realize its full potential in applications dealing with untrusted code, Java needs a flexible resource accounting interface. The design and prototype implementation of such an interface  JRes - is presented in this paper. The interface allows to account for heap memory, CPU time, and network resources consumed by individual threads or collections of threads. JRes allows limits to be set on resources available to threads and it can invoke callbacks when these limits are exceeded. The JRes prototype described in this paper is implemented on top of standard Java virtual machines and requires only a small amount of native code.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7334,Designing a Calculational Logic Theorem Prover: Insight into SearchProcedure via Eye Movements,"We are designing and implementing an automated theorem prover that will in part attempt to simulate human performance on calculational logic theorem proving.  To support this project, we recorded and analyzed people's eye movements while they constructed calculational proofs.  Our findings confirm some expected behaviors (based on strategies and principles taught to students) that may previously have seemed untestable, such as the influence of the form of the current proof step and of syntax in general on the microcognition of the problem solver.  The experiment also uncovered other interesting patterns, such as the seemingly inefficient but widely occurring tendency to attend to premises that are not used in the proof under consideration.  Overall, we gained insights into microcognition that could not have been gained merely by studying written proofs.  We expect these insights to directly impact the theorem prover under development, but they may also find a wider audience, appealing to educators and logicians who are familiar with calculational methods and student performance on calculational proofs.  Our findings also support the notion that analyses of eye movements can improve our understanding of the way people perform some theorem proving tasks.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7335,STRUCTURED AUTOMATIC DIFFERENTIATION,"Differentiation is one of the fundamental problems in numerical mathemetics. The solution of many optimization problems and other applications require knowledge of the gradient, the Jacobian matrix,  or the Hessian matrix of a given function. Many large scale optimization applications (e.g., inverse problems) are very complex in nature. It becomes impractical to consider the function evaluation of such problems as a ``black-box'' function, since the computation is structured in some manner, going through a set of defined structured steps, i.e., problem structure. It pays to expose the problem structure in the computation to be able to compute the derivatives efficiently thus making the solution procedure practical. Automatic differentiation (AD) can compute fast and accurate derivatives of any degree computationally via propagating Taylor series coefficients using the chain rule. AD doesn't incur any truncation error and to compute the derivatives efficiently thus making the problem solution practical. would yield exact results if the calculations were done in real arithmetic; in other words the derivatives obtained are accurate to machine precision. This thesis is concerned with the efficient application of AD to large (and complex) optimization problems. The major theme is  the structure exploitation of the user problem. We present methodologies which allow AD to exploit problem structure. An important idea is the exploitation of sparsity in the Jacobian matrices: We present a scheme which combines the forward and reverse modes of AD. Problem structure can be viewed in many different ways; one way is to look at the granularity of the operations involved. For example, differentiation carried out at the  matrix-vector operations can lead to great savings in the time as well as space requirements. Figuring out the {\em kind} of computation is another way to view structure, e.g., partially separable or composite functions whose structur e can be exploited to get performance gains. In this thesis we develop a general structure framework which can be viewed hierarchically  and allows for structure exploitation at various levels. For example, for time integration schemes employing stencils it is possible to exploit structure at both the stencil level and the timestep level. We also present some advanced structure exploitation ideas, e.g., parallelism in structured computations and using structure in  implicit  computations. The use of AD as a derivative computing engine naturally automates all the methodologies presented in this work -- we present ways to make the design of numerical optimization software very transparent, and the presentation of problems by the user as easy as possible.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7336,Correctness Proof of Ben-Or's Randomized Consensus Algorithm,"We present a correctness proof for Ben-Or's Randomized Consensus Algorithm for the case in which processes can fail by crashing, and a majority of processes is correct.  This is the first time that the proof of Ben-Or's algorithm appears for this case.  The proof has been extracted from [AT96]: it is a simplification of the correctness proof of a more complex consensus algorithm that involves both randomization and failure detection.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7337,Some Results of the Space Requirements of Dynamic Memory Allocation Algorithms,Some Results of the Space Requirements of Dynamic Memory Allocation Algorithms,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7338,Scalable Message Stability Detection Protocols,"In group communication, in order to deliver multicast messages reliably in a group, it is common practice for each member to maintain copies of all messages it sends and receives in a buffer for potential local retransmission. The storage of these messages is costly and buffers may grow out of bound. A form of garbage collection is needed to address this issue. Garbage collection occurs once a process learns that a message in its buffer has been received by every process in the group. The message is declared {\it stable} and is released from the buffer. An important part of garbage collection is message stability detection. This dissertation presents the result of an investigation into message stability detection protocols.  A number of message stability detection protocols used in popular reliable multicast protocols are studied with a focus on their performance in large scale settings. This dissertation proposes a new gossip-style protocol with improved scalability and fault tolerance. This dissertation also shows that by adding a hierarchical structure to the set of basic protocols, their performance can be significantly improved when the number of participants is large.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7339,Parallel Computing as a Commodity,"Massively parallel computers have become undisputed champions in the supercomputing arena.  The global computer industry, however, is increasingly dominated by consumer machines.  In this thesis, we argue that everyday computers must become highly parallel machines in order to sustain the performance gains we have come to expect. For parallel computation to become a commodity, there must be an architecture which can be scaled as easily as memory arrays are now. We also need to establish that parallelism can benefit everyday applications and that operating systems for such machines can provide as comfortable and robust an environment as we have on sequential machines. We introduce an architecture based on cellular automata---meshes of simple, locally-connected processors in either 2 or 3 dimensions. We argue that this architecture is easily scalable, and from a theoretical viewpoint it is essentially as efficient as any other scalable architecture. We show two instances of this architecture, a simple one implemented in silicon and a more complex one implemented through a simulator. To show the viability of this architecture for everyday tasks, we have developed fast parallel algorithms for RSA encryption (using residue number systems and a new method for converting one RNS to another) and for document formatting (using a space-filling curve for data layout to achieve optimal $O(\droot{n})$ running time on a $d$-dimensional mesh). We also describe the design of an operating system for a cellular array based on the notion of the OS as the periphery, rather than the kernel, and show several advantages in security and performance this confers. Finally, we investigate the 3-dimensional dynamic allocation problem faced by such a system.  This problem is NP-hard even in its static form, but we describe a simple best-fit allocator that works well in practice.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7340,Formalizations Of Substitution Of Equals For Equals,"Inference rule ""substitution of equals for equals"" has been  formalized in terms of simple substitution (which performs a replacement even though a free occurrence of a variable is captured), contextual substitution (which prevents such capture), and function application. We show that in connection with pure first-order predicate calculus, the function-application and no-capture versions of the inference rule are the same and are weaker than the capture version. We discuss the deductive apparatus needed for the no-capture version to be as powerful as the capture version.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7341,A Gossip-Style Failure Detection Service,"Failure Detection is valuable for system management, replication, load balancing, and other distributed services. To date, Failure Detection Services scale badly in the number of members that are being monitored. This paper describes a new protocol based on gossiping that does scale well and provides timely detection. We analyze the protocol, and then extend it to discover and leverage the underlying network topology for much improved resource utilization. We then combine it with another protocol, based on broadcast, that is used to handle partition failures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7342,Centralized Multicast,"Most current schemes for multicast routing assume that multicast routers participate both in forwarding multicast packets and in control algorithms for routing, resource reservation, and group management. By separating data and control flow, and by centralizing control in distinct control elements, we have designed a simple and scalable approach to IP multicast that we call Centralized Multicast. We present the details of our approach, a proof of its correctness, analysis of its performance, and a discussion of its advantages over current schemes.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7343,Publishing Formal Mathematics on the Web,"Paper describes the design of the Nuprl Web Publisher - an automated tool for converting formal, computer-generated, mathematical texts into a set of hyper-linked HTML pages that preserves original, non-linear, text structure. The current version of the Web Publisher, also developed by the author, provides access to term structure of the displayed formulas and links to definitions of abstractions used in these formulas.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7344,An Infrastructure for Open-Architecture Digital Libraries,"A digital library is a managed collection of digital objects  and services that support the storage, discovery, retrieval, and preservation of those objects. We describe an open architecture in which core digital library functionality is partitioned into a set of well-defined services.  Each service can be accessed through a set of service requests that define its public interface. This paper describes a general digital object model and a set of service components, which include a naming service, a repository service, an index service, and a collection service.  Interoperability is promoted when digital libraries are assembled from this set of core service components.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7345,Automated Stream-Based Analysis of Fault-Tolerance,"A rigorous, automated approach to analyzing fault-tolerance of distributed systems is presented.  The method is based on a stream model of computation that incorporates approximation mechanisms.  One application is described: a protocol for fault-tolerant",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7346,On Quiescent Reliable Communication,"We study the problem of achieving reliable communication with quiescent algorithms (i.e., algorithms that eventually stop sending messages) in asynchronous systems with process crashes and lossy links. We first show that it is impossible to solve this problem without failure detectors. We then show that, among failure detectors that output lists of suspects, the weakest one that can be used to solve this problem is less than or greater than P, a failure detector that cannot be implemented. To overcome this difficulty, we introduce an implementable failure detector called Heartbeat and show that it can be used to achieve quiescent reliable communication. Heartbeat is novel: in contrast to typical failure detectors, it does not output lists of suspects and it is implementable without timeouts. With Heartbeat, many existing algorithms that tolerate only process crashes can be transformed into quiescent algorithms that tolerate both process crashes and message losses. This can be applied to consensus, atomic broadcast, k-set agreement, atomic commitment, etc.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7347,Relational Query Optimization with Enhanced ADTs,"Object-relational queries access large complex data types and  expensive methods of those data types. In earlier work, we modeled complex types as ""Enhanced ADTs"" (E-ADTs) and demonstrated the resulting performance improvements when implemented in the PREDATOR system. This paper explores the opportunities for further improvements through interactions between relational query optimization and E-ADT optimization. We identify four broad categories of optimization opportunities and study specific examples in each of these categories. These examples span query rewrite, indexing, aggregation and join optimization. Our conclusion is that non-trivial interactions exist between E-ADTs and relational queries, and that special optimization techniques are necessary to achieve good performance. These techniques have been prototyped in PREDATOR, and we present experimental results that demonstrate their effect.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7348,Dynamical Automata,"The recent work on automata whose variables and parameters are real numbers (e.g., Blum, Shub, and Smale, 1989; Koiran, 1993; Bournez and Cosnard, 1996; Siegelmann, 1996; Moore, 1996) has focused largely on questions about computational complexity and tractability.  It is also revealing to examine the metric relations that such systems induce on automata via the natural metrics on their parameter spaces.  This brings the theory of computational classification closer to theories of learning and statistical modeling which depend on measuring distances between models.  With this in mind, I develop a generalized method of identifying pushdown automata in one class of real-valued automata. I show how the real-valued automata can be implemented in neural networks.  I then explore the metric organization of these automata in a basic example, showing how it fleshes out the skeletal structure of the Chomsky Hierarchy and indicates new approaches to problems in language learning and language typology.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7349,Dynamic Virtual Private Networks,"We extend traditional Virtual Private Networks (VPNs) with fault-tolerance and dynamic membership properties, defining a Dynamic Virtual Private Network (DVPN). We require no new hardware and make no special assumptions about line security. An implementation exhibits low overheard, provides guarantees of authenticity and confidentiality to any IP application running over the virtual network. Our system is lightweight, allowing the use of multiple fine-grained VPNs. Instead of using many point-to-point secure connections to bridge insecure communication paths we share a single symmetric encryption key throughout the VPN. This permits tight control of the VPN membership and fast dynamic membership change. Since we lower the cost of a single DVPN, we propose using multiple DVPNs to implement fine grained security. By enforcing policies over communication between DVPNs, our scheme supports multilevel security.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7350,Availability and Consistency in a Partitionable Low Bandwidth Network,"The Internet is a partitionable low bandwidth network. Two computers connected by the Internet could temporarily become unable to communicate for various reasons, from a failure at either end, to overloading of an intermediate node connecting the two, to an out-of-date routing table. The bandwidth of the Internet is relatively low: its data transfer speed is inadequate for applications that need to access very large data objects. Since its introduction the Internet kept a much faster rate of increase for the data available than for the data transfer speed. This trend is not likely to change any time soon.  This thesis presents techniques to deal with availability and consistency in partitionable low bandwidth networks, and it presents a service suitable for use in such networks. The first part of the thesis presents replication techniques suitable in a partitionable network.  A partitionable network puts goals of availability and consistency at odds. Making objects available in a partitionable network requires replication; yet modifications of replicated objects during a partition can introduce inconsistencies.  We show various replication techniques that provide continuous availability while managing inconsistencies among replicas.  The second part of the thesis describes the PEX system, an example of a service that instantiates these abstractions. PEX is an execution service that facilitates processing of remote data.  It allows computations to be performed near data, so that data need not be copied over the network. It provides a session interface which facilitates the management of related computations operating on scattered data. Internally, PEX replicates various information, including sessions, using some of the techniques introduced in the first section of the thesis.  This permits the system to keep computations running in the face of partitions.  The third part of the thesis gives two example applications that use PEX (a distributed shell and a parallel make) and reports the performance of the PEX system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7351,Lyapunov Exponents from Random Fibonacci Sequences to the LorenzEquations,Ph.D. thesis. Please see inside document for an abstract.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7352,Automatic Discovery of Logical Document Structure,"The availability of large, heterogeneous repositories of electronic documents is increasing rapidly, and the need for flexible, sophisticated document manipulation tools is growing correspondingly.  These tools can benefit greatly by exploiting logical structure, a hierarchy of visually observable organizational components of a document, such as paragraphs, lists, sections, em etc.  Knowledge of this structure can enable a multiplicity of applications, including hierarchical browsing, structural hyperlinking, logical component-based retrieval, and style translation. Most work on the problem of deriving logical structure from document layout either relies on knowledge of the particular document style or finds a single flat set of text blocks. This thesis describes an implemented approach to discovering a full logical hierarchy in generic text documents, based primarily on layout information.  Since the styles of the documents are not known a priori, the precise layout effects of the logical structure are unknown.  Nonetheless,typographical capabilities and conventions provide cues that can be used to deduce a logical structure for a generic document.  In particular, the key idea is that analyses of the text contours at appropriate levels of granularity offer a rich source of information about document structure. The problem of logical structure discovery is divided into problems of segmentation, which separates the text into logical pieces, and classification, which labels the pieces with structure types.  The segmentation algorithm relies entirely on layout-based cues, and the classification algorithm uses word-based information only when this is demonstrably unavoidable.  Thus, this approach is particularly appropriate for scanned-in documents, since it is more robust with respect to OCR errors than a content-oriented approach would be.  It is applicable, however, to the problem of analyzing any electronic document whose original formatting style rules remain unknown; thus, it can provide the basis for flexible document manipulation tools in heterogeneous collections.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7353,Type-Theoretic Methodology for Practical Programming Languages,"The significance of type theory to the theory of programming languages has long been recognized.  Advances in programming languages have often derived from understanding that stems from type theory.  However, these applications of type theory to practical programming languages have been indirect; the differences between practical languages and type theory have prevented direct connections between the two. This dissertation presents systematic techniques directly relating practical programming languages to type theory.  These techniques allow programming languages to be interpreted in the rich mathematical domain of type theory. Such interpretations lead to semantics that are at once denotational and operational, combining the advantages of each, and they also lay the foundation for formal verification of computer programs in type theory. Previous type theories either have not provided adequate expressiveness to interpret practical languages, or have provided such expressiveness at the expense of essential features of the type theory.  In particular, no previous type theory has supported a notion of partial functions (needed to interpret recursion in practical languages), and a notion of total functions and objects (needed to reason about data values), and an intrinsic notion of equality (needed for most interesting results).  This dissertation presents the first type theory incorporating all three, and discusses issues arising in the design of that type theory. This type theory is used as the target of a type-theoretic semantics for a expressive programming calculus.  This calculus may serve as an internal language for a variety of functional programming languages.  The semantics is stated as a syntax-directed embedding of the programming calculus into type theory. A critical point arising in both the type theory and the type-theoretic semantics is the issue of admissibility. Admissibility governs what types it is legal to form recursive functions over. To build a useful type theory for partial functions it is necessary to have a wide class of admissible types.  In particular, it is necessary for all the types arising in the type-theoretic semantics to be admissible.  In this dissertation I present a class of admissible types that is considerably wider than any previously known class.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7354,DENSITY ESTIMATION TECHNIQUES FOR GLOBAL ILLUMINATION,"In this thesis we present the density estimation framework  for computing view-independent global illumination solutions.   The framework consists of three phases:  particle tracing, density estimation, and decimation. Monte Carlo particle tracing is used to accurately simulate the  light transport under a general spectral geometric-optics based  physical model.  Next kernel density estimation is used to reconstruct perceptual illumination functions.   Finally decimation is used to optimize the resulting mesh for  compactness and rapid interactive display as Gouraud-shaded triangles. The three principal contributions of this work are the framework's  separation of  transport and function reconstruction computations, its ability to  produce accurate solutions with precisely known error  characteristics, and the techniques that we introduce to improve its  efficiency and accuracy. Particle tracing's generality allows us to eliminate or delay many  common simplifying assumptions and improves our accuracy and error  analysis.  Delaying the density estimation until particle tracing is  complete allows us to make better  use of the expensive particle data.  The separation of  global transport and local representation computations also reduces the  computational complexity of each phase, enhances the framework's  scalability, and exposes abundant opportunities for parallelism. Another advantage is that we can solve directly for the radiant  exitance without  needing to estimate the more complicated spectral radiance function. Despite its advantages, if naively implemented the framework would be  prohibitively expensive.  Thus we also introduce several techniques  that significantly improve its accuracy and efficiency.   These include the separation of luminance and chromaticity bandwidths,  perceptually-motivated noise visibility predictors, statistical bias  detection techniques to automatically enhance underresolved  illumination features, a local polynomial density estimation method  to eliminate boundary bias, and wavelength importance sampling to  reduce the spectral noise. Results of the framework are shown for some complex environments and  compared against measured data for a simple scene.   The strength of  our framework is that it can  simulate a wider variety of  lighting effects, with fewer simplifying assumptions, and more  precise error analysis that current view-independent methods. Furthermore, because of its accuracy, our density estimation  framework solutions are used as reference solutions for judging the  quality and effectiveness of more approximate but faster rendering  methods.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7355,A Simple Bivalency Proof that t-Resilient Consensus Requires t+1 Rounds,We use a straightforward bivalency argument borrowed from [FLP85] to show that in a synchronous system with up to t crash failures solving consensus requires at least t+1 rounds. The proof is simpler and more intuitive than the traditional one: It uses an easy forward induction rather than a more complex backward induction which needs the induction hypothesis several times.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7356,Proposal for an Interactive Environment for Information Extraction,"Information extraction systems have been successfully deployed for domains ranging from terrorist activities to medical records. However, building these systems remains costly for users who lack annotated training corpora or knowledge engineering expertise.  This paper proposes a framework for an interactive information extraction environment in which the user trains the system by example and by feedback about performance.  If successful, this will be the first system that allows end-users to create information extraction systems without the aid of computational linguists and NLP system designers.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7357,Ensemble Security,"Ensemble is a Group Communication System built at Cornell and the Hebrew Universities. It allows processes to create {\it process groups} in which scalable reliable fifo-ordered multicast and point-to-point communication are supported. The system also supports other communication properties, such as multicast causal and total ordering, flow control, etc.. This paper describes the security protocols and infrastructure of Ensemble. Applications using Ensemble with the extensions described here benefit from strong security properties. Assuming trusted authenticated members may not be corrupted, all communication is secured from tampering by outsiders. Our work extends previous work performed in the Horus system (Ensemble's predecessor) adding support for multiple partitions, efficient rekeying, and application defined security policies. Unlike Horus, which used its own security infrastructure with non-standard key distribution and timing services, Ensemble's security mechanism is based on a standard and very widely used security infrastructure: the PGP authentication engine.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7358,Segmentation of Pulmonary Nodule Images Using Total VariationMinimization,"Total variation minimization has edge preserving and enhancing  properties which make it suitable for image segmentation.  We present Image Simplification, a new formulation and algo rithm for image segmentation.  We illustrate the edge enhancing properties of total variation minimization in a discrete setting by giving exact solutions  to the problem for piecewise constant functions in the presence of noise.  In this case, edges can be exactly recovered if the noise is sufficiently small.  After optimization, segmentation is completed using edge detection.  We find that our image segmentation approach  yields good results when applied to the segmentation of pulmonary nodules.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7359,Fast Detection of Common Geometric Substructure in Proteins,"We consider the problem of identifying common three-dimensional substructures between proteins.  Our method is based on comparing the shape of the $\alpha$-carbon backbone structures of the proteins in order to find 3D rigid motions that bring portions of the geometric structures into correspondence.  We propose a geometric representation of protein backbone chains that is compact yet allows for similarity measures that are robust against noise and outliers.  We represents the structure of the backbone as a sequence of unit vectors, defined by each adjacent pair of $\alpha$-carbons; we then define a measure of the similarity of two protein structures based on the RMS (root mean squared) distance between corresponding orientation vectors in the two proteins. Our measure has several advantages over standard position-based RMS measures that are commonly used for comparing protein shapes.  In particular, the measure behaves well for comparing substructures, because unlike position-based measures the nonmatching portions of the structure do not dominate the measure.  At the same time, it avoids the quadratic space and computational difficulties associated with the use of distance matrices and contact maps.  We show applications of our approach to detecting common contiguous substructures in pairs of proteins, as well as the more difficult problem of identifying common protein domains (i.e., larger substructures that are not necessarily contiguous along the protein chain).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7360,Reconstructing the unknown volatility function,"Using market European option prices, a method for computing a {\em smooth} local volatility function in a 1-factor continuous diffusion model is proposed. Smoothness is introduced to facilitate accurate approximation of the true local volatility function from a finite set of observation data. It is emphasized that accurately approximating the true local volatility function is crucial in hedging even simple European options, and pricing exotic options. A spline functional approach is used: the local volatility function is represented by a spline whose values at chosen knots are determined by solving a constrained nonlinear optimization problem. The optimization formulation is amenable to various option evaluation methods; a partial differential equation implementation is discussed. Using a synthetic European call option example, we illustrate the capability of the proposed method in reconstructing the unknown local volatility function. Accuracy of pricing and hedging is also illustrated. Moreover, it is demonstrated that, using a different constant implied volatility for an option with different strike/maturity can produce erroneous hedge factors. In addition, real market European call option data on the S and P 500 stock index is used to compute the local volatility function; stability of the approach is demonstrated.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7361,Formal Reasoning about Communication Systems II: Automated Fast-TrackReconfiguration,We present formal techniques for improving the performance of group      communication systems built with the Ensemble toolkit. For       common sequences of operations we identify a fast-track through a stack      of communication protocols and reconfigure the system's code       accordingly. Our techniques are implemented as fully automated tactics of      the NuPRL proof development system and are based on an embedding the      implementation language of Ensemble into the logical       language of NuPRL. Together with verification techniques to be developed      in the near future they will lead to a logical      programming environment for the construction of reliable and efficient       group communication systems.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7362,A Software Architecture for Zero-Copy RPC in Java,"RPC has established itself as one of the more powerful communication paradigms for distributed computing. In recent years, object-oriented languages have impacted RPC semantics, with a number of variants providing remote method invocation and various forms of distributed object systems. At the same time, performance has changed little with the bottleneck being the network transport, in particular the in-kernel protocol implementations. This paper describes J-RPC, an RPC architecture that leverages user-level network interfaces (UNI) to circumvent the kernel on the critical path. It describes how the wire format and the RPC system can be engineered to allow zero-copy reception of Java objects and zero-copy transmission of arrays. All objects received are fully type-checked and can be directly used by the receiving program. The design is connection-oriented for performance and leverages the JVM's garbage collector when managing receive buffers. An implementation built from an off-the-shelf JVM and a commercial UNI is used to evaluate the architecture and the tradeoffs of type-safe, zero-copy data marshaling.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7363,"Formalizing Reference Types in NuPRL, PhD Thesis","This dissertation defines a Type Theory based semantics for Java-like reference type constructors. The primary focus is made on finding an adequate axiomatization of reference types in Type Theory. An extension of Type Theory, called {\em Reference Type Theory}, is introduced. It adds to the Type Theory language a reference type constructor and operations on reference type elements as primitive notions. The dissertation provides informal graph-based semantics for the Reference Type Theory, describes inference rules for this theory, and proves their consistency. Reference Type Theory is formalized in the Nuprl Proof Development System. This formalization is used to define a formal semantics for a fragment of the Java programming language and to verify several simple Java programs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7364,On the Structure of Syntenic Distance,"This paper examines some of the rich structure of the syntenic distance measure of the evolutionary distance between genomes.  This model, introduced by Ferretti, Nadeau, and Sankoff, abstracts away from the order of genes, and considers chromosomes as unordered sets of genes.  The syntenic distance between two genomes is given by the minimum number of moves (fusing two chromosomes, fissioning one chromosome, or completing a reciprocal translocation between two chromosomes) required to transform one into the other.  We consider previously unanalyzed approximation algorithm given by Ferretti et al, and prove that it is in fact a 2-approximation and that, further, it outperforms the algorithm presented by DasGupta et al on all instances.  We prove a number of properties which give insight into the structure of optimal move sequences.  We prove a monotonicity property for the syntenic distance, and give bounds on the number of moves required to solve the hardest instance of any given size.  We then demonstrate that there exist instances in which any move sequence working solely within connected components is $2 - \epsilon$ times longer than optimal, which indicates that all previously proposed approximation algorithms can be no better than 2-approximations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7365,Theory of Reference Types,"Type Theory language is extended by a new constructor to deal with types, representing circular data structures. Although this constructor was designed to model Java reference types, it is general enough to represent self-referring data in many other programming languages. Informal introduction of the new reference type constructor is followed by a set of inference rules and a proof of their consistency.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7366,Clustered File Generation and Its Application to Computer Science Taxonomies,"A clustered file organization is one where related, or similar records are  grouped into classes, or clusters of items in such a way that all items  within a cluster are jointly retrievable. Such a file organization is  advantageous for interactive searching where tentative query formulations may  be used and the records may be specified incompletely or approximately. An inexpensive file clustering method applicable to large files is given  together with an appropriate file search method. The method is used to cluster  a file of research articles in computer science based on citation similarities  between the papers; this leads to the identification of groups of active  computer science research topics and of productive computer scientists.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7367,A New Bayesian Framework for Object Recognition,"We describe a new approach to feature-based object recognition, using maximum a posteriori (MAP) estimation under a Markov random field (MRF) model.  The main advantage of this approach is that it allows explicit modeling of dependencies between individual features of an object. For instance, we use the approach to model the fact that mismatched features due to partial occlusions tend to form spatially coherent groups rather than being independent.  Efficient computation of the MAP estimate in our framework can be accomplished by finding a minimum cut on an appropriately defined graph.  An even more efficient approximation, that does not use graph cuts, is also presented.  This approximation technique, which we call spatially coherent matching (SCM), is closely related to generalized Hausdorff matching.  We report some Monte Carlo experiments showing that the SCM technique improves substantially on the tradeoff between correct detection and false alarms compared with previous feature matching methods such as the Hausdorff distance.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7368,Efficient Algorithms for Protein Sequence Design and the Analysis ofCertain Evolutionary Fitness Landscapes,"Protein sequence design is a natural inverse problem to protein structure prediction: given a target structure in three dimensions, we wish to design an amino acid sequence that is likely fold to it.  A model of Sun, Brem, Chan, and Dill casts this problem as an optimization on a space of sequences of hydrophobic (H) and polar (P) monomers; the goal is to find a sequence which achieves a dense hydrophobic core with few solvent-exposed hydrophobic residues.  Sun et al. developed a heuristic method to search the space of sequences, without a guarantee of optimality or near-optimality; Hart subsequently raised the computational tractability of constructing an optimal sequence in this model as an open question.  Here we resolve this question by providing an efficient algorithm to construct optimal sequences; our algorithm has a polynomial running time, and performs very efficiently in practice.  We illustrate the implementation of our method on structures drawn from the Protein Data Bank.  We also consider extensions of the model to larger amino acid alphabets, as a way to overcome the limitations of the binary H/P alphabet.  We show that for a natural class of arbitrarily large alphabets, it remains possible to design optimal sequences efficiently. Finally, we analyze some of the consequences of this sequence design model for the study of evolutionary fitness landscapes.  A given target structure may have many sequences that are optimal in the model of Sun et al.; following a notion raised by the work of J. Maynard Smith, we can ask whether these optimal sequences are ``connected'' by successive point mutations.  We provide a polynomial-time algorithm to decide this connectedness property, relative to a given target structure.  We develop the algorithm by first solving an analogous problem expressed in terms of submodular functions, a fundamental object of study in combinatorial optimization.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7369,Design and Evaluation of an Extensible Web and Telephony Server based on the J-Kernel,"This paper describes the design and performance of the J-Server, an integrated web and telephony server that allows untrusted Java servlets to be dynamically uploaded to extend the server's functionality. The J-Kernel provides for protection and communication between J-Server servlets, and ensures that servlets can be cleanly terminated. A resource monitor called JRes is used to account for servlet resource usage. Two sample applications show that the overhead of J-Kernel task boundary crossings is small compared to the applications' overall running time. Experience developing applications for the J-Server demonstrates the benefits of extensible systems based on safe language protection, and the flexibility of the servlet model.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7370,NAP: Practical Fault-Tolerance for Itinerant Computations,"NAP, a detection and recovery based scheme for implementing fault-tolerant itinerant computations, is presented. We give the semantics for the scheme and describe a protocol that implements NAP in Tacoma.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7371,Critical Infrastructures You Can Trust:  Where Telecommunications Fits,"This paper discusses two NISs: the public telephone network (PTN) and the Internet.  Being themselves large and complex NISs, they not only merit study in their own right but can help us to understand some of the technical problems faced by the developers and operators of other NISs.  In addition, the high cost of building a global communications infrastructure from the ground up implies that one or both of these two networks is likely to furnish communications services for most other NISs.  Therefore, an understanding of the vulnerabilties of the PTN and Internet informs the assessment of the trustworthiness of other NISs. Ideas for improving the trustworthiness of the PTN and Internet are also proposed, both for the short-term (by improved use of existing technologies and procedures) and for the long-term (by identifying some areas where the state-of-the-art is inadequate and research is therefore needed).  Finally, some observations are offered about Internet telephony and the use of the Internet for critical infrastructures.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7372,Resource Control for Database Extensions,"While object-relational database servers can be extended with user-defined functions (UDFs), the security of the server may be compromised by these extensions. The use of Java to implement the UDFs is promising because it addresses some security concerns. However, it still permits interference between different users through the uncontrolled consumption of resources. In this paper, we explore the use of a Java resource management mechanism (JRes) to monitor resource consumption and enforce usage constraints. JRes enhances the security of the server in the presence of extensions allowing for (i) detection and neutralization of denial-of-service attacks aimed at resource monopolization, (ii) monitoring resource consumption which enables precise billing of users relying on UDFs, and (iii) obtaining feedback that can be used for adaptive query optimization.   The feedback can be utilized either by the UDFs themselves or by the database system to dynamically modify the query execution plan. Both models have been prototyped in the Cornell Predator database system. We describe the implementation techniques, and present experiments that demonstrate the effects of the adaptive behavior facilitated by JRes. We conclude that, minimally, a database system supporting extensions should have a built-in resource monitoring and controlling mechanism. Moreover, in order to fully exploit information provided by the resource control mechanisms, both the query optimizer and the UDFs themselves should have access to this information.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7373,Client-Site Query Extensions,"We explore the execution of queries with client-site user-defined functions (UDFs). Many UDFs can only be executed at the client site, for reasons of scalability, security, confidentiality, or availability of resources. How should a query with client-site UDFs be executed? We demonstrate that the standard execution technique for server-site UDFs performs poorly. Instead, we adapt well-known distributed database algorithms and apply them to client-site UDFs. The resulting query execution techniques are implemented in the Cornell Predator database system, and we present performance results to demonstrate their effectiveness.  We also reconsider the question of query optimization in the context of client-site UDFs. The known techniques for expensive UDFs are inadequate because they do not take the location of the UDF into account. We present an extension of traditional 'System-R' optimizers that suitably optimize  queries with client-site operations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7374,A Compression Framework for Query Results,"Decision-support applications in emerging environments require that entire SQL query results be shipped to clients for further analysis and presentation. These clients may use low bandwidth connections (like modems) or have severe memory restrictions (like palmtops). Consequently, there is a need to compress the results of a query for efficient transfer and client-side storage. This paper explores a variety of techniques that address this issue. We model the problem as the choice of an appropriate compression plan and present a framework to model acceptable compression plans. The factors that influence this choice include schema information and statistics on stored tables. Importantly, we demonstrate that the query itself and its evaluation plan can provide semantic information that can be used to compress the result. We demonstrate that these techniques can result in 75% greater compression than standard compression tools like WinZip on queries adapted from the TPC-D benchmark. We identify two topics for future research: the choice of an optimal compression plan, and the integration of query result compression into the regular query evaluation plan.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7375,Intensional Polymorphism in Type-Erasure Semantics,"Intensional polymorphism, the ability to dispatch to   different routines based on types at run time, enables a variety of advanced implementation techniques for polymorphic languages, including tag-free garbage collection, unboxed function arguments, polymorphic marshalling, and flattened data structures.  To date, languages that support intensional polymorphism have required a type-passing (as opposed to type-erasure) interpretation where types are constructed and passed to polymorphic functions at run time. Unfortunately, type-passing suffers from a number of drawbacks: it requires duplication of constructs at the term and type levels, it prevents abstraction, and it severely complicates polymorphic closure conversion. We present a type-theoretic framework that supports intensional polymorphism,  but avoids many of the disadvantages of type passing.  In our approach, run-time type information is represented by ordinary terms.  This avoids the duplication problem, allows us to recover  abstraction, and avoids complications with closure conversion.  In addition,  our type system provides another improvement in expressiveness;  it allows unknown types to be refined in place thereby avoiding certain beta-expansions required by other frameworks.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7376,"Decidability Extracted: Synthesizing ""Correct-by-Construction"" DecisionProcedures from Constructive Proofs","The topic of this thesis is the extraction of efficient and readable programs from formal constructive proofs of decidability.  The proof methods employed to generate the efficient code are new and result in clean and readable Nuprl extracts for two non-trivial programs.  They are based on the use of Nuprl's set type and techniques for extracting efficient programs from induction principles. The constructive formal theories required to express the decidability theorems are of independent interest. They formally circumscribe the mathematical knowledge needed to understand the derived algorithms. The formal theories express concepts that are taught at the senior college level.  The decidability proofs themselves, depending on this material, are of interest and are presented in some detail. The proof of decidability of classical propositional logic is relative to a semantics based on Kleene's strong three-valued logic.  The constructive proof of intuitionistic decidability presented here is the first machine formalization of this proof.  The exposition reveals aspects of the Nuprl tactic collection relevant to the creation of readable proofs; clear extracts and efficient code are illustrated in the discussion of the proofs.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7377,On Hoare Logic and Kleene Algebra with Tests,We show that Kleene algebra with tests subsumes propositional Hoare logic.  Thus the specialized syntax and deductive apparatus of Hoare logic are inessential and can be replaced by ordinary equational reasoning.  It follows from the reduction that propositional Hoare logic is in PSPACE; we show that it is PSPACE-complete.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7378,Parikh's Theorem in Commutative Kleene Algebra,"Parikh's Theorem says that the commutative image of every  context free language is the commutative image of some regular  set.  Pilling has shown that this theorem is essentially a  statement about least solutions of polynomial inequalities.   We prove the following general theorem of commutative Kleene  algebra, of which Parikh's and Pilling's theorems are special  cases: Every system of polynomial inequalities  $f_i(x_1,\ldots,x_n) \leq x_i$, $1\leq i\leq n$, over a  commutative Kleene algebra $K$ has a unique least solution  in $K^n$; moreover, the components of the solution are given  by polynomials in the coefficients of the $f_i$.  We also give  a closed-form solution in terms of the Jacobian matrix.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7379,A Characterization Study of NCSTRL Distributed Searching,"NCSTRL, the Networked Computer Science Technical Reference Library, is a federated digital library based on the Dienst architecture.  One aspect of this architecture is distributed searching, with digital library queries being dispatched from query routers to globally distributed indexers that process them and return results.  We studied user data for a two-month period at five query routers in order to characterize some key performance aspects of distributed searching in an operational digital library.  This study uncovered the following characteristics. Query processing at NCSTRL servers involves significant time waiting for responses from indexers. Each indexer's availability and response times appear unique to each query router. Different indexers' availability and response times are not similar from the viewpoint of a single query router. Query router waiting time for indexers is larger than indexer processing time, implying that communication time over the network is significant. We close by examining the breakdown of NCSTRL queries: the number of fielded vs. non-fielded queries, and the complexity of these queries.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7380,A Review of Experiences with Reliable Multicast,"By understanding how real users have employed reliable multicast in real distributed systems, we can develop insight concerning the degree to which this technology has matched expectations.  This paper reviews a number of applications with that goal in mind.   Our findings point to tradeoffs between the form of reliability used by a system and its scalability and performance.  We also find that to reach a broad user community (and a commercially interesting market) the technology must be better integrated with component and object-oriented systems architectures.  Looking closely at these architectures, however, we identify some assumptions about failure handling which make reliable multicast difficult to exploit.  Indeed, the major failures of reliable multicast are associated with attempts to position it within object oriented systems in ways that focus on transparent recovery from server failures.  The broader opportunity appears to involve relatively visible embeddings of these tools into object-oriented architectures enabling knowledgeable users to make tradeoffs. Fault-tolerance through transparent server replication may be better viewed as an unachievable holy grail.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7381,Interfacing Java with the Virtual Interface Architecture,"User-level network interfaces (UNIs) have reduced the overheads of communication by exposing the buffers used by the network interface DMA engine to the applications. This removes the kernel from the critical path of message transmission and reception, and it reduces the number of data copies performed on that path. Unfortunately, the fact that UNIs require the application to manage buffers explicitly makes it difficult to provide direct access to a UNI from Java, as the language explicitly prevents programs from controlling the location or layout of objects. This paper describes Javia, a Java interface to the Virtual Interface Architecture (VIA), an emerging UNI standard in the industry. Javia implements a special buffer abstraction that allows Java programs to allocate arrays in pinned memory and use them as communication buffers without copy. The location and lifetime of these arrays are controlled through small modifications to the garbage collector. Simple experiments show that Java programs can achieve round-trip times of 21us for small messages and bandwidths of 95Mbytes/sec for 4Kbyte messages.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7382,Efficient and Accurate Ethernet Simulation,"The Internet is increasingly being called upon to provide different levels of service to different applications and users. A practical problem in doing so is that although Ethernet is one of the hops for nearly all communication in the Internet, it does not provide any QoS guarantees. A natural question, therefore, is the effect of offered load on Ethernet throughput and delay. In this paper, we present several techniques for accurately and quickly modeling the behavior of a heavily loaded Ethernet link. We first present a distributed approach to exact simulation of Ethernet, which eliminates sophisticated collision detection. Then, we describe an efficient distributed simulation model, called Fast Ethernet Simulation, that empirically models an Ethernet link to quickly and accurately simulate it. By eliminating the implementation of CSMA/CD protocol, our approach reduces computational complexity drastically while still maintaining desirable accuracy. Performance results show that our techniques not only add very little overhead (less than 5 in our tests) to the basic cost of simulating an Ethernet link, but also closely match real-world mesurements. We also present efficient techniques for compressing cumulative distributions using hyperbolic curves and for monitoring the load on a heavily-loaded link.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7383,Image Disorientation Auto-Recovery,"Automatically detecting and correcting disoriented image frames in a content-related image sequence is a problem that must be  addressed in many image and video applications. In this paper,  we give a robust feature-based algorithm to efficiently detect  and adjust the disorientation of images.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7384,Detecting Static Objects in Busy Scenes,"Detecting static objects in scenes containing significant number  of moving objects has several applications in video surveillance. One  example is the detection of suspicious packages which is left unattended in an airport terminal or railway station.  This paper  outlines an approach to automatically detect static objects from a video sequence of a busy scene. Our approach consists of two phase : foreground  object extraction and object matching.  In the first phase, we find  the foreground objects in current video frame, using an image of a background  as reference.  In the object matching phase, we try to match the objects with objects that appears before in previous frames.  Matching is done based on three parameter : shape and position, intensity and edge. Temporary occluded  of objects is also handled.  We built a system based on our approach.  Preliminary experiments shows that our system are able to identify static objects in  a busy scene in real time.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7385,Optimizing TCP Start-up Performance,"The performance of many networking protocols is dependent on a  handful of tuning parameters. However, it is not obvious how to set or adapt these parameters to optimize performance. We  believe that this optimization task can benefit from passive monitoring of current network performance.  In this paper, we apply this methodology for initializing TCP  parameters, such as initial congestion window size and slow  start threshold for short connections. We analytically derive  the optimal initial parameters, and use simulations to study  its effectiveness.  Our innovations include: (i) derivation of optimal TCP initial parameters as a function of link  characteristics; (ii) abstract a communication path as a  virtual link and model cross traffic as perturbation on it;  (iii) an efficient architecture for network performance  discovery; (iv) a new pacing algorithm that combines leaky  bucket flow control with traditional window-based flow control.  Our results show this approach leads to significant performance improvement.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7386,Relational Algebraic Techniques for the Synthesis of Sparse MatrixPrograms,"Sparse matrix computations are ubiquitous in computational science. However, the development of high-performance software for sparse matrix computations is a tedious and error-prone task, for two reasons. First, there is no standard way of storing sparse matrices, since a variety of formats are used to avoid storing zeros, and the best choice for the format is dependent on the problem and the architecture. Second, for most algorithms, it takes a lot of code reorganization to produce an efficient sparse program that is tuned to a particular format. We view the problem of supporting effective development of high-performance sparse matrix codes as one of {\em generic   programming}.  Generic programming is a discipline of designing and implementing software components which can be used when there is a set of {\em related data structures} supporting a common semantics described by an API or protocol, and a set of {\em common   algorithms} that can be formulated in terms of this API. When designing a generic programming system one must address the following fundamental questions: -- How do we  represent efficient algorithms independently of any particular data-representation scheme? -- How do we provide an interface to a diverse set of data-structures? -- How do we ``knit'' together the representation of the algorithms and the representation for the data to obtain an efficient implementation? This dissertation presents a {\em relational algebraic model} for automatically generating efficient sparse codes starting with dense matrix codes and specification of sparse matrix formats.  Our techniques are based on viewing arrays as relations and the execution of DOALL loop nests and loops with reductions as evaluation of queries over these relations. Storage formats are specified to the compiler through search and enumeration access methods and their costs.  Code restructuring is then formulated as the search for the most efficient plan for the query.  The main step in this process is the identification of simultaneous enumeration of data structures (relational joins) and the determination of the best implementations of this enumeration.  This software architecture not only provides for a clean design of the compiler, but it also exposes additional opportunities for code optimization and has led us to more general transformation algorithms than previously reported in the literature. We present experimental data that demonstrates that the code generated by our compiler achieves performance competitive with that of hand-written codes for important computational kernels.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7387,Insight into Theorem Proving via Eye Movements,"We are implementing an automated theorem proving system that will in part attempt to simulate human per-formance on calculational logic. To support this project, we recorded and analyzed people's eye movements while they constructed calculational proofs. Our find-ings confirm some expected behaviors (based on strate-gies and principles taught to students) that previously may have seemed untestable, such as the influence of the form of the current proof step and of syntax in gen-eral on the moment-by-moment computations of the problem solver. The experiment also uncovered other interesting patterns, such as the seemingly inefficient but widely occurring tendency to attend to particular premises despite their not being used in the proof under consideration. Overall, we gained insights into real-time problem solving that directly apply to our automated system and could not have been gained merely by studying written proofs. Our findings also demonstrate that analyses of eye movements can improve our under-standing of the psychology of theorem proving.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7388,Importing Isabelle Formal Mathematics into NuPRL,"Isabelle and NuPRL are two theorem proving environments that are written in different dialects of ML using different formula syntaxes and different logical foundations. In spite of this, they have similar sets of basic theories, representing the same mathematical concepts. This paper presents the design of an automated converter from Isabelle into NuPRL that allows sharing formal knowledge between these two provers. Such sharing eliminates the need for re-proving the same results in different systems and opens door for joint work on large verification projects. The paper starts with an overview of the problem and of the related works. The second part outlines the embedding of Isabelle syntax into NuPRL and technical details of the converter design. In the third section logical soundness of this embedding is shown.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7389,Weighting Unusual Feature Types,"Feature weighting is known empirically to improve classification accuracy for k-nearest neighbor classifiers in tasks with irrelevant features.  Many feature weighting algorithms are designed to work with symbolic features, or numeric features, or both, but cannot be applied to problems with features that do not fit these categories.  This paper presents a new k-nearest neighbor feature weighting algorithm that works with any kind of feature for which a distance function can be defined.  Applied to an image classification task with unusual set-like features, the technique improves classification accuracy significantly.  In tests on standard data sets from the UCI repository, the technique yields improvements comparable to weighting features by information gain.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7390,Approximately Optimal Elimination Orderings for Sparse Matrices,PhD thesis of Wee-Liang Heng,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7391,NAP: Practical Fault-Tolerance for Itinerant Computations,"NAP is a protocol for supporting fault-tolerance in intinerant computations. It employs a form of failure detection and recovery, and it generalizes the primary-backup approach to a new compuational model. The guarantees offered by NAP as well as an implementation for NAP in Tacoma are discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7392,Type Dispatch for Named Hierarhical Types,"Type dispatch constructs are an important feature of many programming languages.  Scheme has predicates for testing the runtime type of a value.  Java has a class cast expression and a try statement for switching on an exception's class.  Crucial to these mechanisms, in typed languages, is type refinement: The static type system will use type dispatch to refine types in successful dispatch branches.  Existing work in functional languages has addressed certain kinds of type dispatch, namely, intensional type analysis.  However, this work does not extend to languages with subtyping nor to named types. This paper describes a number of type dispatch constructs that share a common theme: class cast and class case constructs in object oriented languages, ML style exceptions, hierarchical extensible sums, and multimethods. I describe a unifying mechanism, {\em tagging}, that abstracts the operation of these constructs, and formalise a small tagging language.  After discussing how to implement the tagging language, I present a more primitive language and give a formal translation from the tagging language.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7393,A Multicast Flow Control Protocol,"This paper describes the goals, approach, implementation, and performance of Mflow, a multicast flow control protocol.  Our work focuses on the issues that arise from the increase in acknowledgments that occur as the size of the group grows.  Mflow makes use of bulk acknowledgments to substantially reduce the number of acknowledgments per multicast message.  It also staggers acknowledgments from different destinations to avoid storms of messages.  We demonstrate that staggering can both decrease the number of acknowledgments needed for effective flow control as well as increase the robustness of the protocol to changes in the environment.  We analyze both message and computation efficiency of Mflow.  The protocol is computationally efficient and performs well in our experiments.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7394,A Type System for Expressive Security Policies,"{\em Certified code} is a general mechanism for enforcing security properties.  In this paradigm, untrusted agent code carries annotations that allow a host to verify its trustworthiness. Before running the agent, the host checks the annotations and proves that they imply the host's security policy.   Despite the flexibility of this scheme, so far, compilers that generate proof-carrying code have focused on simple memory and control-flow safety rather than more general security properties. {\em Security automata} can enforce an expressive collection of security policies including access control policies and resource bounds  policies.  In this paper, we show how to take specifications in the form of security automata and automatically transform them into signatures for a typed lambda calculus that will enforce the corresponding safety property.  Moreover, we describe how to instrument typed source language programs with security checks and typing annotations so that the resulting programs are provably secure and can be mechanically checked.  This work provides a foundation for the process of automatically generating secure certified code in a type-theoretic framework.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7395,Revisiting the Weakest Failure Detector for Uniform Reliable Broadcast,"Uniform Reliable Broadcast (URB) is a communication primitive that requires that if a process delivers a message, then all correct processes also deliver this message.  A recent PODC paper [HR99] uses Knowledge Theory to determine what failure detectors are necessary to implement this primitive in asynchronous systems with process crashes and lossy links that are fair.  In this paper, we revisit this problem using a different approach, and provide a result that is simpler, more intuitive, and, in a precise sense, more general.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7396,WebScript -- A Scripting Language for the Web,"WebScript is a scripting language for processing Web documents.  Designed as an extension to Jacl, the Java implementation of  Tcl, WebScript allows programmers to manipulate HTML in the same  way as Tcl manipulates text strings and GUI elements. This leads  to a completely new way of writing the next generation of Web  applications. This paper presents the motivation behind the  design and implementation of WebScript, an overview of its major  features, as well as some demonstrations of its power.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7397,Predicting Indexer Performance in a Distributed Digital Library,"Resource discovery in a distributed digital library poses many challenges, one of which is how to choose search engines for query distribution, given a query and a set of search engines.  This paper focuses on search engine performance as a criterion for search engine selection and defines two measurements of search engine performance: availability - will the search engine respond within a time limit and response time - how quickly will the search engine respond, given that it responds at all.  We predicted both of these performance characteristics with a variety of algorithms, all of which required little computation time and combined past performance data for each search engine into a succinct record.  We used operational data from the NCSTRL distributed digital library to make and evaluate predictions, and we found that simple prediction methods performed as well as more complex methods and that prediction accuracy was closely related to data consistency.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7398,On Individual and Aggregate TCP Performance,"As the most widely used reliable transport in today's  Internet, TCP has been extensively studied in the past  decade. However, previous research usually only considers  a small or medium number of concurrent TCP connections. The TCP behavior under many competing TCP flows has not  been sufficiently explored.  In this paper we use extensive simulations to investigate  the individual and aggregate TCP performance for large  number of concurrent TCP flows.  We have made three major  contributions.  First, we develop an abstract network model  that captures the essence of wide-area Internet  connections. Second, we study the performance of a single  TCP flow with many competing TCP flows by evaluating the  best-known analytical model proposed in the literature.   Finally, we examine the aggregate TCP behavior exhibited  by many concurrent TCP flows, and derive general  conclusions about the overall throughput, goodput, and  loss probability.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7399,Bimodal Multicast (revised),"There are many methods for making a multicast protocol ""reliable"".  At one end of the spectrum, a reliable multicast protocol might offer atomicity guarantees, such as all-or-nothing delivery, delivery ordering, and perhaps additional properties such as virtually synchronous addressing. At the other are protocols that use local repair to overcome transient packet loss in the network, offering 'best effort' reliability. Yet none of this prior work has treated stability of multicast delivery as a basic reliability property, such as might be needed in an internet radio, TV, or conferencing application. This paper looks at reliability with a new goal: development of a multicast protocol which is reliable in a sense that can be rigorously quantified and includes throughput stability guarantees.  We characterize this new protocol as a ""bimodal multicast"" in reference to its reliability model, which corresponds to a family of bimodal probability distributions.  Here, we introduce the protocol, provide a theoretical analysis of its behavior, review experimental results, and discuss some candidate applications.  These confirm that bimodal multicast is reliable, scalable, and that the protocol provides remarkably stable delivery throughput.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7400,Programming Language Translation,"As programming languages become more and more diversified,  there is an increasing demand to translate programs written in  one high-level language into another. Such translation can help  us more effectively reuse the existing code, especially when  automating translation is possible. However due to many subtle  distinctions between different languages, usually only a subset  of translation can be automated. The first half of the paper  describes the details of automating most of the translation from  C to C++, as well as the difficulties encountered. The second  half of the paper talks about the experience of manually porting  Java programs to C++, and identifies some of the issues and  challenges in automating this translation process. Through the  discussions, it is evident that translation is heavily language  specific. Comprehensive knowledge about the languages and their  subtle distinctions is essential. On the other hand, designing  tools to allow high level specification of translation rules and  effectively incorporate human interaction is a generic approach  to any language translation problem, which is an interesting  research problem to explore.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7401,A Survey of Web Caching Schemes for the Internet,"The World Wide Web can be considered as a large distributed  information system that provides access to shared data objects. As one of the most popular applications currently running on the Internet, the size of World Wide Web is of an exponential growth, which results in network congestion and server overloading. Web  caching has been recognized as one of the effective schemes to  alleviate the server bottleneck and reduce the network traffic, thereby minimize the user access latencies. In this paper, we  first discribe the elements of a Web caching system and its  desirable properties. Then, we survey the state-of-art  techniques which have been used in Web caching systems. Finally,  we discuss the research frontier in Web caching.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7402,Scalability of Two Reliable Multicast Protocols,"Growing demand for multicast commun-ication in large network settings has focused attention on the scalability of reliable multicast protocols.  Our paper uses both simulation tools and experiments to compare two scalable protocols, focusing on an aspect not often studied: we emphasize stability of latency distributions as these protocols scale, although also considering overhead and link utilization.   These properties are considered in a variety of network topologies and with several levels of packet loss.  Our findings confirm that SRM scales poorly under some conditions: to obtain reliability, the protocol incurs overhead linear in group size and throughput fluctuates erratically.  We also show that SRM latencies can be very large and that latency distributions are unstable as a function of group size and network topology.  Our own protocol, Bimodal Multicast, also exhibits overhead growth, but the rate of growth is slow, and latency distributions and delivery throughput rates are stable.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7403,Efficient and Accurate Ethernet Simulation (revised),"The Internet is increasingly being called upon to provide  different levels of service to different applications and users.  A practical problem in doing so is that although Ethernet is one  of the hops for nearly all communication in the Internet, it  does not provide any QoS guarantees. A natural question,  therefore, is the effect of offered load on Ethernet throughput and delay. In this paper, we present several techniques for  accurately and efficiently modeling the behavior of a heavily  loaded Ethernet link. We first present a distributed approach to exact simulation of Ethernet. Then, we describe an efficient distributed simulation model, called Fast Ethernet Simulation,  that empirically models an Ethernet link to quickly and  accurately simulate it. By eliminating the implementation of  CSMA/CD protocol, our approach reduces computational complexity  drastically while still maintaining desirable accuracy.  Performance results show that our techniques not only add very  little overhead (less than 5% in our tests) to the basic cost of simulating an Ethernet link, but also closely match real-world  measurements. We also present efficient techniques for  compressing cumulative distributions using hyperbolic curves and for monitoring the load on a heavily loaded link. Finally, we  show applications to illustrate the potential usage of the Fast  Ethernet Simulation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7404,Pervasive Query Processing,"We propose a radical departure from the architecture of conventional server-centered database query processing systems. Instead, we propose pervasive query processing on every component of the system: the server, the clients, and the storage components. The demands of modern applications and the current technology trends suggest that it is a significant limitation to require that all query processing is confined to the server. Consequently, we develop an architecture that is based on query processing engines that are integrated on every site of the database system. These software platforms that allow the execution of portable database programs on a variety of underlying physical platforms are called Database Virtual Machines.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7405,Language-Based Security,"Security of mobile code is a major issue in today's global computing environment.  When you download a program from an untrusted source, how can you be sure it will not do something undesirable?  In this paper I will discuss a particular approach to this problem called language-based security.  In this approach, security information is derived from a program written in a high-level language during the compilation process and is included in the compiled object.  This extra security information can take the form of a formal proof, a type annotation, or some other form of certificate or annotation. It can be downloaded along with the object code and automatically verified before running the code locally, giving some assurance against certain types of failure or unauthorized activity.  The verifier must be trusted, but the compiler, code, and certificate need not be.  Java bytecode verification is an example of this approach.  I will give an overview of some recent work in this area, including a particular effort in which we are trying to make the production of certificates and the verification as efficient and invisible as possible.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7406,Principals in Programming Languages: Technical Results,"This is the companion technical report for ``Principals in   Programming Languages''   [20].  See that document   for a more readable version of these results.   In this paper, we describe two variants of the simply typed   $\lambda$-calculus extended with a notion of {\em principal}.  The   results are languages in which intuitive statements like ``the   client must call $\mathtt{open}$ to obtain a file handle'' can be   phrased and proven formally.     The first language is a two-agent calculus with references and   recursive types, while the second language explores the possibility   of multiple agents with varying amounts of type information.  We use   these calculi to give syntactic proofs of some type abstraction    results that traditionally require semantic arguments.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7408,The Implication of Network Performance on Service Quality,"As the Internet infrastructure evolves to include Quality of  Service (QoS), it is necessary to map application quality  requirements to the the network performance specifications in  terms of delay and loss rate. While past work has addressed the  dependency of audio and video applications on these underlying  QoS metrics, little work has been done in the area of Web  traffic. In this paper, we use a combination of emulation,  simulation, and analysis to quantify the effect of network  performance metrics on HTTP request latency and the perceptual  quality of an audio application. Although our work is done in  the context of a LAN environment, the results generalize to a  more general WAN environment. Our contributions are three-fold.  First, we combine simulation and emulation techniques in setting up an accurate yet controllable testbed. The use of network  simulator Entrapid and its built-in Fast Ethernet Simulation  makes our simulation both efficient and accurate. Second, for  Web applications, we define a new TCP short connection model  that computes the latency of Web retrieval accurately and  efficiently given only packet delay and loss rate characteristics apriori. Experiments show that our model significantly improves  the accuracy of the best-known TCP short connection model by  correctly capturing TCP retransmission behavior. Finally, for  Internet telephony, we show that the packet delay variance is  the dominant network characteristics which affect the perceptual quality. As a result, the service quality drops dramatically when the Ethernet offered load reaches 80%. This can serve as a  guideline for studies towards improving service quality of Internet telephony.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7409,A Generic Programming System for Sparse Matrix Computations,"Sparse matrices are stored in compressed formats in which zeros are not stored explicitly. Writing high-performance sparse matrix libraries is a difficult and tedious job because there are many compressed formats in use and each of them requires specialized code. In this paper, we argue that (i) compressed formats should be viewed as {\em indexed-sequential access structures} (in the database sense), and (ii) efficient sparse codes exploit such indexing structures wherever possible. This point of view leads naturally to restructuring compiler technology that can be used to synthesize many sparse codes from high-level algorithms and specifications of sparse formats, exploiting indexing structures for efficiency. We show that appropriate abstractions of the indexing structures of commonly used formats can be provided to such a compiler through the type structure of a language like C++. Finally, we describe experimental results obtained from the {\em Bernoulli Sparse Compiler} which demonstrate that the performance of code generated by this compiler is comparable to the performance of programs in the NIST Sparse BLAS library. One view of this system is that it exploits restructuring compiler technology to perform a novel kind of template instantiation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7410,Unsupervised Statistical Segmentation of Japanese Kanji Strings,Word segmentation is an important issue in Japanese language processing because Japanese is written without space delimiters between words.  We propose a simple dictionary-less method to segment Japanese kanji sequences into words based solely on character $n$-gram counts from an unannotated corpus.  The performance was often better than that of rule-based morphological analyzers over a variety of both standard and novel error metrics.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7411,Efficient Buffering in Reliable Multicast Protocols,"Reliable multicast protocols provide all-or-none delivery to participants.  Traditionally, such protocols suffer from large buffering requirements, as receivers have to buffer messages, and buffer sizes grow with the number of participants.  In this paper, we describe an optimization that allows such protocols to reduce the amount of buffering drastically at the cost of a very small probability that all-or-none delivery is violated. We analyze this probability, and simulate an optimized version of an epidemic multicast protocol to validate the effectiveness of the optimization.  We find that the buffering requirements are sub-constant, that is, the requirements shrink with group size, while the probability of all-or-none violation can be set to very small values.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7412,SASI Enforcement of Security Policies:  A Retrospective,SASI enforces security policies by modifying object code for a target system before that system is executed.  The approach has been prototyped for two rather different machine architectures: Intel x86 and Java JVML.  Details of these prototypes and some generalizations about the SASI approach are discussed.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7413,Enforceable Security Policies,"A precise characterization is given for the class of security policies enforceable with mechanisms that work by monitoring system execution, and automata are introduced for specifying exactly that class of security policies.  Techniques to enforce security policies specified by such automata are also discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7414,"On Hoare Logic, Kleene Algebra, and Types",We show that propositional Hoare logic is subsumed by the type calculus of typed Kleene algebra augmented with subtypes and typecasting.  Assertions are interpreted as typecast operators. Thus Hoare-style reasoning with partial correctness assertions reduces to typechecking in this system.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7415,A Generic Programming System for Sparse Matrix Computations (REVISED),"Sparse matrices are stored in compressed formats in which zeros are not stored explicitly. Writing high-performance sparse matrix libraries is a difficult and tedious job because there are many compressed formats in use and each of them requires specialized code. In this paper, we argue that (i) compressed formats should be viewed as {\em indexed-sequential access structures} (in the database sense), and (ii) efficient sparse codes exploit such indexing structures wherever possible. This point of view leads naturally to restructuring compiler technology that can be used to synthesize many sparse codes from high-level algorithms and specifications of sparse formats, exploiting indexing structures for efficiency. We show that appropriate abstractions of the indexing structures of commonly used formats can be provided to such a compiler through the type structure of a language like C++. Finally, we describe experimental results obtained from the {\em Bernoulli Sparse Compiler} which demonstrate that the performance of code generated by this compiler is comparable to the performance of programs in the NIST Sparse BLAS library. One view of this system is that it exploits restructuring compiler technology to perform a novel kind of template instantiation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7416,A Bayesian Framework for Model Based Tracking,"We present a Bayesian framework for tracking an object in a sequence of image frames.  A maximum a posteriori (MAP) recognition method is used to detect the object in each image frame, and a Kalman filter is used to estimate the true location from these observed locations.  There is a natural feedback loop between the recognition method and the Kalman filter. The recognition method requires a prior on object location which is provided by the Kalman filter, and the Kalman filter requires an observed location which is provided by the recognition method.  This framework has two desirable properties.  First, the threshold for recognition in each frame depends on the system noise of the Kalman filter.  This allows the system to identify partially occluded or distorted objects as long as the predicted locations are accurate.  But requires a very good match if there is uncertainty as to the object location.  Second, the search area for the recognition method is adaptively pruned using the current level of noise in the system, yielding an efficient overall method. Promising experimental  results are demonstrated.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7417,Object Closure Conversion,"An integral part of implementing functional languages is closure conversion-the process of converting code with free variables into closed code and auxiliary data structures.  Closure conversion has been extensively studied in this context, but also arises in languages with first-class objects.  In fact, one variant of Java's inner classes are an example of objects that need to be closure converted, and the transformation for converting these inner classes into Java Virtual Machine classes is an example of closure conversion.  This paper argues that a direct formulation of object closure conversion is interesting and gives further insight into general closure conversion.  It presents a formal closure-conversion translation for a second-order object language and proves it correct.  The translation and proof generalise to other object-oriented languages, and the paper gives some examples to support this statement.  Finally, the paper discusses the well known connection between function closures and single-method objects. This connection is formalised by showing that an encoding of functions into objects, object closure conversion, and various object encodings compose to give various closure-conversion translations for functions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7418,Optimized Group Rekey for Group Communications Systems,"In this paper we describe an efficient algorithm for the management of  group keys. Our algorithm is based on a protocol for secure IP-multicast and is used to manage group-keys in group-communications systems. Unlike prior work, based on centralized key-servers, our solution is completely distributed and fault-tolerant, and its performance is comparable to the centralized solution.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7419,Safe and Efficient Cluster Communication in Java using Explicit MemoryManagement,"This thesis presents a framework for using explicit memory management to improve the communication performance of JavaTM cluster applications. The framework allows programmers to explicitly manage Java communication buffers, called jbufs, which are directly accessed by the DMA engines of high-performance network interfaces and by Java programs as primitive-typed ar-rays. The central idea is to remove the hard separation between Java's gar-bage-collected heap and the non-collected memory region in which DMA buffers must normally be allocated. The programmer controls when a jbuf is part of the garbage-collected heap so that the garbage collector can ensure it is safely re-used or de-allocated, and when it is not so it can be used for DMA transfers. Unlike other techniques, jbufs preserve Java's storage- and type-safety and do not depend on a particular garbage collection scheme. The safety, efficiency, and programmability of jbufs are demonstrated throughout this thesis with implementations of an interface to the Virtual In-terface Architecture, of an Active Messages communication layer, and of Java Remote Method Invocation (RMI). The impact on applications is also evalu-ated using an implementation of cluster matrix multiplication as well as a publicly available RMI benchmark suite. The thesis proposes in-place object de-serialization (de-serialization with-out allocation and copying of objects) to further enhance the performance of RMI on homogeneous clusters. This optimization takes advantage of the zero-copy capabilities of network devices to reduce the per-object de-serialization costs to a constant irrespective of object size, which is particularly beneficial for large objects such as arrays. In-place de-serialization is realized using jstreams, an extension of jbufs with object I/O streams. Jstreams use the ex-plicit memory management offered by jbufs to incorporate de-serialized ob-jects into the receiving Java virtual machine without compromising its integrity, without restricting the usage of those objects, and without making assumptions about the underlying garbage collection scheme. The perform-ance impact of jstreams on Java RMI and the benchmark suite is evaluated.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7420,On the Completeness of Propositional Hoare Logic,"We investigate the completeness of Hoare Logic on the propositional level.  In particular, the expressiveness requirements of Cook's proof are characterized propositionally. We give a completeness result for Propositional Hoare Logic (PHL): all relationally valid rules   	{b1}p1{c1}, ..., {bn}pn{cn}         ---------------------------                             {b}p{c}   are derivable in PHL, provided the propositional expressiveness conditions are met.  Moreover, if the programs pi in the premises are atomic, no expressiveness assumptions are needed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7421,A Scalable Efficient Robust Adaptive (SERA) Architecture for the NextGeneration of Web Service,"The World Wide Web can be considered as a large distributed  information system that provides access to shared data objects.  As one of the most popular applications currently running on the  Internet, the World Wide Web is of an exponential growth in  size, which results in network congestion and server overloading.  Web caching has been recognized as one of the effective schemes  to alleviate the service bottleneck and reduce the network  traffic, thereby minimize the user access latency. In this paper,  we propose a Scalable Efficient Robust Adaptive (SERA) Web  caching architecture which accommodates the exponential growth  and extreme dynamic environment of the World Wide Web. We  developed a piggybacked prefetching/pre-resolving scheme, which  uses user access pattern and network environment information.  Cooperative consistency control mechanism is employed to further  improve the performance. In order to assist the cache  resolution, an efficient cache routing scheme is employed. A  loose group membership is maintained among nearby proxy caches  to make the entire caching system scalable and fault tolerant.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7422,ITX Programmer's Guide,"ITX is a set of Java packages which allow one to write telephony applications in Java.  (Some sample applications are provided with the ITX distribution.)  This Guide introduces the reader to the ITX Application Programming Interface (API), starting with an overview. Subsequent sections explain each component of the API in more detail.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7423,Formalization of Isabelle Meta Logic in NuPRL,"NuPRL and Isabelle are two general purpose theorem provers. Both of them are based on a version of Constructive Higher Order Type Theory. In an earlier work the author has proposed an informal semantics of Isabelle Meta Logic in an extension of NuPRL Type Theory. An automated converter, based on this semantics, has been developed, that translates Isabelle theorem statements into NuPRL. This work presents a formalization of the above semantics in NuPRL. It starts with a deep embedding of Isabelle type and term syntax into NuPRL Constructive Type Theory. Next, two internal NuPRL functions are defined. One of them maps Isabelle types into NuPRL types and the other maps Isabelle terms into elements of appropriate NuPRL types. These two functions provide an interpretation of Isabelle in NuPRL. Finally, interpretations of all Isabelle Meta Logic rules are proven as theorems in some classical extension of NuPRL Type Theory.  This formalization is aimed to provide a more secure foundation for the interaction between two systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7424,Tiling Imperfectly-nested Loops,"Tiling is one of the more important transformations for enhancing locality of reference in programs. Intuitively, tiling a set of loops achieves the effect of interleaving iterations of these loops. Tiling has been applied only to perfectly-nested loop nests which are loop nests in which all assignment statements are contained in the innermost loop. In practice, most loop nests are imperfectly-nested, so existing techniques have limited utility. In this paper, we propose an approach to tiling imperfectly-nested loop nests. The key idea is to embed the iteration space of every statement in the imperfectly-nested loop nest into a special space called the product space which is tiled to produce the final code. We evaluate the effectiveness of this approach for dense numerical linear algebra benchmarks, relaxation codes, and the tomcatv code from the SPEC benchmarks.  No other approach in the literature can tile all these codes automatically.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7425,Justifying Calculational Logic by a Conventional Metalinguistic Semantics,"We provide a metalinguistic formalization of calculational logic, an alternative to higher-order logic for escaping the restrictions of first-order logic.  We show that conventional semantic techniques can provide an adequate foundation for calculational logic, even its atypical metalinguistic features.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7426,Securing Ad Hoc Networks,"Ad hoc networks are a new wireless networking paradigm for mobile hosts.  Unlike traditional mobile wireless networks, ad hoc networks do not rely on any fixed infrastructure. Instead, hosts rely on each other to keep the network connected. The military tactical and other security-sensitive operations are  still the main applications of ad hoc networks, although there is a trend to adopt ad hoc networks for commercial uses due to their unique properties.  One main challenge in design of these networks is their vulnerability to security attacks. In this paper, we study the threats an ad hoc network faces and the security goals to be achieved.  We identify the new challenges and opportunities posed  by this new networking environment and explore new approaches to secure its communication. In particular, we take advantage of the inherent redundancy in ad hoc  networks --- multiple routes between nodes --- to defend routing against  denial of service attacks.  We also use replication and new cryptographic schemes, such as threshold cryptography, to build a highly secure and highly available key management service, which forms the core of our security framework.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7427,Alias Types,"Linear type systems allow destructive operations such as object deallocation and imperative updates of functional data structures. These operations and others, such as the ability to reuse memory at different types, are essential in low-level typed languages.  However, traditional linear type systems are too restrictive for use in low-level code where it is necessary to exploit pointer aliasing.  We present a new typed language that allows functions to specify the shape of the store that they expect and to track the flow of pointers through a computation.  Our type system is expressive enough to represent pointer aliasing and yet safely permit destructive operations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7428,The Horus and Ensemble Projects: Accomplishments and Limitations,"The Horus and Ensemble efforts culminated a multi-year Cornell research program in process group communication used for fault-tolerance, security and adaptation.  Our intent was to understand the degree to which a single system could offer flexibility and yet maintain high performance, to explore the   integration of fault-tolerance with security and real-time mechanisms, and to increase trustworthiness of our solutions by applying formal methods.  Here, we summarize the accomplishments of the effort and evaluate the successes and failures of the approach.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7429,Query Processing in a Device Database System,"In the next decade, networks of devices will be widely deployed for measurement, detection and surveillance applications. Millions of sensors and small-scale mobile devices will integrate processors, memory and communication capabilities. Large collections of devices need to be controlled and accessed in an ad-hoc manner.  This paper shows that database technology can be adapted to meet the challenges of this new computing environment. In our new concept of a device database system, individual devices are modeled as database objects, which allows us to access collections of devices with declarative queries. We present a semantics for queries over device database systems and novel query processing techniques for evaluating such queries. We describe our implementation of these techniques in the Cornell COUGAR system and present a experimental evaluation that illustrates the performance characteristics of query processing in a device database system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7430,The Small-World Phenomenon: An Algorithmic Perspective,"Long a matter of folklore, the ``small-world phenomenon'' --- the principle that we are all linked by short chains of acquaintances --- was inaugurated as an area of experimental study in the social sciences through the pioneering work of Stanley Milgram in the 1960's.  This work was among the first to make the phenomenon quantitative, allowing people to speak of the ``six degrees of separation'' between any two people in the United States.  Since then, a number of network models have been proposed as frameworks in which to study the problem analytically.  One of the most refined of these models was formulated in recent work of Watts and Strogatz; their framework provided compelling evidence that the small-world phenomenon is pervasive in a range of networks arising in nature and technology, and a fundamental ingredient in the evolution of the World Wide Web. But existing models are insufficient to explain the striking algorithmic component of Milgram's original findings: that individuals using local information are collectively very effective at actually constructing short paths between two points in a social network.  Although recently proposed network models are rich in short paths, we prove that no decentralized algorithm, operating with local information only, can construct short paths in these networks with non-negligible probability. We then define an infinite family of network models that naturally generalizes the Watts-Strogatz model, and show that for one of these models, there is a decentralized algorithm capable of finding short paths with high probability.  More generally, we provide a strong characterization of this family of network models, showing that there is in fact a unique model within the family for which decentralized algorithms are effective.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7431,The Next Generation Internet: Unsafe at Any Speed?,"Will the Next Generation Internet provide an appropriate infrastructure for critical applications, such as are emerging in such settings as health care, electric power grid control, air traffic control, banking, and military command and control? This paper suggests that current trends are unlikely to yield the required platform.  Drawing lessons from successful critical networking projects of the past, we propose an alternative based on Virtual Overlay Networks (VONs).  Support for VONs would not require radical departure from existing router capabilities, because a limited mechanism of the type we propose is already available.  Given a simple Overlay Network (ON) capability, we show that tools for building more sophisticated VONs are already widely available.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7432,Efficient Reconciliation of Unordered Databases,"We consider the problem of reconciling two unordered databases whose contents are related.  Specifically, we wish to determine the mutual difference of these databases with a minimum communication complexity.  This type of problem arises naturally in the context of gossip protocols.  We analyze two instances of the reconciliation problem, a client-server model and a more general peer-to-peer model, and provide interactive solutions for both.  For the former instance, we also provide a simple one-message reconciliation algorithm, based on elementary symmetric polynomials, which has an almost optimal communication complexity.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7433,Certification of Compiler Optimizations using Kleene Algebra with Tests,"We use Kleene algebra with tests to verify a wide assortment of common compiler optimizations, including dead code elimination, common subexpression elimination, copy propagation, loop hoisting, induction variable elimination, instruction scheduling, algebraic simplification, loop unrolling, elimination of redundant instructions, array bounds check elimination, and introduction of sentinels.  In each of these cases, we give a formal equational proof of the correctness of the optimizing transformation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7434,On the Generation of Prime Implicants,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7435,Two Papers on the Linearity of Finite Automata,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7436,PL/CS - A Disciplined Subset of PL/I,"PL/CS is an instructional dialect of PL/I. It is defined by selection features  of PL/I, and then restricting the manner in which those features can be used.  The implementation is an error-repairing compiler based on PL/C, in which  error-repair is carried to the point where a user is deliberately encouraged  to use an abbreviated entry syntax and rely on the compiler to expand this to  produce a complete, PL/I-compatible program. PL/CS also includes an  ""assertion"" facility that can be used either as a conventional diagnostic  tool, or as the basis of a formal proof of correctness in a logical system  provided within the language.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7437,Term Relevance Weights in On-Line Information Retrieval,"Considerable evidence exists to show that the use of term relevance weights is  beneficial in interactive information retrieval. Various term weighting  systems are reviewed. An experiment is then described in which information  retrieval users are asked to rank query terms in decreasing order of presumed  importance prior to actual search and retrieval. The experimental design is  examined, and various relevance ranking systems are evaluated, including fully  automatic systems based on inverse document frequency parameters, human  rankings performed by the user population, and combinations of the two.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7438,A Study of Automatic Indexing for Patent Examination,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7439,On Log-Tape Isomorphisms of Complete Sets,"In this paper we study $\log n$-tape computable reductions between sets and  investigate conditions under which $\log n$-tape reductions between sets can  be extended to $\log n$-tape computable isomorphisms of these sets. As an  application of these results we obtain easy to check necessary and sufficient  conditions that sets complete under $\log n$-tape reductions in NL, CSL, P,  NP, PTAPE, etc. are $\log n$-tape isomorphic to the previously known complete  sets in the respective classes. As a matter of fact, all the ""known"" complete  sets for NL, CSL, P, NP, PTAPE, etc. are now easily seen to be, respectively,  $\log n$-tape isomorphic. These results strengthen and extend substantially  the previously known results about polynomial time computable reductions and  isomorphisms of NP and PTAPE complete sets. Furthermore, we show that any set  complete in CSL, PTAPE, etc. must be dense and therefore, for example, cannot  be over a single letter alphabet.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7440,Language Features for Process Interaction and Access Control,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7441,Analyzing and Improving Quasi-Newton Methods for Unconstrained Optimization,"This thesis is concerned with analyzing and improving the performance of  quasi-Newton methods for finding the minimum of a real valuedd function of a  finite number of real variables. Quasi-Newton methods are a successful way of  iteratively solving this problem when the Hessian matrix of second partial  derivatives of the function cannot be cheaply computed. Instead they keep an  approximation to the Hessian matrix at the current point, and update it at  each iteration. A recent algorithm of Davidon's has contributed two important  new ideas to the formulation of such updates, while improving upon the  computational performance of existing algorithms. In this thesis we analyze  the work of Davidon, propose some changes to his algorithm and test some of  these, and extend much of the existing analysis of quasi-Newton updates for  optimization problems to a broader class of updates which includes Davidon's. The two innovations in Davidon's algorithm are the use of a new update class  intended to preserve past derivative information in the Hessian approximation,  and the selection of the actual update from this class by a method called  optimal conditioning. We explain and analyze both of these aspects thoroughly.  The use of the new update class seems to be very beneficial, although our  analysis suggests several alternative implementations which are equivalent to  Davidon's algorithm on quadratic problems. We extend existing convergence  techniques to show that two of these methods enjoy local Q-superlinear  convergence under normal assumptions. On the other hand, our theoretical and  computational analysis of optimal conditioning indicates that it may not be  helpful in most cases, and that further computational testing definitely is  required. However, we introduce and test an update which uses optimal  conditioning only on some selected iterations, and which seems to show promise. To aid our analysis of Davidon's ideas we introduce the concept of a  restricted update class, of which his is an example. We then extend much of  the existing analysis of rank-two quasi-Newton updates, including questions of  hereditary positive definiteness, mimimum change updates, and performance  using perfect line search, to include this broadened update class. This work  helps suggest some of our proposed changes to Davidon's algorithm, and is  useful in deriving and analyzing quasi-Newton updates for other problems. A  basic equivalence shows that our analysis extends to a very general class of  rank-two updates. Quasi-Newton methods are currently being applied in a variety of problem  areas. We hope that our analysis improves upon their use in unconstrained  optimization, and helps make the leading new ideas in the field accessible to  other application areas.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7442,An Adaptive Nonlinear Least-Squares Algorithm,"NL2SOL is a modular program for solving nonlinear least-squares problems that  incorporate a number of novel features. It maintains a secant approximation  S to the second-order part of the least-squares Hessian and adaptively decides  when to use this approximation. S is ""sized"" before updating, something which  is similar to Oren-Luenberger scaling. The step choice algorithm is based on  minimizing a local quadratic model of the sum of squares function constrained  to an elliptical trust region centered at the current approximate minimizer.  This is accomplished using ideas discussed by More', together with a special  module for assessing the quality of the step thus computed. These and other  ideas behind NL2SOL are discussed and its evolution and current implemetation  are also described briefly.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7443,Variable Metric Methods for Minimizing a Class of Nondifferentiable Functions,"We develop a class of methods for minimizing a nondifferentiable function  which is the maximum of a finite number of smooth functions. The methods  proceed by solving iteratively qquadratic programming problems to generate  search directions. For efficiency the matrices in the quadratic programming  problems are suggested to be updated in a variable metric way. By doing so,  the methods possess many attractive features of variable metric methods and  can be viewed as their natural extension to the nondifferentiable case. To  avoid the difficulties of an exact line search, a practical stepsize procedure  is also introduced. Under mild asumptions the resulting method converge  globally.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7444,A Note on Iteration,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7445,Local and Linear Convergence of an Algorithm for Solving A Sparse Minimization Problem,"For an unconstrained minimization problem with a sparse Hessian, a symmetric  version of Schubert's update is given which preserves the sparseness structure  defined by the Hessian. At each iteration of the algorithm there are two  sparse linear systems to be solved. These have the same sparseness structure  defined by the Hessian. The differences between succeeding approximations to  the Hessian and the Hessian at the solution are related by a careful  evaluation of the difference in the Frobenius norm. This relation is used in  proving the local and linear convergence of the algorithm.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7446,Static Restriction of the GOTO Statement,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7447,An Algorithm for Checking PL/CV Arithmetic Inferences,This paper describes the operation and implementation of the arithmetic proof  rule for the quantifier free integer arithmetic used in the PL/CV 2 program  verification system. The general arithmetic satisfiability problem underlying  the rule is shown to be NP complete.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7448,A Brief Introduction to Quasi-Newton Methods,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7449,Access Control in Parallel Programs,"An important component of a programming language for writing operating  systems, or other large parallel systems, is the set of access control  facilities. Two principles for access control, expressive power and access  validation, are discussed. Then two new language mechanisms are presented: one  for expressing the static structure and access rights of parallel systems, the  other for controlling dynamic access to shared objects (monitors). The use of  the proposed mechanisms is illustrated by message passing and file systems.  Finally, the relationship between the mechanisms and access validation is  discussed and a solution to the safety problem for the facilities is given. Key Words and Phrases: access control, programming language, protection,  security, processes, monitors, access safety. CR Categories: 4.20, 4.32, 4.35",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7450,Modula and the Design of a Message Switching Communication System,"This report describes the functions of a message switching communications  system and presents an implementation in terms of the Modula programming  language. In particular, the report: (1) describes a representative  application of the proposed new Department of Defense high order language; (2)  presents a design technique for software specification; (3) develops Modula  programs for each of the message switching components; and (4) evaluates the  utility of Modula as a language for the design of large parallel systems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7451,The Design of Parallel Systems: An Application and Evaluation of Modula,"Modula is a new programming language for implementing dedicated, parallel  systems. Following a systematic design technique, this paper illustrates the  use of Modula for the design of a message switching communication system. A  message switching system poses a number of interesting problems: a high degree  of concurrent activity exists, a variety of IO devices need to be controlled,  messages can have multiple destinations, and messages can be preempted. The  strengths and weaknesses of Modula with respect to these specific problems  and its utility as a general purpose language are evaluated. Key Words and Phrases: structured multiprogramming, concurrent systems,  Modula, message switching, software design, processes, monitors, modular  design. CR Categories: 3.81, 4.2, 4.21, 4.3",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7452,Mathematics and Information Retrieval,"The development of a given discipline in science and technology often depends  on the availability of theories capable of describing the processes which  control the field and of modelling the interactions between these processes.  The absence of an accepted theory of information retrieval has been blamed for  the relative disorder and the lack of technical advances in the area. The main mathematical approaches to information retrieval are examined in this  study, including both algebraic and probabilistic models, and the difficulties  which impede the formalization of information retrieval processes are  described. A number of developments are covered where new theoretical  understandings have directly led to the improvement of retrieval techniques  and operations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7453,Language Based Protection Mechanisms,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7454,Parallelism in Random Access Machines,"A model of computation based on random access machines operating in parallel  and sharing a common memory is presented. The computational power of this  model is related to that of traditional models. In particular, deterministic  parallel RAM's can accept in polynomial time exactly the sets accepted by  polynomial tape bounded Turing machines; nondeterministic RAM's can accept in  polynomial time exactly the sets accepted by nondeterministic exponential time  bounded Turing machines. Similar results hold for other classes. The effect of  limiting the size of the common memory is also considered.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7455,Exploiting Sparsity in Newtown-Like Methods,"The basic problem considered here is to solve sparse systems of nonlinear  equations. A system is considered to be sparse when the Jacobian has fewer  than ten percent nonzero entries. Algorithms are presented and their  convergence properties are analyzed. Schubert's method for solving sparse nonlinear equations is a modification of  Broyden's method, a well known quasi-Newton method. The modification preserves  the zero-nonzero structure defined by the sparse Jacobian in the sequence of  approximate Jacobians. The algorithm is shown to satisfy the Bounded  Deterioration Theorem of Broyden, Dennis and More to obtain a simple local  convergence result. A more detailed study of the error bound in the Frobenfus  norm shows that the method is superlinearly convergent. Schubert's method  satisfies a minimum norm property and a Kantorovich analysis is also presented. A symmetric Schubert update is derived using an iterative projection technique  of Dennis and Powell. The update is expressed in a closed form at the expense  of an additional sparse linear system to be solved at each iteration in the  algorithm. These sparse linear systems that occur all have the same structure  which means they can be handled using the pre-processing performed when  solving the first such system. Again the Frobenfus norm is used to estimate  the error in the approximate Jacobian. The algorithm is locally and linearly  convergent. The update is applicable to a symmetric nonlinear system,  particularly those systems arising from unconstrained minimization problems  with a continuous second derivative. Another method of solving sparse nonlinear equations using a matrix  factorization is presented. Some theory of sparse linear equations is needed  to maintain sparseness in triangular factors of a matrix. An approximate  Jacobian is factored and one of the triangular factors is updated with  Schubert's updating formula. After a finite number of iterations, a new  approximate Jacobian is needed. Algorithms are suggested with local and  superlinear convergence properties. The convergence depends on the local  continuity of the matrix factorization. Finally, another application of Schubert's method is proposed for problems in  which the Jacobian of the nonlinear system can be written as the direct sum  of two transformations. One of these is assumed to be easily computed, and the  other is assumed to be sparse. An algorithm is sketched and local and  superlinear convergence properties are conjectured.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7456,Superlinear Convergence of a Minimax Method,"To solve a minimax problem Han [1977b] suggested the use of quadratic programs  to find search directions. If the matrices in the quadratic programs are  positive definite, the method can be shown convergent globally. In this paper  we study that for efficiency the matrices should also be good approximations  to a certain convex combination of Hessians on some subspace. Therefore, we  suggest Powell's scheme [Powell 1977] for updating these matrices. By doing  so, we can avoid computing Hessians. Meanwhile, the matrices maintain positive  definiteness and Han's global convergence theorems can apply. Besides, the  convergence of the resulting method is superlinear, indeed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7457,The Assertion Table System for the PL/CV2 Program Verifier,"A system to implement the block structured storage of PL/CV2 assertions is  described. The system allows certain simple logical deductions to be performed  automatically. These include deductions involving propositional reasoning,  associativity and commutativity of arithmetic operators, and reasoning about  equality. The implementation is described at a conceptual level.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7458,A Note on Cryptography and NP$\cap$ CoNP-P,"Diffie and Hellman [2] propose the use of the exponential function in a finite  field for cryptographic purposes. The proposal is based on the conjecture  that the inverse function, the logarithm, is not feasibly computable. We show  that a proof of this conjecture would have important consequences for  theoretical computer science, even under the assumption that P $neq$ NP.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7459,First Order Semantics: A Natural Programming Logic for Recursively Defined Functions,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7460,A Note on Rabin's Nearest-Neighbor Algorithm,Rabin has proposed a probabilistic algorithm for finding the closest pair of a  set of points in Euclidean space. His algorithm is asymtomatically linear  whereas the best of the known deterministic algorithms take order $n \log n$  time. We show that at least part of the speed up is due to the model rather  than the probabilistic nature of the algorithm.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7461,Solution of Definite Quadratic Programming Problems,A algorithm for solving the definite quadratic programming problem is  presented. An implementation of this algorithm in FORTRAN is discussed.  Numerical tests of this algorithm and a similar one not using the positive  definiteness property show the former to be more stable. This algorithm is  paarticularly suited for numerical methods for solving general nonlinear  programming problems or minimax problems.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7462,Is Sometimes Ever Better Than Always?,"The ""intermittent assertion"" method for proving programs correct is explained  and compared to the conventional axiomatic method. Simple axiomatic proofs of  iterative algorithms that compute recursively defined functions, including  Ackermann's function, are given. A critical examination of the two methods  leads to the opinion that the axiomatic method is preferable.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7463,Least Change Secant Updates for Quasi-Newton Methods,"In many problems involving the solution of a system of nonlinear equations, it  is necessary to keep an approximation to the Jacobian matrix which is updated  at each iteration. Computational experience indicates that the best updates  are those that minimize some reasonable measure of the change to the current  Jacobian approximation subject to the new approximation obeying a secant  condition and perhaps some other approximation properties such as symmetry. In this paper we extend the affine case of a theorem of Cheney and Goldstein  on proximity maps of convex sets to show that a generalization of the  symmetrization technique of Powell always generates least change updates. This  generalization has such broad applicability that we obtain an easy unified  derivation of all the most successful updates. Furthermore, our techniques  apply to interesting new cases such as when the secant condition might be  inconsistent with some essential approximation property like sparsity. We also  offer advice on how to choose the properties which are to be incorporated into  the approximations and how to choose the measure of changes to be minimized.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7464,On the Succintness of Different Representations of Languages,"The purpose of this paper is to give simple new proofs of some interesting  recent results about the relative succintness of different representations of  regular, deterministic and unambiguous context-free languages and to derive  some new results about how the relative succintness of representations change  when the representations contain a formal proof that the languages generated  are in the desired subclass of languages.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7465,One-Way Log-Tape Reductions,"One-way log-tape (1-L) reductions are mappings defined by log-tape Turing  machines whose read head on the input can only move to the right. The 1-L  reductions provide a more refined tool for studying the feasible complexity  classes than the P-time [2,7] or log-tape [4] reductions. Although the 1-L  computations are provably weaker than the feasible classes L, NL, P and NP,  the known complete sets for those classes are complete under 1-L reductions.  However, using known techniques of counting arguments and recursion theory  we show that certain log-tape reductions cannot be 1-L and we construct sets  that are complete under log-tape reductions but not under 1-L reductions.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7466,An Improved Simulation Result for Ink Bounded Turing Machines,"A (one tape, deterministic) Turing machine is $f(n)$ ink bounded if the  machine changes a symbol of its work tape at most $O(f(n))$ times while  processing any input of length $n$. The main result of our paper is the construction of an ""ink efficient""  universal machine which, for any $f(n)$ ink bounded machine $M$ and input  $x$, can simulate the processing of $M$ on $x$ or detect that $M$ is looping  infinitely on input $x$. The universal machine requires $O(f(n)^{1+\epsilon)$  ink for this simulation where $\epsilon$ is an arbitrarily small positive  number. As a corollary, we establish that the class of all $f(n)$ ink bounded  computations is properly contained in the class of all $g(n)$ ink bounded  computations assuming $\stackrel{inf}{n \rightarrow \infty}  \frac{f(n)^{1+\varepsilon}}{g(n)} = 0$ and a technical condition on g.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7467,Relative Succinctness of Representations of Languages and Separation of Complexity Classes,"In this paper we study the relative succinctness of different representations  of polymomial time languages and investigate what can and cannot be formally  verified about these representations. We also show that the relative  succintness of different representations of languages is directly related to  the separation of the corresponding complexity classes; for example, PTIME  $\neq$ NPTIME if and only if the relative succintness of representing  languages in PTIME by deterministic and nondeterministic clocked polynomial  time machines is not recursively bound which happens if and only if the  relative succintness of these representations is not linearly bounded.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7468,Information Flow in Parallel Programs: An Axiomatic Approach,"The information flow problem is concerned with controlling the transmission  of information in computer systems. This thesis addresses this problem by  developing an axiomatic logic that captures the information flow semantics  of a program. Using this technique the scope of information flow analysis is  extended from terminating sequential programs to parallel programs in which  non-termination, synchronization and deadlock are possible. Once the  information flow generated by a program has been determined, it is easy to  check whether or not the program satisfies a given security policy. The main contribution of the thesis is an axiomatic proof system for  determining the flow of information produced by sequential or parallel  programs. Just as proofs of correctness capture the effect of program  execution upon the values in variables, proofs of information flow capture the  effect of program execution upon the information in variables. An advantage of  this approach is that once a flow proof of a program has been generated,  various security policies, such as high water mark or final value, can be  verified readily. Although flows in parallel programs need to be determined so that  confidentiality in shared systems can be maintained, current information flow  techniques are limited to terminating sequential programs. The thesis  addresses this problem by capturing the flows generated by programs containing  independent processes that synchronize with each other. The practicability of  the method is demonstrated by developing the flow semantics for Concurrent  Pascal.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7469,An Efficient Algorithm for Testing Losslessness of Joins in Relational Data Bases,"Answering queries in a relational database model often requires the  computation of joins of relations. Losslessness of joins is an important  property for joins of relations to be semantically meaningful. In this paper  we present an $O(n^{3})$ algorithm for testing losslessness of joins in  relational databases with functional dependencies, which improves the  $O(n^{4})$ result by Aho, Beeri and Ullman.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7470,Unsymmetric Positive Definite Linear Systems,Is it necessary to pivot when solving an unsymmetric positive definite linear  system $Ax = b?$ Define $T = (A + A^{T})/2$ and $S=(A+AA^{T})/2$. It is shown  that pivoting is unnecessary if the quantitity is $\Vert S T^{-1} S \Vert_{2}/  \Vert A \Vert_{2}$ is suitably small with respect to the working machine  precision.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7471,A Note on the Evaluation of Matrix Polynomials,"The problem of evaluating a polynomial p(x) in a matrix A arises in many  applications, e.g. the Taylor approximation of $e^{A}$. The $O(\sqrt{q}n^{3})$  algorithm of Paterson and Stockmeyer has the drawback that it requires  $O(\sqrt{q}n^{2})$ storage, where $q$ is the degree of $p$ and $n$ is the  dimension of $A$. An algorithm which greatly reduces this storage requirement  without undue loss of speed is presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7472,A Hessenberg-Schur Method for the Problem AX + XB = C,"ONe of the most effective methods for solving the matrix equation AX + XB = C  is the Bartels-Stewart algorithm. Key to this technique is the orthogonal  reduction of A and B to triangular form using the QR algorithm for  eigenvalues. A new method is proposed which differs from the Bartels-Stewart  algorithm in that A is only reduced to Hessenberg form. The resulting  algorithm is between 30 and 70 percent faster depending upon the dimensions of  the matrices A and B. The stability of the new method is demonstrated through  a roundoff error analysis and supported by numerical tests. Fianlly, it is  shown how the techniques described can be applied and generalized to other  matrix equation problems.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7473,A Note on the Sparse Complete Sets,"Hartmanis and Berman have conjectured that all NP-complete sets are polynomial  time isomorphic. A consequence of the conjecture is that there are no sparse  NP-complete sets. We show that the existence of an NP-complete set whose  complement is sparse implies P = NP. We also show that if there is a  polynomial time reduction with sparse range to a PTAPE-complete set, then  P=PTAPE. Keywords: reduction, polynomial time, nondeterministic polynomial time,  complete sets, sparsity.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7474,Classes and Objects - A Dynamic Approach,"Data encapsulation, abstract data types and classes are terms associated with  a concept not fully clarified or accepted. This paper presents a class concept  that differs slightly from previous definitions by the associated dynamics.  This allows us to interpret nested and recursive classes as well as class  parameters. We will distinguish between types and classes and permit types as parameters  in a way that allows simple implementation. A number of examples will be given to illustrate the class concept itself and  its application to access control problems for concurrent programs.  Synchronization primitives will be viewed as classes and the need for explicit  high-level constructs like monitors is questioned. Keywords: Programming language, encapsulation, abstract data type, class,  object, synchronization, monitor.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7475,A Survey of Graduate Programs in Computer Science,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7476,The Logic of Aliasing,We give a new version of Hoare's logic which correctly handles programs with  aliased variables. The central proof rules of the logic (procedure call and  assignment) are proved sound and complete.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7477,Synchronizing Resources,"A new proposal for synchronization and communication in parallel programs is  presented. The proposal, called synchronization resources, combines and  extends aspects of procedures, coroutines, monitors, communicating sequential  processes, and distributed processes. It provides a single notation for  parallel programming with or without shared variables and is suited for either  shared or distributed memory architectures. The essential new concepts are  operations, input statements, multiple processes and resources. The proposal  is illustrated by solving a variety of parallel programming problems. Key Words and Phrases: parallel programming, processes, synchronization,  process communication, monitors, distributed processing, programming  languages, operating systems, data bases. CR Categories: 4.20, 4.22, 4.32, 4.35",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7478,An Axiomatic Approach to Information Flow in Parallel Programs,"This paper presents a new, axiomatic approach to information flow in  sequential and parallel programs. Flow axioms that capture the information  flow semantics of a variety of statements are given and used to construct  program flow proofs. The method is illustrated by a variety of examples. The  applications of flow proofs to certifying information flow policies and  solving the confinement problem are considered. It is also shown that flow  axioms and correctness axioms can be combined to form an even more powerful  proof system.  Keywords and Phrases: information flow, information security, security  certification, parallel programs,  axiomatic logic, proof rules.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7479,Sorting and Searching Using Controlled Density Arrays,"Algorithms like insertion sort run slowly because of costly shifting of array  elements when a value is inserted or deleted. The amount of shifting, however,  can be reduced by leaving gaps - unused array locations into which new values  can be inserted - at regular intervals in the array. The proper arrangement of  gaps is maintained by periodic adjustment. We demonstrate this technique with a stable comparison sort algorithm with  expected time $O(N \log N)$, worst case time $O(N \sqrt{N})$, and space  requirements 2N. We conjecture that, by using an interpolation search, the  expected time can be reduced to $O(N \log \log N)$. By comparison, Quicksort  takes expected time $O(N \log N)$, worst case time $O(N^{2})$ and space  $N + \log N$. Second, we show that for any fixed $d \geq 2$ a table management algorithm can  be constructed that can process a sequence of $N$ instructions chosen from  among INSERT, DELETE, SEARCH, and, MIN in worst case time $O(N^{1+1/d})$.  Experiments with a version of the algorithms using $d=2$ show a marked  improvement over balanced tree schemes for $N$ as large as several thousand.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7480,Suggestions for a Uniform Representation of Query and Record Content in Data Base and Document Retrieval,A standard approach is introduced for the representation of information  content in data base and document retrieval environments. The use of composite  concept vectors representing individual information items leads to a uniform  system in different retrieval situations for the identification of answers in  response to incoming information requests.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7481,A Citation Study of the Computer Science Literature,"The bibliographic references and citations which exist between documents in a  given collection environment can be used to study the history and scope of  particular subject areas and to assess the importance of individual authors,  documents, and journals. A clustering study of the computer science literature  is described using bibliographic citations as a clustering criterion, and  conclusions are drawn regarding the scope of computer science, and the  characteristics of individual documents in the area.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7482,Mechanisms for Specifying Scheduling Policies,"Extensions to concurrent programming languages are presented which allow  control of scheduling policies previously defined by the run-time support  system. It is shown that the use of these mechanisms simplifies the solutions  of concurrent programming problems. In addition, the proposed extensions  allow easy identification of those aspects of a program concerned with  performance, thereby making programs easier to read and understand. Keywords: concurrent pascal, monitors, communicating sequential processes,  operating systems, scheduling algorithms.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7483,A File System Extension to Micro-PL/CS,"Micro-PL/CS is a version of PL/CS developed for interactive use with a  dedicated microprocessor. A file system extension is proposed to give PL/CS a  simple, but extremely powerful file system capability. The system allows for  the creation and manipulation of files for sequential, random, or keyed access  (or any combination) in an unrestricted manner. Essential to the capability is  a set of built-in functions and pseudo-variables which allow file  manipulation without syntactic complication.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7484,Implementation of an Unrestricted File Organization for Micro-PL/CS,"Micro PL/CS is a version of PL/CS developed for a single-user, interactive  environment. A file system extension makes PL/CS self-sufficient for  standalone file processing and secondary storage management. The basis of the  file system extension is the Unrestricted File Organization which provides a  free mixture of sequential, indexed and random file operations. The structure,  operation, and system-interfaced procedures of the UFO are presented and  explained. The Micro-PL/CS file extension implementation is then sketched in  terms of the UFO primitives.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7485,A Progress Report on Automatic Information Retrieval,"This study is a state-of-the-art report of work in automatic information  retrieval. Various enhancements of operational on-line retrieval systems are  described such as the utilization of special front-end devices providing  compatibility among different search services, the introduction of fast  back-end search devices, and the use of local clustering and query  reformulation operations designed to improve retrieval output. Certain new  algorithms for fast text matching and for optimum term weighting are also  mentioned, as are advances in the construction of theoretical retrieval  models.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7486,Comments on a Draft Pascal Standard,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7487,The Cornell Program Synthesizer:  A Microcomputer Implementationof PL/CS,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7488,APL and the Grzegorczyk Hierarchy,"We show in this paper that the set of ""traditional"" APL 1-liners (using  arithmetic functions only) compute precisely the set of functions in the class  E4 of Grzegorczyk hierarchy (the class immediately above the elementary  functions). We also show that if we extend the set of 1-liners to include  either the ""execute"" operator, or 1 line programs with gotos, then any  partial recursive function can be computed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7489,On Restrictions to Ensure Reproducible Behavior in Concurrent Programs,"One of the major difficulties encountered when dealing with concurrent  programs is that reproducible behavior may not be assumed. As a result, it is  difficult to validate and debug such systems. In this paper, structural  restrictions are presented that ensure that reproducible behavior will occur  in concurrent programs. The application of this to system design is discussed.  Keywords: time dependent behavior, concurrency, synchronization, monitors,  Concurrent Pascal.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7490,Representation of Almost Constant Vectors,"An example in a recent report on the programming language Russell has  illustrated difficulties related to user defined storage management. Here is  demonstrated how the dynamic approach to encapsulation earlier proposed by the  author provides means to solve the particular storage management problem. The  method used is, however, easily generalized to other similar cases. In addition to the example a number of notational conveniences are introduced.  One that allows abbreviated references to components of record-like structures  is called controlled coercion. Another allows a function-like use of classes. Keywords: Classes, abstract data types, storage management, programming  languages.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7491,Computer Science and the Liberal Arts Student,"The computer science education of nontechnical liberal arts students is a  matter of increasing concern. In this paper it is argued that computer  scientists should promote and teach their subject more in line with the  traditional aims of liberal education when dealing with students of this type.  A framework for doing this is presented which involves a broad view of  ""computer literacy"" based upon what other authors have written about  ""scientific literacy."" The structure of a computer science appreciation  course is outlined which embodies the ideas of liberal education described.  The importance of historical perspective is emphasized. Key Words and Phrases: Computer literacy, liberal arts student, liberal  education, history of computation, scientific literacy.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7492,A Hamiltonian-Schur Decomposition,,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7493,Upson's Familiar Quotations,"This report is a compilation of several hundred examples of context free  language and very irregular expressions. Contributions were submitted over the  last five years by numerous computer science graduate students who collected  these now immortal words in classes and seminars. We wish to express our  gratitude to the faculty, guest lecturers, and students who provided the bulk  of this work.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7494,A Procedure Call Proof Rule (With a Simple Explanation),NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7495,On the Proof Theory of the Modal Logic G,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7496,The Cornell Program Synthesizer: A Tutorial Introduction,This tutorial introduces a novice student to the basic facilities of the  Cornell Program Synthesizer for developing programs written in the PL/CS  dialect of PL/I. No knowledge of programming is assumed or required. It is  assumed that you possess a Synthesizer diskette and have access to a TERAK  microcomputer.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7497,Efficiency Considerations In Implementing Dijkstra's Guarded Command Constructs,"The guarded command alternative and iterative constructs proposed by E. W.  Dijkstra subsume the conventional alternative and iterative constructs. The  extra flexibility of these guarded command constructs enables the programmer  to express his ideas more directly and clearly. Moreover, Dijkstra has  developed a calculus for the derivation of correct programs that utilizes  these guarded command constructs. This thesis addresses the problem of efficiently implementing these guarded  command constructs. Several new optimizations that are particularly well  suited to the guarded command constructs are described. The most useful is the  elimination of redundant boolean expressions. This optimization provides a  means of implementing the guarded command alternative statement with  efficiency comparable to the IF-THEN-ELSE statement. The main contribution of this thesis is a detailed description of an algorithm  for eliminating redundant boolean expressions. The algorithm itself is  presented in a program written in a PASCAL supplemented with the guarded  command constructs. The basis method involves considering individual execution  paths through the guarded command construct and applying rules of inference to  recognize and avoid evaluation of many boolean expressions. It is shown that  the number of execution paths through a guarded command construct remains  small enough to make this method practical.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7498,Local Convergence Theorems for Quasi-Newton Methods,"This paper presents generalizations of the two results which have been useful  for analyzing methods of the form $x_{k+1} = x_{k} - B_{k}^{-1}F(x_{k})$. The  bounded deterioration theorem of Broyden-Dennis-More is generalized to show  that if \{$B_{k}$\} or \{$B_{k}^{-1}$\} is of bounded deterioration as a  sequence of approximants to some $B_{*}$ or $B_{*}^{-1}$ then the iteration  above has the same local convergence properties and arbitrarily nearly the  same linear rate as would be achieved by the stationary iteration function  which uses $B_{k} = B_{*}$. The characterization theorem for superlinear  convergence given by Dennis-More is then generalized to give conditions under  which the rates are the same. In the case when $B_{*} = F'(x_{*})$, these  results reduce to those already known.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7499,Convergence Theorems for Least Change Secant Update Methods,The purpose of this paper is to present a convergence analysis of the least  change secant methods in which part of the derivative matrix being  approximated is computed by other means. The theorems and proofs given here  can be viewed as generalizations of those given by Broyden-Dennis-More and by  Dennis-More. The analysis is done in the orthogonal projection setting of  Dennis-Schnabel and many readers might feel that it is easier to understand.  The theorems here readily imply local and q-superlinear convergence of all the  standard methods in addition to proving these results for the first time for  the sparse symmetric method of Marwil and Toint and the nonlinear least  squares method of Dennis-Gay-Welsch.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7500,A Time-Space Tradeoff for In-Place Array Permutation,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7501,A Linear Time Algorithm for the Generalized Consecutive Retrieval Problem,THe Generalized Consecutive Retrieval Problem (GCRP) is to find a directed  tree on $n$ records in which each of $k$ subsets forms a directed path. The  problem arises in organizing information for efficient retrieval. A linear  time algorithm for the GCRP is given. Further generalization leads to problems  that are complete for NP.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7502,The Complexity of Parallel Computations,"Recent advances in microelectronics have brought closer to feasibility the  construction of computers containing thousands (or more) of processing  elements. This thesis addresses the question of effective utilization of such  processing power. We study the computational complexity of synchronous  paarallel computations using a model of computation based on random access  machines operating in parallel and sharing a common memory, the P-RAM. Two  main areas within the field of parallel computational complexity are  investigated. First, we explore the power of the P-RAM model viewed as an  abstract computing device. Later, we study techniques for developing efficient  algorithms for parallel computers. We are able to give concise characterizations of the power of deterministic  and nondeterministic P-RAMS in terms of the more widely known space and time  complexity classes for multi-tape Turing machines. Roughly speaking,  time-bounded deterministic P-RAMS are equivalent in power to (can accept the  same sets as) space-bounded Turing machines, where the time and space bounds  differ by at most a polynomial. In the context of comparing models of  computation, we consider such polynomial differences in resources to be  insignificant. Adding the feature of nondeterminism to the time-bounded P-RAM  changes its power to that of a nondeterministic Turing machine with an  exponentially higher running time. The later sections of the thesis examine algorithm design techniques for  parallel computers. We first develop efficient procedures for some common  operations on linked lists and arrays. Given this background, we introduce  three techniques that permit the design of parallel algorithms that are  efficient in terms of both their time and processor requirements. We  illustrate the use of these techniques by presenting time and processor  efficient algorithms for three problems, in each case improving upon the best  previously known parallel resource bounds. We show how to compute minimum  string edit distances, using the technique of pairwise function composition.  We describe an algorithm for the off-line MIN that organizes its computation  in the form of a complete binary tree. Finally, we present an algorithm for  undirected graph connectivity that relies on redundancy in its representation  of the input graph.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7503,A Logic For Correct Program Development,,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7504,On Easily Infinite Sets and On a Statement of R. Lipton,"For a complexity measure $\kappa$, a set is $\kappa$-infinite if it contains  a $\kappa$-decidable infinite subset. For a time-based $\kappa$, we prove  that there is a recursive S s.t. both S and its complements, $\bar{S}$, are  infinite but not $\kappa$-infinite. Lipton [6] states that the existence of a recursive set S s.t. neither S nor  $\bar{S}$ os polynomially infinite is not a purely logical consequence of  $\prod^{0}_{2}$ theorems of Peano's Arithmetic PA. His proof uses a  construction of an algorithm within a non-standard model of of Arithmetic,  in which the existence of infinite descending chains in such models is  overlooked. We give a proof of a stronger statement to the effect that the  existence of a recursive set S s.t. neither S nor $\bar{S}$ is linearly  infinite is not a tautological consequence of all true $\prod^{0}_{2}$  assertions. We comment on other aspects of [6], and show $(\S 2)$ that a tautological  consequence of true $\prod^{0}_{2}$  assertions may not be equivalent (in PA,  say) to a $\prod^{0}_{2}$ sentence. The three sections of this paper use  techniques of Recursion Theory, Proof Theory and Model Theory, respectively.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7505,Synchronization in Distributed Programs,"A technique for solving synchronization problems in distributed programs is  described. Use of this technique in environments in which processes may fail  is discussed. The technique can be used to solve synchronization problems  directly, to implement new synchronization mechanisms (which are presumably  well suited for use in distributed programs), and to construct distributed  versions of existing synchronization mechanisms. Use of the technique is  illustrated with implementations of distributed semaphores and a conditional  message passing facility.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7506,Ensuring Consistency in a Distributed Database System by Use of Distributed Semaphores,"Solutions to the database consistency problem in distributed databases are  developed. It is shown how any solution to the consistency problem for a  centralized database system that involves locking can be adapted for use in  distributed systems. This is done, constructively, in two steps. First, it is  shown how locking can be implemented in terms of semaphores. Then, a semaphore  implementation that is suitable for use in distributed systems is developed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7507,Efficient On-Line Construction and Correction of Position Trees,"This paper presents an on-line algorithm for the construction of position  trees, i.e. an algorithm which constructs the position tree for a given string  while reading the string from left to right. In addition, an on-line  correction algorithm is presented which - upon a change in the string - can be  used to construct the new position tree. Moreover, special attention is paid  to computers with small memory. Compactification of the trees and transport  costs between main and secondary storage are discussed.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7508,A Unified View of Semantics,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7509,Ada/CS - An Instructional Subset of the Programming Language Ada,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7510,Quadratic Programming with M-Matrices,"In this paper, we study the problem of quadratic programming with M-matrices.  We describe (1) an effective algorithm for the case where the variables are  subject to a lower bound constraint, and (2) an analogous algorithm for the  case where the variables are subject to lower and upper bounds constraints. We  demonstrate the special monotone behavior of the iterate and gradient vectors.  The result on the gradient vector is new. It leads us to consider a simple  updating procedure which preserves the monotonicity of both vectors. The  procedure uses the fact that an M-matrix has a non-negative inverse. Two new  algorithms are then constructed by incorporating this updating procedure into  the two given algorithms. We give numerical examples which show that the new  methods can be more efficient than the original ones.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7511,A Program Development System Execution Supervisor,The Cornell Program Development System is an experimental vehicle to explore  the applicability of highly cooperative tactics to a contemporary development  environment. The CPDS provides significant facilities for modifying and  immediately executing programs. The execution supervisor and the internal user  program representation it uses to implement these facilities are described.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7512,The System Architecture for CORE: A Tolerant Program Development Environment,CORE is a program development environment intended primarily to explore a  highly tolerant useer interface. In some respects the internal architecture is  also novel. It permits a highly interactive and supportive user interface to  be implemented with processing routines which are essentially oblivious to any  user interaction.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7513,On Linear Natural Deduction,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7514,A Proof Technique for Communicating Sequential Processes(With an Example),"We present proof rules for an extension of the Communicating Sequential  Processes proposed by Hoare. The send and receive statements are treated  symmetrically, simplifying the rules and allowing send to appear in guards. An  example is given to explain the use of the technique. This is an outline of a  substantial part of a PhD thesis that is expected to be completed in June 1980.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7515,Cand and Cor Before and Then or Else in Ada,NO ABSTRACT SUPPLIED,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7516,On the Modelling Power of Petri Nets,The behavior of a Petri net is expressed as a formal language. Certain  families of Petri net languages are characterized by propositions similar to  the classical pumping theorems. The results are used to give examples of  behaviors that cannot be expressed by languages in these families.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7573,SGER:  Planning Information Infrastructure Through a New Library-Research Partnership [final report],"The purpose of this Small Grant for Exploratory Research was to explore the issues surrounding a 
new type of collaboration between scientists and research libraries to support the preservation, 
discovery, and sharing of primary research data. With recent advances in computing and 
telecommunications technology, the stage is set for a major shift in the way science is conducted. 
Researchers and funding agencies are recognizing that data can be valuable for purposes beyond 
the studies in which they were originally collected, and some agencies are requiring data sharing 
plans as prerequisites for funding support. There is, however, a lack of established infrastructure 
to support the services necessary for handling research data. This grant investigated the premise 
that research libraries might serve as natural partners in addressing the data management needs of 
the communities they serve.",document contains most significant sections of a final report to NSF submitted 2007-01-21.,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7622,CONMan: A Step towards Network Manageability,"Networks are hard to manage and in spite of all the so called holistic management packages, things are getting worse. Further, there is a general lack of research on fundamentals and an increasing reliance on temporary ?bandaids?. We argue that the difficulty of network management can partly be attributed to a fundamental flaw in the existing architecture: protocols expose all their internal details and hence, the complexity of the ever-evolving data plane encumbers the management plane. Guided by this observation, in this paper we explore an alternative approach and propose Complexity Oblivious Network Management (CONMan), a network architecture in which the management interface of data-plane protocols includes minimal protocol-specific information. This restricts the operational complexity of protocols to their implementation and allows the management plane to achieve high level policies in a structured fashion. Apart from building the CONMan interface of a few protocols and a management tool that can achieve high-level configuration goals based on this interface, our preliminary experience with applying this tool to real world VPN configuration indicates the architecture?s potential to alleviate the difficulty of network management.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7874,Applications of Metric Coinduction,"Metric coinduction is a form of coinduction that can be used to establish properties of objects constructed as a limit of finite approximations.  One proves a coinduction step showing that some property is preserved by one step of the approximation process, then automatically infers by the coinduction principle that the property holds of the limit object.  This can often be used to avoid complicated analytic arguments involving limits and convergence, replacing them with simpler algebraic arguments.  This paper examines the application of this principle in a variety of areas, including infinite streams, Markov chains, Markov decision processes, and non-well-founded sets.  These results point to the usefulness of coinduction as a general proof technique.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7875,Civitas: A Secure Voting System,"Civitas is the first electronic voting system that is coercion-resistant, universally and voter
verifiable, and suitable for remote voting. This paper describes the design and implementation
of Civitas. Assurance is established in the design through security proofs, and in the implementation
through information-flow security analysis. Experimental results give a quantitative
evaluation of the tradeoffs between time, cost, and security.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7876,Evolution vs. Intelligent Design in Consensus Protocols,"Consensus is an important building block for building replicated systems, and many consensus protocols have been proposed. In this paper, we show that many consensus protocols can be derived from the same simple genes. We present these genes in the form of a skeleton algorithm that can be configured to produce, among others, three well-known consensus protocols: Paxos, Chandra- Toueg, and Ben-Or. Although each of these protocols specify only one quorum system explicity, we show that all employ a second quorum system. We use the skeleton algorithm to implement a replicated service, allowing us to compare the performance of these consensus protocols under various workloads and failure scenarios. From this we learn, for example, that weak leader election in Paxos unnecessarily causes performance degradation in certain failure scenarios.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7877,Collective Inference on Markov Models for Modeling Bird Migration,"We investigate a family of inference problems on Markov models, where many sample paths are drawn from a Markov chain and partial information is revealed to an observer who attempts to reconstruct the sample paths. We present algorithms and hardness results for several variants of this problem which arise by revealing different information to the observer and imposing different requirements for the reconstruction of sample paths. Our algorithms are analogous to the classical Viterbi algorithm for Hidden Markov Models, which finds single most probable sample path given a sequence of observations. Our work is motivated by an important application in ecology: inferring bird migration paths from a large database of observations.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7878,On Distance Coloring,"Call a connected undirected graph (d,c)-colorable if there is a vertex coloring using at most c colors such that no two vertices of distance d or less have the same color.  It is well known that (1,2)-colorability is decidable in linear time, but (1,c)-colorability for c greater than or equal to 3 is NP-complete.  Sharp (2007) shows that for fixed d greater than or equal to 2, the (d,c)-colorability problem is solvable in linear time for c less than or equal to 3d/2 and NP-complete otherwise.  In this note we give an alternative construction that improves the upper time bound as a function of d for the case c less than or equal to 3d/2.  The construction entails a generalization of the notion of tree decomposition and bounded treewidth (Robertson and Seymour 1986) to arbitrary overlay graphs, not just trees, which may be of independent interest.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7879,Manipulation-resistant Reputations Using Hitting Time,"Popular reputation systems for linked networks can be manipulated by spammers who strategically place links.  The reputation of node v is interpreted as the world's opinion of v's importance. In PageRank, v's own opinion can be seen to have considerable influence on her reputation, where v expresses a high opinion of herself by participating in short directed cycles. In contrast, we show that expected hitting time --- the time to reach v in a random walk --- measures essentially the same quantity as PageRank, but excludes v's opinion. We make these notions precise, and show that a reputation system based on hitting time resists tampering by individuals or groups who strategically place outlinks. We also present an algorithm to efficiently compute hitting time for all nodes in a massive graph; conventional algorithms do not scale adequately. Our algorithm, which applies to any random walk with restart, exploits a relationship between PageRank and hitting time in random walks with restart. This relationship also provides novel insights into spam detection and PageRank computation.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7984,Cornell University Department of Pathology and Bacteriology Poultry Disease Diagnostic Laboratory Reports: 1926,,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7985,"Cornell University Department of Pathology and B
acteriology Poultry Disease Diagnostic Laboratory Reports: 1927",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7986,"Cornell University Department of Pathology and B
acteriology Poultry Disease Diagnostic Laboratory Reports: 1928",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7987,"Cornell University Department of Pathology and B
acteriology Poultry Disease Diagnostic Laboratory Reports: 1929",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7988,"Cornell University Department of Pathology and B
acteriology Poultry Disease Diagnostic Laboratory Reports: 1930",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7989,"Cornell University Department of Pathology and B
acteriology Poultry Disease Diagnostic Laboratory Reports: 1931",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7990,"Cornell University Department of Pathology and B
acteriology Poultry Disease Diagnostic Laboratory Reports: 1932",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7992,"1946 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7993,"1947 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7994,"1948 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7995,"1949 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7996,"1950 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7997,"1951 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7998,"1952 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/7999,"1953 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8000,"1954 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8001,"1955 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8002,"1956 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8003,"1957 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8004,"1958 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8005,"1959 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8006,"1960 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8007,"1961 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8008,"1962 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8009,"1963 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8010,"1964 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8011,"1965 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8012,"1966 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8013,"1967 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8014,"1968 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8015,"1969 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8016,"1970 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8017,"1971 Poultry disease diagnostic laboratory report, East Aurora, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8018,"1932 Central New York State Official Egg Laying Contest, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8019,"1933 Central New York State Official Egg Laying Contest, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8020,"1934 Central New York State Official Egg Laying Contest, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8021,"1935 Central New York State Official Egg Laying Contest, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8022,"1936 Central New York State Official Egg Laying Contest, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8023,"1937 Central New York State Official Egg Laying Contest, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8024,"1938 Central New York State Official Egg Laying Contest, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8025,"1939 Central New York State Official Egg Laying Contest, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8026,"1940 Central New York State Official Egg Laying Contest, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8027,"1941 Central New York State Official Egg Laying Contest, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8028,"1942 Central New York State Official Egg Laying Contest, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8029,"1943 Central New York State Official Egg Laying Contest, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8030,"1944 Central New York State Official Egg Laying Contest, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8031,"1950 Random Sample Poultry Test, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8032,"1963 Random Sample Poultry Test, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8033,"1965 Random Sample Poultry Test, Horseheads, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8034,"1924 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8035,"1925 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8036,"1926 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8037,"1927 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8038,"1928 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8039,"1929 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8040,"1930 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8041,"1931 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8042,"1932 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8043,"1933 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8044,"1934 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8045,"1935 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8046,"1938 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8047,"1939 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8048,"1940 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8049,"1941 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8050,"1942 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8051,"1943 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8052,"1944 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8053,"1945 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8054,"1946 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8055,"1947 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8056,"1948 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8057,"1949 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8058,"1950 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8059,"1951 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8060,"1952 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8061,"1953 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8062,"1954 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8063,"1955 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8064,"1956 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8065,"1957 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8066,"1958 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8067,"1959 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8068,"1960 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8069,"1961 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8070,"1962 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8071,"1963 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8072,"1964 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8073,"1965 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8074,"1966 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8075,"1967 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8076,"1968 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8077,"1969 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8078,"1970 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8079,"1971 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8080,"1972 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8081,"1973 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8082,"1974 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8083,"1975 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8084,"1976 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8085,"1977 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8086,"1978 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease and Aquatic Animal Medicine. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8087,"1979 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease and Aquatic Animal Medicine. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8088,"1980 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease and Aquatic Animal Medicine. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8089,"1982 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease and Aquatic Animal Medicine. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8090,"1985 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease and Aquatic Animal Medicine. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8091,"1988 Poultry disease diagnostic laboratory report, Ithaca, New York",,"Documentation of poultry disease by the Cornell University Department of Avian Disease and Aquatic Animal Medicine. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8092,"1950 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8093,"1951 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8094,"1952 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8095,"1953 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8096,"1954 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8097,"1955 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8098,"1956 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8099,"1957 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8100,"1958 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8101,"1959 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8102,"1960 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8103,"1961 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8104,"1962 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8105,"1963 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8106,"1964 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8107,"1965 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8108,"1966 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8109,"1967 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8110,"1968 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8111,"1970 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8112,"1971 Poultry disease diagnostic laboratory report, Oneonta, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8113,"1931 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8114,"1932 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8115,"1933 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8116,"1934 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8117,"1935 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8118,"1936 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8119,"1938 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8120,"1939 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8121,"1940 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8122,"1941 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8123,"1942 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8124,"1943 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8125,"1945 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8126,"1946 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8127,"1947 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8128,"1949 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8129,"1950 Western New York State Official Egg Laying Contest, Stafford, New York",,"Documentation of poultry disease by the Cornell University Department of Pathology and Bacteriology. These records included name and address of the owner, date of observation, accession number, description of tissue, procedure and results, and diagnosis of the problem.",application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8219,Scalable Publish-Subscribe in a Managed Framework,"Reliable multicast, publish-subscribe and group communication are highly effective in support of replication and event notification, and could serve as the enabling technologies for new types of applications that are both interac-tive and decentralized. To fully realize this vision, we need a high-performance, scalable, and reliable multicast en-gine as an integral part of the runtime environment. Since the majority of development today is done in managed, strongly-typed environments such as Java or .NET, integration with such environments is of particular importance. What factors limit performance and scalability of a reliable multicast engine in a managed environment? What support from the runtime could improve performance, avoid instabilities, or make such systems easier to build? This paper sheds light on these questions by analyzing the performance of QuickSilver Scalable Multicast (QSM), a new multicast protocol and system built entirely in .NET. Memory-related overheads and scheduling-related phenomena are shown to dominate the behavior of our system. We discuss techniques that helped us alleviate some of these problems, and point to areas where better support from the runtime would be desirable.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8220,Implementing High Performance Multicast in a Managed Environment,"Component integration environments such as Microsoft .NET and J2EE have become widely popu-lar with application developers, who benefit from standardized memory management, system-wide type checking, debugging, and performance analysis tools that operate across component boundaries. This paper describes QuickSilver Scalable Multicast1 (QSM), a new multicast platform designed to achieve high performance in managed environments. Memory-related overheads and phenomena related to schedul-ing are shown to dominate the behavior of the system. We discuss techniques that helped us to alleviate these problems, and argue that they reveal general principles applicable to other kinds of high-data-rate protocols and applications in managed settings.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8221,Declarative Reliable Multi-Party Protocols,"We propose a novel, declarative approach to im-plementing reliable multi-party protocols that enables efficient and scalable implementations. Our Proper-ties Framework (PF) is able to express semantics as simple as gossip or resource cleanup, or as complex as transactions, consensus, and virtual synchrony. Protocols written in the PF compile to a hierarchical, scalable runtime infrastructure. Evaluation confirms that solutions developed this way can achieve high performance, while also benefiting from better inte-gration with the underlying runtime platform and its type system.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8222,Demand-Driven Alias Analysis for C,"This paper presents a demand-driven, flow-insensitive analysis algorithm for answering may-alias queries. We formulate the computation of alias queries as a CFL-reachability problem, and use this formulation to derive a demand-driven analysis algorithm. The analysis uses a worklist algorithm that gradually explores the program structure and stops as soon as enough evidence is gathered to answer the query. Unlike existing techniques, our approach does not require building or intersecting points-to sets. Experiments show that our technique is effective at answering alias queries accurately and efficiently in a demand-driven fashion.  For a set of alias queries from the SPEC2000 benchmarks, our analysis is able to accurately answer 97% of the queries in less than 1 millisecond per query. Compared to a demand-driven points-to analysis that constructs and intersects points-to sets on-the-fly, our alias analysis is more than two times faster.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8223,Motion Design and Learning of Autonomous Robots Based on Primitives and Heuristic Cost-to-Go,"The task of trajectory design of autonomous vehicles is typically two-fold. First, it needs to take into account the intrinsic dynamics of the vehicle, which are sometimes termed local constraints. Second, on a higher level, the designed trajectories must allow the vehicle to achieve some application-specific task. The specification of the task results in the so-called global constraints. Both of these two components of trajectory design are generally nontrivial problems, and very often, they are pursued as two parallel areas. When the results drawn from the two areas are applied in conjunction, the synthesis is usually somewhat arbitrary. In this paper, we assume some optimal control strategy that addresses the vehicle dynamics is available as a set of motion primitives. The trajectories that achieve the task are determined solely through the primitives and do not reference the vehicle dynamics directly. For the higher level, we translate the task into a very special type of cost-to-go function, which is partially specified artificially, and partially determined by an admissibility condition imposed by the set of primitives. The optimality feature of the primitives is formally extended to the final trajectory design. We illustrate our result with the example of a mobile robot retrieving an object, which is an interesting problem of its own right. Both a direct design approach and a learning approach are presented.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8225,High-Speed Function Approximation,"Learning methods for predictive models have traditionally focused on prediction quality and model building time, while prediction time(the time taken to make a prediction) is often ignored. However, there is an increasing need for models that are not only accurate, but also make fast predictions. Some of the most accurate models like ensemble models are often too slow to be used in practice.  We believe that exploring the tradeoff between prediction time and model accuracy is an exciting new direction for data mining research.  In this paper, we make a first step toward exploring this tradeoff. We introduce a new learning problem where we minimize model prediction time subject to a constraint on model accuracy. Our solution is a generic framework that leverages existing data mining algorithms while taking prediction time into account. We show a first application of our framework to a combustion simulation, and our results show significant improvements over existing methods.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8226,A Generalized Frequency Weighting Framework for LQG Compensator Design,"This paper specifies methods enabling specific types of frequency domain loopshaping in the LQG framework. It gives the augmented state and observation equations for a general system with colored sensor or motor noise, sensor and actuator dynamics, and frequency weight on the control and performance costs.  The performance weights are useful in design for dealing with the effects of many challenges facing control designers other than colored control and performance in the narrow sense, through shaping the sensitivity and loop gain.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8227,Visuomotor Optimality and its Utility in Parametrization of Response,"We present a method of characterizing visuomotor response by inferring subject-specific physiologically meaningful parameters within the framework of optimal control theory.  The characterization of visuomotor response is of interest in the assessment of impairment and rehabilitation, the analysis of man-machine systems, and sensorimotor research. We model visuomotor response as a Linear Quadratic Gaussian (LQG) controller, a Bayesian optimal state estimator in series with a linear quadratic regulator. Subjects used a modified computer mouse to attempt to keep a displayed cursor at a fixed desired location despite a Gaussian random disturbance and simple cursor dynamics. Nearly all subjects' behavior was consistent with the hypothesized optimality. Experimental data was used to fit an LQG model whose assumptions are simple and consistent with other sensorimotor work. The parametrization is parsimonious and yields quantities of clear physiological meaning: noise intensity, level of exertion, delay, and noise bandwidth. Inferred control cost and noise intensity varied significantly across subjects. Response variations were consistent with changes in exerted effort. This is a novel example of the role of optimal control theory in explaining variance in human visuomotor response. We also present technical improvements on the use of LQG in human operator modeling.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8425,Optimal Sequential Plans Based on Prior Distributions and Costs,Optimal Sequential Plans Based on Prior Distributions and Costs,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8426,A Comparison of the Performance Characteristics of Two Sequential Procedures for Ranking Means of Normal Populations,A Comparison of the Performance Characteristics of Two Sequential Procedures for Ranking Means of Normal Populations,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8427,Sequencing Against Due-Dates,Sequencing Against Due-Dates,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8428,"On Balanced Sets, Cores, and Linear Programming","On Balanced Sets, Cores, and Linear Programming",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8429,Optimal Policies for Two Product Inventory Systems With and Without Setup Costs,Optimal Policies for Two Product Inventory Systems With and Without Setup Costs,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8430,Adjacent Extreme Point Algorithms for the Fixed Charge Problem,Adjacent Extreme Point Algorithms for the Fixed Charge Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8431,Estimation of Ordered Parameters,Estimation of Ordered Parameters,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8432,A Multiple-Decision Approach to the Selection of the Best Set of Predictor Variates,A Multiple-Decision Approach to the Selection of the Best Set of Predictor Variates,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8433,Asymptotically Optimal Ranking and Selection Procedures,Asymptotically Optimal Ranking and Selection Procedures,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8434,Asymptotic Efficiency of the Maximum Likelihood Estimators for the Parameters of Certain Stochastic Processes,Asymptotic Efficiency of the Maximum Likelihood Estimators for the Parameters of Certain Stochastic Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8435,Queuing of Side Street Traffic at a Priority Type Vehicle -Actuated Signal,Queuing of Side Street Traffic at a Priority Type Vehicle -Actuated Signal,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8436,Asymptotic Efficiency of One Multifactor Experiment Relative to Several One-Factor Experiments for Selecting the Normal Population with the Largest Mean,Asymptotic Efficiency of One Multifactor Experiment Relative to Several One-Factor Experiments for Selecting the Normal Population with the Largest Mean,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8437,"Optimal Allocation of Observations when Comparing Several Treatments with a Control, III: Globally Best One-Sided Intervals for Unequal Variances","Optimal Allocation of Observations when Comparing Several Treatments with a Control, III: Globally Best One-Sided Intervals for Unequal Variances",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8438,Bounds and Optimal Strategies for Stochastic Systems,Bounds and Optimal Strategies for Stochastic Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8439,Solution Concepts of N-Person Cooperative Games as Points in the Game Space,Solution Concepts of N-Person Cooperative Games as Points in the Game Space,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8440,Statistical Multiple-Decision Procedures for some Multivariate Selection Problems,Statistical Multiple-Decision Procedures for some Multivariate Selection Problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8441,Complementarity Algorithms without Rays,Complementarity Algorithms without Rays,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8442,Measuring Power in Weighted Voting Systems,Measuring Power in Weighted Voting Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8443,"Chebyshev Type Lower Bounds for the Probability of Correct Selection, I: The Location Problem with One Observation from each of Two Populations","Chebyshev Type Lower Bounds for the Probability of Correct Selection, I: The Location Problem with One Observation from each of Two Populations",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8444,A (k+1)-decision Single-Stage Selection Procedure for Comparing k Normal Means with a Fixed Known Standard: The Case of Common Known Variance,A (k+1)-decision Single-Stage Selection Procedure for Comparing k Normal Means with a Fixed Known Standard: The Case of Common Known Variance,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8445,A Bivariate Test of Goodness of Fit Based on A Gradually Increasing Number of Order Statistics,A Bivariate Test of Goodness of Fit Based on A Gradually Increasing Number of Order Statistics,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8446,Dynamic Programming with Negative Rewards and Average Reward Criterion,Dynamic Programming with Negative Rewards and Average Reward Criterion,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8447,A (k+1)-decision Single-Stage Selection Procedure for Comparing k Normal Means with a Fixed Known Standard: The Case of Common Unknown Variance,A (k+1)-decision Single-Stage Selection Procedure for Comparing k Normal Means with a Fixed Known Standard: The Case of Common Unknown Variance,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8448,Multiple Decision Rules for Comparing Several Populations with a Fixed Known Standard,Multiple Decision Rules for Comparing Several Populations with a Fixed Known Standard,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8449,On Minimax Multistage Elimination Type Rules for Selecting the Largest Normal Mean,On Minimax Multistage Elimination Type Rules for Selecting the Largest Normal Mean,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8450,An Application of Lagrangian Relaxation to Scheduling in Powe Generation Systems,An Application of Lagrangian Relaxation to Scheduling in Powe Generation Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8451,A Sequential Goodness-of-Fit Test for Composite Hypotheses Involving Unknown Scale and Location Parameters,A Sequential Goodness-of-Fit Test for Composite Hypotheses Involving Unknown Scale and Location Parameters,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8452,An Application of Majorization to the Problem of Selecting the Largest Interaction in a Two-Factor Experiment,An Application of Majorization to the Problem of Selecting the Largest Interaction in a Two-Factor Experiment,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8453,"The Empirical Distribution Function with Arbitrarily Grouped, Censored and Truncated Data","The Empirical Distribution Function with Arbitrarily Grouped, Censored and Truncated Data",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8454,A Likelihood Ration Statistic for Testing Goodness of Fit with Randomly Censored Data,A Likelihood Ration Statistic for Testing Goodness of Fit with Randomly Censored Data,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8455,An Analysis of Weighted Voting Systems Using the Banzhaf Value (MS Thesis),An Analysis of Weighted Voting Systems Using the Banzhaf Value (MS Thesis),,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8456,"Optimal Policy for Database Batch Operations: Backup, Check-Pointing, and Batch Update","Optimal Policy for Database Batch Operations: Backup, Check-Pointing, and Batch Update",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8457,"Some Approximations in Multi-Item, Multi-Echelon Inventory Systems for Recoverable Items","Some Approximations in Multi-Item, Multi-Echelon Inventory Systems for Recoverable Items",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8458,"The Consolidated Support Model: A Three-Echelon, Multi-Item Model for Recoverable Items","The Consolidated Support Model: A Three-Echelon, Multi-Item Model for Recoverable Items",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8459,A Two-Stage Minimax Procedure with Screeming for Selecting the Largest Normal Mean,A Two-Stage Minimax Procedure with Screeming for Selecting the Largest Normal Mean,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8460,Sequential Adaptive Sampling Rules for Choosing the Best of Several Normal Populations,Sequential Adaptive Sampling Rules for Choosing the Best of Several Normal Populations,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8461,Internal Telephone Billing Rates: A Novel Application of Non-Atomic Game Theory,Internal Telephone Billing Rates: A Novel Application of Non-Atomic Game Theory,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8462,A Survey of Covariance Models for Censored Life Daya with an Application to Recidivism Analysis,A Survey of Covariance Models for Censored Life Daya with an Application to Recidivism Analysis,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8463,Optimal Asymptotic Properties of Maximum Likelihood Estimators of Parameters of Some Economic Models (Thesis),Optimal Asymptotic Properties of Maximum Likelihood Estimators of Parameters of Some Economic Models (Thesis),,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8464,On the Probability Distribution for Inventory Position in Two Echelon Continuous Review Systems,On the Probability Distribution for Inventory Position in Two Echelon Continuous Review Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8465,"Analysis of a Two-Echelon Inventory System in which all Locations Follow Continuous Review (S,s) Policies","Analysis of a Two-Echelon Inventory System in which all Locations Follow Continuous Review (S,s) Policies",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8466,Combinatorial Algorithms in Certain Classes of Binary Matroids (Thesis),Combinatorial Algorithms in Certain Classes of Binary Matroids (Thesis),,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8467,A General Algorithm for Optimal Job Sequencing with Series-Parallel Precedence Constraints,A General Algorithm for Optimal Job Sequencing with Series-Parallel Precedence Constraints,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8468,On the Selection of Numbers of Servers for the N Server-Type Problem (Thesis),On the Selection of Numbers of Servers for the N Server-Type Problem (Thesis),,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8469,Computational Complexity of Specially Structured Integer Programming Problems,Computational Complexity of Specially Structured Integer Programming Problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8470,Integral Near-Optimal Solutions to Certain Classes of Linear Programming Problems (Thesis),Integral Near-Optimal Solutions to Certain Classes of Linear Programming Problems (Thesis),,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8471,An Analysis of Two Two-Echelon Inventory Systems,An Analysis of Two Two-Echelon Inventory Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8472,A Comparison of Alternative Methods for Computing Inventory Levels in a Two-Echelon System in which All Locations Follow Coninuous Review Policies,A Comparison of Alternative Methods for Computing Inventory Levels in a Two-Echelon System in which All Locations Follow Coninuous Review Policies,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8473,Scheduling with Interactive Computer Graphics,Scheduling with Interactive Computer Graphics,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8474,Graphs with K-Balanced Closed Neighborhood Matrices,Graphs with K-Balanced Closed Neighborhood Matrices,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8475,J': A new Triangulation of R^n,J': A new Triangulation of R^n,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8476,Central Limit Theorems for Quadratic Forms in Random Variables Having Long-Range Dependence,Central Limit Theorems for Quadratic Forms in Random Variables Having Long-Range Dependence,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8477,Non-Central Limit Theorems for Quadratic Forms in Random Variables Having Long-Range Dependence,Non-Central Limit Theorems for Quadratic Forms in Random Variables Having Long-Range Dependence,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8478,Maximum Likelihood Type Estimator for the Self-Similarity Parameter,Maximum Likelihood Type Estimator for the Self-Similarity Parameter,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8479,Stochastic Comparison of Bulk Queues,Stochastic Comparison of Bulk Queues,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8480,Initialization Effects in Computer Simulation Experiments,Initialization Effects in Computer Simulation Experiments,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8481,Polynomial Expected Behavior of a Pivoting Algorithm for Linear Complementarity and Linear Programming Problems,Polynomial Expected Behavior of a Pivoting Algorithm for Linear Complementarity and Linear Programming Problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8482,Expository multinomial...,Expository multinomial...,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8483,Counting Faces and Chains in Polytopes and Posets,Counting Faces and Chains in Polytopes and Posets,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8484,An Empirical Bayes Goodness of Fit Test,An Empirical Bayes Goodness of Fit Test,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8485,Multiple Stochastic Integrals with Dependent Integrators,Multiple Stochastic Integrals with Dependent Integrators,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8486,Optimal Properties of the Bechhofer-Kulkarni Bernoulli Selection Procedure,Optimal Properties of the Bechhofer-Kulkarni Bernoulli Selection Procedure,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8487,A Proof of the Conjecture that the TUKEY-KRAMER Multiple Comparisons Procedure is Conservative,A Proof of the Conjecture that the TUKEY-KRAMER Multiple Comparisons Procedure is Conservative,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8488,A Polynomial-Time Dual Simplex Algorithm for the Transportation Problem,A Polynomial-Time Dual Simplex Algorithm for the Transportation Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8489,Cost Estimating Methods for Evaluating the Conversion from a Functional Manufacturing Layout to Group Technology,Cost Estimating Methods for Evaluating the Conversion from a Functional Manufacturing Layout to Group Technology,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8490,A Survey of Functional Laws of the Iterated Logarithm for Self-Similar Processes,A Survey of Functional Laws of the Iterated Logarithm for Self-Similar Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8491,The Uncapicitated Facility Location Problem,The Uncapicitated Facility Location Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8492,Designing Experiments for Selecting a Normal Population with a Large Mean and a Small Variance,Designing Experiments for Selecting a Normal Population with a Large Mean and a Small Variance,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8493,Packing and Covering with Integral Feasible Flows in Integral Supply-Demand Networks,Packing and Covering with Integral Feasible Flows in Integral Supply-Demand Networks,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8494,On the Expected Sample Size for the Bechhofer-Kulkarni Bernoulli Selection Procedure,On the Expected Sample Size for the Bechhofer-Kulkarni Bernoulli Selection Procedure,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8495,"Generalized Dehn-Sommerville Relations for Polytopes, Spheres and Eulerian Partially Ordered Sets","Generalized Dehn-Sommerville Relations for Polytopes, Spheres and Eulerian Partially Ordered Sets",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8496,Estimating a Paramatized Mixture of Normal Distributions,Estimating a Paramatized Mixture of Normal Distributions,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8497,Discrete Packing and Covering: An Annotated Bibliography,Discrete Packing and Covering: An Annotated Bibliography,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8498,Process in a Randomly Fluctuating Environment,Process in a Randomly Fluctuating Environment,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8499,A Survey of Literature on Estimation Methods for Quantal Response Curves with a View Toward Applying them to the...,A Survey of Literature on Estimation Methods for Quantal Response Curves with a View Toward Applying them to the...,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8500,Closed Sequential Procedures for Selecting the Multinomial Events which Have the Largest Probabilities,Closed Sequential Procedures for Selecting the Multinomial Events which Have the Largest Probabilities,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8501,"Two-Period, Two-Echelon Newsboy Problem","Two-Period, Two-Echelon Newsboy Problem",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8502,Modifying the Forrest-Tomlin and Saunders Updates for Linear Programming Problems with Variable Upper Bounds,Modifying the Forrest-Tomlin and Saunders Updates for Linear Programming Problems with Variable Upper Bounds,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8503,Double Integration with Respect to Symmetric Stable Processes,Double Integration with Respect to Symmetric Stable Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8504,Clipped Gaussian Processes are not M-Step Markov,Clipped Gaussian Processes are not M-Step Markov,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8505,The Banzhof Power Index,The Banzhof Power Index,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8506,Generalizations of the Basic Renewal Theorem for Dependent Variables,Generalizations of the Basic Renewal Theorem for Dependent Variables,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8507,Symmetric Polynomials of Random Variables Attracted to an Infinitely Divisible Law,Symmetric Polynomials of Random Variables Attracted to an Infinitely Divisible Law,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8508,Repeated Confidence Intervals for the Median Surival Time,Repeated Confidence Intervals for the Median Surival Time,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8509,Determining Optimal Reorder Intervals in Capcitated Production-Distribution Systems,Determining Optimal Reorder Intervals in Capcitated Production-Distribution Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8510,An Optimal Sequential Procedure for Selecting the Best Bernoulli Process,An Optimal Sequential Procedure for Selecting the Best Bernoulli Process,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8511,The Ellipsoid Method Generates Dual Variables,The Ellipsoid Method Generates Dual Variables,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8512,Nonlinear Scaling of Sample Maxima,Nonlinear Scaling of Sample Maxima,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8513,A Restricted Class of Allocation Policies in a Two-Echelon Inventory System,A Restricted Class of Allocation Policies in a Two-Echelon Inventory System,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8514,A Distribution System Policy Simulator,A Distribution System Policy Simulator,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8515,Sojourn in an Elliptical Domain,Sojourn in an Elliptical Domain,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8516,Symmetry and Positive Definiteness in Oriented Matroids,Symmetry and Positive Definiteness in Oriented Matroids,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8517,A Constructive Algorithm for Planning Production in Multi-Stage Systems with Stationary Demand,A Constructive Algorithm for Planning Production in Multi-Stage Systems with Stationary Demand,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8518,Planning Component Delivery Intervals in Constrained Assembly Systems,Planning Component Delivery Intervals in Constrained Assembly Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8519,"Risk Polling in a Two-Period, Two-Echelon Inventory Stocking and Allocation Problem","Risk Polling in a Two-Period, Two-Echelon Inventory Stocking and Allocation Problem",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8520,A Geometric Approach to Constructing Martingale Measures: The Finite Case,A Geometric Approach to Constructing Martingale Measures: The Finite Case,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8521,The Analysis of Finite Security Markets Using Martingales,The Analysis of Finite Security Markets Using Martingales,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8522,Tag Systems: A Combinatorial Abstraction of Integral Dependence,Tag Systems: A Combinatorial Abstraction of Integral Dependence,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8523,An Abstract Linear Duality Model,An Abstract Linear Duality Model,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8524,On the Ramey-Alam Sequential Procedure for Selecting the Multinomial Event which has the Largest Probability,On the Ramey-Alam Sequential Procedure for Selecting the Multinomial Event which has the Largest Probability,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8525,Truncation of the Bechhofer-Kiefer-Sobel Sequential Procedure for Selecting the Multinomial Event which has the Largest Probability,Truncation of the Bechhofer-Kiefer-Sobel Sequential Procedure for Selecting the Multinomial Event which has the Largest Probability,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8526,"A 98%-Effective Lot Sizing Rule for a Multi-Product, Multi-Stage Production/Inventory System","A 98%-Effective Lot Sizing Rule for a Multi-Product, Multi-Stage Production/Inventory System",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8527,Generalized Powers of Strongly Dependent Random Variables,Generalized Powers of Strongly Dependent Random Variables,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8528,Reproducing Kernel Hilbert Space for Some Non-Gaussian Processes,Reproducing Kernel Hilbert Space for Some Non-Gaussian Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8529,Confidence Intervals for a Binomial Parameter Based on Multistage Tests,Confidence Intervals for a Binomial Parameter Based on Multistage Tests,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8530,"Planning Shipping Intervals in Multi-Item, One-Warehouse, Multi-Retailer Distribution Systems","Planning Shipping Intervals in Multi-Item, One-Warehouse, Multi-Retailer Distribution Systems",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8531,The Effects of a Biased Estimate of Demand on Inventory Levels and Customer Service,The Effects of a Biased Estimate of Demand on Inventory Levels and Customer Service,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8532,An Extension of Karmarkar's Algorithm for Linear Programming Using Variables,An Extension of Karmarkar's Algorithm for Linear Programming Using Variables,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8533,An Analysis of Optimal Production Plans for Sample GM Component Manufacture Using the MAXSTADT Planning Package,An Analysis of Optimal Production Plans for Sample GM Component Manufacture Using the MAXSTADT Planning Package,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8534,Discrete Linear Duality,Discrete Linear Duality,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8535,Graphic Greedoids and their Duals,Graphic Greedoids and their Duals,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8536,Greedoid Polyhedra,Greedoid Polyhedra,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8537,Computational Experience with a Polynomial-Time Dual Simplex Algorithm for the Transportation Problem,Computational Experience with a Polynomial-Time Dual Simplex Algorithm for the Transportation Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8538,Significant Factor Identification using Discrete Spectral Methods,Significant Factor Identification using Discrete Spectral Methods,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8539,Ex-dividend Stock Price Behavior and Arbitrage Opportunities,Ex-dividend Stock Price Behavior and Arbitrage Opportunities,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8540,Optimal Replacement for Fault Tolerant Systems,Optimal Replacement for Fault Tolerant Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8541,Minimizing or Maximizing the Expected Time to Reach Zero,Minimizing or Maximizing the Expected Time to Reach Zero,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8542,"Frequency Domain Experiments: Spectral Amplification, Input-Output Correlations, and Model Parameters","Frequency Domain Experiments: Spectral Amplification, Input-Output Correlations, and Model Parameters",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8543,"Production-Distribution Systems Inventory Planning (SIP): Rationale, Economic and Realities","Production-Distribution Systems Inventory Planning (SIP): Rationale, Economic and Realities",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8544,Throughput Analysis of Closed Loop Material Handling Systems: Deterministic Case,Throughput Analysis of Closed Loop Material Handling Systems: Deterministic Case,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8545,On the Computational Behavior of a Polynomial-Time Network Flow Algorithm,On the Computational Behavior of a Polynomial-Time Network Flow Algorithm,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8546,A Note on Albert and Anderson's Conditions for the Existence of Maximum Likelihood Estimates in Logistics Regression Models,A Note on Albert and Anderson's Conditions for the Existence of Maximum Likelihood Estimates in Logistics Regression Models,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8547,Rounding off to Powers of Two in the Economic Lot Scheduling Problem,Rounding off to Powers of Two in the Economic Lot Scheduling Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8548,On the Adequacy of Pseudo-Random Number Generators,On the Adequacy of Pseudo-Random Number Generators,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8549,A Class of Ruin Problems,A Class of Ruin Problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8550,Probability Modelling Across the Continents,Probability Modelling Across the Continents,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8551,A Class of Production Planning Problems Solvable by Network Flows,A Class of Production Planning Problems Solvable by Network Flows,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8552,Dyadic Approximation of double Integrals with Respect to Symmetric Stable Processes,Dyadic Approximation of double Integrals with Respect to Symmetric Stable Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8553,An Epxerimental Procedure for Simulation Response Surface Model Identification,An Epxerimental Procedure for Simulation Response Surface Model Identification,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8554,Almost Sure Ordering of Some Continuous Time Stochastic Processes with Applications (Thesis),Almost Sure Ordering of Some Continuous Time Stochastic Processes with Applications (Thesis),,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8555,"Efficient, Effective Lot-Sizing for Multi-Product Multi-Stage Production/Distribution Systems with Correlated Demands","Efficient, Effective Lot-Sizing for Multi-Product Multi-Stage Production/Distribution Systems with Correlated Demands",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8556,Balanced Subdivision and Enumeration in Balanced Spheres,Balanced Subdivision and Enumeration in Balanced Spheres,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8557,Reformulations of Economic Equilibrium Problems for Solution by Quasi-Newton and Simplicial Algorithms,Reformulations of Economic Equilibrium Problems for Solution by Quasi-Newton and Simplicial Algorithms,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8558,94%-Effective Lot-Sizing in Multi-Stage Assembly Systems,94%-Effective Lot-Sizing in Multi-Stage Assembly Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8559,"Operating Policies for Water-Supply Reservoirs in Parallel, I: The Single Demand System","Operating Policies for Water-Supply Reservoirs in Parallel, I: The Single Demand System",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8560,Estimating the Compensator from Poisson Type Counting Processes,Estimating the Compensator from Poisson Type Counting Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8561,On the Stochastic Minimization of Sample Size by the Bechhofer-Kulkarni Bernoulli Sequential Selection Procedure,On the Stochastic Minimization of Sample Size by the Bechhofer-Kulkarni Bernoulli Sequential Selection Procedure,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8562,Two-Stage Selection of the Best Factor Level Combination in Multi-Factor Experiments: Common Unknown Variance,Two-Stage Selection of the Best Factor Level Combination in Multi-Factor Experiments: Common Unknown Variance,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8563,On Randomized Stopping Points and Perfect Graphs,On Randomized Stopping Points and Perfect Graphs,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8564,Integer Rounding and Combinatorial Max-Min Theorems,Integer Rounding and Combinatorial Max-Min Theorems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8565,Conditioning in Rank 1 Quasi-Newton Updates,Conditioning in Rank 1 Quasi-Newton Updates,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8566,On Bounds in Anstreicher's Monotonic Projective Algorithm,On Bounds in Anstreicher's Monotonic Projective Algorithm,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8567,Truncation of the Bechhofer-Kiefer-Sobel Sequential Procedure for Selecting the Multinomial Event which has the Largest Probability (II): Extended Tables and an Improved Procedure,Truncation of the Bechhofer-Kiefer-Sobel Sequential Procedure for Selecting the Multinomial Event which has the Largest Probability (II): Extended Tables and an Improved Procedure,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8568,Cornell Simulator of Manufacturing Operations,Cornell Simulator of Manufacturing Operations,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8569,Nonparametric Inference from Poisson-Type Counting Processes (Thesis),Nonparametric Inference from Poisson-Type Counting Processes (Thesis),,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8570,Residual Methods for Computing Hermite and Smith Normal Forms (Thesis),Residual Methods for Computing Hermite and Smith Normal Forms (Thesis),,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8571,The Symmetric Rank-One Quasi-Newton Method is a Space Dilation Subgradient Algorithm,The Symmetric Rank-One Quasi-Newton Method is a Space Dilation Subgradient Algorithm,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8572,Computing the Volume is Difficult,Computing the Volume is Difficult,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8573,Empty Simplices in Euclidean Space,Empty Simplices in Euclidean Space,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8574,Cutting-plane Proofs in Polynomial Space,Cutting-plane Proofs in Polynomial Space,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8575,On the Convex Hull of Random Points,On the Convex Hull of Random Points,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8576,The interaction between Design and Scheduling in Repetitive Manufacturing Environments,The interaction between Design and Scheduling in Repetitive Manufacturing Environments,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8577,Scheduling the Factory of the Future - Results of a Research Planning Session,Scheduling the Factory of the Future - Results of a Research Planning Session,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8578,Rearrangement of Series in Infinite-Dimensional Spaces,Rearrangement of Series in Infinite-Dimensional Spaces,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8579,A Model for the Failure Process of Semi-Crystalline Polymer Materials Under Static Fatigue,A Model for the Failure Process of Semi-Crystalline Polymer Materials Under Static Fatigue,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8580,Arranging Points in R^d: A Question of Balance,Arranging Points in R^d: A Question of Balance,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8581,The Lot Scheduling Problem in the Hierarchy of Decision Models,The Lot Scheduling Problem in the Hierarchy of Decision Models,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8582,Invariant Small Sample Confidence Intervals for the Difference of Two Success Probabilities,Invariant Small Sample Confidence Intervals for the Difference of Two Success Probabilities,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8583,Buffer placement in Sequential production lines: Considerations of Processing Time Viability,Buffer placement in Sequential production lines: Considerations of Processing Time Viability,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8584,On Infinite Perfect Graphs And Randomized Stopping Points on the Plane,On Infinite Perfect Graphs And Randomized Stopping Points on the Plane,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8585,Buffer placement in Sequential production lines: Further Studies,Buffer placement in Sequential production lines: Further Studies,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8586,Estimating Logistic Regression Probabilities,Estimating Logistic Regression Probabilities,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8587,Sequential Selection Procedures for Multi-factor Experiments Involving Koopman-Darmois Populations with Additivity,Sequential Selection Procedures for Multi-factor Experiments Involving Koopman-Darmois Populations with Additivity,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8588,Percentage Points of Multivariate Student t Distributions,Percentage Points of Multivariate Student t Distributions,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8589,Nonparametric Estimation from a censored Markov Renewal Process Observed Over a Long Period of Time,Nonparametric Estimation from a censored Markov Renewal Process Observed Over a Long Period of Time,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8590,Polynomial Algorithms for Linear Programming,Polynomial Algorithms for Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8591,Life-Testing and Estimation with Arbitrary Distribution Function,Life-Testing and Estimation with Arbitrary Distribution Function,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8592,Inference from Censored Markov Chains with Applications to Multiwave Panel Data,Inference from Censored Markov Chains with Applications to Multiwave Panel Data,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8593,An Improvement on Paulson's Sequential Procedure for Selecting the Largest Normal Mean,An Improvement on Paulson's Sequential Procedure for Selecting the Largest Normal Mean,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8594,Integral Monoid Duality Models,Integral Monoid Duality Models,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8595,Tandem Queueing Systems with Blocking,Tandem Queueing Systems with Blocking,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8596,An Abstract Duality,An Abstract Duality,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8597,Driving Frequency Selection for Frequency Domain Simulation Experiments,Driving Frequency Selection for Frequency Domain Simulation Experiments,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8598,A Review of Techniques for Simulation Optimization,A Review of Techniques for Simulation Optimization,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8599,Rounding Off to Powers of Two in Coninuous Relaxations of Capacitated Lot Sizing Problems,Rounding Off to Powers of Two in Coninuous Relaxations of Capacitated Lot Sizing Problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8600,Oriented Matroids and the Linear Complementarity Problem,Oriented Matroids and the Linear Complementarity Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8601,Some Problems of Estimation from Poisson Type Counting Processes,Some Problems of Estimation from Poisson Type Counting Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8602,Buffer Placement in Sequential Production Lines: Still Further Studies,Buffer Placement in Sequential Production Lines: Still Further Studies,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8603,Exploiting Special Structure in Karmarkar's Linear Programming Algorithm,Exploiting Special Structure in Karmarkar's Linear Programming Algorithm,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8604,Improved Bounds and Containing Ellipsoids in Karmarkar's Linear Programming Algorithm,Improved Bounds and Containing Ellipsoids in Karmarkar's Linear Programming Algorithm,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8605,Leaving an Interval in Limited Playing Time,Leaving an Interval in Limited Playing Time,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8606,Coherent Inference from Improper Priors and from Finitely Additive Priors,Coherent Inference from Improper Priors and from Finitely Additive Priors,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8607,A Note on the Tail Distribution of the Accumulated Value of an Additive Functional of an Irreducible Markov Chain,A Note on the Tail Distribution of the Accumulated Value of an Additive Functional of an Irreducible Markov Chain,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8608,On the Relationship Between the Search Directions in the Affine and Projective Variants of Karmarkar's Linear Programming Algorithm,On the Relationship Between the Search Directions in the Affine and Projective Variants of Karmarkar's Linear Programming Algorithm,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8609,A Unified Interpretation of Several Combinatorial Dualities,A Unified Interpretation of Several Combinatorial Dualities,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8610,Parallel Computing in Combinatorial Optimization,Parallel Computing in Combinatorial Optimization,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8611,Subset Selection for Normal Means in Multi-Factor Experiments,Subset Selection for Normal Means in Multi-Factor Experiments,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8612,Random Time Changes for Processes with Random Birth and Death,Random Time Changes for Processes with Random Birth and Death,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8613,Large Traveling Salesmen Problems Arising from Experiments in X-Ray Crystallography: A Preliminary Report on Computation,Large Traveling Salesmen Problems Arising from Experiments in X-Ray Crystallography: A Preliminary Report on Computation,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8614,Multi-Echelon and Joint Replenishment Production and Distribution Systems with Non-Stationary Demands,Multi-Echelon and Joint Replenishment Production and Distribution Systems with Non-Stationary Demands,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8615,Weakly Oriented Matroids,Weakly Oriented Matroids,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8616,Balancing Configurations in R^d by Reflection of Points,Balancing Configurations in R^d by Reflection of Points,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8617,A Framework for a Computer-Aided Logistics System,A Framework for a Computer-Aided Logistics System,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8618,The Cosmos Scheduler,The Cosmos Scheduler,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8619,Lot Sizing in Cyclic Scheduling,Lot Sizing in Cyclic Scheduling,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8620,On Abstract Integral Dependence,On Abstract Integral Dependence,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8621,Estimation from an Infinite Server Queueing System with Two Demands,Estimation from an Infinite Server Queueing System with Two Demands,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8622,Shortest Rectilinear Paths Among Obstacles,Shortest Rectilinear Paths Among Obstacles,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8623,Transaction Tagging in Highly Congested Queueing Systems,Transaction Tagging in Highly Congested Queueing Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8624,Two Variants of Karmarkar's Linear Programming Algorithm for Problems with Some Unrestricted Variables,Two Variants of Karmarkar's Linear Programming Algorithm for Problems with Some Unrestricted Variables,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8625,"Combinatorial Perspectives on Linear Programming, Part I: Linear Programming Duality and Minty's Lemma","Combinatorial Perspectives on Linear Programming, Part I: Linear Programming Duality and Minty's Lemma",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8626,A Generalization of Robacker's Theorem,A Generalization of Robacker's Theorem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8627,Truncation of the Bechhofer-Kiefer-Sobel Sequential Procedure for Selecting the Normal Population which ahs the Largest Mean,Truncation of the Bechhofer-Kiefer-Sobel Sequential Procedure for Selecting the Normal Population which ahs the Largest Mean,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8628,"Optimal Allocation of Observations in Subset Selection and Multiple Comparisons with a Control, and Associated Tables (With Application to Drug Screening)","Optimal Allocation of Observations in Subset Selection and Multiple Comparisons with a Control, and Associated Tables (With Application to Drug Screening)",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8629,An Optimal Visibility Algorithm for A Simple Polygon with Star-Shaped Holes,An Optimal Visibility Algorithm for A Simple Polygon with Star-Shaped Holes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8630,Gradient Computation for Transient Markov Chains,Gradient Computation for Transient Markov Chains,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8631,On the Worst Case Arithmetic Complexity of Approximating Zeros of Systems of Polynomials,On the Worst Case Arithmetic Complexity of Approximating Zeros of Systems of Polynomials,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8632,A Theory of Semiregenerative Phenomena,A Theory of Semiregenerative Phenomena,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8633,"An Analog of Karmarkar's Algorithm for Inequality Constrained Linear Programs, with a New Class of Projective Transformations for Centering a Polytope","An Analog of Karmarkar's Algorithm for Inequality Constrained Linear Programs, with a New Class of Projective Transformations for Centering a Polytope",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8634,Computing Nested Reorder Intervals for Multi-Item Distribution Systems,Computing Nested Reorder Intervals for Multi-Item Distribution Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8635,COSMOS: The Cornell Simulator of Manufacturing Operations,COSMOS: The Cornell Simulator of Manufacturing Operations,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8636,Complexity of Gradient Estimation for Transient Markov Chains,Complexity of Gradient Estimation for Transient Markov Chains,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8637,Testing Strategies for Simulation Optimization,Testing Strategies for Simulation Optimization,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8638,Computing the Gradient of Expected Reward up to Absorption,Computing the Gradient of Expected Reward up to Absorption,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8639,Truncation of the Bechhofer-Kiefer-Sobel Sequential Procedure for Selecting the Normal Population which has the Largest Mean (II): 2-Factor Experiments With Additivity,Truncation of the Bechhofer-Kiefer-Sobel Sequential Procedure for Selecting the Normal Population which has the Largest Mean (II): 2-Factor Experiments With Additivity,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8640,Optimal Accelerated Lifetest Plans Which Minimize the Maximum Test Stress,Optimal Accelerated Lifetest Plans Which Minimize the Maximum Test Stress,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8641,Generating Markov-Chain Transitions Efficiently,Generating Markov-Chain Transitions Efficiently,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8642,Fitting Heteroscedastic Models to Individual Pharmacokinetic Data Using Standard Statistical Software,Fitting Heteroscedastic Models to Individual Pharmacokinetic Data Using Standard Statistical Software,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8643,Fitting Mathematical Models to Biological Data: A Review of Recent Developments,Fitting Mathematical Models to Biological Data: A Review of Recent Developments,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8644,Beating Future-Event Schedules,Beating Future-Event Schedules,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8645,Transformations to Symmetry and Homoscedasticity,Transformations to Symmetry and Homoscedasticity,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8646,A Centered Projective Algorithm for Linear Programming,A Centered Projective Algorithm for Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8647,"Shortest Paths Among Obstacles, Zero-Cost Regions, and Roads","Shortest Paths Among Obstacles, Zero-Cost Regions, and Roads",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8648,The Joint Replenishment Problem: New Heuristics and Worst Cast Performance Bonds,The Joint Replenishment Problem: New Heuristics and Worst Cast Performance Bonds,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8649,Optimal Cyclic Schedules for Job Shops with Identical Jobs,Optimal Cyclic Schedules for Job Shops with Identical Jobs,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8650,Minimizing Separable Convex Objectives on Arbitrarily Directed Trees of Variable Upper Bound Constraints,Minimizing Separable Convex Objectives on Arbitrarily Directed Trees of Variable Upper Bound Constraints,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8651,Weighted-Tardiness Scheduling with Weights Proportional to Processing Times,Weighted-Tardiness Scheduling with Weights Proportional to Processing Times,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8652,The Extended Economic Lot Scheduling Problem,The Extended Economic Lot Scheduling Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8653,Linear Control Policies for Scheduling a Single Facility After an Initial Disruption,Linear Control Policies for Scheduling a Single Facility After an Initial Disruption,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8654,Produce-Up-To Policies for Scheduling a Single Facility after an Initial Disruption,Produce-Up-To Policies for Scheduling a Single Facility after an Initial Disruption,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8655,"Recursive Estimations for Stationary, Strong Mixing Processes- A Representation Theorem and Asymptotic Distributions","Recursive Estimations for Stationary, Strong Mixing Processes- A Representation Theorem and Asymptotic Distributions",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8656,On the Generality of Simulation Graphs,On the Generality of Simulation Graphs,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8657,Establishing Reorder Intervals and Inspection Policies when Production and Inspection Processes are Unreliable,Establishing Reorder Intervals and Inspection Policies when Production and Inspection Processes are Unreliable,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8658,Extremal Behavior of Solutions to a Stochastic Difference Equation with Applications to Arch-Processes,Extremal Behavior of Solutions to a Stochastic Difference Equation with Applications to Arch-Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8659,On Anstreicher's Combined Phase I - Phase II Projective Algorithm for Linear Programming,On Anstreicher's Combined Phase I - Phase II Projective Algorithm for Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8660,Linear Programming,Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8661,Replication Schemes for Limiting Expectations,Replication Schemes for Limiting Expectations,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8662,An Algorithmic Approach to some Problems in Terrain Navigation,An Algorithmic Approach to some Problems in Terrain Navigation,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8663,On the Convergence of Algorithms for Unconstrained Minimization,On the Convergence of Algorithms for Unconstrained Minimization,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8664,Efficient Estimations from a Slowly Convergent Robbins-Monro Process,Efficient Estimations from a Slowly Convergent Robbins-Monro Process,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8665,Karmarkar as Dantzig-Wolfe,Karmarkar as Dantzig-Wolfe,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8666,"Discussion of a Paper in Statistical Science by A.S. Hetadat, M. Jacroux and D. Mayumdur","Discussion of a Paper in Statistical Science by A.S. Hetadat, M. Jacroux and D. Mayumdur",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8667,Frequency Domain Simulation Experiments: The False Negatives Problem,Frequency Domain Simulation Experiments: The False Negatives Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8668,Gradient Estimation of Stochastic Dynamical System Responses in the Frequent Domain,Gradient Estimation of Stochastic Dynamical System Responses in the Frequent Domain,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8669,Random Effect Models in Nonlinear Regression with Applications to Bioassay,Random Effect Models in Nonlinear Regression with Applications to Bioassay,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8670,Quantifying Closeness of Distributions of Sums and Maxima when Tails are Fat,Quantifying Closeness of Distributions of Sums and Maxima when Tails are Fat,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8671,Subexponential Distribution Tails and Point Processes,Subexponential Distribution Tails and Point Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8672,A Comparison of the Performances of Procedures for Selecting the Normal Population Having the Largest Mean when the Variances are Known and Equal,A Comparison of the Performances of Procedures for Selecting the Normal Population Having the Largest Mean when the Variances are Known and Equal,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8673,Discrete-Time Conversion for Finite-Horizon Markov Processes,Discrete-Time Conversion for Finite-Horizon Markov Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8674,Extremes of Moving Averages of Random Variables from the Domain of the Double Exponential Distribution,Extremes of Moving Averages of Random Variables from the Domain of the Double Exponential Distribution,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8675,A Faster PSPACE Algorithm for Deciding the Existential Theory of the Reals,A Faster PSPACE Algorithm for Deciding the Existential Theory of the Reals,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8676,Simulating Discounted Costs,Simulating Discounted Costs,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8677,Equivalence of Simulations: A Graph Theoretical Approach,Equivalence of Simulations: A Graph Theoretical Approach,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8678,Interval Estimation of the Marginal Probability of Success for the Beta-Binomial Distribution,Interval Estimation of the Marginal Probability of Success for the Beta-Binomial Distribution,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8679,A Transformation/Weighting Model for Estimating Michaelis-Menten Parameters,A Transformation/Weighting Model for Estimating Michaelis-Menten Parameters,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8680,Interim Analysis: The Repeated Confidence Interval Approach,Interim Analysis: The Repeated Confidence Interval Approach,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8681,Lot Sizing in Multi-Echelon Assembly Systems: Heuristics and Worst Case Performance Bounds,Lot Sizing in Multi-Echelon Assembly Systems: Heuristics and Worst Case Performance Bounds,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8682,An Implementation of Todd's Algorithm for Variable Upper Bounds,An Implementation of Todd's Algorithm for Variable Upper Bounds,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8683,Basic Properties and Prediction of Max-Arma Processes,Basic Properties and Prediction of Max-Arma Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8684,Two-Stage Procedures for Comparing Treatments with a Control Elimination at the First Stage and Estimation at the Second Stage,Two-Stage Procedures for Comparing Treatments with a Control Elimination at the First Stage and Estimation at the Second Stage,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8685,"Efficient, Effective Lot-Sizing for Multi-Product Multi-Stage Production/Distribution Systems with Correlated Demands","Efficient, Effective Lot-Sizing for Multi-Product Multi-Stage Production/Distribution Systems with Correlated Demands",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8686,"A Two-Stage Procedure for Selecting the Best Normal Population Whose First Stage Selects a Bounded, Random Number for Populations","A Two-Stage Procedure for Selecting the Best Normal Population Whose First Stage Selects a Bounded, Random Number for Populations",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8687,A Curtailed Sequential Procedure for Subset Selection of Multinomial Cells,A Curtailed Sequential Procedure for Subset Selection of Multinomial Cells,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8688,Stochastic Approximation,Stochastic Approximation,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8689,Analysis of Multistage Production Systems,Analysis of Multistage Production Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8690,Unified Complexity Analysis for Newton LP Methods,Unified Complexity Analysis for Newton LP Methods,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8691,A Dynamic Response Surface Model for Frequency Domain Simulation Experiments,A Dynamic Response Surface Model for Frequency Domain Simulation Experiments,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8692,Monotone Transformations for Extremes: I. Discrete time limit processes,Monotone Transformations for Extremes: I. Discrete time limit processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8693,Numerical Methods for Transient Markov Chains,Numerical Methods for Transient Markov Chains,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8694,Multivariate Records and Shape,Multivariate Records and Shape,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8695,A Pseudo-Polynomial Time Algorithm for Weighted-Tardiness Scheduling with Proportional Weights,A Pseudo-Polynomial Time Algorithm for Weighted-Tardiness Scheduling with Proportional Weights,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8696,Convergence of Scaled Random Sample in R^d,Convergence of Scaled Random Sample in R^d,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8697,A Single-Stage Selection Procedure for Multi-Factor Multinomial Experiments with Multiplicativity,A Single-Stage Selection Procedure for Multi-Factor Multinomial Experiments with Multiplicativity,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8698,Truncation of the Bechhofer-Kiefer-Sobel Sequential Procedure for Selecting the Normal Population which has the Largest Mean (III): Supplementary Truncation Numbers and Resulting Performance Characteristics,Truncation of the Bechhofer-Kiefer-Sobel Sequential Procedure for Selecting the Normal Population which has the Largest Mean (III): Supplementary Truncation Numbers and Resulting Performance Characteristics,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8699,Computational Complexity of Uncapacitated Multi-Echelon Production Plannin Problems,Computational Complexity of Uncapacitated Multi-Echelon Production Plannin Problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8700,Analysis of Multi-Type Recurrent Events in Longitudinal Studies; Applications to a Skin Cancer Prevention Trial,Analysis of Multi-Type Recurrent Events in Longitudinal Studies; Applications to a Skin Cancer Prevention Trial,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8701,Beautification is Hard,Beautification is Hard,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8702,Cutting Planes and the Complexity of the Integer Hull,Cutting Planes and the Complexity of the Integer Hull,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8703,Group Sequential tests and Repeated Confidence Intervals,Group Sequential tests and Repeated Confidence Intervals,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8704,Arbitrage and Martingales,Arbitrage and Martingales,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8705,Complexity of the Multiple Product Single Facility Stockout Avoidance Problem,Complexity of the Multiple Product Single Facility Stockout Avoidance Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8706,A Price-Directed Approach to Real-Time Scheduling of Production Operations,A Price-Directed Approach to Real-Time Scheduling of Production Operations,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8707,The Rate Simulator,The Rate Simulator,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8708,Designing Experiments for Selecting the Largest Normal Mean when the Variances are Known and Unequal: Optimal Sample Size Allocation,Designing Experiments for Selecting the Largest Normal Mean when the Variances are Known and Unequal: Optimal Sample Size Allocation,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8709,Optimal Control of Favorable Games with a Time Limit,Optimal Control of Favorable Games with a Time Limit,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8710,Recent Developments and New Directions in Linear Programming,Recent Developments and New Directions in Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8711,Node-Packing Problems with Integer Rounding Properties,Node-Packing Problems with Integer Rounding Properties,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8712,Weyl-Minkowski Duality for Integral Monoids,Weyl-Minkowski Duality for Integral Monoids,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8713,Multi-Item Production Planning with Joint Replenishment and Capacity Constraints: The Trucking Problem,Multi-Item Production Planning with Joint Replenishment and Capacity Constraints: The Trucking Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8714,Path Planning in O/1/infinity Weighted Regions with Applications,Path Planning in O/1/infinity Weighted Regions with Applications,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8715,A New Algorithm for Shortest Paths Among Obstacles in the Plane,A New Algorithm for Shortest Paths Among Obstacles in the Plane,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8716,On Maximum Flows in Polyhedral Domains,"This paper was published in ""Linear Algebra and its Applications"" 152 (1991) 93-105",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8717,The Affine-Scaling Direction for Linear Programming is a Limit of Projective-Scaling Directions,"This paper was published in ""Theory Appl."" 5 (1989), 215-245",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8718,Markov-modulated Queueing Systems Queueing Systems,"This paper was published in ""Mathematics of Operations Research"" 16 (1991) 671-693. Erratum: Mathematics of Operations Research 23 (1988) 767-768",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8719,Probabilistic Models for Linear Programming,"This paper was published in ""Annals of Probability"" 18, 1990",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8720,Erratum: Probabilistic Models for Linear Programming,"This paper was published in ""Annals of Probability"" 18, 1990.  This is a correction to the original paper.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8721,Association of Stable Random Variables,"This paper was published in ""Proceedings Fifth Annual ACM Symposium on Computational Geometry"", Saarbrucken, West Germany, June 1989, pp. 334-343",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8722,On Monotone Paths Among Obstacles with Applications to Planning Assemblies,"This paper was published in ""Stochastic Processes and Their Applications"" 30, 41-68",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8723,Extremes of Moving Averages of Random Variables with Finite Endpoint,"This paper was published in ""American Journal of Epidemiology"" 132 (1) Supplement: S136-S143",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8724,Monitoring for Clusters of Disease; Application to Leukemia Incidence in Upstate New York,"This paper was published in ""Biometrics"" 46, 359-374",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8725,Detection of Associations Between Diseases in Animal Carcinogenicity Experiments,Detection of Associations Between Diseases in Animal Carcinogenicity Experiments,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8726,Simulation Graph Duality: A World View Transformation for Simple Queueing Models,"This paper was published in ""Mathematical Programming"" (A) 49 (1991), 281-283",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8727,A Topological Characterization for Closed Sets Under Polar Duality in Q^n,"This paper was published in ""Advanced in Applied Probability"" 22, 309-331",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8728,Multivariate Extremal Processes and Dynamic Choice Models,"This paper to apper in ""IEEE Transactions on Pattern Analysis and Machine Intelligence""",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8729,An Efficiently Computable Metric for Comparing Polygonal Shapes,An Efficiently Computable Metric for Comparing Polygonal Shapes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8730,The Warehouse Scheduling Problem,The Warehouse Scheduling Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8731,A Note on a formal Development of Event Graphs as an Aid to Structured and Efficient Simulation Programs,A Note on a formal Development of Event Graphs as an Aid to Structured and Efficient Simulation Programs,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8732,Proofs of the Asymptotic Properties of the Conditional Maximum Likelihood Estimator for Log Odds Ratio Regression,"This paper was published in ""The Mathematical Scientist"" 16 (1991) 83-106",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8733,Point Processes and Tauberian Theory,"This paper was published in the ""Journal of Theoretical Biology"" 150 (1991), 497-528",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8734,Modeling and Measuring Gill Packing of Agaric Sporocarps,Modeling and Measuring Gill Packing of Agaric Sporocarps,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8735,Asymptotic Expansions for Waiting Time Probabilities in an M/G/1 Queue with Longtailed Service Time,"This paper published in ""Tijdschrift voor Economie en Management"" 36 (1991), 311-344",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8736,The Cumulative Flow Plot: Understanding Basic Concepts in Material Flow,"This paper published in the ""Journal of Symbolic Computation"" 13 (1992) 255-352",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8737,"On the Computational Complexity and Geometry of the First-Order Theory of the Reals, Part I","This paper published in the ""Journal of Symbolic Computation"" 13 (1992) 255-352",PLEASE NOTE: The original Technical Report TR00853 is missing.  A copy can be found at http://www.sciencedirect.com/science/article/pii/S0747717110800033,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8738,"On the Computational Complexity and Geometry of the First-Order Theory of the Reals, Part II","On the Computational Complexity and Geometry of the First-Order Theory of the Reals, Part II",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8739,An Application of a Hierarchical Modeling Framework to the Computer Maintenance Industry,"This paper published in the ""Journal of Symbolic Computation"" 13 (1992) 255-352",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8740,"On the Computational Complexity and Geometry of the First-Order Theory of the Reals, Part III","This paper was published in ""Large-Scale Numerical Optimization"" (T.F. Coleman and Y. Li, eds.), SIAM, Philadelphia, 1990, 81-91",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8741,The Effects of Degeneracy and Null and Unbounded Variables on Variants of Karmarkar's Linear Programming Algorithm,"This paper to appear in ""SIAM Journal on Computing""",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8742,On the Computational Complexity of Approximating Solutions for Real Algebraic Formulae,On the Computational Complexity of Approximating Solutions for Real Algebraic Formulae,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8743,One-step GM-estimates for Regression with Bounded Influence and High Breakdown-Point,"This paper was published in ""Paths, Flows and VLSI-Design"" (eds. B. Korte, L. Lovasz and A. Schrijver) Springer-Verlag, 1990, 101-164",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8744,Network Flow Algorithm,"This paper published in ""SIAM Journal on Optimization"" 2 (1992) 349-359",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8745,Analysis of a Kanban Controlled Manufacturing System: Iteration Large-Step Primal-Dual Affine Algorithm for Linear Programming,"This paper published in ""Technometrics"" 33 (1991), 393-404",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8746,An O(square-root[nL])-Iteration Large-Step Primal-Dual Affine Algorithm for Linear Programming,An O(square-root[nL])-Iteration Large-Step Primal-Dual Affine Algorithm for Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8747,Probability Limits on Outgoing Quality for Continuous Sampling Plans,"This paper published in ""Stochastic Processes and Their Applications"" 38 (1991), 55-84",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8748,Probability Tails of Gaussian Extrema,Probability Tails of Gaussian Extrema,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8749,The Manufacturing System Development Game,"This paper published in the ""Journal of Algorithms"" 13 (SODA '90 special issue) 79-98",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8750,Using Separation Algorithms in Fixed Dimension,Using Separation Algorithms in Fixed Dimension,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8751,Scheduling the Production of Several Items With Random Demands on a Single Facility,Scheduling the Production of Several Items With Random Demands on a Single Facility,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8752,Statistical Approaches to Interim Monitoring of Medical Trials: A Review and Commentary,"This paper published in ""SIAM Journal on Discrete Mathematics"" 4, (1991), 436-447",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8753,On the Geometry and Computational Complexity of Radon Partitions in the Integer Lattice,"Thhis paper published in the ""Journal of Multivariate Analysis"" 37 (1991), 115-133",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8754,Sample Path Properties of Stochastic Processes Represented as Multiple Stable Integrals,Sample Path Properties of Stochastic Processes Represented as Multiple Stable Integrals,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8755,Improved Approximation Algorithm for oncurrent Multi-Commodity Flows,"This paper published in ""Annals of Applied Probability"" 1 (1991), 267-292",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8756,"Random USC Functions, Max-Stable Processes and Continuous Choice","This paper published in ""American Journal of Clinical Nutrition"" 53 (1991), 1354-1360",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8757,Reporting the Accuracy of Biochemical Measurements for Epidemiologic and Nutrition Studies,Reporting the Accuracy of Biochemical Measurements for Epidemiologic and Nutrition Studies,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8758,State SAT Averages: A Model-Based Exploration,State SAT Averages: A Model-Based Exploration,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8759,"Comments on: Holland and Wainer's, Sources of Uncertainty Often Ignored in Adjusting State Mean SAT Scores for Differential Participation Rates: The Rules of the Game","This paper published in ""Algorithmica"" 9 (1993) 64-83",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8760,On Combined Phase 1 - Phase 2 Projective Methods for Linear Programming,On Combined Phase 1 - Phase 2 Projective Methods for Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8761,Anticipated Behavior of Path-Following Algorithms for Linear Programming,Anticipated Behavior of Path-Following Algorithms for Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8762,Anticipated Behavior of Karmarkar's Algorithm,Anticipated Behavior of Karmarkar's Algorithm,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8763,Misconceptions in Variance Effect: Counterexamples and Proofs,"This paper published in the Proceedings Sixth Annual ACM Symposium on Computational Geometry, Berkeley, CA, June 1990",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8764,Structured Visibility Profiles with Applications to Problems in Simple Polygons,Structured Visibility Profiles with Applications to Problems in Simple Polygons,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8765,Anticipated Behavior of Long-Step Algorithms for Linear Programming.,Anticipated Behavior of Long-Step Algorithms for Linear Programming.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8766,Graphical methods for the Design and Analysis of Simulation Experiments,Graphical methods for the Design and Analysis of Simulation Experiments,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8767,Experiments in Computing Finite Difference Derivatives when Optimizing Low Accuracy Functions,"This paper published in the Proceedings Third Annual ACM Conference on Computational Geometry, Waterloo, Ontario, June 1987",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8768,The Weighted Region Problem: Finding Shortest Paths Through a Weighted Planar Subdivision,The Weighted Region Problem: Finding Shortest Paths Through a Weighted Planar Subdivision,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8769,Max-geometric Infinite Divisibility and Stability,"This paper published in the ""International Journal of Production Research"" 32 (1994), 851-871 and ""Biometrika"" 78 (1991), 133-141",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8770,"An Approach to Production Planning, Scheduling, and Due-Date Quotation in Cyclically Scheduled Manufacturing Systems","An Approach to Production Planning, Scheduling, and Due-Date Quotation in Cyclically Scheduled Manufacturing Systems",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8771,"Exact Calculations for Sequential t, x^2, and F Tests","Exact Calculations for Sequential t, x^2, and F Tests",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8772,The Solution of Massive Generalized Set Partitioning Problems in Aircrew Rostering,"This paper published in ""American Statistician"" 46 (1992), 5-12",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8773,Probability Plotting with Censored Data,"This paper published in the ""Journal of Multivariate Analysis"" 35 (1990), 308-313",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8774,Optimal checking procedures for monitoring laboratory analyses,"This paper published in ""Mathematical Programming"" 61 (1993) 137-159",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8775,1/alpha-Self Similar alpha-Stable Processes with Stationary Increments,1/alpha-Self Similar alpha-Stable Processes with Stationary Increments,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8776,On the complexity of approximating the maximal inscribed ellipsoid for a polytope,"This paper published in ""Communications in Statistics-Simulation and Computation"" 19(3) (1990), 971-1006",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8777,A comparison of the performances of procedures for selecting the normal population having the largest mean when the populations have a common unknown variance,"This paper published in the Proceedings First Canadian Conference on Computational Geometry, Montreal, Canada, August 1989",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8778,Optimal enclosure problems,Optimal enclosure problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8779,Optimal motion of covisible points among obstacles in the plane,"This paper published in the Proceedings of the Integer Programming and Combinatorial Optimization Conference, pp. 457-466. (Eds. Kannan, R. and W.R. Pulleyblank) University of Waterloo Press, Waterloo Ontario, Canada. To appear in the ""Journal of Combinatorial Theory"" (B)",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8780,Stability critical graphs and even subdivisions of K4,Stability critical graphs and even subdivisions of K4,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8781,Llenroc plastics: Market driven integration of manufacturing and distribution systems,"This paper published in ""The Review of Future Markets"" 9 (1990), 54-76",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8782,Contingent claim valuation with a random evolution of interest rates,"This paper published in ""Econometrica"" 60(1) (1992)",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8783,Bond pricing and the term structure of interest rates: a new methodology for contingent claims valuation,"This paper published in ""Algorithmica"" 11 (1994) 353-359",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8784,On the complexity of preflow-push algorithms for maximum flow problems,On the complexity of preflow-push algorithms for maximum flow problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8785,Graphical tools for experiment design: a brief survey,"This paper is published in the ""SIAM Journal on Optimization"" 2 (1992) 198-209",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8786,A low complexity interior-point algorithm for linear programming,A low complexity interior-point algorithm for linear programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8787,Distributions arising in the modelling of environmental processes,Distributions arising in the modelling of environmental processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8788,Stability critical graphs and the stable set polytope,"This paper to appear in the ""Annals of Probability"".",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8789,Stochastic monotonicity and Slepian-type inequalities for infinitely divisible and stable random vectors,"This paper published in ""Mathematical Programming"" 59 (1993) 133-150",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8790,Combining phase I and phase II in a potential reduction algorithm for linear programming,Combining phase I and phase II in a potential reduction algorithm for linear programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8791,Densities with Gaussian tails,Densities with Gaussian tails,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8792,Characterizations of Camion trees and depth-first search trees by excluded configurations,Characterizations of Camion trees and depth-first search trees by excluded configurations,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8793,Linear-time algorithms for weakly-monotone polygons,Linear-time algorithms for weakly-monotone polygons,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8794,On the estimation of the exceedance probability of a high level,"This paper to appear in ""Probability and Mathematical Statistics"".",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8795,Integrability of stable processes,Integrability of stable processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8796,Lecture notes OR320/520,Lecture notes OR320/520,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8797,Random transformations for Poisson processes and sup-integral processes,Random transformations for Poisson processes and sup-integral processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8798,Submodularity and the travelling salesman problem,Submodularity and the travelling salesman problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8799,Heuristics for a one warehouse multi-retailer distribution problem with performance bounds,Heuristics for a one warehouse multi-retailer distribution problem with performance bounds,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8800,Proof of the quadratic convergence of differential dynamic programming,"This paper to appear in ""Handbook of Combinatorics"" (eds. R. Graham, M. Grotschel, and L. Lovasz), North Holland",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8801,Computational complexity,"This paper published in ""Operations Research Letters"" 10 (1991), 281-284",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8802,Permutation vs. non-permutation flow shop schedules,"This paper published in Proceedings Sixth Annual ACM Symposium on Computational Geometry, Berkeley, CA (1990), 63-72",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8803,Minimum-link paths among obstacles in the plane,Minimum-link paths among obstacles in the plane,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8804,Improved approximation algorithms for shop scheduling problems,"This paper published in Proceedings of the International Congress of Mathematicians, Kyoto, Japan (1990), 1595-1606",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8805,Computational complexity of solving real algebraic formulae,Computational complexity of solving real algebraic formulae,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8806,Stochastic storage processes with finite boundaries,"This paper published in ""Stochastic Models"" 7 (1990), 511-526",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8807,Moving averages of random series with random coefficients and random coefficient auto-models,Moving averages of random series with random coefficients and random coefficient auto-models,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8808,Combinatorics in OR,"This paper to appear in ""Algorithmica"" (special issue on network flow).",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8809,A faster parametric minimum cut algorithm,A faster parametric minimum cut algorithm,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8810,An algorithm to find a 2-isomorphic image of a depth-first search tree,"This paper to appear in ""Biometrics"" 49.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8811,"Sequential equivalence testing and repeated confidence intervals, with applications to normal and binary response","This paper published in ""Stochastic Processes and Their Applications"" 42 (1993), 91-110",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8812,Characterization of linear and harmonizable fractional stable motions,Characterization of linear and harmonizable fractional stable motions,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8813,Time variant lot sizing models for the warehouse scheduling problem,Time variant lot sizing models for the warehouse scheduling problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8814,Time Phasing of Equal Interval Deliveries in the Warehouse Scheduling Problem,Time Phasing of Equal Interval Deliveries in the Warehouse Scheduling Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8815,The warehouse scheduling problem formulation and algorithms,The warehouse scheduling problem formulation and algorithms,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8816,Heuristics for Kanban allocation in a multi-stage stochastic environment,Heuristics for Kanban allocation in a multi-stage stochastic environment,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8817,Structural properties of a Kanban controlled serial manufacturing system,Structural properties of a Kanban controlled serial manufacturing system,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8818,Chip assignment algorithms for dynamic wafer design in semiconductor manufacturing,Chip assignment algorithms for dynamic wafer design in semiconductor manufacturing,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8819,Multivariate subexponential distributions,Multivariate subexponential distributions,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8820,Algorithmic approaches to optimal route planning,Algorithmic approaches to optimal route planning,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8821,Strategic planning in field service: trade-offs between field engineers and inventory,"This paper to appear in the ""Journal of Complexity"".",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8822,Is it possible to know a problem instance is ill-posed? Some foundations for a general theory of condition numbers,Is it possible to know a problem instance is ill-posed? Some foundations for a general theory of condition numbers,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8823,The translation square map and approximate congruence,"This paper published in ""Operations Research"" 41 (1993), 947-958",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8824,Stochastic analysis of cyclic schedules,Stochastic analysis of cyclic schedules,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8825,Stochastic analysis of cyclic schedules,Stochastic analysis of cyclic schedules,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8826,Stochastic analysis of cyclic schedules,Stochastic analysis of cyclic schedules,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8827,Matching points into noise regions: combinatorial bounds and algorithms,Matching points into noise regions: combinatorial bounds and algorithms,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8828,The wild card option in treasury bond futures is relatively worthless,"This paper published in ""Mathematics of Operations Research"" 18 (1993) 964-981",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8829,On adaptive-step primal-dual interior-point algorithms for linear programming,On adaptive-step primal-dual interior-point algorithms for linear programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8830,Stochastic analysis of cyclic schedules: algorithms and examples,"This paper published in ""SIAM Journal on Discrete Mathematics"" 6 (1993) 167-180",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8831,A new triangulation for simplicial algorithms,A new triangulation for simplicial algorithms,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8832,Controlling serial production lines w/yield losses using kanbans,Controlling serial production lines w/yield losses using kanbans,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8833,Finding optimal bipartitions of points and polygons,Finding optimal bipartitions of points and polygons,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8834,An improved algorithm for finding optimal lot sizing policies for finite production rate assembly systems,An improved algorithm for finding optimal lot sizing policies for finite production rate assembly systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8835,Projected scaled steepest descent in Kojima-Mizuno-Yoshise's potential reduction algorithm for the linear complementarity problem,"This paper to appear in the ""Journal of Multivariate Analysis"".",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8836,Zero-one laws for multilinear forms in Gaussian and other infinitely divisible random variables,"This paper published in ""Operations Research Letters"" 11 (1992) 199-207",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8837,Todd's low-complexity algorithm is a predictor-corrector path-following method,Todd's low-complexity algorithm is a predictor-corrector path-following method,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8838,An optimal algorithm for computing visibility in the plane,An optimal algorithm for computing visibility in the plane,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8839,"Kanbans, generalized semi-Markov processes and anti-matroids","This paper published in ""Multiple Comparisons in Biostatistics: Current Research in the Topics of Dunnett, C. W."" (Ed. Fred M. Hoppe) Marcel Dekker, NY (Chap. 18, p. 315-330)",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8840,One-sided sequential tests to establish equivalence between treatments with special reference to normal and binary responses,One-sided sequential tests to establish equivalence between treatments with special reference to normal and binary responses,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8841,Subproblems in cyclic scheduling for repetitive manufacturing,"This paper published in ""DIMACS Series in Discrete Mathematics and Theoretical Computer Science"" 6 (1991) 287-308",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8842,Recent progress on the complexity of the decision problem for the reals,"This paper published in ""COAL Newsletter of the Mathematical Programming Society"" 19 (1991) 17-25",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8843,Playing with interior points,"This paper published in ""New Directions in Time Series Analysis, Part II. IMA Volumes in Mathematics and Its Applications"", 46. Springer-Verlag, 1992",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8844,Linear models with long-range dependence and with finite or infinite variance,"This paper to appear in ""Biometrics"" 49",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8845,Group sequential tests for bivariate response: interim analyses of clinical trials with both efficacy and safety endpoints,Group sequential tests for bivariate response: interim analyses of clinical trials with both efficacy and safety endpoints,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8846,Faster approximation algorithms for the unit capacity concurrent flow problem with applications to routing and finding sparse cuts,"This paper to appear in ""IIE Transactions"".",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8847,A comparison of alternative Kanban control mechanisms,A comparison of alternative Kanban control mechanisms,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8848,Properties of throughput in Kanban lines,Properties of throughput in Kanban lines,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8849,Another variational derivation of a self-scaling Quasi-Newton update formula,"This paper to appear in ""Annals of Probability"".",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8850,Distributions of subadditive functionals of sample paths of infinitely divisible processes,Distributions of subadditive functionals of sample paths of infinitely divisible processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8851,Study of the performance of a generalized Paulson sequential selection procedure for two-factor experiments involving normal populations with common known variance and no factor-level interaction,Study of the performance of a generalized Paulson sequential selection procedure for two-factor experiments involving normal populations with common known variance and no factor-level interaction,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8852,Testing pricing models for the treasury bond futures contract (thesis),Testing pricing models for the treasury bond futures contract (thesis),,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8853,Approximate algorithms for the geometric covering salesman problem,Approximate algorithms for the geometric covering salesman problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8854,Link distance query problems in polygons,"This paper to appear in ""Annals of Applied Probability"".",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8855,Prediction of stationary max-stable processes,Prediction of stationary max-stable processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8856,Super-extremal processes and the argmax process,Super-extremal processes and the argmax process,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8857,Arrangements of line segments that share endpoints single face results,Arrangements of line segments that share endpoints single face results,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8858,Combinatorial bounds for single faces in arrangements of pseudo-segments and chords in polygons,Combinatorial bounds for single faces in arrangements of pseudo-segments and chords in polygons,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8859,Separation and approximation of polyhedral surfaces,"This paper published in ""Operations Research Letters"" 11 (1992), 255-259",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8860,On the convexity of a function related to Wagner-Whitin model,"This paper to appear in ""Stochastic Models"".",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8861,Consistent empirical estimators of multivariate extreme value distributions,"This paper published in the ""Proceedings of the ACM Symposium on the Theory of Computing"" (1991), 101-110",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8862,Fast approximation algorithms for multicommodity flow problems,"This paper published in ""Mathematical Programming"" 65 (1994), 217-245",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8863,Interior-point algorithms for semi-infinite programming,Interior-point algorithms for semi-infinite programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8864,Approximate decision algorithms for point set congruence,Approximate decision algorithms for point set congruence,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8865,On the existence of equivalent local martingale measures,"This paper published in ""SIAM Journal on Optimization"" 5 (1995), 247-268",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8866,A potential reduction algorithm with user specified Phase I - Phase II balance for solving a linear program from an infeasible warm start,A potential reduction algorithm with user specified Phase I - Phase II balance for solving a linear program from an infeasible warm start,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8867,Detection and assessment of clusters of disease: an application to nuclear power plant facilities and childhood leukemia in Sweden,"This paper published in the ""Proceedings of KAIST Mathematics Workshop"", 6 (1991), 47-56 (KAIST Math. Research Center, Taejon)",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8868,Elementary methods for Markov-modulated queueing systems,"This paper published in the ""Proceedings of KAIST Mathematics Workshop"", 6 (1991), 57-94 (KAIST Math. Research Center, Taejon)",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8869,Markov renewal and Markov-additive processes,"This paper published in the ""Proceedings of KAIST Mathematics Workshop"", 6 (1991), 57-94 (KAIST Math. Research Center, Taejon)",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8870,Some new results for the Markov random walk,Some new results for the Markov random walk,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8871,A continuous-time network flow problem arising from machine scheduling,A continuous-time network flow problem arising from machine scheduling,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8872,"Directed S-T numberings, rubber bands, and testing digraph K-vertex connectivity","Directed S-T numberings, rubber bands, and testing digraph K-vertex connectivity",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8873,A randomized maximum-flow algorithm,A randomized maximum-flow algorithm,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8874,Modelling the evolution of demand forecasts with application to safety stock analysis in production distribution systems,Modelling the evolution of demand forecasts with application to safety stock analysis in production distribution systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8875,Option pricing formulae for speculative prices modelled by subordinated stochastic processes,"This paper to appear in the ""Annals of Applied Probability"".",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8876,"The expected number of level crossings for stationary, harmonisable, symmetric, stable processes","This paper to appear in ""Stochastic Processes and Their Applications"".",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8877,Subexponentiality of the product of independent random variables,"This paper published in ""Applied Mathematics Letters"" 6 (1993) 63-67",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8878,Scan-first search and sparse certificates; an improved parallel algorithm for K-vertex connectivity,Scan-first search and sparse certificates; an improved parallel algorithm for K-vertex connectivity,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8879,Superlinear Convergence of a Class of ?-Bounded Rank-One Update Methods,Superlinear Convergence of a Class of ?-Bounded Rank-One Update Methods,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8880,Another derivation of the Karmarkar direction for linear programming,Another derivation of the Karmarkar direction for linear programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8881,The velocity manufacturing company,"This paper published in ""Computational Optimization and Applications"" 2 (1993) 299-316.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8882,The ellipsoid algorithm using parallel cuts,"This paper to appear in ""Mathematical Programming"".",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8883,Polynomial dual network simplex algorithms,"This paper published in the ""Proc. of the Thirty-second IEEE Symp. on Foundations of Computer Science"" (1991), 495-504.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8884,Fast approximation algorithms for fractional packing and covering problems,"This paper published in ""Computational Optimization and Applications"" 2 (1993) 301-318",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8885,Reduced Hessian method for constrained programming problems,Reduced Hessian method for constrained programming problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8886,Scheduling unrelated parallel machines with costs,Scheduling unrelated parallel machines with costs,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8887,"An hierarchical approach to machine batching, loading and tool allocation problems","This paper published in ""Computational Optimization and Applications"" 4 (1995), 139-158",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8888,On the convergence of primal-dual interior point methods with wide neighborhoods,On the convergence of primal-dual interior point methods with wide neighborhoods,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8889,A note on the primal-dual affine scaling algorithms,"This paper published in ""Stochastic Models"" 8 (1992), 479-498",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8890,Estimation for Autoregressive Processes with Positive Innovations,"This paper published in ""Mathematical Programming"" 67 (1994), 109-119, Iteration Homogeneous and Self-dual Linear Programming Algorithm (6/92), ""Mathematics of Operations Research"" 19 (1994) 53-67",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8891,Polynomiality of the Kojima-Megiddo-Mizuno Infeasible Interior Point Algorithm for Linear Programming,Polynomiality of the Kojima-Megiddo-Mizuno Infeasible Interior Point Algorithm for Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8892,An O(square-root[nL])-Iteration Homogeneous and Self-Dual Linear Programming Algorithm,An O(square-root[nL])-Iteration Homogeneous and Self-Dual Linear Programming Algorithm,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8893,Cardinality-restricted Chains and Antichains in Partially Ordered Sets,Cardinality-restricted Chains and Antichains in Partially Ordered Sets,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8894,Stability Critical Graphs and Rank Facets of the Stable Set Polytopes,Stability Critical Graphs and Rank Facets of the Stable Set Polytopes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8895,On the Height of the Minimal Hilbert Basis,"This paper published in ""Queueing Systems"" 15 (1994), 289-308",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8896,Second-order Properties of the Loss Probability in M/M/s/s+c Systems,Second-order Properties of the Loss Probability in M/M/s/s+c Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8897,Markov-modulated Single Server Queueing Systems,Markov-modulated Single Server Queueing Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8898,Limit Theorems for Markov Random Walks,"This paper published in ""SIAM Journal on Optimization"" 4 (1994) 613-625",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8899,Monotonicity of Primal and Dual Objective Values in Primal-dual Interior Point Algorithms,Monotonicity of Primal and Dual Objective Values in Primal-dual Interior Point Algorithms,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8900,Geometric Stable Distributions in Banach Spaces,"This paper published in ""Mathematics of Operations Research"" 20 (1995), 415-440",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8901,"Barrier Functions and Interior-Point Algorithms for Linear Programming with Zero-, One-, or Two-sided Bounds on the Variables","This paper appear in ""International Journal of Production Research""",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8902,A Hierarchical Approach for Metal Parts Fabrication,"This paper published in ""Mathematical Programming"" 66 (1994), 145-159",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8903,Constant Potential Primal-Dual Algorithms: A Framework,Constant Potential Primal-Dual Algorithms: A Framework,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8904,Critical Time of the Lognormal Distribution,Critical Time of the Lognormal Distribution,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8905,Reliability Bounds and Critical Time for the Bernstein Distribution,Reliability Bounds and Critical Time for the Bernstein Distribution,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8906,Reliability Bounds and Critical Time of the Birmbaum-Saunders Distribution,Reliability Bounds and Critical Time of the Birmbaum-Saunders Distribution,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8907,Percentile Bounds and Predication Limits for the Inverse Gaussian Distribution,"This paper published in ""SIAM Journal on Optimization"" 5 (1995) 52-67",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8908,Infeasible-Interior-Point Primal-Dual Potential-Reduction Algorithms for Linear Programming,Infeasible-Interior-Point Primal-Dual Potential-Reduction Algorithms for Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8909,Nonparametric Methods for Evaluating Diagnostic Tests,Nonparametric Methods for Evaluating Diagnostic Tests,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8910,"Discrete Geometry, Group Representations and Combinatorial Optimization: An Interplay","Discrete Geometry, Group Representations and Combinatorial Optimization: An Interplay",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8911,Non- and Semi-Parametric Estimation of the Receiver Operating Characteristic (ROC) Curve,Non- and Semi-Parametric Estimation of the Receiver Operating Characteristic (ROC) Curve,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8912,"Modelling the Impact of Assembly Demand Forecast Accuracy on Customer Service, Inventory, and Expediting","Modelling the Impact of Assembly Demand Forecast Accuracy on Customer Service, Inventory, and Expediting",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8913,Strategic Planning for Field Service Support Systems,Strategic Planning for Field Service Support Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8914,"Multistage, identical job cyclic scheduling for repetitive manufacturing","Multistage, identical job cyclic scheduling for repetitive manufacturing",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8915,Modeling and Analysis of Quick Response in Production-Inventory Systems,"This paper published in ""Mathematics of Operations Research"" 21 (1996) 354-381",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8916,Asymptotic Behavior of Interior-Point Methods: A View from Semi-Infinite Programming,"This paper to appear in ""J. Optimization Theory and Applications"" (1994)",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8917,Some Variants of Todd's Low-Complexity Algorithm,Some Variants of Todd's Low-Complexity Algorithm,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8918,Limit Distributions for Linear Programming Time Series Estimators,Limit Distributions for Linear Programming Time Series Estimators,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8919,Computation of the Exact Solution from a Near Optimum Solution for Convex QP,Computation of the Exact Solution from a Near Optimum Solution for Convex QP,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8920,Production Control of Cyclic Schedules with Demand and Process Variability,Production Control of Cyclic Schedules with Demand and Process Variability,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8921,Stable Processes with Sample Paths in Orlicz Spaces,"This paper published in ""Mathematics of Operations Research"" 20 (1995) 135-162",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8922,A Surface of Analytic Centers and Infeasible- Interior-Point Algorithms for Linear Programming,A Surface of Analytic Centers and Infeasible- Interior-Point Algorithms for Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8923,Some Perturbation Theory for Linear Programming,Some Perturbation Theory for Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8924,Notes on the Efficiency of the Barrier Method,Notes on the Efficiency of the Barrier Method,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8925,Further Results for Semiregenerative Phenomena,Further Results for Semiregenerative Phenomena,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8926,Estimating the Home Range,Estimating the Home Range,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8927,Improved Bounds on the Max-flow Min-cut Ratio for Multicommodity Flows,Improved Bounds on the Max-flow Min-cut Ratio for Multicommodity Flows,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8928,Analysis of Interior-Point Methods for Linear Programming Problems with Variable Upper Bounds,Analysis of Interior-Point Methods for Linear Programming Problems with Variable Upper Bounds,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8929,Delphi: A C-Based Queuing Network Simulator,Delphi: A C-Based Queuing Network Simulator,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8930,OR 630 Notes - Linear Programming,OR 630 Notes - Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8931,Levy Measures of Infinitely Divisible Random Vectors and Slepian Inequalities,Levy Measures of Infinitely Divisible Random Vectors and Slepian Inequalities,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8932,Possible Sample Paths of Self-Similar a-Stable Processes,Possible Sample Paths of Self-Similar a-Stable Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8933,On the Polyhedral Structure of Relatively Transitive Subgraphs,"This paper published in ""Numerical Analysis"" 1993 (G.A. Watson and D.F. Griffiths, eds.), Pitman Research Notes in Mathematics 303, Longman Press, 1994, pp. 237-259",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8934,A Lower Bound on the Number of Iterations of Primal-Dual Interior-Point Methods for Linear Programming,A Lower Bound on the Number of Iterations of Primal-Dual Interior-Point Methods for Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8935,An Exact Analysis of a Production-Inventory Stretegy for Industrial Suppliers,"This paper published in ""Queueing Systems"" 15 (1994), 309-324",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8936,Some Properties of the Delay Probability in M/M/s/s+c Systems,This paper published in Teor. Veroyatnost. i Primenen. (1994),,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8937,A Storage Model for Data Communication Systems,A Storage Model for Data Communication Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8938,On the Continuous Time Capacitated Production/Inventory Problem with No Set Up Costs,On the Continuous Time Capacitated Production/Inventory Problem with No Set Up Costs,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8939,On the Problem of Overlapping Pseudo-Random Number Streams: A Queuing Simulation Example,On the Problem of Overlapping Pseudo-Random Number Streams: A Queuing Simulation Example,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8940,A Comparison of Alternative Kanban Control Mechanisms: Part 2 Experimental Results,A Comparison of Alternative Kanban Control Mechanisms: Part 2 Experimental Results,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8941,Stability of Random Sets Generated by Multivariate Samples,Stability of Random Sets Generated by Multivariate Samples,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8942,Zero-One Laws for Multiple Stochastic Integrals,Zero-One Laws for Multiple Stochastic Integrals,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8943,Markov-Compound Poisson Arrival Processes,Markov-Compound Poisson Arrival Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8944,A Computational Study of the Job-Shop and the Flow-Shop Scheduling Problems (Thesis),A Computational Study of the Job-Shop and the Flow-Shop Scheduling Problems (Thesis),,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8945,"Multi-item, Multi-period Production Planning with Uncertain Demand","Multi-item, Multi-period Production Planning with Uncertain Demand",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8946,Some Recent Developments in the Design and Analysis of Approximation Algorithms,Some Recent Developments in the Design and Analysis of Approximation Algorithms,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8947,A Note on the Local Asymptotically Minimax Rate for Estimating a Crossing Point in a Diagnostic Marker Problem,"This paper published in ""SIAM Journal on Optimization"" 6 (1996) 933-960",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8948,Solving LP Problems Via Weighted Centers,Solving LP Problems Via Weighted Centers,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8949,Association of Infinitely Divisible Random Vectors,Association of Infinitely Divisible Random Vectors,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8950,Consistency of Hill's Estimator for Dependent Data,"This paper published in ""Computational Optimization and Applications"" 3 (1994) 305-315",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8951,"Scaling, Shifting and Weighting in Interior-Point Methods","Scaling, Shifting and Weighting in Interior-Point Methods",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8952,Estimating Performance Measures in Stochastic Cyclic Schedules,Estimating Performance Measures in Stochastic Cyclic Schedules,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8953,A Geometric Buchberger Algorithm for Integer Programming,A Geometric Buchberger Algorithm for Integer Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8954,"Super Fractional Brownian Moton, Fractional Super Brownian Motion and Related Self-Similar (Super) Processes","This paper published in ""Linear Algebra and its Applications"" 223/224 (1995), 717-729",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8955,Reducing Horizontal Linear Complementarity Problems,Reducing Horizontal Linear Complementarity Problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8956,Second-Order Regular Variation and Rates of Convergence in Extreme-Value Theory,Second-Order Regular Variation and Rates of Convergence in Extreme-Value Theory,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8957,Incorporating Condition Measures into the Complexity Theory of Linear Programming,Incorporating Condition Measures into the Complexity Theory of Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8958,Nova Incorporated: A-Case The Rebirth of an International Corporation,Nova Incorporated: A-Case The Rebirth of an International Corporation,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8959,Nova Incorporated: B-Case Operational Analysis of the New Logistics System,Nova Incorporated: B-Case Operational Analysis of the New Logistics System,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8960,Nova Incorporated: Case D Local Outsourcing of Production for Performance Improvement,Nova Incorporated: Case D Local Outsourcing of Production for Performance Improvement,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8961,A Study of Sequencing Heuristics for Periodic Production Environments,A Study of Sequencing Heuristics for Periodic Production Environments,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8962,"Convexity and Sensitivity Properties of (R,T) Inventory Control Policies for Stochastic Demand Models","Convexity and Sensitivity Properties of (R,T) Inventory Control Policies for Stochastic Demand Models",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8963,A Markovian Storage Model,A Markovian Storage Model,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8964,Functionals of infinitely divisible stochastic processes with exponential tails,Functionals of infinitely divisible stochastic processes with exponential tails,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8965,Instructor's Notes for Llenroc Plastics: Market Driven Integration of Manufacturing and Distribution Systems,"This paper published in ""Annals of Operations Research"" 62 (1996), 233-252",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8966,A Lower Bound on the Number of Iterations of Long-Step and Polynomial Interior-Point Linear Programming Algorithms,A Lower Bound on the Number of Iterations of Long-Step and Polynomial Interior-Point Linear Programming Algorithms,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8967,"The Llenroc Plastics Experience: Student Evaluations, 1993","The Llenroc Plastics Experience: Student Evaluations, 1993",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8968,Nova Incorporated: Case C Results of a Worldwide Market Research Study,Nova Incorporated: Case C Results of a Worldwide Market Research Study,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8969,Testing for Independence in Heavy Tailed and Positive Innovation Time Series,Testing for Independence in Heavy Tailed and Positive Innovation Time Series,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8970,All 0-1 Polytopes are Traveling Salesman Polytopes,All 0-1 Polytopes are Traveling Salesman Polytopes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8971,Greedy Algorithms by Derandomizing Unknown Distributions,Greedy Algorithms by Derandomizing Unknown Distributions,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8972,Markov-additive Processes of Arrivals,Markov-additive Processes of Arrivals,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8973,Incorporating Condition Measures into the Complexity Theory of Linear Programming,Incorporating Condition Measures into the Complexity Theory of Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8974,"Linear Programming, Complexity Theory and Elementary Functional Analysis","This paper published in ""Mathematics of Operations Research"" 22 (1997), 1-42",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8975,Self-Scaled Barriers and Interior-Point Methods for Convex Programming,Self-Scaled Barriers and Interior-Point Methods for Convex Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8976,A Class of Pulse Processes,A Class of Pulse Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8977,An Efficient Staggering Algorithm for the Warehouse Scheduling Problem,An Efficient Staggering Algorithm for the Warehouse Scheduling Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8978,The Effect of Long Range Dependence in a Simple Queueing Model,The Effect of Long Range Dependence in a Simple Queueing Model,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8979,A Computer Program for the Statistical Analysis of Repeated Event Data Using a Mixed Effects Regression Model,A Computer Program for the Statistical Analysis of Repeated Event Data Using a Mixed Effects Regression Model,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8980,Markov-additive Processes Arising in Storage Models for Communications Systems,"This paper published in ""Optimization Methods and Software"" 5 (1995), 27-55",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8981,Two Interior-Point Algorithms for a Class of Convex Programming Problems,Two Interior-Point Algorithms for a Class of Convex Programming Problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8982,A Storage Equation on Continuous Time,A Storage Equation on Continuous Time,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8983,Nova Inc.: Case E - Two Opportunities,Nova Inc.: Case E - Two Opportunities,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8984,Capacitated Facility Location: Separation Algorithms and Computational Experience,Capacitated Facility Location: Separation Algorithms and Computational Experience,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8985,Matroid Covering,Matroid Covering,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8986,A Bound on the Sum of Weighted Pairwise Distances of Points Constrained to Balls,A Bound on the Sum of Weighted Pairwise Distances of Points Constrained to Balls,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8987,"Condition Numbers, the Barrier Method and the Conjugate Gradient Method","Condition Numbers, the Barrier Method and the Conjugate Gradient Method",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8988,Variation of Cost Functions in Integer Programming,Variation of Cost Functions in Integer Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8989,Analyzing Multifacility Inventory Systems,Analyzing Multifacility Inventory Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8990,Experiential Learning in Manufacturing System Design,"This paper published in ""Mathematical Programming"" 81 (1998) 1-21",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8991,Approximate Farkas Lemmas and Stopping Rules for Iterative Infeasible-Point Algorithms for Linear Programming,Approximate Farkas Lemmas and Stopping Rules for Iterative Infeasible-Point Algorithms for Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8992,Finding the Overall Minimum Cut in Undirected Planar Graphs with Non-negative Edge Costs,Finding the Overall Minimum Cut in Undirected Planar Graphs with Non-negative Edge Costs,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8993,Parameter Estimation for Moving Averages with Positive Innovations,"This paper published in ""Mathematical Programming"" 76 (1996) 3-45",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8994,Potential-Reduction Methods in Mathematical Programming,Potential-Reduction Methods in Mathematical Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8995,Optimization-based Scheduling for the stochastic Lot Scheduling Problem,Optimization-based Scheduling for the stochastic Lot Scheduling Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8996,Smoothing the Hill Estimator,Smoothing the Hill Estimator,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8997,Fast Approximation Algorithms for Multicommodity Flow Problems,Fast Approximation Algorithms for Multicommodity Flow Problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8998,Improved approximation algorithms for network design problems,Improved approximation algorithms for network design problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/8999,Polynomial Time Algorithms for Some Evacuation Problems,Polynomial Time Algorithms for Some Evacuation Problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9000,The Quickest Transshipment Problem,The Quickest Transshipment Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9001,Approximation Algorithms for Steiner and Directed Multicuts,Approximation Algorithms for Steiner and Directed Multicuts,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9002,Computing Near-Optimal Solutions to Combinatorial Optimization Problems,Computing Near-Optimal Solutions to Combinatorial Optimization Problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9003,Approximations for the Disjoint Paths Problem in High-Diameter Planar Networks,Approximations for the Disjoint Paths Problem in High-Diameter Planar Networks,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9004,The QQ-Estimator and Heavy Tails,The QQ-Estimator and Heavy Tails,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9005,An Event Graph Model of a Turing Machine,An Event Graph Model of a Turing Machine,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9006,Linear Programming Estimators and Bootstrapping for Heavy Tailed Phenomena,"This paper published in ""SIAM Journal on Optimization"" 8 (1998) 324-364",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9007,Primal-dual Interior-Point Methods for Self-Scaled Cones,Primal-dual Interior-Point Methods for Self-Scaled Cones,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9008,Ordered Independent Scattering,Ordered Independent Scattering,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9009,Disjoint Paths in Densely Embedded Graphs,Disjoint Paths in Densely Embedded Graphs,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9010,Gibbs Sampler Routines,Gibbs Sampler Routines,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9011,Distribution Theory for Group Sequential Analysis of General Linear Models,Distribution Theory for Group Sequential Analysis of General Linear Models,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9012,A Computer Program for Sample Size and Power Calculations in the Design of Multi-arm and Factorial Clinical Trials with Survival Time Endpoints,A Computer Program for Sample Size and Power Calculations in the Design of Multi-arm and Factorial Clinical Trials with Survival Time Endpoints,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9013,Chi-square Approximations in Unbalanced Analysis of Variance,Chi-square Approximations in Unbalanced Analysis of Variance,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9014,Local Polynomial Variance Function Estimation,Local Polynomial Variance Function Estimation,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9015,"Second Order Regular Variation, Convolution and the Central Limit Theorem","Second Order Regular Variation, Convolution and the Central Limit Theorem",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9016,Heavy Tail Modelling and Teletraffic Data,"This paper published in ""Computational Optimization and Applications"" 8 (1997) 5-19",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9017,"On the Interplay Among Entropy, Variable Metrics and Potential Functions in Interior-Point Algorithms","On the Interplay Among Entropy, Variable Metrics and Potential Functions in Interior-Point Algorithms",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9018,An Infeasible-Interior-Point Potential-Reduction Algorithm for Linear Programming,An Infeasible-Interior-Point Potential-Reduction Algorithm for Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9019,Empirical-bias Bandwidths for Local Polynomial Nonparametric Regression and Density Estimation,Empirical-bias Bandwidths for Local Polynomial Nonparametric Regression and Density Estimation,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9020,On the Computation of Queue Length Probabilities in a Two-Priority Class M/G/1 Queue,On the Computation of Queue Length Probabilities in a Two-Priority Class M/G/1 Queue,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9021,Complications with Stochastic Volatility Models,Complications with Stochastic Volatility Models,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9022,Limit Theory for Bilinear Processes with Heavy Tailed Noise,Limit Theory for Bilinear Processes with Heavy Tailed Noise,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9023,Llenroc Plastics Europe: Students' Notes,Llenroc Plastics Europe: Students' Notes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9024,Llenroc Plastics Europe: Students' Notes,Llenroc Plastics Europe: Students' Notes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9025,Llenroc Plastics Europe: Teaching Notes,This paper to appear in Annals of Probability,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9026,Symmetrization and Concentration Inequalities for Multilinear Forms with Applications to Zero-one Laws for Levy Chaos,Symmetrization and Concentration Inequalities for Multilinear Forms with Applications to Zero-one Laws for Levy Chaos,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9027,Classes of Mixing Stable Processes,Classes of Mixing Stable Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9028,Heavy Tails and Long Range Dependence in On/Off Processes and Associated Fluid Models,This paper to appear in the Proceeding of the 1st International Conference on Time Series and Applied Probability.,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9029,Level Crossings of Absolutely Continuous Stationary Symmetric ?-stable Processes,Level Crossings of Absolutely Continuous Stationary Symmetric ?-stable Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9030,A Class of Shot Noise Models for Financial Applications,"This paper published in Stochastic Processes and Their Applications, 59 (1995) 217-233",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9031,Sample Quantiles of Heavy Tailed Stochastic Processes,This paper to appear in Mathematica Scandinavica,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9032,L1 Norm of Levy Processes with Exponential Tails,L1 Norm of Levy Processes with Exponential Tails,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9033,Lower Tails of Self-Similar Stable Processes,Lower Tails of Self-Similar Stable Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9034,Separating Maximally Violated Comb Inequalities in Planar Graphs,Separating Maximally Violated Comb Inequalities in Planar Graphs,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9035,A fully Automated Bandwidth Selection Method for Fitting Additive Models,A fully Automated Bandwidth Selection Method for Fitting Additive Models,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9036,Fitting a Bivariate Additive Model by Local Polynomial Regression,Fitting a Bivariate Additive Model by Local Polynomial Regression,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9037,Local Polynomial Regression and Its Applications in Environmental Statistics,"This paper published in SIAM Journal on Optimization, 8 (1998) 769-796",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9038,On the Nesterov-Todd Direction in Semidefinite Programming,On the Nesterov-Todd Direction in Semidefinite Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9039,On Asymptotic Normality of the Hill Estimator,On Asymptotic Normality of the Hill Estimator,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9040,Infeasible-Start Primal-Dual Methods and Infeasibility Detectors for Nonlinear Programming Problems,Infeasible-Start Primal-Dual Methods and Infeasibility Detectors for Nonlinear Programming Problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9041,Why Non-Linearities Can Ruin the Heavy Tailed Modeler's Day,Why Non-Linearities Can Ruin the Heavy Tailed Modeler's Day,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9042,Smoothing the Moment Estimator of the Extreme Value Parameter,Smoothing the Moment Estimator of the Extreme Value Parameter,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9043,Scheduling to Minimize Average Completion Time: Off-line and On-line Approximation Algorithms,Scheduling to Minimize Average Completion Time: Off-line and On-line Approximation Algorithms,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9044,LPSQL: Block Form Representations of Integer/Linear Optimization Problems with Relational Databases,LPSQL: Block Form Representations of Integer/Linear Optimization Problems with Relational Databases,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9045,Estimating the Size of the Transitive Closure,Estimating the Size of the Transitive Closure,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9046,Symmetric Infinitely Divisible Processes with Sample Paths in Orlicz Spaces and Absolute Continuity of Infinitely Divisible Processes,Symmetric Infinitely Divisible Processes with Sample Paths in Orlicz Spaces and Absolute Continuity of Infinitely Divisible Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9047,Pitfalls of Fitting Autoregressive Models for Heavy-tailed Time Series,Pitfalls of Fitting Autoregressive Models for Heavy-tailed Time Series,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9048,"Optimal and Heuristic (s,S) Inventory Policies for Levy Demand Processes","Optimal and Heuristic (s,S) Inventory Policies for Levy Demand Processes",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9049,Asymptotic Behavior of Hill's Estimator for Autoregressive Data,Asymptotic Behavior of Hill's Estimator for Autoregressive Data,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9050,Efficient Continuous-Time Dynamic Network Flow Algorithms,Efficient Continuous-Time Dynamic Network Flow Algorithms,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9051,A Simple Roughness Penalty Approach to Regression Spline Estimation,A Simple Roughness Penalty Approach to Regression Spline Estimation,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9052,"Nonparametric Estimation via Local Estimating Equations, with Applications to Nutrition Calibration","Nonparametric Estimation via Local Estimating Equations, with Applications to Nutrition Calibration",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9053,Patterns of Buffer Overflow in a Class of Queues with Long Memory in the Input Stream,Patterns of Buffer Overflow in a Class of Queues with Long Memory in the Input Stream,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9054,On Adjusting Parameters in Homotopy Methods for Linear Programming,On Adjusting Parameters in Homotopy Methods for Linear Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9055,Strictly Local Martingales and Hedge Ratios on Stochatic Volatility Models,Strictly Local Martingales and Hedge Ratios on Stochatic Volatility Models,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9056,How Heavy Are the Tails of a Stationary HARCH(k) Process? A Study of the Moments,How Heavy Are the Tails of a Stationary HARCH(k) Process? A Study of the Moments,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9057,Tail Behavior of Shot Noise Processes,Tail Behavior of Shot Noise Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9058,Tail Index Estimation for Dependent Data,Tail Index Estimation for Dependent Data,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9059,The Economics of Sharing Inventories,The Economics of Sharing Inventories,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9060,Heuristic Computation of Periodic-Review Base Stock Inventory Policies,Heuristic Computation of Periodic-Review Base Stock Inventory Policies,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9061,SDPT3 -- A Matlab Software Package for Semidefinite Programming,SDPT3 -- A Matlab Software Package for Semidefinite Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9062,Discussion of the Danish Data on Large Fire Insurance Losses,Discussion of the Danish Data on Large Fire Insurance Losses,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9063,Fixing Up the Rate of Return Approach: The Rate of Return on Invested Capital,Fixing Up the Rate of Return Approach: The Rate of Return on Invested Capital,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9064,A Paridigm Lost and F Tests for General Linear Mixed Models,A Paridigm Lost and F Tests for General Linear Mixed Models,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9065,"Distribution Theory of Group Sequential t, x^2, and F Tests for General Linear Mixed Models","Distribution Theory of Group Sequential t, x^2, and F Tests for General Linear Mixed Models",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9066,Regression Models for Recurrent Event Data: Parametric Random Effects Models with Measurement Error,Regression Models for Recurrent Event Data: Parametric Random Effects Models with Measurement Error,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9067,Point Process Regression Models for Multiple Events with Random Effects and Measurement Error,Point Process Regression Models for Multiple Events with Random Effects and Measurement Error,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9068,Likelihood Ratio Tests for a Change Point with Survival Data,Likelihood Ratio Tests for a Change Point with Survival Data,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9069,Group Sequential Analysis Incorporating Covariate Information,Group Sequential Analysis Incorporating Covariate Information,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9070,A Characterization of Measures of Risk,A Characterization of Measures of Risk,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9071,Heavy Tailed Hidden Semi-Markov Models,Heavy Tailed Hidden Semi-Markov Models,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9072,Assessing Multivariate Nonnormality Using Univariate Distributions,Assessing Multivariate Nonnormality Using Univariate Distributions,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9073,Changepoint Modeling of Longitudinal PSA as a Biomarker for Prostate Cancer,Changepoint Modeling of Longitudinal PSA as a Biomarker for Prostate Cancer,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9074,A Faster Algorithm for the Quickest Transshipment Problem,A Faster Algorithm for the Quickest Transshipment Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9075,Tails of Levy Measure of Geometric Stable Random Variables,Tails of Levy Measure of Geometric Stable Random Variables,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9076,The Velocity Manufacturing Company - Two Years Later,The Velocity Manufacturing Company - Two Years Later,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9077,Distribution tails of sample quantiles and subexponentiality,Distribution tails of sample quantiles and subexponentiality,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9078,A computationally efficient approach for determining inventory levels in a capacitated multi-echelon production-distribution system,A computationally efficient approach for determining inventory levels in a capacitated multi-echelon production-distribution system,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9079,Velocity Inc.: Case B Results of the market research study,Velocity Inc.: Case B Results of the market research study,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9080,Simultaneous inference for multiple endpoint dependent competing risk data,Simultaneous inference for multiple endpoint dependent competing risk data,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9081,Electro technical production works,Electro technical production works,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9082,Llenroc Plastics: Teaching Notes,Llenroc Plastics: Teaching Notes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9083,Price-directed scheduling for semiconductor manufacturing systems,Price-directed scheduling for semiconductor manufacturing systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9084,Subset third derivative diagnostics of nonnormality,Subset third derivative diagnostics of nonnormality,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9085,Activity periods of an infinite server queue and performance of certain heavy tailed fluid queues,Activity periods of an infinite server queue and performance of certain heavy tailed fluid queues,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9086,Sample correlations of infinite variance time series models: an empirical and theoretical study,Sample correlations of infinite variance time series models: an empirical and theoretical study,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9087,Instructor's notes for the Manufacturing Operations Game,Instructor's notes for the Manufacturing Operations Game,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9088,How system performance is affected by the interplay of averages in a fluid queue with long range dependence induced by heavy tails,How system performance is affected by the interplay of averages in a fluid queue with long range dependence induced by heavy tails,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9089,A study of search directions in primal-dual interior-point methods for semidefinite programming,A study of search directions in primal-dual interior-point methods for semidefinite programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9090,The maximum of the periodogram for a heavy-tailed sequence,The maximum of the periodogram for a heavy-tailed sequence,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9091,Using PSA to detect prostate cancer onset: An application of Bayesian retrospective and prospective changepoint identification,Using PSA to detect prostate cancer onset: An application of Bayesian retrospective and prospective changepoint identification,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9092,Certain probabilistic aspects of semistable laws,Certain probabilistic aspects of semistable laws,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9093,How misleading can sample ACF's of stable MA's Be? (Very!),How misleading can sample ACF's of stable MA's Be? (Very!),,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9094,Sample correlation behavior for the heavy tailed general bilinear process,Sample correlation behavior for the heavy tailed general bilinear process,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9095,The supremum of a negative drift random walk with dependent heavy-tailed steps,The supremum of a negative drift random walk with dependent heavy-tailed steps,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9096,On two homogeneous self-dual systems for linear programming and its extensions,On two homogeneous self-dual systems for linear programming and its extensions,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9097,"Product formula, tails and independence of multiple stable integrals","Product formula, tails and independence of multiple stable integrals",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9098,How to make a Hill plot,How to make a Hill plot,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9099,The production transportation scheduling system,The production transportation scheduling system,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9100,Evolution of semiconductor demand forecasts,Evolution of semiconductor demand forecasts,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9101,Modeling the Worker,Modeling the Worker,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9102,Probabilistic analysis of two complexity measures for linear programming problems,Probabilistic analysis of two complexity measures for linear programming problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9103,Growth Rates of Sample Covariances of Stationary Symmetric ?-stable Processes Associated with Null Recurrent Markov Chains,Growth Rates of Sample Covariances of Stationary Symmetric ?-stable Processes Associated with Null Recurrent Markov Chains,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9104,A heavy traffic limit theorem for workload processes with heavy tailed service requirements,A heavy traffic limit theorem for workload processes with heavy tailed service requirements,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9105,A test for nonlinearity of time series with infinite variance,A test for nonlinearity of time series with infinite variance,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9106,Notes on median and quantile estimation,Notes on median and quantile estimation,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9107,Testing for structural breaks in time series regressions with heavy-tailed disturbances,Testing for structural breaks in time series regressions with heavy-tailed disturbances,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9108,Network flows in hotel yield management,Network flows in hotel yield management,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9109,A uniform strong law of large numbers for sample kernel-weighted moments,A uniform strong law of large numbers for sample kernel-weighted moments,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9110,Procurement of common components in a stochastic environment,Procurement of common components in a stochastic environment,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9111,Self-similar communication models and very heavy tails,Self-similar communication models and very heavy tails,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9112,Demand forecasting and capacity planning in the semiconductor industry,Demand forecasting and capacity planning in the semiconductor industry,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9113,SeDFAM: Semiconductor demand forecast accuracy model,SeDFAM: Semiconductor demand forecast accuracy model,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9114,"Determining and allocating capacity-driven safety stock in multi-item, multi-echelon systems","Determining and allocating capacity-driven safety stock in multi-item, multi-echelon systems",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9115,Analytic methods for estimating labor requirements at a parts distribution center,Analytic methods for estimating labor requirements at a parts distribution center,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9116,Capacity-driven acceptance of customer orders for a multi-stage batch manufacturing system: models and algorithms,Capacity-driven acceptance of customer orders for a multi-stage batch manufacturing system: models and algorithms,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9117,Lecture notes on approximation algorithms: Fall 1998,Lecture notes on approximation algorithms: Fall 1998,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9118,Domains of attraction for exponential families,Domains of attraction for exponential families,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9119,Weak Convergence of high-speed network traffic models,Weak Convergence of high-speed network traffic models,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9120,Ruin probability with claims modeled by a stationary ergodic stable process,Ruin probability with claims modeled by a stationary ergodic stable process,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9121,Least-change quasi-Newton updates for equality-constrained optimization,Least-change quasi-Newton updates for equality-constrained optimization,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9122,Velocity Manufacturing Company supplier partnership proposal,Velocity Manufacturing Company supplier partnership proposal,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9123,Randomness and dependence in etch process and their effects on predictability of failures and on cycle times $infty$> input fluid queues,Randomness and dependence in etch process and their effects on predictability of failures and on cycle times $infty$> input fluid queues,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9124,Steady State Distribution of the Buffer Content for M/G/infinity Input Fluid Queues,Steady State Distribution of the Buffer Content for M/G/infinity Input Fluid Queues,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9125,Wavelet analysis of conservative cascades,Wavelet analysis of conservative cascades,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9126,Chapter 1. From dams to telecommunication - a survey,Chapter 1. From dams to telecommunication - a survey,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9127,Single server queues with arch-type dependence,Single server queues with arch-type dependence,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9128,Exact random sampling from independent sets,Exact random sampling from independent sets,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9129,Is Network Traffic Approximated by Stable Levy Motion or Fractional Brownian Motion?,Is Network Traffic Approximated by Stable Levy Motion or Fractional Brownian Motion?,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9130,The Distribution of Test Statistics for Outlier Detection in Heavy-tailed Samples,The Distribution of Test Statistics for Outlier Detection in Heavy-tailed Samples,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9131,Penalized regression splines,Penalized regression splines,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9132,Machine purchasing strategies under demand- and technology-driven uncertainties,Machine purchasing strategies under demand- and technology-driven uncertainties,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9133,The effects of load smoothing on inventory levels in a capacitated production and inventory system,The effects of load smoothing on inventory levels in a capacitated production and inventory system,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9134,Long strange segments of a stochastic process and long range dependence,Long strange segments of a stochastic process and long range dependence,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9135,Sensitivity analysis in linear programming and semidefinite programming using interior-point methods,Sensitivity analysis in linear programming and semidefinite programming using interior-point methods,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9136,Manufacturing logistics research: taxonomy and directions,Manufacturing logistics research: taxonomy and directions,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9137,The Engineering Factory Game: Facilitator's Guide,The Engineering Factory Game: Facilitator's Guide,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9138,Empirical testing of the infinite source Poisson data traffic model,Empirical testing of the infinite source Poisson data traffic model,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9139,Warm-start strategies in interior-point methods for linear programming,Warm-start strategies in interior-point methods for linear programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9140,Tail probabilities of subadditive functionals acting on Levy processes,Tail probabilities of subadditive functionals acting on Levy processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9141,Integrating production and transportation scheduling in a make-to-order environment,Integrating production and transportation scheduling in a make-to-order environment,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9142,Designing a systems engineering educational program using academic/industry collaboration,Designing a systems engineering educational program using academic/industry collaboration,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9143,Long strange segments in a long range dependent moving average,Long strange segments in a long range dependent moving average,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9144,Reticle management analysis for the photolithography sector of a semiconductor fabrication facility,Reticle management analysis for the photolithography sector of a semiconductor fabrication facility,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9145,"Multivariate extremes, aggregation and risk estimation","Multivariate extremes, aggregation and risk estimation",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9146,Evaluation of capacity planning practices for the semiconductor industry,Evaluation of capacity planning practices for the semiconductor industry,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9147,Group sequential tests with outcome-dependent treatment assignment,Group sequential tests with outcome-dependent treatment assignment,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9148,On group sequential tests for data in unequally sized groups and with unknown variance,On group sequential tests for data in unequally sized groups and with unknown variance,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9149,An interior point approach to sensitivity analysis in degenerate linear programs,An interior point approach to sensitivity analysis in degenerate linear programs,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9150,Maintenance support for the reusable launch vehicle program: determining and evaluating spare stock levels for recoverable Parts,Maintenance support for the reusable launch vehicle program: determining and evaluating spare stock levels for recoverable Parts,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9151,Maintenance support for the reusable launch vehicle program: the RLV repair cycle simulator,Maintenance support for the reusable launch vehicle program: the RLV repair cycle simulator,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9152,"Optimal Capacity Expansion for Multi-Product, Multi-Machine Manufacturing Systems with Stochastic Demand","Optimal Capacity Expansion for Multi-Product, Multi-Machine Manufacturing Systems with Stochastic Demand",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9153,A Single Channel on/off Model with TCP-Like Control,A Single Channel on/off Model with TCP-Like Control,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9154,Minimizing Flow Time in Cyclic Schedules for Identical Jobs with Acyclic Precedence: The Bottleneck Lowerbound,Minimizing Flow Time in Cyclic Schedules for Identical Jobs with Acyclic Precedence: The Bottleneck Lowerbound,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9155,Base Stock Policies for Lost-Sales Problems with Stochastic Lead Times,Base Stock Policies for Lost-Sales Problems with Stochastic Lead Times,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9156,Base Stock Policies for Lost-Sales Problems with Deterministic Lead Times,Base Stock Policies for Lost-Sales Problems with Deterministic Lead Times,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9157,Analysis of Ordering Patterns in Serial Supply Chains,Analysis of Ordering Patterns in Serial Supply Chains,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9158,A Network Traffic Model with Random Transmission Rate,A Network Traffic Model with Random Transmission Rate,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9159,Perfect Sampling for Doeblin Chains,Perfect Sampling for Doeblin Chains,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9160,Software Process Improvement: Operations Perspectives,Software Process Improvement: Operations Perspectives,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9161,Limits of On/Off Hierarchical Product Models for Data Transmission,Limits of On/Off Hierarchical Product Models for Data Transmission,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9162,Buffer Content of a Leaky Bucket System with Long-Range Dependent Input Traffic,Buffer Content of a Leaky Bucket System with Long-Range Dependent Input Traffic,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9163,Some Analytic Results for a Periodic Review Lost Sales Problem,Some Analytic Results for a Periodic Review Lost Sales Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9164,"A Combinatorial Multi-Indenture, Multi-Item Inventory Model for NASA's Reusable Launch Vehicle Program","A Combinatorial Multi-Indenture, Multi-Item Inventory Model for NASA's Reusable Launch Vehicle Program",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9165,NOVA Incorporated: F-Case Two Years Later,NOVA Incorporated: F-Case Two Years Later,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9166,Guidelines for Collaborative Supply Chain System Design and Operation,Guidelines for Collaborative Supply Chain System Design and Operation,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9167,An Efficient Auction Mechanism for a Production-Transportation Problem,An Efficient Auction Mechanism for a Production-Transportation Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9168,The Transportation Exchange Game,The Transportation Exchange Game,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9169,An Interior-Point Perspective on Sensitivity Analysis in Semidefinite Programming,An Interior-Point Perspective on Sensitivity Analysis in Semidefinite Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9170,On the Riemannian Geometry Defined by Self-Concordant Barriers and Interior-Point Methods,On the Riemannian Geometry Defined by Self-Concordant Barriers and Interior-Point Methods,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9171,Visualizing Infinitesimal Perturbation Analysis Estimators,Visualizing Infinitesimal Perturbation Analysis Estimators,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9172,Convergence of the Stochastic Mesh Estimator for Pricing American Options,Convergence of the Stochastic Mesh Estimator for Pricing American Options,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9173,A production-based model for predicting heating oil,A production-based model for predicting heating oil,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9174,Report on practices related to demand forecasting for semiconductor products,Report on practices related to demand forecasting for semiconductor products,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9175,Numerical method for backward stochastic differential equations,Numerical method for backward stochastic differential equations,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9176,An analysis of the Longstaff-Schwartz algorithm for American option pricing,An analysis of the Longstaff-Schwartz algorithm for American option pricing,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9177,Explicit form and path regularity of Martingale representations,Explicit form and path regularity of Martingale representations,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9178,Explicit form and robustness of Martingale representations,Explicit form and robustness of Martingale representations,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9179,The Monte-Carlo method for filtering with discrete-timeobservations,The Monte-Carlo method for filtering with discrete-timeobservations,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9180,The Euler scheme for Levy driven stochastic differential equations,The Euler scheme for Levy driven stochastic differential equations,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9181,A partial introduction to financial asset pricing theory,A partial introduction to financial asset pricing theory,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9182,"An elementary approach to naturality, predictability, and the fundamental theorem of local Martingales","An elementary approach to naturality, predictability, and the fundamental theorem of local Martingales",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9183,Long range dependence in heavy tailed stochastic processes,Long range dependence in heavy tailed stochastic processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9184,"Ruin problem, operational risk and how fast stochastic processes mix","Ruin problem, operational risk and how fast stochastic processes mix",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9185,"A Multi-Echelon, Multi-Item Inventory Model for Service Parts Management with Generalized Service Level Constraints","A Multi-Echelon, Multi-Item Inventory Model for Service Parts Management with Generalized Service Level Constraints",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9186,A Model for Inventory Allocation and Repair in a Two-Echelon Network with Emergency Shipments,A Model for Inventory Allocation and Repair in a Two-Echelon Network with Emergency Shipments,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9187,A Simple Algorithm for Part Stocking to Satisfy Pooled Customer Service Requirements at Minimum Cost,A Simple Algorithm for Part Stocking to Satisfy Pooled Customer Service Requirements at Minimum Cost,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9188,Optimal Stocking in Reparable Parts Networks with Repair Capacity and Inventory Pooling,Optimal Stocking in Reparable Parts Networks with Repair Capacity and Inventory Pooling,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9189,Small and Large Time Scales Analysis of a Network Traffic Model,Small and Large Time Scales Analysis of a Network Traffic Model,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9190,"Random Logistic Maps II, The Critical Case","Random Logistic Maps II, The Critical Case",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9191,On the Supercritical Bellman-Harris Process with Finite Mean,On the Supercritical Bellman-Harris Process with Finite Mean,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9192,Estimating the Stationary Distribution of a Markov Chain,Estimating the Stationary Distribution of a Markov Chain,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9193,Nonexistence of a Class of Variate Generation Schemes,Nonexistence of a Class of Variate Generation Schemes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9194,Function Space Valued Markov Model for Electric Arc Furnaces,Function Space Valued Markov Model for Electric Arc Furnaces,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9195,A Robust Markov Model for Three Phase Arc Furnaces,A Robust Markov Model for Three Phase Arc Furnaces,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9196,Modelling Stochastic Volatility in Time Series of Stock Returns: Empirical Evidence,Modelling Stochastic Volatility in Time Series of Stock Returns: Empirical Evidence,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9197,Periodic Review Inventory Control In Distribution Systems: A Note on Linear Purchase and Transfer Costs,Periodic Review Inventory Control In Distribution Systems: A Note on Linear Purchase and Transfer Costs,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9198,Log-normal Durations Can Give Long Range Dependence,Log-normal Durations Can Give Long Range Dependence,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9199,"Hidden Regular Variation, Second Order Regular Variation and Asymptotic Independence","Hidden Regular Variation, Second Order Regular Variation and Asymptotic Independence",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9200,SAP: An Efficient Scheduling Protocol for Web Servers,SAP: An Efficient Scheduling Protocol for Web Servers,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9201,A Generic Analysis of Selfish Routing,A Generic Analysis of Selfish Routing,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9202,Convergence of Simulation-Based Policy Iteration,Convergence of Simulation-Based Policy Iteration,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9203,Optimal Machine Capacity Expansions with Nested Limitations Under Demand Uncertainty,Optimal Machine Capacity Expansions with Nested Limitations Under Demand Uncertainty,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9204,Optimal Capacity Expansion and Contraction under Demand Uncertainty,Optimal Capacity Expansion and Contraction under Demand Uncertainty,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9205,Tails of solutions of certain nonlinear stochastic differential equations driven by heavy tailed Levy motions,Tails of solutions of certain nonlinear stochastic differential equations driven by heavy tailed Levy motions,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9206,Improving Demand Forecasting in Semiconductor Manufacturing,Improving Demand Forecasting in Semiconductor Manufacturing,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9207,Likelihood inference for exchangeable binary data with varying cluster sizes,Likelihood inference for exchangeable binary data with varying cluster sizes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9208,Mid-course sample size modification in clinical trials,Mid-course sample size modification in clinical trials,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9209,Curvature vs. Slope Inference for Features in Nonparametric Curve Estimates,Curvature vs. Slope Inference for Features in Nonparametric Curve Estimates,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9210,Nonparametric estimation for a nonhomogeneous Poisson process,Nonparametric estimation for a nonhomogeneous Poisson process,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9211,A SiZer analysis of IP Flow start times,A SiZer analysis of IP Flow start times,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9212,Variable heavy tailed durations in internet traffic,Variable heavy tailed durations in internet traffic,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9213,On the Foundations of Multivariate Heavy Tail Analysis,On the Foundations of Multivariate Heavy Tail Analysis,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9214,An alternate proof technique for a key result in 'Lost-Sales Problems With Stochastic Lead Times: Convexity Results For Base-Stock Policies',An alternate proof technique for a key result in 'Lost-Sales Problems With Stochastic Lead Times: Convexity Results For Base-Stock Policies',,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9215,Performance evaluation and policy selection in multiclass networks,Performance evaluation and policy selection in multiclass networks,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9216,Stationary measures for some Markov chain models in ecology and economics,Stationary measures for some Markov chain models in ecology and economics,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9217,Distance Weighted Discrimination,Distance Weighted Discrimination,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9218,"Extreme value theory, ergodic theory, and the boundary between short memory and long memory for stationary stable processes","Extreme value theory, ergodic theory, and the boundary between short memory and long memory for stationary stable processes",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9219,"On Overload in a Storage Model, with a Self-Similar and Infinitely Divisible Input","On Overload in a Storage Model, with a Self-Similar and Infinitely Divisible Input",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9220,Call center staffing with simulation and cutting plane methods,Call center staffing with simulation and cutting plane methods,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9221,Resource Allocation among Simulation Time Steps,Resource Allocation among Simulation Time Steps,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9222,Ideological Platforms and Probabilistic Voting Equilibria,Ideological Platforms and Probabilistic Voting Equilibria,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9223,Modeling Data Networks,Modeling Data Networks,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9224,The Extremal Dependence Measure and Asymptotic Independence,The Extremal Dependence Measure and Asymptotic Independence,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9225,Harris Irreducibility of Iterates of iid Random Maps on R+,Harris Irreducibility of Iterates of iid Random Maps on R+,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9226,Cyclic Scheduling with Acyclic Job Precedence Constraints: Improvement Heuristics,Cyclic Scheduling with Acyclic Job Precedence Constraints: Improvement Heuristics,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9227,Cyclic Scheduling with Acyclic Job Precedence Constraints: Construction Heuristics,Cyclic Scheduling with Acyclic Job Precedence Constraints: Construction Heuristics,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9228,"Long Range Dependence, Heavy Tails and Rare Events","Long Range Dependence, Heavy Tails and Rare Events",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9229,Pricing and Hedging in Incomplete Markets: Fundamental Theorems and Robust Utility Maximization,Pricing and Hedging in Incomplete Markets: Fundamental Theorems and Robust Utility Maximization,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9230,Extremal Dependence: Internet Traffic Applications,Extremal Dependence: Internet Traffic Applications,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9231,A Continuous-Time Strategic Capacity Planning Model,A Continuous-Time Strategic Capacity Planning Model,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9232,An Improved Algorithm for the Deterministic Lot-Sizing Problem for General Multi-stage Production Systems,An Improved Algorithm for the Deterministic Lot-Sizing Problem for General Multi-stage Production Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9233,Using Auctions for Procurement,Using Auctions for Procurement,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9234,Ruin theory revisited: stochastic models for operational risk,Ruin theory revisited: stochastic models for operational risk,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9235,The Self-Similar and Multifractal Nature of a Network Traffic Model,The Self-Similar and Multifractal Nature of a Network Traffic Model,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9236,Optimized Bioregenerative Space Diet Selection with Crew Choice,Optimized Bioregenerative Space Diet Selection with Crew Choice,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9237,Work Measurement for Estimating Food Preparation Time of a Bioregenerative Diet,Work Measurement for Estimating Food Preparation Time of a Bioregenerative Diet,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9238,Extending the 'Single Unit - Single Customer' Approach to Capacitated Systems,Extending the 'Single Unit - Single Customer' Approach to Capacitated Systems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9239,"A Faster, Better Approximation Algorithm for the Minimum Latency Problem","A Faster, Better Approximation Algorithm for the Minimum Latency Problem",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9240,Detecting Infeasibility in Infeasible-Interior-Point Methods for Optimization,Detecting Infeasibility in Infeasible-Interior-Point Methods for Optimization,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9241,Estimating extreme values in delay-measurements via probes,Estimating extreme values in delay-measurements via probes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9242,Behaviour of the NORTA method for correlated random vector generation as the dimension increases,Behaviour of the NORTA method for correlated random vector generation as the dimension increases,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9243,Pricing Capacity in the Face of Intertemporal Demand: Deterministic Case,Pricing Capacity in the Face of Intertemporal Demand: Deterministic Case,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9244,"Effective Strong Dimension, Algorithmic Information, and Computational Complexity","Effective Strong Dimension, Algorithmic Information, and Computational Complexity",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9245,Markov Chain Monte Carlo Methods: Park I: Simple Monte Carlo,Markov Chain Monte Carlo Methods: Park I: Simple Monte Carlo,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9246,Iteration of IID Random Maps on R+,Iteration of IID Random Maps on R+,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9247,Markov Chain Monte Carlo Methods: Part II: The Markov Chain case,Markov Chain Monte Carlo Methods: Part II: The Markov Chain case,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9248,Convergence in Probability of Compressed Annealing,Convergence in Probability of Compressed Annealing,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9249,Behaviour of the NORTA Method for correlated random vector generation as the dimension increases,Behaviour of the NORTA Method for correlated random vector generation as the dimension increases,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9250,Protective Scheduling,Protective Scheduling,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9251,Adaptive Simulation Using Perfect Control Variates,Adaptive Simulation Using Perfect Control Variates,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9252,Markov Chain Monte Carlo Methods Part III: Statistical Concepts,Markov Chain Monte Carlo Methods Part III: Statistical Concepts,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9253,A Simple Proof of the Glivenko-Cantelli Theorem,A Simple Proof of the Glivenko-Cantelli Theorem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9254,The Indirect Method - Robust Inference Based on Intermediate Statistics,The Indirect Method - Robust Inference Based on Intermediate Statistics,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9255,Modeling and Analysis of Uncertain Time-Critical Tasking Problems (UTCTP),Modeling and Analysis of Uncertain Time-Critical Tasking Problems (UTCTP),,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9256,A General Capacity Planning Model Under Demand Uncertainty,A General Capacity Planning Model Under Demand Uncertainty,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9257,A General Capacity Planning Model Under Demand Uncertainty: Implementation Details,A General Capacity Planning Model Under Demand Uncertainty: Implementation Details,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9258,Two New Proofs of Afriat's Theorem,Two New Proofs of Afriat's Theorem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9259,Characterizations and Examples of Hidden Regular Variation,Characterizations and Examples of Hidden Regular Variation,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9260,The Evolution of Price in a Market for Capacity,The Evolution of Price in a Market for Capacity,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9261,The Martingale Evolution of Price Forecasts in a market for Supply Chain Capacity,The Martingale Evolution of Price Forecasts in a market for Supply Chain Capacity,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9262,Root-n Consistency of Penalized Spline Estimator for Partially Linear Single-Index Models under General Euclidean Space,Root-n Consistency of Penalized Spline Estimator for Partially Linear Single-Index Models under General Euclidean Space,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9263,Wonham Filter with Random parameters: Rate of Convergence and Error Bounds,Wonham Filter with Random parameters: Rate of Convergence and Error Bounds,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9264,On the Optimality of Conditional Expectation as a Bregman Predictor,On the Optimality of Conditional Expectation as a Bregman Predictor,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9265,Convergence of infeasible-interior-point methods for self-scaled conic programming,Convergence of infeasible-interior-point methods for self-scaled conic programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9266,Proofs of theorems for the JRSS-B paper `Likelihood ratio tests in linear mixed models with one variance component',Proofs of theorems for the JRSS-B paper `Likelihood ratio tests in linear mixed models with one variance component',,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9267,Optimal selling rules in a regime switching model,Optimal selling rules in a regime switching model,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9268,"A Regime Switching Model: Estimation, Robustness, and Empirical Evidence","A Regime Switching Model: Estimation, Robustness, and Empirical Evidence",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9269,Point processes associated with stationary stable processes,Point processes associated with stationary stable processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9270,Maxima of continuous time stationary stable processes,Maxima of continuous time stationary stable processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9271,Limit behavior of fluid queues and networks,Limit behavior of fluid queues and networks,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9272,Improving Forecast Accuracy by Combination,Improving Forecast Accuracy by Combination,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9273,Experiments on Combining Demand Forecasts with Semiconductor Data,Experiments on Combining Demand Forecasts with Semiconductor Data,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9274,On 'Optimal Bidding in a Uniform Price Auction with Multi-Unit Demand',On 'Optimal Bidding in a Uniform Price Auction with Multi-Unit Demand',,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9275,Multiplicity of Bidding Strategies in Reverse Auctions,Multiplicity of Bidding Strategies in Reverse Auctions,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9276,Analysis and Strategic Implications of Multi-Unit Auction Mechanisms,Analysis and Strategic Implications of Multi-Unit Auction Mechanisms,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9277,Primal-Dual Algorithms for Deterministic Inventory Problems,Primal-Dual Algorithms for Deterministic Inventory Problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9278,Modeling Random Vectors Using Chessboard Distributions,Modeling Random Vectors Using Chessboard Distributions,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9279,"Null Flows, Positive Flows and the Structure of Stationary Symmetric Stable Processes","Null Flows, Positive Flows and the Structure of Stationary Symmetric Stable Processes",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9280,Asymptotic Distribution of Unbiased Linear Estimators in the Presence of Heavy-tailed Stochastic Regressors and Residuals,Asymptotic Distribution of Unbiased Linear Estimators in the Presence of Heavy-tailed Stochastic Regressors and Residuals,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9281,"Hyperbolic Programs, and Their Derivative Relaxations","Hyperbolic Programs, and Their Derivative Relaxations",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9282,Polynomial Convergence of Infeasible-Interior-Point Methods Over Symmetric Cones,Polynomial Convergence of Infeasible-Interior-Point Methods Over Symmetric Cones,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9283,A Constant Approximation Algorithm for the One Warehouse Multi-Retailer Problem,A Constant Approximation Algorithm for the One Warehouse Multi-Retailer Problem,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9284,Hidden Regular Variation and the Rank Transform,Hidden Regular Variation and the Rank Transform,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9285,Dual versus Primal-Dual Interior-Point Methods for Linear and Conic Programming,Dual versus Primal-Dual Interior-Point Methods for Linear and Conic Programming,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9286,Activity Rates with Very Heavy Tails,Activity Rates with Very Heavy Tails,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9287,Approximation Algorithms for Stochastic Inventory Control Models,Approximation Algorithms for Stochastic Inventory Control Models,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9288,Efficient group sequential designs when there are several effect sizes under consideration,Efficient group sequential designs when there are several effect sizes under consideration,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9289,Adaptive and non-adaptive group sequential tests,Adaptive and non-adaptive group sequential tests,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9290,Meta-analyses and adaptive group sequential designs in the clinical development process,Meta-analyses and adaptive group sequential designs in the clinical development process,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9291,Service system planning in the presence of a random arrival rate,Service system planning in the presence of a random arrival rate,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9292,Adaptive Control Variates,Adaptive Control Variates,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9293,Functional large deviations for multivariate regularly varying random walks,Functional large deviations for multivariate regularly varying random walks,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9294,The Evolution of Family Level Sales Forecasts into Product Level Forecasts,The Evolution of Family Level Sales Forecasts into Product Level Forecasts,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9295,Limit Laws for Random Vectors with an Extreme Component,Limit Laws for Random Vectors with an Extreme Component,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9296,Inexact primal-dualpath-following algorithms for a special class of convex quadratic SDPand related problems,Inexact primal-dualpath-following algorithms for a special class of convex quadratic SDPand related problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9297,"Scaling, Renormalization, and Universality in Combinatorial Games: the Geometry of Chomp (with technical appendices)","Scaling, Renormalization, and Universality in Combinatorial Games: the Geometry of Chomp (with technical appendices)",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9298,Extremal behavior of stochastic integrals driven by regularly varying Levy processes,Extremal behavior of stochastic integrals driven by regularly varying Levy processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9299,Real-time Optimization for Aircraft Availability,Real-time Optimization for Aircraft Availability,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9300,Counterexamples Related to a Characterization of Multivariate Regular Variation,Counterexamples Related to a Characterization of Multivariate Regular Variation,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9301,Largest Dual Ellipsoids Inscribed in Dual Cones,Largest Dual Ellipsoids Inscribed in Dual Cones,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9302,Data Network Models of Burstiness,Data Network Models of Burstiness,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9303,"Random rewards, fractional Brownian local times and stable self-similar processes","We give deterministic versions of randomized approximation algorithms for several ranking and clustering problems that were proposed by Ailon, Charikar and Newman. We show that under a reasonable extension of the triangle inequality in clustering problems, we can resolve Ailon et al.'s open question wehter there is an approximation algorithm for weighted correlation clustering with weights satisfying the triangle inequality.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9304,Deterministic Approximation Algorithms for Ranking and Clustering Problems,Deterministic Approximation Algorithms for Ranking and Clustering Problems,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9305,Modeling Teletraffic Arrivals by a Poisson Cluster Process,Modeling Teletraffic Arrivals by a Poisson Cluster Process,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9306,A two-fluid actuarial model with an alternating payoff policy,A two-fluid actuarial model with an alternating payoff policy,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9307,An analytical approach to the two-fluid theory of Prigogine and German for Town Traffic,An analytical approach to the two-fluid theory of Prigogine and German for Town Traffic,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9308,On Khachiyan's Algorithm for the Computation of Minimum Volume Enclosing Ellipsoids,On Khachiyan's Algorithm for the Computation of Minimum Volume Enclosing Ellipsoids,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9309,Optimizing Inventory in a Multi-Echelon Multi-Item Supply Chain with Time-Based Customer Service Level Agreements,Optimizing Inventory in a Multi-Echelon Multi-Item Supply Chain with Time-Based Customer Service Level Agreements,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9310,Subadditivity Re-Examined: The Case for Value-At-Risk,Subadditivity Re-Examined: The Case for Value-At-Risk,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9311,A Planning Model for Bioterrorism Response Logisitics,A Planning Model for Bioterrorism Response Logisitics,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9312,An Exact Optimal Solution to a Threshold Inventory Rationing Model for Two Priority Demand Classes,An Exact Optimal Solution to a Threshold Inventory Rationing Model for Two Priority Demand Classes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9313,Heavy-Tailed Insurance Portfolios: Buffer Capital and Ruin Probabilities,Heavy-Tailed Insurance Portfolios: Buffer Capital and Ruin Probabilities,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9314,"Optimality Inequalities for Average Cost Markov Decision Processes and the Optimality of (s,S) Policies","Optimality Inequalities for Average Cost Markov Decision Processes and the Optimality of (s,S) Policies",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9315,Scaling Limits for Workload Process,Scaling Limits for Workload Process,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9316,Characteristic Function for the Stationary State of One-Dimensional Dynamic Systems with Levy Noise,Characteristic Function for the Stationary State of One-Dimensional Dynamic Systems with Levy Noise,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9317,Nonparametric Estimation of ROC Curves Based on Bayesian Models When the True Disease State is Unknown,Nonparametric Estimation of ROC Curves Based on Bayesian Models When the True Disease State is Unknown,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9318,The Impact of Financial Turbulence on Inventory Control,The Impact of Financial Turbulence on Inventory Control,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9319,Stationary Symmetric alpha-stable Discrete Parameter Random Fields,Stationary Symmetric alpha-stable Discrete Parameter Random Fields,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9320,The Influence of Dependence on Data Network Models of Burstiness,The Influence of Dependence on Data Network Models of Burstiness,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9321,An Exact Optimal Solution to a Threshold Inventory Rationing Model for Multiple Priority Demand Cases,An Exact Optimal Solution to a Threshold Inventory Rationing Model for Multiple Priority Demand Cases,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9322,Warranty Claims Modelling,Warranty Claims Modelling,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9323,Linear Convergence of a Modified Frank-Wolfe Algorithm for Computing Minimum Volume Enclosing Ellipsoids,Linear Convergence of a Modified Frank-Wolfe Algorithm for Computing Minimum Volume Enclosing Ellipsoids,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9324,Maharam Extension for Nonsingular Group Actions,Maharam Extension for Nonsingular Group Actions,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9325,Maximizing Influence in a Competitive Social Network: A Follower's Perspective,Maximizing Influence in a Competitive Social Network: A Follower's Perspective,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9326,Ruin Probability with Certain Stationary Stable Claims Generated by Conservative Flows,Ruin Probability with Certain Stationary Stable Claims Generated by Conservative Flows,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9327,Asymptotic Analysis of Exceedance Probability with Stationary Stable Steps,Asymptotic Analysis of Exceedance Probability with Stationary Stable Steps,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9328,Tail probabilities for Infinite series of Regularly Varying Random Sectors,Tail probabilities for Infinite series of Regularly Varying Random Sectors,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9329,"QQ Plots, Random Sets and Data from a Heavy Tailed Distribution","QQ Plots, Random Sets and Data from a Heavy Tailed Distribution",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9330,ORBIT: Optimization by Radial Basis Function Interpolation in Trust-Regions,ORBIT: Optimization by Radial Basis Function Interpolation in Trust-Regions,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9331,Lecture Notes on Network Flow Spring 2004,Lecture Notes on Network Flow Spring 2004,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9332,Long Range Dependence,Long Range Dependence,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9333,The Effect of Memory on Functional Large Deviations of Infinite Moving Average Processes,The Effect of Memory on Functional Large Deviations of Infinite Moving Average Processes,,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9334,"The Pareto Copula, Aggregation of Risks and the Emperor's Socks","The Pareto Copula, Aggregation of Risks and the Emperor's Socks",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9335,"Multivariate Regular Variation on Cones: Application to Extreme Values, Hidden Regular Variation and Conditioned Limit Laws","Multivariate Regular Variation on Cones: Application to Extreme Values, Hidden Regular Variation and Conditioned Limit Laws",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/9339,Scalable Winner Determination in Advertising Auctions,"Internet search results are a growing and highly profitable advertising platform.
Search providers auction advertising slots to advertisers on their search result pages.
Due to the high volume of searches and the users' low tolerance for search result latency, it is imperative to resolve these auctions fast.
Current approaches restrict the expressiveness of bids in order to achieve fast winner determination, which is the problem of allocating slots to advertisers so as to maximize the expected revenue given the advertisers' bids.
The goal of our work is to permit more expressive bidding, thus allowing advertisers to achieve complex advertising goals, while still providing fast and scalable techniques for winner determination.  We also discuss the application of our framework to advertising in massively multiplayer online games.",,application/pdf,Technical Report
oai:ecommons.cornell.edu:1813/10127,Inferior Point Methods for Optimization,"This article describes the current state of the art of interior-point methods (IPMs)for convex, conic, and general nonlinear optimization.  We discuss the theory, outline the algorithms, and comment on the applicability of this class of methods, which have revolutionized the field over the last twenty years.",,,Technical Report
oai:ecommons.cornell.edu:1813/10504,End-to-End Enforcement of Erasure and Declassification,"Declassification occurs when the confidentiality of information is weakened; erasure occurs when the confidentiality of information is strengthened, perhaps to the point of completely removing the information from the system. 

This paper shows how to enforce erasure and declassification policies. A combination of a type system that controls information flow and a simple runtime mechanism to overwrite data ensures end-to-end enforcement of policies. We prove that well-typed programs satisfy the semantic security condition noninterference according to policy.

We extend the Jif programming language with erasure and declassification enforcement mechanisms and use the resulting language in a large case study of a voting system.",,,Technical Report
oai:ecommons.cornell.edu:1813/10772,Concurrent Zero Knowledge: Simplifications and Generalizations,"Few techniques for obtaining concurrent zero-knowledge exist; all require a complex and subtle analysis.
We provide an arguably simpler and more general analysis of the oblivious simulation technique of Kilian and Petrank (STOC'01) while achieving the same bounds as Prabhakaran, Rosen and Sahai (FOCS'02). Using this analysis, and relying on tools recently developed by Ong and Vadhan (Eurocrypt'07, TCC'08) we are able to establish the following \emph{unconditional} results:
\begin{itemize}
\item every language in NP which has a ZK proof (resp. ZK argument, statistical ZK argument) also has a black-box concurrent ZK proof (resp. ZK argument, statistical ZK argument). 
\item every languge which has a statistical ZK proof also has an $\omega(\log n)$-round black-box concurrent statistical ZK proof.
\end{itemize}",,,Technical Report
oai:ecommons.cornell.edu:1813/10915,The Workload process with a Poisson cluster input can look like a Fractional Brownian motion even in the slow growth regime,"The workload process with a Poisson cluster input can look like a Fractional Brownian motion even in the slow growth regime

Vicky Fasen_and Gennady Samorodnitsky ?
May 20, 2008

Abstract

We show that, contrary to the common wisdom, the workload process in a _uid queue with
a cluster Poisson input can converge, in the slow growth regime, to a Fractional Brownian
motion, and not to a L?vy stable motion. This emphasizes lack of robustness of L?vy stable
motions as _bird-eye_ descriptions of the tra_c in communication networks.

AMS 2000 Subject Classi_cations: primary: 90B22 secondary: 60F17

Keywords: cluster Poisson process, _uid queue, Fractional Brownian motion, slow growth regime, scaling limit, workload process

? Center for Mathematical Sciences, TU M?nchen, D-85747 Garching, Germany, email: fasen@ma.tum.de. Parts of the paper were written while the _rst author was visiting the Department of Operations Research and Information Engineering at Cornell University. Financial support from the Deutsche Forschungsgemeinschaft through a research grant is gratefully acknowledged.

?School of Operations Research and Information Engineering, Cornell University, Ithaca, NY 14853, email:
gennady@orie.cornell.edu. Samorodnitsky's research was partially supported by an NSA grant MSPF-05G-049 and an ARO grant W911NF-07-1-0078 at Cornell University.",,,Technical Report
oai:ecommons.cornell.edu:1813/11101,ShutUp: End-to-End Containment of Unwanted Traffic,"While the majority of Denial-of-Service (DoS) defense proposals
assume a purely infrastructure-based architecture, some recent
proposals suggest that the attacking endhost may be enlisted
as part of the solution, through tamper-proof software,
network-imposed incentives, or user altruism. While intriguing,
these proposals ultimately raise the deployment bar by requiring
both the infrastructure and endhosts to cooperate. In this
paper, we explore the design of a pure end-to-end architecture
based on tamper-proof endhost software implemented for instance
with trusted platforms and virtual machines. We present
the design of a ?Shutup Service?, whereby the recipient of unwanted
traffic can ask the sender to slowdown or stop. We show
that this service is effective in stopping DoS attacks, and in significantly
slowing down other types of unwanted traffic such as
worms. The Shutup service is incrementally deployable with
buy-in from OS or antivirus vendors, requiring only minimal
changes to the endhost software stack and no changes to the protocol
stack. We show through experimentation that the service
is effective and has little impact on legitimate traffic.",,,Technical Report
oai:ecommons.cornell.edu:1813/11102,A Dirty-Slate Approach to Routing Scalability,"This paper presents Virtual Aggregation, an
architecture that attempts to tackle the Internet routing scalability
problem. Our approach does not require any changes
to router software and routing protocols and can be deployed
by any ISP without the cooperation of other ISPs. Hence,
Virtual Aggregation is a configuration-only solution. The key
insight here is to use divide-and-conquer so that default-free
zone routers don?t need to maintain the entire routing table.
Instead, an ISP can modify its internal routing such that
individual routers in its network only maintain a part of the
routing table.
We evaluate the application of Virtual Aggregation to a
few tier-1 and tier-2 ISPs and show that it can reduce routing
table size on individual routers by an order of magnitude
while imposing almost no traffic stretch and very little increase
in router load. We also deploy Virtual Aggregation across
two different testbeds comprising of Cisco and Linux routers.
Finally, we detail some shortcomings of the proposed design
and discuss alternative designs that alleviate some of these.
However, in spite of the limitations, we believe that the
simplicity of the proposal and its possible short-term impact
on routing scalability suggest that it is an alternative worth
considering.",,,Technical Report
oai:ecommons.cornell.edu:1813/11153,Hyperproperties: Verification of Proofs,"This paper formalizes some proofs by Clarkson and Schneider about
hyperproperties. The proofs are mechanically verified using the proof
assistant Isabelle.",,,Technical Report
oai:ecommons.cornell.edu:1813/11220,On The Difficulty of Finding the Nearest Peer in P2P Systems,"Finding the nearest peer, in terms of latency, is an important problem in many Internet applications. In this paper, we argue that solutions that only examine inter-peer latencies as part of their operation will find it infeasible, in certain cases, to discover the nearest peer in P2P systems. The difficulty arises out of the way the last hop is typically laid out in the Internet, where a single PoP (point of presence) belonging to an ISP provides connectivity to numerous client networks. This setup leads to a large number of peers being at about the same latency from one another, which, we argue, presents a serious obstacle when a peer tries to discover another peer residing in the same network as itself. We use large-scale measurements over hosts in the Azureus P2P network and DNS servers to show that this condition does occur in real settings, and use simulations of the Meridian closest-server algorithm to show that the condition does indeed lead to difficulty in finding the exact-closest peer. We also propose a few heuristics that help address this issue.",,,Technical Report
oai:ecommons.cornell.edu:1813/11579,Network Reputation Games,"Originally, hyperlinks on the web were placed for organic reasons, presumably to aid navigation or identify a resource deemed relevant by the human author. However, link-based reputation measures used by search engines (e.g., PageRank)  have altered the dynamics of link-placement by introducing new incentives into the system. Strategic authors --- spammers and others --- now explicitly attempt to boost their own PageRank by careful link-placement. This paper investigates the consequences of such strategic behavior via a network formation game. Our model assumes that authors may place outlinks arbitrarily, but have no control over their inlinks, and their objective is to maximize reputation. What is the best link-placement strategy? What are the equilibrium outcomes? What properties do equilibria possess?

We show that two similar reputation measures --- PageRank and hitting time --- lead to dramatically different equilibrium outcomes.  Since hitting time is immune to strategic placement of outlinks, any directed graph is a Nash equilibrium. On the other hand, equilibria in the PageRank game have a very rich structure: unless the links are delicately balanced, some page can increase its PageRank by dropping all of its links and pointing to just one carefully chosen page. Every equilibrium has a core in which all edges are bidirectional. In a slightly restricted setting, equilibria are characterized exactly by simple properties, the essential of which is a combintorial equivalence among all (bidirectional) edges called edgewise walk-regularity. We also demonstrate surprising algebraic properties of equilibria, relating eigenvalues and their multiplicities to graph structure.",,,Technical Report
oai:ecommons.cornell.edu:1813/11688,Olin Library Digital Sign Evaluation,"The Olin Library Communications Department installed a digital sign in Olin's lobby in order to facilitate communication with users. The sign has been used to promote library events, services, and resources. Library Communications requested that Research and Assessment Unit (RAU) conduct an evaluation of the sign's effectiveness in reaching its audience and the impact of the messages it displays.
RAU conducted a paper survey within the library. For two weeks, four large ""ballot boxes"" offering surveys to library users were placed in different locations on Olin's first floor. A total of 269 competed surveys were turned in, about 90% of which came from undergraduate and graduate students.
A large number of comments were gathered. The sign is being noticed and has an impact, but changes to its physical environment and the design of messages may help make it more effective.",,,Technical Report
oai:ecommons.cornell.edu:1813/11795,User Survey for the Cornell University Libraries,"This report includes results of a major survey of the Cornell research community's evaluation of the libraries' research support performance and capabilities. The survey population included faculty, graduate students, and professional library staff.
Survey instruments were pre-tested during June and July 1979. Questionnaires were then tailored to the three populations of interest. Actual data were collected from the three populations during the period October-December 1979.
Completed surveys included 910 from faculty and full-time research staff and over 1000 from graduate students.",The full text of this document is available upon request to some staff within CUL. Please send an email request to researchandassessment@cornell.edu.,,Technical Report
oai:ecommons.cornell.edu:1813/11799,"Workshop on Atmospheric Deposition of Nitrogen - Chesapeake Bay Program, Science and Technical Advisory Committee","Nutrient management in the Chesapeake region largely has focused on agricultural sources and on municipal wastewater treatment plants.  This workshop was convened to advise the Chesapeake Bay Program on the role of atmospheric deposition as a source of nitrogen pollution to the Bay.  The most recent evidence suggests that at least one third and probably significantly more of all the nitrogen that reaches Chesapeake Bay comes from atmospheric deposition, which also contributes to acid rain.  Most of this deposition falls onto the landscape, and then a portion of it runs off and eventually reaches the Bay.",,,Technical Report
oai:ecommons.cornell.edu:1813/11813,The Number of Necessary Constraints in an Integer Program:  A New Proof of Scarf's Theorem,I give a new proof of Scarf's result that an integer program in n variables has a set of binding constraints of cardinality at most 2n-1.,,,Technical Report
oai:ecommons.cornell.edu:1813/11814,Reference Statistics Reporting System Transaction Counts,"The purpose of this project was to analyze reference transaction data in
order to support decisions for optimizing staffing at the reference desks in Olin and Uris
Libraries. Data about reference transactions have been compiled for over a year in the
RSRS system. Using a subset of the RSRS data, this report presents charts and tables of
the number of transactions that were submitted by hour, day of week, week, and month
over a one-year period. Transaction category, duration, mode, and staff data are reported.
Some limitations of the data and recommendations for further research are discussed.

Olin and Uris Library reference desks sees the most traffic during the fall and spring
semesters (fall more than spring), early in the work week and at midday hours. Olin
Library reported an average of 636 transactions per week during the fall semester, 500
transactions per week during the spring semester, and an average of 321 transactions per
week during the summer break. Uris reported an average of 107 transactions per week
during the fall semester and 92 per week transactions during the spring semester.",,,Technical Report
oai:ecommons.cornell.edu:1813/12140,Water Quality of the North End of Cayuga Lake: 1991-2006,"Monitoring the water quality of Cayuga Lake has continued periodically from the early
1900s to the present. The Seneca County Soil and Water Conservation District
(SCSWCD) has collected limnological data on the waters of the northern end of Cayuga
Lake since 1991. This report updates the 1999 report (1991 to 1998) (Makarewicz et al.
1999) with data taken by the SCSWCD from 1999 to 2006. By considering nutrient and
chlorophyll a concentrations and water clarity measurements, we reviewed the current
data from Cayuga Lake with historical measurements of the lake.",,,Technical Report
oai:ecommons.cornell.edu:1813/11820,2008 Environmental Scan of Goals,"This report reviews and summarizes the 2008 Cornell Strategic Plan along with the associated goals and priorities of individual Cornell schools and colleges, and analyzes their content relative to CUL's stated goals and priorities for 2007-2010. The goal is to determine if the library's goals align with and if the library's goals directly link to the colleges for what they identify as their priorities, and to identify gaps between the two.
Results and analysis suggest that some modifications to the CUL goals might be useful in order to align them better with those of other academic units on campus. It is likely that more direct information gathering from college officials would evoke a clearer and more robust connection between CUL's and their goals and priorities.",This report is available only to Cornell University Library staff.,,Technical Report
oai:ecommons.cornell.edu:1813/11821,Book Usage Data Scan,"This document provides some preliminary data on national trends in reading of books, purchase of books, and book publishing. It also provides data on monographic stacks circulation charges for Olin and Engineering.
Recent national data shows a decline in book reading, especially among high school and college students, and other young adults. Book purchase revenue is either flat or increasing slightly, but this appears to be the result of inflation, since the actual number of titles purchased has declined.
Olin and Engineering monographic circulation data (every other year, from 2001/2002 to 2007/2008) show that faculty charges have generally increased, while student charges have generally dropped. Overall circulation has also decreased.",This report is available only to Cornell University Library staff.,,Technical Report
oai:ecommons.cornell.edu:1813/12125,Dynamic Modeling of Workforce Requirements for Mass Prophylaxis Under Highly Uncertain Conditions:  Cornell Dynamic POD Simulator,"The public health response to a bioterrorist attack or other large-scale health emergency may include mass prophylaxis using multiple Points of Dispensing (PODs) to deliver countermeasures rapidly to affected populations.  Although computer models exist to determine ""optimal"" staffing levels at PODs under certain steady-state conditions, no quantitative studies address the requirements of the POD workforce management systems needed to enable efficient, population-wide coverage in the face of a dynamic and uncertain operational environment.

Our goal was to investigate quantitatively the impact of dynamic and uncertain patient arrival patterns on workforce requirements and on overall POD effectiveness and efficiency over the duration of a mass prophylaxis campaign.

To investigate the dynamic behavior of POD systems, many extensive simulation experiments were conducted using a Monte Carlo simulation model, called the Dynamic POD Simulator (D-PODS). Using this simulation environment, we designed POD station layouts, capacities, staffing patterns, patient types, and work flows and then observed the consequences of operating PODs based on these plans under various patient arrival scenarios. The D-PODS user interface is an Excel worksheet and the model is implemented in Visual Basic.

Using several illustrative POD experiments, we demonstrate that uncertain patient arrival patterns require higher staffing levels than might be expected if a stationary environment is assumed.  These experiments further show that PODs may develop severe bottlenecks unless staffing levels vary over time to meet changing patient arrival patterns.  Because of the unpredictability of the operating environment, efficient POD networks require command and control systems capable of dynamically adjusting intra- and inter-POD staffing levels to meet demand.  Furthermore, we show that fewer large PODs require a smaller total staff than many small PODs require to serve the same number of patients.  

We conclude that modeling environments that capture the effects of fundamental uncertainties in public health disasters are essential for the realistic evaluation of response mechanisms and policies.  D-PODS quantifies POD operational efficiency under more realistic conditions than have been modeled previously. Our experiments demonstrate the critical role of variation and uncertainty in POD arrival patterns in establishing effective POD staffing plans. These experiments also highlight the need for command and control systems to be created to manage emergency response successfully.",,,Technical Report
oai:ecommons.cornell.edu:1813/12141,Sharing classes between families,"Class sharing is a new language mechanism for building extensible software systems. Recent work has separately explored two different kinds of extensibility: first, family inheritance, in which an entire family of related classes can be inherited, and second, adaptation, in which existing objects are extended in place with new behavior and state. Class sharing integrates these two kinds of extensibility mechanisms.  With little programmer effort, objects of one family can be used as members of another, while preserving relationships among objects. Therefore, a family of classes can be adapted in place with new
functionality spanning multiple classes. Object graphs can evolve from one family to another, adding or removing functionality even at run time.

Several new mechanisms support this flexibility while ensuring type safety. Class sharing has been implemented as an extension to Java, and its utility for evolving and extending software is demonstrated with realistic systems.",,,Technical Report
oai:ecommons.cornell.edu:1813/12231,Backdoors in the Context of Learning,"The concept of backdoor variables has been introduced as a structural property of combinatorial problems that provides insight into the surprising ability of modern satisfiability (SAT) solvers to tackle extremely large instances. Given a backdoor variable set B, a systematic search procedure is guaranteed to succeed in efficiently deciding the problem instance independent of the order in which it explores various truth valuations of the variables in B. This definition is oblivious to the fact that ""learning during search"" is a key feature of modern solution procedures for various classes of combinatorial problems such as SAT and mixed integer programming (MIP). These solvers carry over often highly useful information from previously explored search branches to newly considered branches. In this work, we extend the notion of backdoors to the context of learning during search. In particular, we prove that the smallest backdoors for SAT that take into account clause learning and order-sensitivity of branching can be exponentially smaller than traditional backdoors oblivious to these solver features. We also provide an experimental comparison between backdoor sizes with and without learning.",,,Technical Report
oai:ecommons.cornell.edu:1813/12244,A Modified Frank-Wolfe Alogorithm for Computing Minimum-Area Enclosing Ellipsoidal Cylinders:  Theory and Algorithms,"We study a first-order method to find the minimum cross-sectional area ellipsoidal cylinder containing a finite set of points.  This problem arises in optimal design in statistics when one is interested in a subset of the parameters.  We provide convex formulations of this problem and its dual, and analyze a method based on the Frank-Wolfe algorithm for their solution.  Under suitable conditions on the behavior of the method, we establish global and local convergence properties.  However, difficulties may arise when a certain submatrix loses rank, and we describe a technique for dealing with this situation.",,,Technical Report
oai:ecommons.cornell.edu:1813/12714,NetQuery: A General-Purpose Channel for Reasoning about Network,"Although the configuration of modern networks has a significant
impact on the performance, robustness, and security of
applications, networks lack support for reporting these differences.
This paper presents the design and implementation
of NetQuery, a novel, general-purpose channel for disseminating
the properties of networks and their participants. Net-
Query implements a distributed, decentralized, tuple-based
attribute store that records information about network entities.
Operators can add new tuples into this store and can
also annotate existing tuples with new, custom attributes,
thus allowing the system to support network entities and
properties not anticipated at the time of deployment. Net-
Query clients can query this attribute store for the current
network state and install event triggers to detect future state
transitions, thus establishing long-running guarantees over
the behavior of the network. We have implemented Net-
Query and deployed networks with NetQuery-enabled devices
that leverage commodity trusted hardware to provide
strong assurance over the accuracy of reported properties.
We describe the NetQuery system, outline the types of new
applications enabled by NetQuery, and report on the performance
of the system from deployments of real devices and
from simulations of ISP networks.",,,Technical Report
oai:ecommons.cornell.edu:1813/12715,Ivy Plus Library Benchmarks,"To inform the strategic budget planning exercise that Cornell is undertaking for the continued reduction of
expenditures, the following library benchmarking data was assembled to answer questions about the level of
relative support, intensity of use, level of staffing and staff efficiency at Cornell University Library and its Ivy Plus
peers. Our analysis shows that Cornell, when put into the context of institutional characteristics, ranks
significantly lower on measures relating to financial support (expenditures, collections and staffing) than on
measures that show how heavily students use our services and staff efficiency.",,,Technical Report
oai:ecommons.cornell.edu:1813/13091,"Trophic State, Tripton, Pelagic Versus Near-Shore, and Modeling Issues for Cayuga Lake, NY.","An analysis of limnological and input monitoring data for Cayuga Lake, NY is presented that addresses differences in metrics of trophic state and turbidity between pelagic waters and a shallow (< 6 m) near-shore area (the shelf) that receives multiple inputs, within the context of the effects of tripton and mixing processes and modeling needs. The analysis is based on a combination of long-term monitoring and shorter-term studies, including: (1) 10 to 20 years of measurements of concentrations of chlorophyll a [Chl], total phosphorus [TP], and other forms of P; (2) 10 years of measurements of Secchi disc depth (SD) and surrogates of light scattering, including turbidity [Tn], and the beam attenuation coefficient at 660 nm [c(660)]; (3) P and Tn measurements for point sources and tributaries that enter the shelf (4 to 10 y) and related constituent loading calculations; (4) a 40 site transect along the length of the lake (> 50 km) with rapid profiling instrumentation that resolves spatial patterns in thermal stratification, fluorometric chlorophyll a, and c(660); (5) light scattering versus gravimetric features of minerogenic tripton particles from tributary, shelf and pelagic sites; and (6) extent of mixing between the shelf and pelagic waters. Despite the P loading received from local sources, summer average [Chl] levels are not significantly higher on the shelf compared to bounding pelagic waters because of the high flushing rate of the shelf promoted by mixing with pelagic waters. The generally higher [TP], c(660), and Tn, and lower SD on the shelf compared to pelagic waters is shown to reflect inputs of clay minerals. The particle sizes of this material, which diminished SD and increased Tn and c(660) on the shelf, are shown to be in the 1 to 10 ?m range. Two water quality modeling initiatives are recommended to guide related management deliberations: (1) a lake-wide seasonal P or nutrient-phytoplankton model, with a twodimensional transport framework that would provide longitudinal and vertical resolution, and (2) a shorter-term three-dimensional model for the tripton component of c(660) that would simulate the dynamics and spatial details of the impacts of runoff events on clarity levels on the shelf.",,,Technical Report
oai:ecommons.cornell.edu:1813/13018,Lexicographic Flow,"The lexicographic flow problem is a flow problem in which the edges are assigned priorities, and we wish to find a flow that is lexicographically maximum with respect to the priority assignment.  The problem is reducible to a weighted flow problem, but we show that exponentially large weights are necessary in general.  We then give an efficient direct algorithm that does not use weights.",,,Technical Report
oai:ecommons.cornell.edu:1813/13088,"Optimal Set Partitioning, Matchings and Lagrangian Duality","We formulate the set partitioning problem as a matching problem with simple side constraints.  As a result we obtain a Lagrangian relaxation of the set partitioning problem in which the primal problem is a matching problem.  To solve the Lagrangian dual we must solve a sequence of matching problems each with different edge-weights.  We use the cyclic coordinate method to iterate the multipliers, which implies that successive matching problems differ in only two edge-weights.  This enables us to use sensitivity analysis to modify one optimal matching to obtain the next one.  We give theoretical and empirical comparisons of these dual bonds with the conventional linear programming ones.",,,Technical Report
oai:ecommons.cornell.edu:1813/13089,Sample Path Properties of Self-Similar Processes with Stationary Increments,"A real-valued process X=(X(t))telR is self-similar with exponent H (H-ss), if X(a.)d aHX for all a>0.  Sample path properties of H-ss processes with stationary increments are investigated.  The main result is that the sample paths have nowhere bounded variation if 0<H<1, unless X(t) tX(1) and H=1, and apart from this can have locally bounded variation only for H>1, in which case they are singular.  Surprisingly, nowhere bounded variation may occur also for H>1.  The first example in the literature exhibiting this combination properties is constructed, as well as many others.  All examples are obtained by subordination of random measures to point processes in in R2 that are Poincare, i.e., invariant in distribution for the transformations (t,x)->(at+b,ax) of R2.  In a final section two ways of combining two ss processes with stationary increments into new ones are studied, one of them being composition of random functions X1oX2=(X1(X1X2(t)))teR.","Vervaat was visitor from Katholieke Universiteit, Nijmegen.",,Technical Report
oai:ecommons.cornell.edu:1813/13090,Marginal Distributions of Self-Similar Processes with Stationary Increments,"Let X= (Xt)t more than or equal to 0 to be a real-valued stochastic process which is self-similar with exponent H>0 and has stationary increments.  Several results about the marginal distribution of X1 are given.  For H inequal to 1, there is a universal bound, depending only on H, on the concentration function of logXsuper+sub1.  For all H>0, X1 cannot have any atoms except in certain trivial cases.  Some lower bounds are given for the tails of the distribution of X1 in case H>1.  Finally, some results are given concerning the connectedness of the support of X1.",Vervaat was a visitor from Katholieke Universiteit.    Technical report dedicated to Professor John Lamperti in recognition of his pioneering work in this field.,,Technical Report
oai:ecommons.cornell.edu:1813/13096,Economic Delivery Quantities For Capacitated Multi-Stage Production Systems,"Procurement lot sizes for externally purchased components used in final assemblies are frequently computed using simple rules. For example, when production rate is constant, Wilson lot size formula is generally used, and when demand rates change over time, formulas such as the part period balancing method, the least unit cost approach, or the Silver-Meal heuristic are used (See reference 4). Each of these methods of computing compare inventory carrying costs to fixed ordering costs in order to minimize total component procurement costs. However, by making this the focus of computation, many issues of practical significance are ignored. Problems arise when amounts ordered for a component are delivered in several lots. To study how assembly plants generally work, the authors set up a model that operates in a ?relatively similar manner? to many assembly plants. They use this example to demonstrate how a model of this environment can be developed to produce economic delivery quantities to each storage area, recognizing capacity limitations.",,,Technical Report
oai:ecommons.cornell.edu:1813/13097,Piecewise-linear Homotopy Algorithms for Sparse Systems of Nonlinear Equations,"When piecewise-linear homotopy algorithms are applied to the problem of approximating a zero of a sparse function $f:R^n \to R^n $, a large piece of linearity can be traversed in one step by using a suitable linear system. The linear system has $n$ rows and $n + 1$ columns, but is subject to a number of inequalities depending on the sparsity pattern of $f$. We show how an algorithm can be implemented using these large pieces; in particular, we demonstrate how to update the linear system corresponding to one large piece to obtain the appropriate system for an adjacent large piece. One measure of the complexity of such an implementation is the number of inequalities that may be required for any one piece. We prove that there can be no more than $O(n^{{3 / 2}} )$ such inequalities, and that this bound is essentially tight; the argument is purely combinatorial. Finally, we provide guidelines on when such a ""large-piece implementation"" should be used instead of much simpler ""small-piece implementations"" for piecewise-linear homotopy algorithms.",,,Technical Report
oai:ecommons.cornell.edu:1813/13102,Exact Analysis of a Lost Sales Model under Stuttering Poisson Demand,"We investigate the (S-1,S) inventory policy under stuttering Poisson
demand and generally distributed lead time when the excess demand is
lost. We correct results presented in Feeney and Sherbrooke's
seminal paper (1966). We also prove that the distribution of
?ordered unit delivery times? becomes increasingly concentrated as
the variance-to-mean ratio of demand increases.",,,Technical Report
oai:ecommons.cornell.edu:1813/13341,Weak  convergence of the function-indexed    integrated periodogram for infinite variance processes,"In this paper we study the weak convergence of the integrated periodogram indexed by classes of functions for linear and stochastic volatility processes with symmetric alpha-stable noise. Under suitable summability conditions on the series of the 
Fourier coefficients of the index functions we show that the weak limits constitute alpha-stable processes which have representation as infinite
Fourier series with  iid alpha-stable coefficients. The 
cases alpha in (0,1) and alpha in [1,2) are dealt with by rather different methods and under different assumptions on the classes of
functions. For example, in contrast to the case alpha in (0,1), entropy conditions are needed for alpha in [1,2) to ensure the
tightness of the sequence of integrated periodograms indexed by functions. 

The results of this paper are of additional interest since 
they provide limit results for infinite mean random quadratic forms with
particular Toeplitz coefficient matrices.",,,Technical Report
oai:ecommons.cornell.edu:1813/13342,"Understanding heavy tails in a bounded world or, is a truncated heavy tail heavy or not?","We address the important question of the extent to which random
variables and vectors with truncated power tails retain the
characteristic features of random variables and vectors with power
tails. We define two truncation regimes,  soft truncation regime
and hard truncation regime, and show that, in the soft truncation
regime, truncated power tails behave, in important respects, as if
no truncation took place. On the other hand, in the had truncation
regime much of ``heavy tailedness'' is lost. We show how to
estimate consistently the tail exponent when the tails are
truncated, and suggest statistical tests to decide on whether the
truncation is soft or hard. Finally, we apply our methods to two
recent data sets arising from computer networks.",,,Technical Report
oai:ecommons.cornell.edu:1813/13343,Large   deviations for point processes based on stationary sequences with heavy   tails,"In this paper we propose a framework that enables the study of  large 
deviations for point processes based on stationary sequences with 
regularly varying tails. This framework allows us to keep track not of
the magnitude of the extreme values of a process, but also of the
order in which these extreme values appear. 
Particular emphasis is put on (infinite)
linear processes with random coefficients. The proposed framework 
provide a rather complete description of the joint asymptotic behavior 
of the large values of the stationary sequence. We apply the general 
result on large deviations for point processes to derive the
asymptotic decay of 
partial sum processes as well as ruin probabilities.",,,Technical Report
oai:ecommons.cornell.edu:1813/13344,Prediction of outstanding   payments in a Poisson cluster model,"We  consider a simple Poisson cluster model for the payment numbers and the 
corresponding total payments for insurance claims arriving in a given
year. Due to the Poisson structure one can 
give reasonably explicit expressions for the prediction of the payment
numbers and total payments in future periods given the
past observations of the payment numbers. One can also derive
reasonably explicit expressions for the corresponding 
prediction errors. In the (a,b)-class of Panjer's claim size distributions, 
these expressions can be evaluated by simple 
recursive algorithms. We study the conditions under which the
predictions   are asymptotically linear as the  number 
of past payments becomes large. We also demonstrate that, in other
regimes, the prediction may be far from linear. For example, a
staircase-like pattern may arise as well. 
We illustrate how the theory works
on real-life data, also in comparison with the chain ladder method.",,,Technical Report
oai:ecommons.cornell.edu:1813/13345,High level excursion set geometry for non-Gaussian infinitely  divisible random fields,"We consider smooth, infinitely divisible random fields with regularly varying
Levy measure, and  are interested in the
geometric characteristics of the excursion sets over high levels u. 

For a large class of such random fields we compute the  asymptotic  
joint distribution of the numbers of critical points, of various types,
 of the random field in the excursion set,  conditional on the latter being non-empty.
 This allows us, for example, to obtain the
asymptotic conditional distribution of the Euler characteristic of the
excursion set.

In a significant departure from the Gaussian situation,
the high level excursion sets for these random fields can have quite a
complicated geometry. Whereas in the Gaussian
case non-empty excursion sets are, with high probability, roughly
ellipsoidal,  in the  more general infinitely divisible setting almost
any shape is possible.",,,Technical Report
oai:ecommons.cornell.edu:1813/13452,Multi-Verifier Signatures,"Multi-verifier signatures generalize traditional digital signatures to a secret-key setting. Just like digital signatures, these signatures are both transferable and secure under arbitrary (unbounded) adaptive chosen-message attacks.  In contrast to digital signature schemes, however, we exhibit practical constructions of multi-verifier signature schemes that are provably secure and are based only on pseudorandom functions in the plain model without any random oracles.",,,Technical Report
oai:ecommons.cornell.edu:1813/13686,Evaluating Planned Capacities for Public Health Emergency Supply Chain Models,"To respond effectively in the event of a public health emergency, careful analysis of preparedness plans is essential. This note describes a linear programming model of the Center for Disease Control Strategic National Stockpile (SNS) supply chain for distributing medical supplies under
emergency conditions. The purpose of the model is to evaluate the effects that a specified collection of planned resource availabilities would have on the efficacy of the distribution network. This efficacy is measured in terms of the number of patient -hours waited during the emergency response
time horizon. The model's constraints describe the physical system, including the relationships between the SNS, the regional distribution warehouse, and the medical supply distribution clinics. In the following note all model constraints and variables are described in detail, and AMPL code implementing the model is given.",,,Technical Report
oai:ecommons.cornell.edu:1813/13700,How Fast Can the Chord-Length Distribution Decay?,"The modelling of random bi-phasic, or porous, media has been, and still is,
under active investigation by mathematicians, physicists or physicians. In this
paper we consider a thresholded random process X as a source of the two
phases. The intervals when X is in a given phase, named chords, are the
subject of interest. We focus on the study of the tails of the chord-length
distribution functions. In the literature, different types of the tail behavior
have been reported, among them exponential-like or power-like decay. We look
for the link between the dependence structure of the underlying thresholded
process X and the rate of decay of the chord-length distribution. When the
process X is a stationary Gaussian process, we relate the latter to the rate
at which the covariance function of $X$ decays at large lags. We show that
exponential, or nearly exponential, decay of the tail of the distribution of
the chord-lengths is very common, perhaps surprisingly so.",,,Technical Report
oai:ecommons.cornell.edu:1813/14150,The Value of New Scientific Communication Models for Chemistry,"This paper is intended as a starting point for discussion on the possible future of scientific communication in chemistry, the value of new models of scientific communication enabled by web based technologies, and the necessary future steps to achieve the benefits of those new models. It is informed by a NSF sponsored workshop that was held on October 23-24, 2008 in Washington D.C. It provides an overview on the chemical communication system in chemistry and describes efforts to enhance scientific communication by introducing new web-based models of scientific communication. It observes that such innovations are still embryonic and have not yet found broad adoption and acceptance by the chemical community. The paper proceeds to analyze the reasons for this by identifying specific characteristics of the chemistry domain that relate to its research practices and socio-economic organization. It hypothesizes how these may influence communication practices, and produce resistance to changes of the current system similar to those that have been successfully deployed in other sciences and which have been proposed by pioneers within chemistry.",,,Technical Report
oai:ecommons.cornell.edu:1813/14199,Diffusion Formulation for Heterogeneous Subsurface Scattering,"Materials with visually important heterogeneous subsurface scattering, including marble, skin, leaves, and minerals, are common in the real world. However, general, accurate and efficient rendering of these materials is an open problem. In this short report, we describe the heterogeneous diffusion equation (DE) formulation that solves this problem. This formulation has
two key results: an accurate model of the reduced intensity (RI) source, the diffusive source boundary condition (DSBC), and its associated render query function. Using there results, we can render subsurface scattering nearly as accurately as Monte Carlo (MC) algorithms. At the end of this report,
we demonstrate this accuracy by comparing our new formulation to other methods used in previous work.",,,Technical Report
oai:ecommons.cornell.edu:1813/14712,"Cayuga Lake Water Quality Monitoring, Related to the LSC Facility: 1998","The primary objective is to conduct an ambient water quality monitoring program
focusing on the southern portion of Cayuga Lake to support long-term records of trophic
state indicators, including concentrations of phosphorus and chlorophyll, and Secchi disc transparency, and other measures of water quality.",,,Technical Report
oai:ecommons.cornell.edu:1813/14713,"Cayuga Lake Water Quality Monitoring, Related to the LSC Facility: 1999","The primary objective is to conduct an ambient water quality monitoring program
focusing on the southern portion of Cayuga Lake to support long-term records of trophic
state indicators, including concentrations of phosphorus and chlorophyll, and Secchi disc transparency, and other measures of water quality.",,,Technical Report
oai:ecommons.cornell.edu:1813/14714,"Cayuga Lake Water Quality Monitoring, Related to the LSC Facility: 2000","The primary objective is to conduct an ambient water quality monitoring program
focusing on the southern portion of Cayuga Lake to support long-term records of trophic
state indicators, including concentrations of phosphorus and chlorophyll, and Secchi disc transparency, and other measures of water quality.",,,Technical Report
oai:ecommons.cornell.edu:1813/14715,"Cayuga Lake Water Quality Monitoring, Related to the LSC Facility: 2001","The primary objective is to conduct an ambient water quality monitoring program
focusing on the southern portion of Cayuga Lake to support long-term records of trophic
state indicators, including concentrations of phosphorus and chlorophyll, and Secchi disc transparency, and other measures of water quality.",,,Technical Report
oai:ecommons.cornell.edu:1813/14716,"Cayuga Lake Water Quality Monitoring, Related to the LSC Facility: 2002","The primary objective is to conduct an ambient water quality monitoring program
focusing on the southern portion of Cayuga Lake to support long-term records of trophic
state indicators, including concentrations of phosphorus and chlorophyll, and Secchi disc transparency, and other measures of water quality.",,,Technical Report
oai:ecommons.cornell.edu:1813/14717,"Cayuga Lake Water Quality Monitoring, Related to the LSC Facility: 2003","The primary objective is to conduct an ambient water quality monitoring program
focusing on the southern portion of Cayuga Lake to support long-term records of trophic
state indicators, including concentrations of phosphorus and chlorophyll, and Secchi disc transparency, and other measures of water quality.",,,Technical Report
oai:ecommons.cornell.edu:1813/14718,"Cayuga Lake Water Quality Monitoring, Related to the LSC Facility: 2004","The primary objective is to conduct an ambient water quality monitoring program
focusing on the southern portion of Cayuga Lake to support long-term records of trophic
state indicators, including concentrations of phosphorus and chlorophyll, and Secchi disc transparency, and other measures of water quality.",,,Technical Report
oai:ecommons.cornell.edu:1813/14719,"Cayuga Lake Water Quality Monitoring, Related to the LSC Facility: 2005","The primary objective is to conduct an ambient water quality monitoring program
focusing on the southern portion of Cayuga Lake to support long-term records of trophic
state indicators, including concentrations of phosphorus and chlorophyll, and Secchi disc transparency, and other measures of water quality.",,,Technical Report
oai:ecommons.cornell.edu:1813/14720,"Cayuga Lake Water Quality Monitoring, Related to the LSC Facility: 2006","The primary objective is to conduct an ambient water quality monitoring program
focusing on the southern portion of Cayuga Lake to support long-term records of trophic
state indicators, including concentrations of phosphorus and chlorophyll, and Secchi disc transparency, and other measures of water quality.",,,Technical Report
oai:ecommons.cornell.edu:1813/14721,"Cayuga Lake Water Quality Monitoring, Related to the LSC Facility: 2007","This report summarizes the results of water quality monitoring efforts related to the LSC
facility in 2007. This monitoring program began in 1998 and was performed annually by the Upstate Freshwater Institute (UFI) until 2006. In 2007 water sample collection and generation of the report was taken over by the DeFrees Hydraulics Laboratory of the School of Civil and Environmental Engineering at Cornell University. UFI continues to carry out all laboratory analysis. This report is largely based on previous annual reports written by UFI.",,,Technical Report
oai:ecommons.cornell.edu:1813/14722,"Cayuga Lake Water Quality Monitoring, Related to the LSC Facility: 2008","This report summarizes the results of water quality monitoring efforts related to the LSC
facility in 2008. This monitoring program began in 1998 and was performed annually by the Upstate Freshwater Institute (UFI) until 2006. In 2007 water sample collection and
generation of the report was taken over by the DeFrees Hydraulics Laboratory of the School of Civil and Environmental Engineering at Cornell University. UFI continues to carry out all laboratory analysis. The format of this report is largely based on previous annual reports written by UFI.",,,Technical Report
oai:ecommons.cornell.edu:1813/14917,Optimal Network Design for the Spread of Cascades,"We introduce a new optimization framework to maximize the expected spread of cascades in networks.  Our model allows a rich set of actions that directly manipulate cascade dynamics by adding nodes or edges to the network.  Our motivating application is one in spatial conservation planning, where a cascade models the dispersal of wild animals through a fragmented landscape.  We propose a mixed integer programming (MIP) formulation that combines elements from network design and stochastic optimization.  Our approach, evaluated on data obtained from a red-cockaded woodpecker (RCW) conservation effort in southeastern United States, results in solutions with stochastic
optimality guarantees and points to conservation strategies that are fundamentally different from naive approaches.",,,Technical Report
oai:ecommons.cornell.edu:1813/14919,Reconcile: A Coreference Resolution Research Platform,"We have created a software infrastructure called Reconcile that is a platform for the development of learning-based noun phrase (NP) coreference resolution systems. Reconcile’s architecture was designed to facilitate the rapid creation of coreference resolutions systems, easy implementation of new feature sets and approaches to coreference resolution, and empirical evaluation of coreference resolvers across a variety of benchmark data sets and standard scoring metrics. Reconcile is written in Java and can be easily customized with different subcomponents, feature sets, and parameter settings. In this report, we describe Reconcile’s architecture, processing pipeline, and the subcomponents and algorithms that are currently implemented and available in Reconcile. We also present experimental results showing that Reconcile can be used to create a coreference resolver which achieves performance levels comparable to state-of-the-art systems on six benchmark data sets.",,,Technical Report
oai:ecommons.cornell.edu:1813/14982,A radiative transfer framework for rendering materials with anisotropic structure,"The radiative transfer framework that underlies all current rendering of volumes is limited to scattering media whose properties are invariant to rotation.  Many systems allow for ""anisotropic scattering,"" in the sense that scattered intensity depends on the scattering angle, but the standard equation assumes that the structure of the medium is isotropic. This limitation impedes physics-based rendering of volume models of cloth, hair, skin, and other important volumetric or translucent materials that do have anisotropic structure.  This paper presents an end-to-end formulation of physics-based volume rendering of anisotropic scattering structures, allowing these materials to become full participants in global illumination simulations.

We begin with a generalized radiative transfer equation, derived from scattering by oriented non-spherical particles.  Within this framework, we propose a new volume scattering model analogous to the well-known family of microfacet surface reflection models; we derive an anisotropic diffusion approximation, including the weak form required for finite element solution and a way to compute the diffusion matrix from the parameters of the scattering model; and we also derive a new anisotropic dipole BSSRDF for anisotropic translucent materials.  We demonstrate results from Monte Carlo, finite element, and dipole simulations.  All these contributions are readily implemented in existing rendering systems for volumes and translucent materials, and they all reduce to the standard practice in the isotropic case.",,,Technical Report
oai:ecommons.cornell.edu:1813/14988,Establishing Stationarity of Time Series Models via Drift Criteria,"Time series models are often constructed by combining nonstationary effects such as trends with stochastic processes that are known (or believed) to be stationary. However, there are numerous time series models for which the stationarity of the underlying process is conjectured but not yet proven. We give an approachable introduction to the use of drift criteria (also known as Lyapunov function techniques) for establishing strict stationarity and ergodicity of such models. These conditions immediately imply consistent estimation of the mean and lagged covariances, and more generally the expectation of any integrable function. We demonstrate by proving stationarity and ergodicity for several novel and useful examples, including Poisson log-link Generalized Autoregressive Moving Average models.",ORIE Technical Report 1477,,Technical Report
oai:ecommons.cornell.edu:1813/14998,Halting and Equivalence of Program Schemes in Models of Arbitrary Theories,"In this note we consider the following decision problems.  Let S be a fixed first-order signature.
(i) Given a first-order theory or ground theory T over S of Turing degree A, a program scheme p over S, and input values specified by ground terms t1,...,tn, does p halt on input t1,...,tn in all models of T?
(ii) Given a first-order theory or ground theory T over S of Turing degree A and two program schemes p and q over S, are p and q equivalent in all models of T?
When T is empty, these two problems are the classical halting and equivalence problems for program schemes, respectively.  We show that problem (i) is Sigma^A_1-complete and problem (ii) is Pi^A_2-complete.  Both problems remain hard for their respective complexity classes even if S is restricted to contain only a single constant, a single unary function symbol, and a single monadic predicate.  It follows from (ii) that there can exist no relatively complete deductive system for scheme equivalence over models of theories of any Turing degree.",,,Technical Report
oai:ecommons.cornell.edu:1813/15133,"On the implementation and usage of SDPT3 - a MATLAB software package for semidefinite-quadratic-linear programming, version 4.0","This software is designed to solve primal and dual semide¯nite-quadratic-linear conic programming problems (known as SQLP problems) whose constraint cone is a product of semide¯nite cones, second-order cones, nonnegative orthants and Euclidean spaces, and whose objective function is the sum of linear functions and log-barrier terms associated with the constraint cones. This includes the special case of determinant maximization problems with linear matrix inequalities. It employs an infeasible primal-dual predictor-corrector path-following method, with either the
HKM or the NT search direction. The basic code is written in Matlab, but key
subroutines in C are incorporated via Mex ¯les. Routines are provided to read in
problems in either SDPA or SeDuMi format. Sparsity and block diagonal structure are exploited. We also exploit low-rank structures in the constraint matrices associ-
ated with the semide¯nite blocks if such structures are explicitly given. To help the
users in using our software, we also include some examples to illustrate the coding of
problem data for our solver. Various techniques to improve the eficiency and robustness of the main solver are incorporated. For example, step-lengths associated with semide¯nite cones are calculated via the Lanczos method. The current version also implements algorithms for solving a 3-parameter homogeneous self-dual model of the primal and dual SQLP problems. Routines are also provided to determine whether the primal and dual feasible regions of a given SQLP have empty interiors. Numerical experiments show that this general-purpose code can solve more than 80% of a total of about 430 test problems to an accuracy of at least 10¡6 in relative duality gap and infeasibilities.",,,Technical Report
oai:ecommons.cornell.edu:1813/15196,"Cayuga LakeWater Quality Monitoring, Related to the LSC Facility: 2009",This report summarizes the results of water quality monitoring efforts related to Cornell University’s Lake Source Cooling (LSC) facility in 2009. This monitoring program began in 1998 and was performed annually by the Upstate Freshwater Institute (UFI) until 2006. In 2007 water sample collection and generation of the annual report was taken over by the DeFrees Hydraulics Laboratory of the School of Civil and Environmental Engineering at Cornell University. UFI continues to carry out all laboratory analysis. The format of this report is largely based on previous annual reports written by UFI.,,,Technical Report
oai:ecommons.cornell.edu:1813/15843,Precomputed & Hybrid Variants of Lightcuts,"Our extensions to multidimensional lightcuts improve rendering performance using precomputation and hierarchial approaches. The first approach precomputes static illumination of static geometry, but defers the remaining light path computations until render time. Once the dynamic content of a scene is known, the remaining light paths are resolved and a final image is computed. The impact of precomputation impacts performance in a view and scene-dependent manner. We also explore a hierarchial approach that computes coarse regional approximations for lighting, then progressively refines these approximations to an error-bounded threshold as necessary. Performance improvements for this hybrid method depend on the realization of fast visibility-testing, either through the use of hardware shadow mapping or packetized ray tracers.",,,Technical Report
oai:ecommons.cornell.edu:1813/15845,Homogeneous Family Sharing,"Recent work has introduced class sharing as a mechanism for adapting a family of related classes with new functionality. This paper introduces homogeneous family sharing, implemented in the J&h language, in which the sharing mechanism is lifted from class-level sharing to true family-level sharing. Compared to the original (heterogeneous) class sharing mechanism, homogeneous family sharing provides useful new functionality and substantially reduces the annotation burden on programmers by eliminating the need for masked types and sharing declarations. This is achieved through a new mechanism, shadow classes, which permit homogeneous sharing of all related classes in shared families. The new sharing mechanism has a straightforward semantics, which is formalized in the J&h calculus. The soundness of the J&h type system is proved. The J&h language is implemented as an extension to the J& language. To demonstrate the effectiveness of family sharing, the Polyglot compiler framework is ported to J&h.",,,Technical Report
oai:ecommons.cornell.edu:1813/17053,Incorporating Economic and Ecological Information into the Optimal Design of Wildlife Corridors,"In an attempt to address the negative ecological impacts of habitat fragmentation, wildlife corridors have been proposed as a way to connect areas of biological significance. In this article we introduce a model to maximize the amount of suitable habitat in a fully connected parcel network linking core habitat areas, subject to a constraint on the funds available for land acquisition. The economic framework of maximizing benefits subject to a budget constraint that we employ is a divergence from other recently proposed models that focus only on minimizing the cost of a single parcel-wide corridor. While the budget constrained optimization model that
we introduce is intuitively appealing, it presents substantial computational challenges above and beyond determining the cost-minimizing corridor.
We formulate the wildlife corridor design problem formally as the so-called connection subgraph problem. This graph problem, NP-hard in terms of the worst case computational complexity, demonstrates an easy-hard-easy pattern in solution runtime. We present a solution method for this optimization problem using a network flow based Mixed Integer Programming (MIP) formulation, and introduce a hybrid technique to improve scalability. We apply our model and methods to real data collected for the optimal design of a wildlife corridor for grizzly bears in the U.S. Northern Rockies, illustrating the underlying computational complexities by
varying the granularity of the parcels available for acquisition. In addition, we show that budget constrained optimization drastically increases total habitat suitability of the corridor over parcel
selection based solely on cost minimization. The model and solution method developed here are general and can be applied, in addition, to conservation of other species or even to problems arising in other fields such as social networks.",,,Technical Report
oai:ecommons.cornell.edu:1813/17316,A large   deviation principle for Minkowski sums of heavy-tailed random   compact convex sets with finite expectation,"We prove large deviation results for Minkowski sums of iid random
compact sets where we assume
that the summands have a regularly varying distribution and 
finite expectation. The main focus is on random convex compact sets. The
results confirm the heavy-tailed large deviation heuristics: 
``large'' values of the sum are essentially due to the ``largest''
summand. These results extend those in Mikosch et al. (2011) for generally
non-convex sets, where we assumed that the normalization of the sum 
grows faster than the number of terms.",,,Technical Report
oai:ecommons.cornell.edu:1813/17317,Large   deviations for Minkowski sums of heavy-tailed  generally non-convex   random compact sets,"We prove large deviation results for Minkowski sums of iid random
compact sets where we assume
that the summands have a regularly varying distribution. The
result confirms the heavy-tailed large deviation heuristics: 
``large'' values of the sum are essentially due to the ``largest''
summand.",,,Technical Report
oai:ecommons.cornell.edu:1813/17360,Settling the Round-Complexity of Non-Malleable Commitments,"We show \emph{unconditionally} that the existence of commitment schemes implies the existence of \emph{constant-round} non-malleable commitments; earlier protocol required additional assumptions such as collision resistant hashfunctions or subexponential one-way functions. 

Our protocol also satisfies the stronger notions of concurrent non-malleability and robustness. As a corollary, we establish that constant-round secure multi-party computation can be based on only enhanced trapdoor permutations; also here, earlier protocols additionally required either collision-resistant hash functions or subexponential one-way functions.",,,Technical Report
oai:ecommons.cornell.edu:1813/19310,Frenetic: A High-Level Language  for OpenFlow Networks,"Network administrators must configure network devices to simultaneously provide several interrelated services such as routing, load balancing, traffic monitoring, and access control. Unfortunately, most interfaces for programming networks are defined at the low level of abstraction supported by the underlying hardware, leading to complicated programs with subtle bugs.  We present Frenetic, a high-level language for OpenFlow networks that enables writing programs in a declarative and compositional style, with a simple ""program like you see every packet"" abstraction.  Building on ideas from functional programming, Frenetic offers a rich pattern algebra for classifying packets into traffic streams and a suite of operators for transforming streams.  The run-time system efficiently manages the low-level details of (un)installing packet-processing rules in the switches. We describe the design of Frenetic, an implementation on top of OpenFlow, and experiments and example programs that validate our design choices.",,,Technical Report
oai:ecommons.cornell.edu:1813/19321,Weak quenched limiting distributions for transient one-dimensional random walk in a random environment,"We consider a one-dimensional, transient random walk in a random
i.i.d. environment. The asymptotic behaviour of such
random walk depends to a large extent on a crucial parameter
kappa>0 that determines the fluctuations of the process. 
When 0<kappa<2, the averaged distributions of the hitting times of the random walk converge to a kappa-stable distribution. However, it was shown recently that in this case there does not exist a quenched limiting distribution of the hitting times.
That is, it is not true that
for almost every fixed environment, the 
distributions of the hitting times (centered and scaled in any manner)
converge to a non-degenerate distribution. We
show, however, that the quenched distributions do have a limit in the
weak sense. That is, the quenched distributions of the hitting times 
%of the random walk 
-- viewed as a random probability measure on R -- converge in
distribution to a random probability measure, which has interesting
stability properties.  Our results generalize both the averaged limiting distribution and the non-existence of quenched limiting distributions.",,,Technical Report
oai:ecommons.cornell.edu:1813/22069,Building Autonomy into a Cell-Free Protein Producing Gel: Integrating T7 RNA Polymerase,"Cell-free protein production is a new technology that offers many advantages over conventional cell-based expression techniques, though low yields (in the range of µg/ml) have been a major drawback.  With the advent of the p-gel system, a DNA hydrogel consisting of genes as part of the gel scaffolding, yields in the mg/ml range have been demonstrated.  As p-gel expression relies on exogenous transcriptional and translational enzymes, cloning these proteins into the p-gel system would increase its autonomy.  Here, we attempt to clone T7 RNA polymerase into a vector compatible with the p-gel system.  Primers were designed to amplify T7 RNA polymerase from E. coli strain BL21 (DE3) as well as attach NcoI and SmaI restriction enzyme sites via PCR.  The amplicon was digested and ligated with Roche’s pIVEX2.4d, a plasmid that supports cell-free protein expression in E. coli lysate with bacteriophage T7 RNA polymerase.  The plasmid was then used to transform chemically competent E. coli cells.  Colonies carrying the plasmid of interest were selected for via colony PCR and submitted for sequencing.  Unfortunately, our samples displayed an abundance of mutations that would likely affect T7 RNA polymerase’s activity.  Nonetheless, with additional work, the plasmid samples produced could be useful in p-gel expression studies.",,,Technical Report
oai:ecommons.cornell.edu:1813/21956,ALSIM 1 (LEVEL 2) User's Manual,"ALSIM 1 (LEVEL 2) is a dynamic computer simulation model of alfalfa (Medicago sativa L.) growth and management written in the computer simulation language CSMP III.  The model was developed primarily for studies of the management of defoliating pests of the alfalfa ecosystem.  It is a refinement of ALSIM 1 (LEVEL 1), and for most applications it should be used in preference to LEVEL 1.  The main improvement in LEVEL 2 is a soil water budget allowing for simulation of the effects of limiting soil water supply on alfalfa growth.  Under most conditions, it will more accurately predict seasonal yield distributions than will LEVEL 1.  Over-winter use of stored food reserves has also been added to LEVEL 2.  Input data needed for LEVEL 2 are (a) yields of leaves, stems, basal buds, and total non-structural carbohydrate reserves (TNC) at the start of simulation; (b) soil water holding capacity of the root zone; (c) dates of harvest; (d) latitude of the study location; and (e) daily weather data for solar radiation, mean air temperature, and precipitation.  The model predicts the yield of alfalfa hay and the growth curves for leaves, stems, basal buds, and TNC with simulated time steps of one day.  It also simulates the supply of available water in the root zone on a daily basis.  The model assumes largely pure stands of alfalfa, and it does not include growth limitations caused by excess soil water content.  Neither does the model predict root growth and yield, assuming a root system sufficient to extract the available water.  A discussion of model development, performance, and use is included in this report.",,,Technical Report
oai:ecommons.cornell.edu:1813/22016,"SURVEY: Views about, knowledge of, and skills in science communication","This file contains the survey developed and reported in the article ""What do scientists need to learn in order to communicate better? Measuring scientists' views about, and knowledge of, and skills in, science communication""","Supporting material for paper on ""What do scientists need to learn in order to communicate better? Measuring scientists' views about, and knowledge of, and skills in, science communication""",,Technical Report
oai:ecommons.cornell.edu:1813/22082,Computing with Capsules,"Capsules provide a clean algebraic representation of the state of a computation in higher-order functional and imperative languages.  They play the same role as closures or heap- or stack-allocated environments but are much simpler.  A capsule is essentially a finite coalgebraic representation of a regular closed lambda-coterm.  One can give an operational semantics based on capsules for a higher-order programming language with functional and imperative features, including mutable bindings.  Lexical scoping is captured purely algebraically without stacks, heaps, or closures.  All operations of interest are typable with simple types, yet the language is Turing complete.  Recursive functions are represented directly as capsules without the need for unnatural and untypable fixpoint combinators.",,,Technical Report
oai:ecommons.cornell.edu:1813/22262,College Students on the Web: Usability Guidelines for Creating Compelling Websites for College Students,"This report is based on user research with university-level students (both undergraduates and graduate students), who varied by age (18–24 years old). The research was conducted in 4 countries on 3 continents (Australia, Germany, the UK, and the USA), but study participants originated from many additional countries.  Nielsen Norman Group tested the way college students use real sites designed for students as well as their use of mainstream websites. The report contains 86 design guidelines that will make websites more suited for students and easier for them to use. The guidelines are based on usability tests and ethnographic observation of 217 websites.  Richly illustrated with 222 color screenshots, showing designs that worked well for students as well as designs they didn't like or that caused them usability problems.",,,Technical Report
oai:ecommons.cornell.edu:1813/22291,Realization of Coinductive Types,We give an explicit combinatorial construction of final coalgebras for a modest generalization of polynomial functors on Set.  Type signatures are modeled as directed multigraphs instead of endofunctors.  The final coalgebra for a type signature F involves the notion of Brzozowski derivative on sets of paths in F.,,,Technical Report
oai:ecommons.cornell.edu:1813/22375,"Trends in air temperature at Geneva, New York","Weather records at Geneva, New York for the years 1893-2009 were examined for the presence of trends in air temperature.  Records include daily maximum and minimum temperatures, and for each year in the series, mean, mean maximum, and mean minimum air temperatures were compiled.  In addition, subsets of each year were examined to determine patterns of winter and summer temperatures.  The figures suggest a cyclical pattern of temperature over the 117 years.  Starting with lower temperatures at the beginning of the series (1893), there was an increase to the 1930s, a decline to about 1980, and a rise thereafter.","PDF file, 12 pages, contains tables and graphs (colour).",,Technical Report
oai:ecommons.cornell.edu:1813/22415,"Detecting the Structure of Social Networks using (\alpha, \beta)-Communities","An (\alpha,\beta)-community is a subset of vertices C with each vertex in C connected to at least \beta vertices of C (self-loops counted) and each vertex outside of C connected to at most \alpha vertices of C (\alpha<\beta). In this paper, we present a heuristic (\alpha,\beta)-Community algorithm, which in practice successfully finds (\alpha,\beta)-communities of a given size. The structure of (\alpha,\beta)-communities in several large-scale social graphs is explored, and a surprising core structure is discovered by taking the intersection of a group of massively overlapping (\alpha,\beta)-communities. For large community size k, the (\alpha,\beta)-communities are well clustered into a small number of disjoint cores, and there are no isolated (\alpha,\beta)-communities scattered between these densely-clustered cores. The (\alpha,\beta)-communities from the same group have significant overlap among them, and those from distinct groups have extremely small pairwise resemblance. The number of cores decreases as k increases, and there are no bridges of intermediate (\alpha,\beta)-communities connecting one core to another. The cores obtained for a smaller k either disappear or merge into the cores obtained for a larger $k$. Further, similar experiments on random graph models demonstrate that the core structure displayed in various social graphs is due to the underlying social structure of these real-world networks, rather than due to high-degree vertices or a particular degree distribution.",,,Technical Report
oai:ecommons.cornell.edu:1813/22478,"Cayuga LakeWater Quality Monitoring, Related to the LSC Facility: 2010","This report summarizes the results of water quality monitoring efforts related to Cornell University’s
Lake Source Cooling (LSC) facility in 2010. This monitoring program began in 1998 and was
performed annually by the Upstate Freshwater Institute (UFI) until 2006. In 2007 water sample collection
and generation of the annual report was taken over by the DeFrees Hydraulics Laboratory of
the School of Civil and Environmental Engineering at Cornell University. UFI continues to carry out
all laboratory analysis. The format of this report is largely based on previous annual reports written
by UFI.",,,Technical Report
oai:ecommons.cornell.edu:1813/22505,Tail Inference: where does the tail begin?,"The quality of estimation of tail parameters, such as tail index in
the univariate case, or the spectral measure in the multivariate case,  
depends crucially on the part of the sample  included in the estimation. 
A simple approach involving sequential statistical testing is proposed
in order to choose this part of the sample. This method can be used
both in the univariate and multivariate cases. It is computationally
efficient, and can be easily automated. No visual inspection of the
data is required. We establish consistency of the Hill estimator when
used in conjunction with the proposed method, as well describe its
asymptotic fluctuations. We compare our method to existing methods in
univariate and multivariate tail estimation, and use it to analyze
Danish fire insurance data.",,,Technical Report
oai:ecommons.cornell.edu:1813/22809,A Robust Robust Optimization Result,,,,Technical Report
oai:ecommons.cornell.edu:1813/22846,On the Feasibility of Completely WIreless Data Centers,"We introduce a novel data center design based on emerging 60 GHz RF technology that uses wires only to deliver power to its server nodes. Fundamental limitation of wireless data centers is that the maximum number of live connections in the network is directly proportional to the full volume occupied by the data center divided by the radiating volume of a single antenna beam. Consequently, we integrate wireless transceivers and switching logic within each server node and collocate them in cylindric racks to establish a semi-regular mesh topology. Our exploration of the resulting design space shows that while attaining comparable bandwidth, our wireless data center exhibits substantially higher fault tolerance, improved latency, lower power consumption, and easier maintenance than a conventional wired data center.",,,Technical Report
oai:ecommons.cornell.edu:1813/22853,Assessment of Risk to Drinking Water from Turf Pesticide Runoff,"A human health risk assessment was performed on pesticide runoff from lawns and golf courses for 9 U.S. locations using a fate and transport modeling program. Pesticide concentrations for 37 turf pesticides registered for application on golf courses were compared to drinking water standards. A maximum 24 hour lake pesticide concentration was used for an acute risk assessment and a mean daily lake concentration was used for a chronic risk assessment. Our results show that a number of the pesticides posed a potential risk as evidenced by a risk quotient (RQ; concentration divided by standard) over 0.01. For fairways, both iprodione and 24-D produced acute and chronic risk at more than 3 locations. Potential risk was only found for myclobutanil applications to greens and tees. MCPA, oxadiazon and 24-D applied to lawns posed both acute and chronic risks. The highest concentrations were seen with acephate applied to fairways with acute RQ≥0.01 in 4 locations and in oxadiazon applied to lawns in Houston with chronic RQ≥0.01. The assessment was based on simulations using TPQPond, a model developed for predicting pesticide runoff and resulting concentrations in a receiving pond, lake, or reservoir. The risk assessment followed general protocols used by USEPA in their pesticide concentration model, FIRST, but with more realistic methods of determining reservoir flow characteristics, pesticide mass balances and region specific weather data. Risk levels were found to vary with location and turf type. Pesticide concentrations were highest for fairways and lowest for greens. Greatest impacts were observed in areas of high annual precipitation rates and long growing seasons whereas lowest impacts were observed in areas of low precipitation rates. These results suggest that persons living in heavy rainfall areas may have higher exposures of turf pesticide in their drinking water than would be predicted by EPA risk assessments.",,,Technical Report
oai:ecommons.cornell.edu:1813/22943,Blueprint for a Science of Cybersecurity,"A secure system must defend against all possible attacks--including those
unknown to the defender. But defenders, having limited resources, typically
develop defenses only for attacks they know about. New kinds of attacks are
then likely to succeed. So our growing dependence on networked computing
systems puts at risk individuals, commercial enterprises, the public sector,
and our military.",,,Technical Report
oai:ecommons.cornell.edu:1813/22959,On Moessner's Theorem,"Moessner's theorem describes a procedure for generating a sequence of n integer sequences that lead unexpectedly to the sequence of nth powers 1^n, 2^n, 3^n, ...  Paasche's theorem is a generalization of Moessner's; by varying the parameters of the procedure, one can obtain the sequence of factorials 1!, 2!, 3!, ... or the sequence of superfactorials 1!!, 2!!, 3!!, ...  Long's theorem generalizes Moessner's in another direction, providing a procedure to generate the sequence  a, (a+d)2^{n-1}, (a+2d)3^{n-1}, ...  Proofs of these results in the literature are typically based on combinatorics of binomial coefficients or calculational scans.  In this note we give a short and revealing algebraic proof of a general theorem that contains Moessner's, Paasche's, and Long's as special cases.  We also prove a generalization that gives new Moessner-type theorems.",,,Technical Report
oai:ecommons.cornell.edu:1813/23171,Results of L’Année philologique online OpenURL Quality Investigation,"1. Restatement of original problem statement
2. Findings
a. Genre Element Frequency Report
b. Element Patterns Report
3. Implications
4. Deliverables
a. Prototype User Interface
b. OpenURL Quality Relational Data Model",,,Technical Report
oai:ecommons.cornell.edu:1813/23555,Water Level Fluctuations of Lake Enriquillo and Lake Saumatre in Response to Environmental Changes,"The water level of Lake Saumatre in Haiti and Lake Enriquillo in the Dominican Republic has been increasing in a continuous manner for the past 10 years. This increase in volume has caused flooding of roads, cities and agricultural land causing the inhabitants of the area to complain about the current situation and seek help from their respective governments. Both national and international organizations have expressed interest in determining the causes of the continuous growth and from there, coming up with aid plans for the cities and inhabitants of the area. 

Various theories haven proposed by national and international organizations, and other technical groups, to explain the growth of the lakes. Among the hypotheses to explain the growth there is 1) Deforestation of the watershed, which would affect the hydrological balance by means of a change in infiltration rates and 2) Regional climate change which would also affected the hydrological balance of the area by either an increase in precipitation or decrease in evaporation rates.

This study analyzed those two main theories to determine whether they are the cause of the growth. First, deforestation was studied by means of remote sensing of the land cover on the years of 1986 and 2010 and analyzing vegetation changes. A Normalized Differential Vegetation Index (NDVI) was also analyzed to validate the land cover change method. It was found that, although there has been some land cover change, the change has not been significant enough to influence major changes in the hydrological balance.  A water balance was also done which resulted in a correlated lakes’ level increase with precipitation patterns, indicating that the watersheds are highly responsive to precipitation trends.

These are only preliminary results since there are many unknowns in the dynamics of the lakes’ systems. The objective of this study was to do a basic analysis of the dynamics of the two watersheds and provide a starting point for a more in depth research.",,,Technical Report
oai:ecommons.cornell.edu:1813/23556,Left-Handed Completeness,"We give a new, significantly shorter proof of the completeness of the left-handed star rule of Kleene algebra.  The proof reveals the rich interaction of algebra and coalgebra in the theory.",,,Technical Report
oai:ecommons.cornell.edu:1813/23562,Generating event logics with higher-order processes as realizers,"Our topic is broadening a practical ”proofs-as-programs” method of program development to “proofs-as-processes”. We extend our previous results that implement proofs-as-processes for the standard model of asynchronous message passing computation to a much wider class of process models including the ¼-calculus and other process algebras. Our first result is a general process model whose definition in type theory is interesting in itself both technically and foundationally. Process terms are type free lambda-terms. Typed processes are elements of a co-inductive type. They are higher-order in that they can
take processes as inputs and produce them as outputs.
A second new result is a procedure to generate event structures over the general process model and then define event logics and event classes over these structures. Processes are abstract realizers for assertions in the event logics over them, and they extend the class of primitively realizable propositions built on the propositions-as-types principle. They also provide a basis for the third new result, showing when programmable event classes generate strong realizers that prevent logical interference as processes are synthesized.",,,Technical Report
oai:ecommons.cornell.edu:1813/23568,Fmeter: Extracting Indexable Low-level System Signatures by Counting Kernel Function Calls,"System monitoring tools have served to provide operators and developers with an insight into system execution and an understanding of how the system behaves under previously untested scenarios. Many system abnormalities leave a signature impact on the system execution which may arise out of performance issues, bugs or errors. Having the ability to quantify and search such behavior in the system execution history can facilitate new ways of looking at problems. For example, operators may use clustering to group and visualize similar system behaviors together. In this work we propose a monitoring infrastructure that extracts a new breed of formal, indexable, low-level system signatures using the classical vector space model from the field of information retrieval and text mining. We drive an analogy between the representation of kernel function invocations with terms within text documents. This parallel allows us to automatically index, store, and later retrieve and compare the system signatures. As with information retrieval, the key insight is that we need not rely on the semantic information in a document. Instead, we consider only the statistical properties of the terms belonging to the document (and to the corpus), which enables us to provide an efficient way to extract signatures at runtime and analyze the signatures using statistical formal methods. We have built a prototype in Linux, Fmeter, which extracts low-level system signatures by recording all kernel function invocations. We show that the signatures are naturally amenable to formal processing with statistical methods like clustering and supervised machine learning.",,,Technical Report
oai:ecommons.cornell.edu:1813/23575,Investigating correct-by-construction attack-tolerant systems,"Attack-tolerant distributed systems change their protocols on-the-fly in response to apparent attacks from the environment;
they substitute functionally equivalent versions possibly more resistant to detected threats. Alternative protocols can be packaged together as a single adaptive protocol or variants from a formal protocol library can be sent to threatened groups
of processes. We are experimenting with libraries of attack-tolerant protocols that are correct-by-construction and testing
them in environments that simulate specified threats, including constructive versions of the famous FLP imaginary adversary against fault-tolerant consensus. We expect that all variants of tolerant protocols are automatically generated and accompanied
by machine checked proofs that the generated code satisfies formal properties.",,,Technical Report
oai:ecommons.cornell.edu:1813/23611,Logical Attestation: An Authorization Architecture for Trustworthy Computing,"ABSTRACT
This paper describes the design and implementation of a new operating
system authorization architecture to support trustworthy computing.
Called logical attestation, this architecture provides a sound
framework for reasoning about run time behavior of applications.
Logical attestation is based on attributable, unforgeable statements
about program properties, expressed in a logic. These statements
are suitable for mechanical processing, proof construction, and verification;
they can serve as credentials, support authorization based
on expressive authorization policies, and enable remote principals
to trust software components without restricting the local user’s
choice of binary implementations.
We have implemented logical attestation in a new operating system
called the Nexus. The Nexus executes natively on x86 platforms
equipped with secure coprocessors. It supports both native
Linux applications and uses logical attestation to support new
trustworthy-computing applications. When deployed on a trustworthy
cloud-computing stack, logical attestation is efficient, achieves
high-performance, and can run applications that provide qualitative
guarantees not possible with existing modes of attestation.",,,Technical Report
oai:ecommons.cornell.edu:1813/23631,Nerio: Leader Election and Edict Ordering,"Coordination in a distributed system is facilitated if there is a unique process, the leader, to manage the other processes. The leader creates edicts and sends them to other processes for execution or forwarding to other processes. The leader may fail, and when this occurs a leader election protocol selects a replacement. This paper describes Nerio, a class of such leader election protocols.",,,Technical Report
oai:ecommons.cornell.edu:1813/24398,Intuitionistic Completeness of First-Order Logic,"We establish completeness for intuitionistic first-order logic, iFOL,  showing that is a formula is provable if and only if it is uniformly valid under the Brouwer Heyting Kolmogorov (BHK) semantics, the intended semantics of iFOL. Our proof is intuitionistic and provides an effective procedure Prf  that converts uniform evidence into a formal first-order proof. We have implemented Prf . Uniform validity is defined using the intersection operator as a universal quantifier over the domain of discourse and atomic predicates. Formulas of iFOL that are uniformly valid are also intuitionistically valid, but not conversely. Our strongest result requires the Fan Theorem; it can also be proved classically by showing that Prf  terminates using K¨onig’s Theorem.

The fundamental idea behind our completeness theorem is that a single evidence term evd witnesses the uniform validity of a minimal logic formula F. Finding even one uniform realizer guarantees validity  because Prf (F, evd) builds a first-order proof of F, establishing its uniform validity  and providing a purely logical normalized realizer.

We establish completeness for iFOL as follows. Friedman showed that iFOL can be embedded in minimal logic (mFOL). By his transformation, mapping formula A to F r(A). If A is uniformly valid, then so is F r(A), and by our Basic Completeness result, we can find a proof of F r(A) in minimal logic. Then we prove A from F r(A) in intuitionistic logic by a proof procedure fixed in advance. Our result resolves an open question posed by Beth in 1947.",,,Technical Report
oai:ecommons.cornell.edu:1813/24566,Length-weight regressions for zooplankton biomass calculations – A review and a suggestion for standard equations,"Zooplankton biomass can be estimated through the use of equations that convert length of individuals to dry weight.  The logarithmic transformation of these power equations follow the form Ln(W) =Ln(α) + β Ln(L) where L is length in mm, W is dry weight in ug, and α and β are species-specific values.  Several sets of L-W equations have been developed for use in the Great Lakes region by agencies such as the Environmental Protection Agency (EPA) and Canada’s Department of Fisheries and Oceans (DFO).  Since we collaborate with both agencies and require comparability with previously collected data, we reviewed these two sets of equations and the publications that were used to develop them.  We offer a third Cornell Standard (CBFS STD) set that resolves many of the discrepancies seen in the other sets.",,,Technical Report
oai:ecommons.cornell.edu:1813/28284,Capsules and Separation,"We study a formulation of separation logic using capsules, a representation of the state of a computation in higher-order programming languages with mutable variables.  We prove soundness of the frame rule in this context and investigate alternative formulations with weaker side conditions.",,,Technical Report
oai:ecommons.cornell.edu:1813/28598,Fractional   moments of  solutions to stochastic recurrence equations,"In this paper we study the fractional moments of the stationary
solution to  a stochastic recursion. 
We derive recursive formulas for the fractional moments of the solution. Special attention is given to the case when
the additive term  has an Erlang distribution. We provide various approximations to the 
moments and show their performance in a small numerical study",,,Technical Report
oai:ecommons.cornell.edu:1813/28632,New,"We propose a theoretical device for modeling the creation of new indiscernible semantic objects during program execution.  The method fits well with the semantics of imperative, functional, and object-oriented languages and promotes equational reasoning about higher-order state.",,,Technical Report
oai:ecommons.cornell.edu:1813/28635,Language Mechanisms for Controlling and Mitigating Timing Channels,"We propose a new language-based approach to mitigating timing channels. In this language, well-typed programs provably leak only a bounded amount of information over time through external timing channels. By incorporating mechanisms for predictive mitigation of timing channels, this approach also permits a more expressive programming model. Timing channels arising from interaction with underlying hardware features such as instruction caches are
controlled. Assumptions about the underlying hardware are explicitly formalized, supporting the design of hardware that efficiently controls timing channels. One such hardware design is modeled
and used to show that timing channels can be controlled in some simple programs of real-world significance.",,,Technical Report
oai:ecommons.cornell.edu:1813/28637,On the   existence of  paths between points in high level excursion sets of   Gaussian random fields,"The structure of Gaussian random fields over high levels is a well researched and 
well understood area, particularly if the field is smooth. However, the question as to whether or not two or more points 
 which lie in an
excursion set belong to the same connected component has constantly eluded analysis. We study this problem from the point of view of large deviations, finding the asymptotic
probabilities that two such points are connected by a path laying within the excursion set, 
and so belong to the same component. In addition, we obtain a characterization and descriptions of the 
most likely paths, given that one exists.",,,Technical Report
oai:ecommons.cornell.edu:1813/28639,"Cayuga LakeWater Quality Monitoring, Related to the LSC Facility: 2011",This report summarizes the results of water quality monitoring efforts related to Cornell University’s Lake Source Cooling (LSC) facility in 2011. This monitoring program began in 1998 and was performed annually by the Upstate Freshwater Institute (UFI) until 2006. In 2007 water sample collection and generation of the annual report was taken over by the De Frees Hydraulics Laboratory of the School of Civil and Environmental Engineering at Cornell University. UFI continues to carry out all laboratory analysis. The format of this report is largely based on previous annual reports written by UFI.,,,Technical Report
oai:ecommons.cornell.edu:1813/28695,"The Logic of Events, a framework to reason about distributed systems",,"We present a logical framework to reason
about distributed systems called the Logic of Events. This logic has been formalized in Nuprl. We developed a suite of tools and tactics in Nuprl to reason about event classes. We also developed a programming language called EventML which allows programmers to write specifications of distributed protocols.",,Technical Report
oai:ecommons.cornell.edu:1813/28696,The Triumph of Types: Principia Mathematica's Impact on Computer Science,"Types now play an essential role in computer science; their ascent originates from Principia Mathematica. Type checking and type inference algorithms are used to prevent semantic errors in programs, and type theories are the native language of several major interactive theorem provers. Some of these trace key features back to Principia.
This lecture examines the in°uence of Principia Mathematica on modern type theories implemented in software systems known as interactive proof assistants. These proof assistants advance daily the goal for which Principia was designed: to provide a comprehensive formalization of mathematics. For instance, the de¯nitive formal proof of the Four Color Theorem was done in type theory. Type theory is considered seriously now more than ever as an adequate foundation for both classical and constructive mathematics as well as for computer science. Moreover, the seminal work in the history of formalized mathematics is the Automath project of N.G. de Bruijn whose formalism is type theory. In addition we explain how type theories have enabled the use of formalized mathematics as a practical programming language, a connection entirely unanticipated at the time of Principia Mathematica's creation.",Video available as the last entry on the Oregon Programming Languages Summer School - curriculum page: http://www.cs.uoregon.edu/Research/summerschool/summer11/curriculum.html,,Technical Report
oai:ecommons.cornell.edu:1813/28697,Polynomial Time Construction for Spatially Balanced Latin Squares,"In this paper we propose a construction that generates spatially balanced
Latin squares (SBLSs) in polynomial time. These structures are central to
the design of agronomic experiments, as they avoid biases that are otherwise
unintentionally introduced due to spatial auto-correlation. Previous
approaches were able to generate SBLSs of order up to 35 and required
about two weeks of computation. Our algorithm runs in O(n2) and generates
SBLSs of arbitrary order n where 2n + 1 is prime. For example, this
algorithm generates a SBLS of order 999 in a fraction of a second.",,,Technical Report
oai:ecommons.cornell.edu:1813/29009,Commodifying Replicated State Machines with OpenReplica,"This paper describes OpenReplica, an open service that
provides replication and synchronization support for
large-scale distributed systems. OpenReplica is designed
to commodify Paxos replicated state machines by providing infrastructure for their construction, deployment and
maintenance. OpenReplica is based on a novel Paxos
replicated state machine implementation that employs an
object-oriented approach in which the system actively
creates and maintains live replicas for user-provided objects. Clients access these replicated objects transparently as if they are local objects. OpenReplica supports
complex distributed synchronization constructs through
a multi-return mechanism that enables the replicated objects to control the execution ﬂow of their clients, in
essence providing blocking and non-blocking method invocations that can be used to implement richer synchronization constructs. Further, it supports elasticity requirements of cloud deployments by enabling any number of servers to be replaced dynamically. A rack-aware
placement manager places replicas on nodes that are unlikely to fail together. Experiments with the system show
that the latencies associated with replication are comparable to ZooKeeper, and that the system scales well.",,,Technical Report
oai:ecommons.cornell.edu:1813/29064,Data Curation Profiles Completed for the DataStaR project,"This collection of profiles was created for the DataStaR project. Authors interviewed researchers at their respective institutions (Cornell University, Washington University in St. Louis) and compiled the information according to the procedure outlined in the Data Curation Profiles Toolkit (http://datacurationprofiles.org/) and using the modified interview worksheet included in this collection.",More information on the DataStaR project is available here: https://sites.google.com/site/datastarsite/.,,Technical Report
oai:ecommons.cornell.edu:1813/29543,NetSlices: Scalable Multi-Core Packet Processing in User-Space,"Modern commodity operating systems do not provide developers with user-space abstractions for building high-speed packet processing applications. The conventional raw socket is inefficient and unable to take advantage of the emerging hardware, like multi-core processors and multi-queue network adapters. In this paper we present the NetSlice operating system abstraction. Unlike the conventional raw socket, NetSlice tightly couples the hardware and software packet processing resources, and provides the application with control over these resources. To reduce shared resource contention, NetSlice performs domain specific, coarse-grained, spatial partitioning of CPU cores, memory, and NICs. Moreover, it provides a streamlined communication channel between NICs and user-space. Although backward compatible with the conventional socket API, the \netslice API also provides batched (multi-) send/receive operations to amortize the cost of protection domain crossings. We show that complex user-space packet processors---like a protocol accelerator and an IPsec gateway---built from commodity components can scale linearly with the number of cores and operate at 10Gbps network line speeds.",,,Technical Report
oai:ecommons.cornell.edu:1813/29612,Reflection in the Chomsky Hierarchy,"We investigate which classes of formal languages in the Chomsky hierarchy are reflexive, that is, contain a language of codes that is universal for the whole class.",,,Technical Report
oai:ecommons.cornell.edu:1813/29996,Functional Central Limit Theorem for Heavy Tailed   Stationary Infinitely Divisible Processes Generated by Conservative Flows,"We establish a new class of functional central limit theorems for
partial sum of certain symmetric stationary infinitely divisible processes with
regularly varying Levy measures. The limit process is a new class of
symmetric stable self-similar  processes with stationary increments,
that coincides on a part of its parameter space with a previously
described process. The normalizing sequence and the limiting process
are determined by the ergodic theoretical properties of the flow
underlying the integral representation of the process. These
properties can be interpreted as determining how long is the memory of
the stationary infinitely divisible process. We also
establish functional convergence, in a strong distributional sense,
for conservative pointwise dual ergodic maps preserving an infinite
measure.",,,Technical Report
oai:ecommons.cornell.edu:1813/30398,Constant-Round Concurrent Zero-Knowledge From Falsifiable Assumptions,"We present a constant-round concurrent zero-knowledge protocol for $\NP$. Our protocol is sound against uniform polynomial-time attackers, and relies on the existence of families of collision-resistant hash functions, and a new (but in our eyes, natural) falsifiable intractability assumption: Roughly speaking, that Micali's non-interactive CS-proofs are sound for languages in $\P$.",,,Technical Report
oai:ecommons.cornell.edu:1813/30404,Analysis of Lake Ontario Lower Aquatic food web Assessment (LOLA 2003 and 2008) within the context of long-term ecological change,"Lake Ontario is the 13th largest lake in the world with a surface area of 18,500 km² (Reynolds et al. 2000), has a population in the watershed of over 8 million, and provides a range of ecosystem services to the people in the watershed (freshwater for various uses, shipping, fisheries, and recreation). Currently, extensive surveys for each Great Lake occur on a rotating five-year schedule. This report presents the status of Lake Ontario’s lower trophic levels in 2008 and a detailed comparison with similarly collected in 2003 and with data collected by the collaborating agencies and Cornell University and discuss observed changes in relation to changes in nutrient concentration and food web configuration in Lake Ontario. There has been a spatial restructuring of the Lake Ontario offshore ecosystem through the increase in the deep chlorophyll layer and associated zooplankton. This has resulted in a Lake Ontario that in 2008 is more similar to Lakes Superior, Huron and Michigan than to the Lake Ontario of the 1990s. Major findings are 
Nutrients: Spring offshore total phosphorus and soluble reactive phosphorus increased from 2003 to 2008, but summer levels did not.  Lake-wide average total phosphorus levels remained at or below the target level of 10 µg/L in all three seasons of 2008.  Lake-wide nutrient concentrations have declined since the 1960s.  However, phosphorus concentrations have been stable (~7-10 µg/L) since the mid-1990s. Spring silica was similar in 2003 and 2008 and was depleted by the summer in both years.  This indicates continued spring diatom production in Lake Ontario.  
Phytoplankton: Summer epilimnetic chlorophyll-a increased by a factor of 2, the proportion of autotrophic algae increased, and summer water clarity declined from 2003 to 2008.  Summer chlorophyll-a levels in 2008 were similar to the concentrations in the 1981-1995 time period.    However, the trend towards mesotrophy in the summer of 2008 may be limited to that year as it was not followed by increased values in 2009 to 2011. Most of the chlorophyll in the water column was located in a deep chlorophyll layer in the thermocline.  
Zooplankton: Offshore epilimnetic zooplankton density and biomass declined from 2003 to 2008 by a factor of 5 to 12 in the summer and by a factor of 1.5 to 2.6 in the fall.  This is consistent with long-term trends of declining epilimnetic zooplankton abundance including a larger decline in 2004-2005 coincident with an increase in the predatory Bythotrephes. Whole water column zooplankton density also declined from 2003 to 2008 in the summer and fall, but zooplankton biomass only declined in the fall.  Large changes in whole water column zooplankton community composition occurred between 2003 and 2008 from a cyclopoid/bosminid dominated system in 2003 to a calanoid dominated system in 2008.  
Mysids, Diporeia and Mussels  Mysid densities were similar in 2003 and 2008 indicating continued high biomass of mysids in Lake Ontario.  In July of 2008, the biomass of Mysis diluviana was 17% of the crustacean zooplankton biomass in the offshore of Lake Ontario (depth >30m).  Mysid densities appear stable in Lake Ontario. The native benthic amphipod Diporeia declined further in 2008 and is almost extirpated from Lake Ontario.  Quagga mussels are very abundant as deep as 90 m, but populations in shallow water declined from 2003 to 2008.  Few zebra mussels were present in either 2003 or 2008.",,,Technical Report
oai:ecommons.cornell.edu:1813/30442,Multivariate tail measure and the estimation of CoVar,"The quality of estimation of multivariate tails depends significantly 
on the portion of the sample included in the estimation.  A simple
approach involving sequential statistical testing is proposed in order
to select which observations should be used for estimation of the tail
and spectral measures.   We prove that the estimator is consistent. We
test the proposed method on simulated data,  and subsequently apply it 
to analyze CoVar for stock and index returns.",,,Technical Report
oai:ecommons.cornell.edu:1813/30471,Federated Identity Management Systems: A Privacy-based Characterization,"Identity management systems store attributes associated with users and facilitate authorization on the basis of these attributes. A privacy-driven characterization of the principal design choices for identity management systems is given, and existing systems are fit into this framework. The taxonomy of design choices also can guide public policy relating to identity management, which is illustrated using the United States NSTIC initiative.",,,Technical Report
oai:ecommons.cornell.edu:1813/30510,Practical Coinduction,"Induction is a well-established proof principle that is taught in most undergraduate programs in mathematics and computer science.  In computer science, it is used primarily to reason about inductively-defined datatypes such as finite lists, finite trees, and the natural numbers.  Coinduction is the dual principle that can be used to reason about coinductive datatypes such as infinite streams or trees, but it is not as widespread or as well understood.  In this paper, we illustrate through several examples the use of coinduction in informal mathematical arguments.  Our aim is to promote the principle as a useful tool for the working mathematician and to bring it to a level of familiarity on par with induction.  We show that coinduction is not only about bisimilarity and equality of behaviors, but also applicable to a variety of functions and relations defined on coinductive datatypes.",,,Technical Report
oai:ecommons.cornell.edu:1813/30798,CoCaml: Programming with Coinductive Types,"We present CoCaml, a functional programming language extending OCaml, which allows us to define 
functions on coinductive datatypes parameterized by an equation solver. We provide numerous examples that attest to the usefulness of the new programming constructs, including operations on infinite lists, infinitary lambda-terms and p-adic numbers.",,,Technical Report
oai:ecommons.cornell.edu:1813/30863,Forecasting adoption of ultra-low-emission vehicles using Bayes estimates of a multinomial probit model and the GHK simulator,"In this paper we use Bayes estimates of a multinomial probit model with fully flexible substitution patterns to forecast consumer response to ultra-low-emission vehicles.  In this empirical application of the probit Gibbs sampler, we use stated-preference data on vehicle choice from a Germany-wide survey of potential light-duty-vehicle buyers using computer-assisted personal interviewing. We show that Bayesian estimation of a multinomial probit model with a full covariance matrix is feasible for this medium-scale problem and provides results that are very similar to maximum simulated likelihood estimates. Using the posterior distribution of the parameters of the vehicle choice model as well as the GHK simulator we derive the choice probabilities of the different alternatives. We first show that the Bayes point estimates of the market shares reproduce the observed values. Then, we define a base scenario of vehicle attributes that aims at representing an average of the current vehicle choice situation in Germany. Consumer response to qualitative changes in the base scenario is subsequently studied. In particular, we analyze the effect of increasing the network of service stations for charging electric vehicles as well as for refueling hydrogen. The result is the posterior distribution of the choice probabilities that represent adoption of the energy-efficient technologies.",,,Technical Report
oai:ecommons.cornell.edu:1813/31293,Student Handbook 1996,"Topics covered in this Handbook include: Table of Contents; Student Services; Academic Policies [specific to the Classes of 1998, 1999 and 2000]; Academic Standards; Honor Code; College and University Policies; Work Opportunities/Placement Service; Student Activities and Special Opportunities; University and Community Support.",Student Handbook 1996,,Technical Report
oai:ecommons.cornell.edu:1813/31294,Student Handbook 1999-2000,Topics covered in this Handbook include: Table of Contents; Student Services; Academic Policies; College and University Policies; The Honor Code; Academic and Personal Support Services; Veterinary Career Development; Student Activities & Special Opportunities; University and Community Support; Publications.,Student Handbook 1999-2000,,Technical Report
oai:ecommons.cornell.edu:1813/31295,Student Handbook 2000-2001,Topics covered in this Handbook include: Table of Contents; Student Services; Academic Policies; College and University Policies; The Honor Code; Academic and Personal Support Services; Veterinary Career Development; Student Activities & Special Opportunities; University and Community Support; Publications.,Student Handbook 2000-2001,,Technical Report
oai:ecommons.cornell.edu:1813/31296,Student Handbook Class of 2011,"Topics covered in this Handbook include: Welcome (Katherine M. Edmondson); Important Dates for Academic Years 2007/08-2010/11; Orientation: Preparing for the DVM Program, Orientation Activities, Important Deadlines to Meet, Shopping [for] Things You Will Need; Financial Planning; The Curriculum: Foundation Courses, Sets of Distribution Courses, An Overview of the DVM Curriculum (Four Year Schematic, Year-by-Year Summary), Tutorial Groups, Learning Resources, Making Use of the CUHA; University and College Policies: Academic Policies, Honor Code; Student Life: Important and Helpful People, University Services and Resources, Veterinary Career Services, Career Planning Map, Student Organizations, Special Opportunities, Honors and Awards, Living in Ithaca; College maps.",Student Handbook Class of 2011,,Technical Report
oai:ecommons.cornell.edu:1813/31297,Student Handbook Class of 2012,"Topics covered in this Handbook include: Welcome (Katherine M. Edmondson); Important Dates for Academic Years 2008/09-2010/11; Orientation: Preparing for the DVM Program, Orientation Activities, Important Deadlines to Meet, Shopping [for] Things You Will Need; Financial Planning; The Curriculum: Foundation Courses, Sets of Distribution Courses, An Overview of the DVM Curriculum (Four Year Schematic, Year-by-Year Summary), Tutorial Groups, Learning Resources, Making Use of the CUHA; University and College Policies: Academic Policies, Honor Code; Student Life: Important and Helpful People, University Services and Resources, Veterinary Career Services, Career Planning Map, Student Organizations, Special Opportunities, Honors and Awards, Living in Ithaca; College maps.",Student Handbook Class of 2012,,Technical Report
oai:ecommons.cornell.edu:1813/31298,Student Handbook Class of 2013,"Topics covered in this Handbook include: Welcome (Katherine M. Edmondson); Important Dates for Academic Years 2009/10-2012/13; Orientation: Preparing for the DVM Program, Orientation Activities, Important Deadlines to Meet, Shopping [for] Things You Will Need; Financial Planning; The Curriculum: Foundation Courses, Sets of Distribution Courses, An Overview of the DVM Curriculum (Four Year Schematic, Year-by-Year Summary), Tutorial Groups, Learning Resources, Making Use of the CUHA; University and College Policies: Academic Policies, Honor Code; Student Life: Important and Helpful People, University Services and Resources, Veterinary Career Services, Career Planning Map, Student Organizations, Special Opportunities, Honors and Awards, Living in Ithaca; College maps.",Student Handbook Class of 2013,,Technical Report
oai:ecommons.cornell.edu:1813/31299,Student Handbook Class of 2014,"Topics covered in this Handbook include: Welcome (Katherine M. Edmondson); Important Dates for Academic Years 2010/11-2013/14; Orientation: Preparing for the DVM Program, Orientation Activities, Important Deadlines to Meet, Shopping [for] Things You Will Need; Financial Planning; The Curriculum: Foundation Courses, Sets of Distribution Courses, An Overview of the DVM Curriculum (Four Year Schematic, Year-by-Year Summary), Tutorial Groups, Learning Resources, Making Use of the CUHA; University and College Policies: Academic Policies, Honor Code; Student Life: Important and Helpful People, University Services and Resources, Veterinary Career Services, Career Planning Map, Student Organizations, Special Opportunities, Honors and Awards, Living in Ithaca; College maps.",Student Handbook Class of 2014,,Technical Report
oai:ecommons.cornell.edu:1813/31300,Student Handbook Class of 2015,"Topics covered in this Handbook include: Welcome (Katherine M. Edmondson); Important Dates for Academic Years 2011/12-2014/15; Orientation: Preparing for the DVM Program, Orientation Activities, Important Deadlines to Meet, Shopping [for] Things You Will Need; Financial Planning; The Curriculum: Foundation Courses, Clinical Pathways, Sets of Distribution Courses, Distribution Clinical Rotations, DVM Curriculum Overview, An Overview of the DVM Curriculum  (Year-by-Year Summary), Graduation Requirements, Tutorial Groups, Learning Resources, Making Use of the CUHA; University and College Policies: Academic Policies, Honor Code; Student Life: College Resources and Services, Important and Helpful People, University Services and Resources, Veterinary Career Services, Career Planning Map, Student Organizations, Special Opportunities, Honors and Awards, Living in Ithaca; Room Index; College maps.",Student Handbook Class of 2015,,Technical Report
oai:ecommons.cornell.edu:1813/31372,Typed Kleene Algebra with Products and Iteration Theories,We develop a typed equational system that subsumes both iteration theories and typed Kleene algebra in a common framework. Our approach is based on cartesian categories endowed with commutative strong monads to handle nondeterminism.,,,Technical Report
oai:ecommons.cornell.edu:1813/31514,Student Handbook Class of 2016,"Topics covered in this Handbook include: Welcome (Katherine M. Edmondson); Important Dates for Academic Years 2012/13-2015/16; Orientation: Preparing for the DVM Program, Orientation Activities, Important Deadlines to Meet, Shopping [for] Things You Will Need; Financial Planning; The Curriculum: Foundation Courses, Clinical Pathways, Distrubution Courses, Sets of Distribution Courses, Distribution Clinical Rotations, DVM Curriculum Overview, An Overview of the DVM Curriculum  (Year-by-Year Summary), Graduation Requirements, Tutorial Groups, Learning Resources: Library, Modular Resource Center, Wiswall Learning Laboratory, Faculty, Animal Health Diagnostic Center; Making Use of the CUHA; University and College Policies: Academic Policies, Honor Code; Student Life: College Services and Resources, Important and Helpful People, University Services and Resources, Veterinary Career Services, Career Planning Map, Student Organizations, Special Opportunities, Honors and Awards, Living in Ithaca; Room Index; College maps.",,,Technical Report
oai:ecommons.cornell.edu:1813/31565,Stone Duality for Markov Processes,"We define Aumann algebras, an algebraic analog of probabilistic modal logic.  An Aumann algebra consists of a Boolean algebra with operators modeling probabilistic transitions. We prove that countable Aumann algebras and countably-generated continuous-space Markov processes are dual in the sense of Stone.  Our results subsume existing results on completeness of probabilistic modal logics for Markov processes.",,,Technical Report
oai:ecommons.cornell.edu:1813/33123,Reconciling Exhaustive Pattern Matching with Objects,"Pattern matching, an important feature of functional languages, is in
conflict with data abstraction and extensibility, which are central to
object-oriented languages.  Modal abstraction offers an integration of
deep pattern matching and convenient iteration abstractions into an
object-oriented setting; however, because of data abstraction, it is
challenging for a compiler to statically verify properties such as
exhaustiveness.  In this work, we extend modal abstraction in the
JMatch language to support static, modular reasoning about
exhaustiveness and redundancy.  New matching specifications allow
these properties to be checked using an SMT solver.  We also introduce
expressive pattern-matching constructs.  Our evaluation shows
that these new features enable more
concise code and that the performance of checking exhaustiveness
and redundancy is acceptable.",,,Technical Report
oai:ecommons.cornell.edu:1813/33124,When not all bits are equal: Worth-based information flow,"Only recently have approaches to quantitative information flow started to challenge the presumption that all leaks involving a given number of bits are equally harmful. This paper proposes a framework to capture the semantics of information, making quantification of leakage independent of the syntactic representation of secrets. Secrets are defined in terms of fields, which are combined to form structures; and a worth assignment is introduced to associate each structure with a worth (perhaps in proportion to the harm that would result from disclosure). We show how worth assignments can capture inter dependence among structures within a secret, modeling: (i) secret sharing, (ii) information-theoretic  predictors, and (iii) computational (as opposed to information-theoretic) guarantees for security. Using non-trivial worth assignments, we generalize Shannon entropy, guessing entropy, and probability of guessing. For deterministic systems, we give a lattice of information to provide an underlying algebraic structure for the composition of attacks. Finally, we outline a design technique to capture into worth assignments relevant aspects of a scenario of interest.",Content replaced at author's request on 2014-02-12.,,Technical Report
oai:ecommons.cornell.edu:1813/33176,Agricultural Plastic Film Recycling: Feasibility and Options in the Central Leatherstocking-Upper Catskill Region of New York State,"This report focuses on the plastic films used in dairy agriculture (#4 LDPE and LLDPE, low density polyethylene resins) with some attention to polypropylene baling twine; nursery/greenhouse films; and non-agricultural plastic films used in the study area. The geographical focus is the Central Leatherstocking-Upper Catskill region of New York State, particularly the southern portion within a 30-mile radius of Oneonta, NY (Otsego County). The rationale for these product-type and geographic foci is that the Central Leatherstocking-Upper Catskill region is a dairying area where agricultural plastics recycling has sparked the interest of local citizenry, the farm and recycling communities, government agency personnel, and policy-makers as a means to reduce environmental and health risks of open burning and possibly as a means for generating value-added economic activity. This report builds on prior research reported in Recycling Agricultural Plastics in New York State (Levitan and Barros 2003).",,,Technical Report
oai:ecommons.cornell.edu:1813/33177,Recycling Agricultural Plastics in New York State,"This report is a product of the Cornell “open burning group,” which formed in Winter 2002 to assess the extent and environmental health significance of open burning of household wastes and agricultural plastics in New York State, and to begin work towards reducing these practices in order to protect public health and the environment. The report focuses on agricultural plastics rather than the household waste stream for reasons that include the importance of agriculture in NYS and the role of Cornell’s College of Agriculture and Life Sciences (CALS) in working with NYS agriculture and the environment.",,,Technical Report
oai:ecommons.cornell.edu:1813/33330,"Well-Founded Coalgebras, Revisited","Theoretical models of recursion schemes have been well studied under the names well-founded coalgebras, recursive coalgebras, corecursive algebras, and Elgot algebras. Much of this work focuses on conditions ensuring unique or canonical solutions, e.g. when the coalgebra is well-founded. If the coalgebra is not well-founded, then there can be multiple solutions. The standard semantics of recursive programs gives a particular solution, namely the least solution in a flat Scott domain, which may not be the desired one. We have recently proposed programming language constructs to allow the specification of alternative solutions and methods to compute them. We have implemented these new constructs as an extension of OCaml. In this paper, we prove some theoretical results characterizing well-founded coalgebras that slightly extend results of Adamek, Luecke, and Milius (2007), along with several examples for which this extension is useful. We also give several examples that are not well-founded but still have a desired solution. In each case, the function would diverge under the standard semantics of recursion, but can be specified and computed with the programming language constructs we have proposed.",,,Technical Report
oai:ecommons.cornell.edu:1813/33380,Strong Completeness for Markovian Logics,"In this paper we present Hilbert-style axiomatizations for three logics for reasoning about continuous-space Markov processes (MPs): (i) a logic for MPs defined for probability distributions on measurable state spaces, (ii) a logic for MPs defined for sub-probability distributions and (iii) a logic defined for arbitrary distributions.These logics are not compact so one needs infinitary rules in order to obtain strong completeness results.

We propose a new infinitary rule that replaces the so-called Countable Additivity Rule (CAR) currently used in the literature to address the problem of proving strong completeness for these and similar logics. Unlike the CAR, our rule has a countable set of instances; consequently it allows us to apply the Rasiowa-Sikorski lemma for establishing strong completeness. Our proof method is novel and it can be used for other logics as well.",,,Technical Report
oai:ecommons.cornell.edu:1813/33417,Infinitary Axiomatization of the Equational Theory of Context-Free Languages,"We give a natural complete infinitary axiomatization of the equational theory of the context-free languages, answering a question of Leiss (1992).",,,Technical Report
oai:ecommons.cornell.edu:1813/34411,General inverse problems for regular variation,"Regular variation of distributional tails is known to be preserved by  
various linear transformations of some random structures.   
An inverse problem for regular  
variation aims at understanding whether the regular variation of a  
transformed random object is caused by regular variation of components  
of the original random structure. In this paper we build up on previous  
work and derive results in the multivariate case and in   
situations where regular variation is  
not restricted to one particular direction or quadrant.",,,Technical Report
oai:ecommons.cornell.edu:1813/34434,Leadership Program for Veterinary Students 2013 Annual Report,"Topics in this Annual Report include: Contents; A Commitment to Excellence (John Parker, David H. Fraser); Acknowledgements; Publications; Agenda; Participants; Activities 2013: Research, Leadership, Leadership in Action, Infectious Diseases, Drug Design, Careers in Industry, Hypothesis Development, Career Explorations; Cornell's Partnership with the National Institutes of Health; Walter Reed Army Institute of Research & Navy Medical Research Center; Presentations and Prizes; Program Scholars and their Research; Facilitators and Counselors; Housing; Time Out; Program Dinner; Program Alumni; Where Are They Now?; What Did They Say?; In the Limelight (Robin Yates).",Cornell Leadership Program for Veterinary Students 2013 Annual Report,,Technical Report
oai:ecommons.cornell.edu:1813/34898,KAT + B!,"It is known that certain program transformations require a small amount of mutable state, a feature not explicitly provided by Kleene algebra with tests (KAT). In this paper we show how to axiomatically extend KAT with this extra feature in the form of mutable tests. The extension is conservative and is formulated as a general commutative coproduct construction. We give several results on deductive completeness and complexity of the system, as well as some examples of its use.",,,Technical Report
oai:ecommons.cornell.edu:1813/35150,A Language for Securely Referencing Persistent Information in a Federated System,"Referential integrity, which guarantees that named resources can be accessed when referenced, is an important property for reliability and security. In distributed systems, however, the attempt to provide referential integrity can itself lead to security vulnerabilities that are not currently well understood. This paper identifies three kinds of _referential security_ vulnerabilities related to the referential integrity of distributed, persistent information. Security conditions corresponding to the absence of these vulnerabilities are formalized. A language model is used to capture the key aspects of programming distributed systems with named, persistent resources in the presence of an adversary. The referential security of distributed systems is proved to be enforced by a new type system.",,,Technical Report
oai:ecommons.cornell.edu:1813/36202,Kleene Algebra with Equations,We identify sufficient conditions for the construction of free language models for systems of Kleene algebra with additional equations. The construction applies to a broad class of extensions of KA and provides a uniform approach to deductive completeness and coalgebraic decision procedures.,,,Technical Report
oai:ecommons.cornell.edu:1813/36235,Guide to Using the BigFootBF300 Baler for Agricultural Plastics: Maintenance & Troubleshooting,"The maintenance chapter of the ""Guide to Using the BigFoot BF300 Baler"" includes full descriptions and a maintenance schedule for the baler compaction chamber, Honda engine, baler and trailer hydraulic systems, paint, trailer, tires and towing. Material in this Guide expands upon the BigFoot BF300 manufacturer’s manual, the Honda Owner's Manual, and manufacturers’ manuals for other parts, with significant additions, revisions and explanations based upon the extensive experience of RAPP staff, expert opinion of engineers and other consultants, and alterations that RAPP made to the BigFoot BF300 to improve safety and performance. RAPP alterations to the BF300s operating under its auspices include installing:
(1) safety chain as backup to the hydraulic door latch;
(2) metal hood over the control box; (3) metal shield at the front of the trailer to protect the engine and exhaust from the elements and from road grit and moisture;
(4) an elbow to the exhaust pipe to deflect emissions away from the operator and prevent road grit and moisture from being driven into the exhaust pipe during travel;
(5) 1” horizontal extenders on front and back of the ram platen to prevent billowing plastic from blocking wire channels; (6) protective jackets around the two hydraulic hoses above the hydraulic control box to reduce operator risk; (7) trailer jack with 5000-lb lift and 8000-lb static load capacity to replace an inadequate trailer jack.",,,Technical Report
oai:ecommons.cornell.edu:1813/36255,A Coalgebraic Decision Procedure for NetKAT,"Program equivalence is a fundamental problem that has practical applications across a variety of areas of computing including compilation, optimization, software synthesis, formal verification, and many others. Equivalence is undecidable in general, but in certain settings it is possible to develop domain-specific languages that are expressive enough to be practical and yet sufficiently restricted so that equivalence remains decidable.

In previous work we introduced NetKAT, a domain-specific language for specifying and verifying network packet-processing functions. NetKAT provides familiar constructs such as tests, assignments, union, sequential composition, and iteration as well as custom primitives for modifying packet headers and encoding network topologies. Semantically, NetKAT is based on Kleene algebra with tests (KAT) and comes equipped with a sound and complete equational theory. Although NetKAT equivalence is decidable, the best known algorithm is hardly practical-it uses Savitch's theorem to determinize a PSPACE algorithm and requires quadratic space.

This paper presents a new algorithm for deciding NetKAT equivalence. This algorithm is based on finding bisimulations between finite automata constructed from NetKAT programs. We investigate the coalgebraic theory of NetKAT, generalize the notion of Brzozowski derivatives to NetKAT, develop efficient representations of NetKAT automata in terms of spines and sparse matrices, and discuss the highlights of our prototype implementation.",,,Technical Report
oai:ecommons.cornell.edu:1813/36263,Access 4-H Membership Trend Interface,"This is a tool for Association 4-H Educators, Executive Directors and Stakeholders to study county enrollment trends",Excel Database,,Technical Report
oai:ecommons.cornell.edu:1813/36286,The Dust Belts of Mars,"From the unrelated facts that Mars is subjected to a flux of asteroidal projectiles and that it has two very small satellites, an elementary analysis leads to the proposition that the planet possesses an orbiting dust belt system, previously unsuspected. Furthermore the satellites themselves should have surfaces resembling that of the Moon. Factors bearing on the evolution of an orbiting debris system are discussed, leading to some speculations concerning the origin and structure of the rings of Saturn.",,,Technical Report
oai:ecommons.cornell.edu:1813/36306,Developing Wind Turbine Modules for Gridlab-D,"As modern energy production techniques move away from monolithic, fossil-fuel-driven generation facilities, heuristics for the development and maintenance of distributed renewable energy systems must be developed; furthermore, antiquated heuristics undervalue renewable energy and ignore externalities.  
The objective of this project was to facilitate the advancement of new decision-making paradigms by incorporating sustainable energy sources into distribution-level simulation software.  Specifically, this report describes the development and implementation of wind-turbine add-ons to an open-source distribution-network simulation and analysis tool called Gridlab-D. The additions include single- and multiple-turbine simulation objects that estimate power generation based on climate data (an existing part of the simulation tool) and user-defined turbine parameters.          
The resulting software was verified by comparing the expected and observed power output for each turbine model.  These values were calculated externally in MATLAB and then compared with the output of Gridlab-D for the same weather information.  Retrospective software validation was carried out by using real-world turbine data from NREL, Weaver Wind, and Middelgrundens Wind Turbine Cooperative to generate model parameters.  The resulting parameters were plugged into Gridlab-D (compiled with the new models) along with observed wind data, and then the simulated output was compared to the observed wind power output.
Further work in this area could entail reproducing existing wind integration studies on the Gridlab-D platform.   This would allow researchers to directly compare studies that were originally carried out in disparate simulation environments.",,,Technical Report
oai:ecommons.cornell.edu:1813/36330,A Metrized Duality Theorem for Markov Processes,We extend our previous duality theorem for Markov processes by equipping the processes with a pseudometric and the algebras with a notion of metric diameter. We are able to show that the isomorphisms of our previous duality theorem become isometries in this quantitative setting. This opens the way to developing theories of approximate reasoning for probabilistic systems.,,,Technical Report
oai:ecommons.cornell.edu:1813/36705,Merlin: A Language for Provisioning Network Resources,"This paper presents Merlin, a new framework for managing resources in software-defined networks. With Merlin, administrators express high-level policies using programs in a declarative language. The language includes logical predicates to identify sets of packets, regular expressions to encode forwarding paths, and arithmetic formulas to specify bandwidth constraints. The Merlin compiler uses a combination of advanced techniques to translate these policies into code that can be executed on network elements including a constraint solver that allocates bandwidth using parameterizable heuristics. To facilitate dynamic adaptation, Merlin provides mechanisms for delegating control of sub-policies and for verifying that modifications made to sub-policies do not violate global constraints. Experiments demonstrate the expressiveness and scalability of Merlin on real-world topologies and applications. Overall, Merlin simplifies network administration by providing high-level abstractions for specifying network policies and scalable infrastructure for enforcing them.",,,Technical Report
oai:ecommons.cornell.edu:1813/36711,Nonstandard regular variation of the in-degree and the out-degree in the preferential attachement model,"For   the directed edge preferential attachment network growth model
studied by  Bollobas et al. (2003) and
Krapivsky and Redner (2001), we prove that the joint distribution of
in-degree and 
out-degree 
 has  jointly regularly varying
tails. 
Typically the marginal tails of the  in-degree distribution and the out-degree
distribution have different regular variation indices and so the joint
regular variation is non-standard.
Only marginal regular variation has been
previously established for this distribution in the cases where the
marginal tail indices are different.",,,Technical Report
oai:ecommons.cornell.edu:1813/36712,Tauberian Theory for   Multivariate Regularly Varying Distributions with Application to   Preferential Attachment Networks,"Abel-Tauberian theorems relate power
law behavior of distributions and their transforms. We formulate and
prove a multivariate version for non-standard regularly varying
measures on R_+^p and then apply it to 
prove that the joint distribution of  in- and out-degree in a directed edge 
preferential attachement model has  jointly regularly varying
tails.",,,Technical Report
oai:ecommons.cornell.edu:1813/38143,Completeness and Incompleteness in Nominal Kleene Algebra,"Gabbay and Ciancia (2011) presented a nominal extension of Kleene algebra as a framework for trace semantics with dynamic allocation of resources, along with a semantics consisting of nominal languages. They also provided an axiomatization that captures the behavior of the scoping operator and its interaction with the Kleene algebra operators and proved soundness over nominal languages. In this paper we show that the axioms are complete and describe the free language models.",,,Technical Report
oai:ecommons.cornell.edu:1813/39018,"HYDROGEOLOGY OF THE AREA NORTHEAST OF THE HILLVIEW ROAD LANDFILL, TOMPKINS COUNTY, NY","The Tompkins County Hillview Landfill was located on the site of an older landfill that had no containment and partially overlay permeable glacial deposits. After its use by the County it was capped and monitored in accordance with NYS Department of Conservation regulations, but there still remained the possibility that leachate could escape downward into local aquifers and from these into major aquifers underlying Cayuga Inlet Valley. Following closure, a number of test and monitoring wells were drilled around the periphery of the landfill, most of which showed little or no leachate migrating from the site.
A review of well data by the Hillview Landview Citizens’ Committee determined, however, that the DGC-2 well cluster, at the northeastern corner of the landfill, did show significantly elevated levels of volatile organic compounds and dissolved metals. Together with a presumed northward groundwater flow gradient, based on water elevations in existing wells, this information suggested the possibility of a contaminant plume escaping from the landfill.",,,Technical Report
oai:ecommons.cornell.edu:1813/39019,Numerical Validation of Fill Rate Estimation Methods for Two- and Three-Demand Class Rationing Policies with One-for-One Replenishment and General Lead Time Distributions,"In this report, we conduct numerical simulations of two- and three-demand class inventory threshold rationing systems under one-for-one replenishment policies. The performance metrics of interest are the fill rates of the high priority demand classes (the gold fill rate in the two demand
class system and the platinum and gold fill rates in the three-demand class system).
Our main interest is in the sensitivity of these fill rates to the form of the replenishment lead time probability distribution and the resulting quality of approximation methods used to estimate
these fill rates. We consider three approximation methods: what we call the single cycle approach attributed to Dekker et al and Deshpande et al, the embedded Markov chain approach of Fadigloglu and Bulut, and the continuous time Markov chain approach of Vicil and Jackson.
We confirm the superiority of the embedded Markov chain approach for the case of constant lead times but we find that the fill rates are relatively insensitive to the form of the lead time distribution and both latter approaches, the embedded Markov chain approach and the continuous time Markov chain approach, perform well over wide ranges of lead time variability. For the
three-demand class system, we demonstrate that it is possible to achieve highly differentiated fill rates by demand class and show that these fill rates can be estimated with high accuracy using the continuous time Markov chain approach, provided the fill rate of the lowest priority demand class (the silver fill rate) is not too low.",,,Technical Report
oai:ecommons.cornell.edu:1813/39108,Nominal Kleene Coalgebra,"We develop the coalgebraic theory of nominal Kleene algebra, including an alternative language-theoretic semantics, a nominal extension of the Brzozowski derivative, and a bisimulation-based decision procedure for the equational theory.",,,Technical Report
oai:ecommons.cornell.edu:1813/39288,Functional central   limit   theorem for negatively dependent heavy-tailed stationary   infinitely   divisible processes generated by conservative   flows,"We prove a functional central limit theorem for
partial sums of symmetric stationary long range dependent heavy tailed
infinitely divisible  processes with a certain type of negative
dependence. Previously only positive dependence could be treated. The
negative dependence involves cancellations of the Gaussian second
order. This 
leads to new types of  {limiting} processes involving stable random
measures, due to heavy tails, Mittag-Leffler processes, due to long
memory, and Brownian motions, due to the Gaussian second order
cancellations.",,,Technical Report
oai:ecommons.cornell.edu:1813/39910,"Genus: Making Generics Object-Oriented, Expressive, and Lightweight","The support for generic programming in modern object-oriented programming languages is awkward and lacks desirable expressive power. We introduce an expressive genericity mechanism that adds expressive power and strengthens static checking, while remaining lightweight and simple in common use cases. Like type classes and concepts, the mechanism allows existing types to model type constraints retroactively. For expressive power, we expose models as named constructs that can be defined and selected explicitly to witness constraints; in common uses of genericity, however, types implicitly witness constraints without additional programmer effort. Models are integrated into the object-oriented style, with features like model generics, model-dependent types, model enrichment, model multimethods, constraint entailment, model inheritance, and existential quantification further extending expressive power in an object-oriented setting. We introduce the new genericity features and show that common generic programming idioms, including current generic libraries, can be expressed more precisely and concisely. The static semantics of the mechanism and a proof of a key decidability property are provided.",Content file updated at author's request on 2015-04-30.,,Technical Report
oai:ecommons.cornell.edu:1813/39933,Asymptotic Normality of Degree Counts in a   Preferential Attachment Model,"Preferential attachment is a widely adopted paradigm for understanding
the dynamics of 
 social networks.  Formal statistical inference,
for instance GLM techniques, and model
verification methods will require knowing test statistics are asymptotically
normal even though node or count based 
network data is nothing like  classical data from
independently replicated experiments. We therefore study asymptotic
normality of degree counts for a sequence of growing simple undirected
preferential attachment graphs. The methods of proof rely on
identifying martingales and then exploiting the martingale central
limit theorems.",,,Technical Report
oai:ecommons.cornell.edu:1813/40138,Flow-Limited Authorization,"Because information flow control mechanisms often rely on an underlying
authorization mechanism, their security guarantees can be
subverted by weaknesses in authorization. Conversely, the security 
of authorization can be subverted by information flows that
leak information or that influence the delegation of authority among
principals.
We argue that interactions between information flow and authorization
create security vulnerabilities that have not been fully identified or
addressed in prior work.
We explore how the security of decentralized information
flow control (DIFC) is affected by
three aspects of its underlying authorization mechanism: first,
delegation of authority between principals; second, revocation of
previously delegated authority; third, information flows created by
the authorization mechanisms themselves. It is no surprise
that revocation poses challenges, but we show that even delegation
is problematic because it enables unauthorized
downgrading. Our solution is a new security model, the Flow-Limited
Authorization Model (FLAM), which offers a new, integrated approach to
authorization and information flow control. 
FLAM ensures robust authorization, a novel security condition for
authorization queries that ensures attackers cannot influence
authorization decisions or learn confidential trust relationships.
We discuss our prototype implementation and its algorithm for
proof search.",Content file updated at author's request on 2015-06-04.,,Technical Report
oai:ecommons.cornell.edu:1813/40139,"Hinman Swamp Restoration, Schuyler County, NY","The purpose of this restoration plan was to raise the water height of a lake and wetland that had been accidentally drained during road construction, and to remove two plant species, Typha and Fallopia japonica, that established while hydrologic conditions were altered. Returning the water height to an acceptable level was achieved by constructing a weir. This will also aid in eliminating the Typha stand that developed by drowning the cut cattail stocks. Fallopia japonica will be managed by injecting glyphosate into each stock once the plant has reached peak flower.",,,Technical Report
oai:ecommons.cornell.edu:1813/40156,Cornell University Library Partnership Assessment Tools,"In 2012 Cornell University Library (CUL) created two assessment tools, drawing heavily on work published in the United Kingdom. These tools are meant to be used to evaluate partnerships at multiple points in their life cycle, from potential partnership to sunset. The Pre-Partnership Check-up is for those considering whether to engage in a partnership. It is intended to guide the thinking of CUL partnership leads as they assess the value, costs, and risks of a new potential partnership. The Existing Partnership Check-up is intended to help partnership leads determine whether an existing partnership is functioning as well as it could be. The document “Partnership assessment tools: procedures” offers more detailed guidance on the use of these tools.",These tools were developed as part of the work of a Cornell University Library team: Priority Team for Goal VI.1 (Partnerships).,,Technical Report
oai:ecommons.cornell.edu:1813/40227,Hygienic Implications of  Small-Scale Composting in New York State,"Small-scale composting is an effective way to recycle organic wastes generated in the home and/or community. Little research has been done to determine potential human health risk of composts generated on a small scale. Bacteriologic testing of twenty composts from across New York State representing a wide variety of small-scale composting practices and situations was conducted. No statistical relationships were found between concentrations of total coliforms, fecal coliforms, enterococci, Escherichia coli, Salmonella spp., and Clostridium perfringens, indicating that none of these organisms could be considered a good indicator of general microbial presence. Compared with microbial standards for sewage sludge composts, these composts generally met those standards. Basic compost parameters were also analyzed. Water holding capacity ranged from50% to 246%, organic matter 9% to 80.5%, C to N ratio 10.4 to 29, Total Kjeldahl Nitrogen 0.185% to 2.419%, density 24 lb/ft3to 82 lb/ft3, solids 27.7% to 75.6%, moisture 24.4% to 72.3%, pH 6.54 to 8.65, and Solvita maturity from 3 to 7. No statistically significant relationships at the p=0.1 level were found between microbial concentrations and compost parameters. However, the relationship between pH and TKN was close to the statistical cut off, with higher pH and TKN associated with higher concentration of microbes. An unanticipated finding was that the two laboratories used for bacteriological testing employed different methodologies to look for the same bacteria which may account for some of the discrepancy in results between the labs. Researchers and composters alike need to ensure methods appropriate for compost are used. The results of this research led to a recommendation to follow good hygiene practices (such as washing hands) when working with composts. Similar practices are advisable when dealing with any soil material since these too may contain bacterial pathogens.",,,Technical Report
oai:ecommons.cornell.edu:1813/40311,Report of 2014 focus group interviews with CUES students,"Brief summary of findings from focus group interviews of CUES students, covering the three main elements of the project: spatial visualization, enhanced tutoring and the engineering summer math institute.",,,Technical Report
oai:ecommons.cornell.edu:1813/40335,Probabilistic NetKAT,"This paper develops a new language for programming software-defined networks based on a probabilistic semantics. We extend the NetKAT language with new primitives for expressing probabilistic behaviors and enrich the semantics from one based on deterministic functions to one based on measures and measurable functions on sets of packet histories. We establish fundamental properties of the semantics, prove that it is a conservative extension of the deterministic semantics, and show that it satisfies a number of natural equations. We present case studies that show how the language can be used to model a diverse collection of scenarios drawn from real-world networks.",,,Technical Report
oai:ecommons.cornell.edu:1813/40572,QUATERNARY GEOLOGY OF THE GREATER SIXMILE CREEK WATERSHED,"Discussion of the Quaternary geology of the Sixmile watershed is logically separated into two
sections: the Sixmile-Willseyville Trough and the upper Sixmile drainage, both of which can be further
divided into sub-units based on geological characteristics. The Sixmile Trough section displays evidence
for 4 glacial advances based on morphologic and/or lithologic criteria. The oldest advance is associated
with the broad U-shaped upper valley slope section and is possibly pre-Illinoian. The probable Illinoian
age of an inner glacial trough is derived from the assumed Sangamon age of a very large interglacial
gorge incised into the floor of that trough. The inner glacial trough is overlain by an array of mid-
Wisconsin (Cherrytree stade) deposits that document a glacial advance that reached into the Sixmile
Trough. An interstadial gorge was cut into the base of the Sangamon gorge, probably following the mid
Wisconsin glaciation but before the Late Wisconsin glaciation, which overrode the entire area and
overprinted most of the earlier glacial features.",,,Technical Report
oai:ecommons.cornell.edu:1813/40575,Election Verifiability: Cryptographic Definitions and an Analysis of Helios and JCJ,"Definitions of election verifiability in the computational model of
cryptography are proposed.  The definitions formalize notions of voters
verifying their own votes, auditors verifying the tally of votes, and
auditors verifying that only eligible voters vote. The Helios (Adida et
al., 2009) and JCJ (Juels et al., 2010) election schemes are analyzed
using these definitions. Helios 4.0 satisfies the definitions, but
Helios 2.0 does not because of previously known attacks. JCJ does not
satisfy the definitions because of a trust assumption it makes, but it
does satisfy a weakened definition. Two previous definitions of
verifiability (Juels et al., 2010; Cortier et al., 2014) are shown to
permit election schemes vulnerable to attacks, whereas the new
definitions prohibit those schemes.",,,Technical Report
oai:ecommons.cornell.edu:1813/40837,Multivariate Subexponential   Distributions and Their Applications,"We propose a new definition of a multivariate subexponential
 distribution. We compare this definition with the two existing
 notions of multivariate subexponentiality, and compute the
 asymptotic  behaviour of the ruin probability in the context of an
 insurance portfolio, when multivariate subexponentiality
 holds. Previously such results were available only in the case of
 multivariate regularly varying claims.",,,Technical Report
oai:ecommons.cornell.edu:1813/41188,Regular Expressions with Dynamic Name Binding,"Nominal Kleene algebra (NKA) is a formalism to specify trace languages with name generation; it extends standard regular expressions with a name binding construct. NKA has been proved complete over a natural nominal language model. Moreover, it has been shown that NKA expressions can be translated into a species of nondeterministic nominal automata, thus providing one half of a Kleene theorem. The other half is known to fail, i.e. there are nominal languages that can be accepted by a nominal automaton but are not definable in NKA. In the present work, we introduce a calculus of regular expressions with dynamic name binding. It satisfies the full Kleene theorem, i.e. it is equivalent to a natural species of nominal automata, and thus strictly more expressive than NKA. We show that containment checking in our calculus is decidable in EXPSPACE, and in fact has polynomial fixed-parameter space complexity. The known EXPSPACE bound for containment of NKA expressions follows.",,,Technical Report
oai:ecommons.cornell.edu:1813/41296,Climate Change Mitigation Potential of Ethiopia’s Productive Safety-Net Program (PSNP),"Food security programs designed to alleviate poverty, of which Ethiopia’s Productive Safety Net Program (PSNP) is a model example, are contributing also to climate-change mitigation in Sub-Saharan Africa.  PSNP’s climate-smart land management and ecosystem restoration interventions deliver climate-change mitigation principally by sequestering carbon in soils and biomass. This opens a new line of thinking and opportunity where food-security interventions that target underlying drivers of food insecurity—such as ecosystem and land degradation—become a vehicle for climate-change mitigation.

Using a combination of geospatial modeling and biophysical approaches, we here show that the mean carbon benefit of all PSNP sites was 5.7 tonnes CO2e /ha /yr.  On average, these carbon benefits were primarily due to increases in biomass (40% of total), in soil organic carbon (38%) and reduced livestock greenhouse gas emissions (22%).  Extrapolating these results to the whole of PSNP’s 600,000 ha of already-established area enclosures would imply that a total carbon benefit in the order of 3.4 million t CO2e /ha /yr has already been achieved by PSNP. This shows that food security safety net programs, despite not being initially intended to provide climate change mitigation, are nonetheless climate smart, achieving mitigation impacts comparable to the largest carbon projects currently implemented in the agriculture forestry and other land use sector globally.",,,Technical Report
oai:ecommons.cornell.edu:1813/41297,"Guide to Developing Agriculture, Forestry and Other Land-Use (AFOLU) Carbon Market Projects under Ethiopia’s Productive Safety Net Programme (PSNP)","This report outlines  the general steps required for development of a carbon project intended for sale of carbon credits via a carbon offset program, whether compliance or voluntary. While there are differences among the numerous offset programs, the major components are generally the same and any carbon project originating in the agriculture, forestry and other land use (AFOLU) sector will follow these steps. 

This report was written as a guide to development of carbon projects for Ethiopia’s Productive Safety Net Programme (PSNP), but the same process outlined here is equally applicable to any AFOLU carbon project.",,,Technical Report
oai:ecommons.cornell.edu:1813/41298,Climate Finance for Ethiopia’s Productive Safety Net Programme (PSNP): Comprehensive report on accessing climate finance and carbon markets to promote socially and environmentally sustainable public works social safety net programs,"Ethiopia’s Productive Safety Net Programme (PSNP)—recognized as a model public works safety-net program—active for over ten years, provides food and cash payments to households suffering from food insecurity in return for labor that builds public infrastructure, including the rehabilitation of degraded lands. In addition to the target benefits of food security and infrastructure development, PSNP’s participatory watershed management interventions deliver climate-change mitigation benefits by sequestering carbon in soils and biomass, and reducing emissions of greenhouse gases (GHGs) from the agricultural, forestry and other land use (AFOLU) sector. To date, Ethiopia’s PSNP has been primarily funded by development assistance from bi- and multi-lateral donors. However, new opportunities from climate finance channels could be opened up by quantifying PSNP’s climate-change mitigation impacts (frequently referred to as “carbon benefits”). 
This study, conducted within PSNP’s Climate Smart Initiative (CSI), demonstrates that PSNP’s participatory watershed management interventions usually deliver net positive carbon benefits across varied agro-ecological zones. On average, the 28 CSI sites are expected to deliver a mean carbon benefit of 5.7 tonnes of carbon dioxide-equivalent per hectare per year (tCO2e ha-1 yr-1) over a 20-year accounting period. These benefits are attributable, in order of importance, to (i) above- and below-ground biomass sequestration, (ii) soil organic carbon accumulation, (iii) reduced GHG emissions from livestock management, and (iv) abatement of other land-use related GHGs. Considering that Ethiopia’s PSNP projects cover hundreds of thousands of hectares, this study provides compelling evidence to recommend that methodologies to quantify the carbon benefits be embedded in future PSNP 4 and related interventions, to facilitate access to climate finance. But, neither compliance nor voluntary carbon-offset markets are currently in a state to support ambitious carbon projects on a scale comparable to the size of PSNP. However, ongoing negotiations within the United Nations Framework Convention on Climate Change (UNFCCC) indicate that a binding international commitment to reduce global GHG emissions is likely to be reached in the near future. And it is probable that carbon offset markets will be one of the mechanisms available for countries to meet their GHG reduction obligations. 
In consideration of the above points, we recommend that Ethiopia act now to that it is well-positioned to take advantage of anticipated carbon market opportunities as they arise. By developing one or more carbon market projects on a scale of tens to at most hundreds of thousands of hectares (a scale that is compatible with current market opportunities), PSNP’s in-country capacity will be greatly enhanced, thus positioning Ethiopia to scale up rapidly as and when the carbon finance outlook improves. 
However, it imperative to note that all carbon market projects must meet additionality requirements. This has specific implications for PSNP in that a program of work that is already planned and financed would not be eligible for carbon finance. To demonstrate additionality, any carbon project established under PSNP will need to demonstrate:
(i)	an increase in the geographic scale, 
(ii)	an improvement in implementation, or 
(iii)	an increase in the longevity of the project 
that would not be achievable without the provision of the additional support from climate finance. It is also important to consider that project development, implementation and monitoring costs can be substantial, and PSNP should address this by focusing on large contiguous areas and deploying lost-cost and streamlined methods for monitoring, reporting and verification (MRV). 

To lay the foundation for larger jurisdictional carbon accounting methodologies, necessary for cost-effective scaling up, PSNP should pursue development of standardized methods to quantify carbon benefits across extensive land areas commensurate with PSNP’s wide geographic extent. One such type of initiative already under development independently of PSNP is the Oromia Forested Landscape Program (OFLP). OFLP can serve as a proving ground for jurisdictional carbon accounting approaches related to reforestation, avoided deforestation and degradation (REDD+) in Oromia Regional State. However, for PSNP’s diverse suite of climate-smart agricultural practices, Oromia remains too large a scale for jurisdictional accounting in the near term, given the current complexities of developing GHG accounting methodologies for smallholder agricultural systems. Given that it will be several years before OFLP mitigation finance begins to flow even for REDD+ projects, PSNP should work in parallel to the OFLP to advance policy objectives of carbon finance support for PSNP in the near-term. A proposal should be developed and submitted to PSNP’s development partners to support creation of a task team within the Climate Resilient Green Economy (CRGE) unit of the Ethiopian Ministry of Agriculture (MoA) for climate finance of PSNP. 
Notwithstanding the anticipated potential of carbon markets to support PSNP, direct income from bi- and multi-lateral donors in the form of grants and loans remains the mainstay of climate finance opportunities at present. The Green Climate Fund (GCF) is an attractive emerging multilateral climate fund for Ethiopia’s PSNP public works, being the main vehicle through which future mitigation and adaptation funds are expected to flow from developed to less-developed nations under the auspices of the UNFCCC. The GCF’s six investment criteria, are all well-aligned with the objectives and scope of PSNP. In addition to bi- and multilateral climate-focused funds, the potential for demonstrated mitigation benefits of Ethiopia’s PSNP to be used in support of negotiations for international development funding should not be overlooked. This is known as results-based finance and is increasingly used by international donors to justify expenditures for climate change mitigation.",,,Technical Report
oai:ecommons.cornell.edu:1813/41301,Ethiopia’s Productive Safety Net Program (PSNP): Soil carbon and fertility impact assessment,"Ethiopia’s climate smart initiative (CSI) aims to integrate the implications of climate change into the Productive Safety Net Program (PSNP) activities, and systems to strengthen this important social safety net program, and enable Ethiopia to better manage climate risks and help its chronically food insecure population to better cope with shocks, create assets and secure livelihoods, even as the climate changes. CSI is also tasked with preparing the ground for PSNP’s sustainable public work programs to access climate finance and possibly payments from ecosystem services and benefits to spur and enable the transition towards low-carbon, climate-resilient growth and development. More robust and cost effective analysis and information on soil carbon stock changes and associate soil fertility and productivity indicators over space and time is required at multiple stages of development and implementation of PSNP’ participatory integrated watershed management projects to access climate finance.

The main objectives of this study are to: (i) assemble business as usual and project scenario baseline database on soil carbon and other soils fertility, health and productivity indicators for six chronically food insecure and vulnerable Ethiopian regional states (i.e., Afar, Amhara, Oromia, SNNPR, Somali and Tigray), where PSNP’s sustainable agricultural and environmental rehabilitation public works have been implemented widely, ii) assess the impacts of Ethiopia’s PSNP participatory integrated watershed intervention projects on soil carbon capture and sequestration, as well as on other climate smart environmental and agricultural co-benefits in light of climate change, food security and low-carbon livelihoods in these regions, and (iii) support Ethiopia’s safety net climate smart initiative to take advantage of international carbon and climate finance opportunities to support sustaining the existing activities as well as scaling-up future implementations of PSNP participatory watershed public works projects in Ethiopia.",,,Technical Report
oai:ecommons.cornell.edu:1813/41302,Climate finance  and carbon markets  for Ethiopia’s  Productive Safety  Net Programme  (PSNP): Executive Summary for  Policymakers.,"Ethiopia’s Productive Safety Net Programme (PSNP) is recognized as a model public works safety net program, which provides food and cash payments to households suffering from food insecurity in return for labor that builds public infrastructure. In addition to the target beneﬁts of food security and infrastructure development, PSNP’s participatory water-shed management interventions, while not their primary objective, are already delivering climate-change mitigation beneﬁts by sequestering carbon in soils and biomass and reducing emissions of greenhouse gases (GHGs) from the agricultural, forestry and other land use (AFOLU) sector. New opportunities for support from dedicated climate ﬁnance channels could be opened up by quantifying the climate change mitigation beneﬁts (a.k.a. carbon beneﬁts) generated by PSNP activities.

This report summarizes the potential of PSNP's food security program to contribute to climate change mitigation, and the policy actions required to access international climate finance to support this program.",,,Technical Report
oai:ecommons.cornell.edu:1813/41453,Emulation and Classification Documentation for PAFDAO Project,The following documentation has been excerpted from the appendices of the Preserving and Emulating Digital Art Objects whitepaper. This documentation outlines the results of in depth technical and forensic analysis of the artworks in the test bed collection of the Rose Goldsen Archive of New Media Art. There are two documents included here: one is a description of the artwork classifications developed by the project team and the second has step-by-step directions for configuring and running standalone emulator software to provide access to now-obsolete digital media.,The full project whitepaper can be found at: https://ecommons.cornell.edu/handle/1813/41368,,Technical Report
oai:ecommons.cornell.edu:1813/41513,A Reconfigurable Analog Substrate for Highly Efficient Maximum Flow Computation,"We present the design and analysis of a novel analog reconfigurable substrate that enables fast and efficient computation of maximum flow on directed graphs. The substrate is composed of memristors and standard analog circuit components, where the on/off states of the crossbar switches encode the graph topology. We show that upon convergence, the steady-state voltages in the circuit capture the solution to the maximum flow problem. We also propose techniques to minimize the impacts of variability and non-ideal circuit components on the solution quality, enabling practical implementation of the proposed substrate. Our performance evaluation indicates two to three orders of magnitude improvements in speed and energy efficiency compared to a standard CPU implementation. In the last part of this report, we also discuss the major limitations of the current design, and suggest promising research directions.",,,Technical Report
oai:ecommons.cornell.edu:1813/41517,"Kolmogorov Extension, Martingale Convergence, and Compositionality of Processes","We show that the Kolmogorov extension theorem and the Doob martingale convergence theorem are two aspects of a common generalization, namely a colimit-like construction in a category of Radon spaces and reversible Markov kernels. The construction provides a compositional denotational semantics for standard iteration operators in programming languages, e.g. Kleene star or while loops, as a limit of finite approximants, even in the absence of a natural partial order.",,,Technical Report
